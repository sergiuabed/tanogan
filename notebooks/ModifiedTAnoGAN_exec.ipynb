{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Mount Google Drive"
      ],
      "metadata": {
        "id": "piEBuS7wOuFz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-THl5TZeOkOM",
        "outputId": "3167911e-da63-4e4e-f479-d9efc69ac9a0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import GitHub repository"
      ],
      "metadata": {
        "id": "3O1zwxgHO04o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "if not os.path.isdir('tanogan'):\n",
        "  !git clone https://github.com/sergiuabed/tanogan\n",
        "else:\n",
        "  %cd tanogan/\n",
        "  !git pull\n",
        "  %cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4Ox58ejO4y4",
        "outputId": "ed39bf82-6d81-4049-9c63-c0606f9f09c4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'tanogan'...\n",
            "remote: Enumerating objects: 41, done.\u001b[K\n",
            "remote: Counting objects: 100% (41/41), done.\u001b[K\n",
            "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
            "remote: Total 41 (delta 18), reused 34 (delta 11), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (41/41), 8.43 KiB | 8.43 MiB/s, done.\n",
            "Resolving deltas: 100% (18/18), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "G1bV4WRPZD8S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "R9zT1LVaYpj-"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import datetime\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tanogan.data_utils.data_utils import get_df_action, get_standardizer, standardization\n",
        "from tanogan.architecture import init_generator, init_discriminator, init_encoder\n",
        "from tanogan.training import adversarial_training"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Dataset\n",
        "Load dataset locally from Google Drive"
      ],
      "metadata": {
        "id": "TlWUp5aRPmHN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.isdir('csv_20220811-20220927T082743Z-001'):\n",
        "  !cp -R /content/drive/MyDrive/ml-applications/TimeSeriesAnomalyDetection_project/csv_20220811-20220927T082743Z-001/ .\n",
        "\n",
        "path = './csv_20220811-20220927T082743Z-001/csv_20220811'\n",
        "\n",
        "# Load normal (non-anomalous) data\n",
        "filepath_csv = [os.path.join(path, f\"rec{r}_20220811_rbtc_0.1s.csv\") for r in [0, 2, 3, 4]]\n",
        "filepath_meta = [os.path.join(path, f\"rec{r}_20220811_rbtc_0.1s.metadata\") for r in [0, 2, 3, 4]]\n",
        "df_action_regular, df_regular, df_meta_regular, action2int_regular = get_df_action(filepath_csv, filepath_meta)\n",
        "\n",
        "# Load anomalous data\n",
        "filepath_csv_rec1 = [os.path.join(path, f\"rec{r}_collision_20220811_rbtc_0.1s.csv\") for r in [1]]\n",
        "filepath_csv_rec5 = [os.path.join(path, f\"rec{r}_collision_20220811_rbtc_0.1s.csv\") for r in [5]]\n",
        "\n",
        "filepath_meta_rec1 = [os.path.join(path, f\"rec{r}_collision_20220811_rbtc_0.1s.metadata\") for r in [1]]\n",
        "filepath_meta_rec5 = [os.path.join(path, f\"rec{r}_collision_20220811_rbtc_0.1s.metadata\") for r in [5]]\n",
        "\n",
        "df_action_rec1, df_rec1, df_meta_rec1, action2int_rec1 = get_df_action(filepath_csv_rec1, filepath_meta_rec1)\n",
        "df_action_rec5, df_rec5, df_meta_rec5, action2int_rec5 = get_df_action(filepath_csv_rec5, filepath_meta_rec5)"
      ],
      "metadata": {
        "id": "zCAar3jmPp47",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e22972c-cf99-4ad4-fa36-f3a7571648b4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading data.\n",
            "Found 31 different actions.\n",
            "Loading data done.\n",
            "\n",
            "Loading data.\n",
            "Found 31 different actions.\n",
            "Loading data done.\n",
            "\n",
            "Loading data.\n",
            "Found 31 different actions.\n",
            "Loading data done.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "0oiJI1snIKTg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Drop some columns and standardize the data"
      ],
      "metadata": {
        "id": "3aaXuEH3qk_y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# drop non-numerical columns\n",
        "df_regular = df_regular.drop([\"time\"], axis=1)\n",
        "df_rec1 = df_rec1.drop([\"time\"], axis=1)\n",
        "df_rec5 = df_rec5.drop([\"time\"], axis=1)\n",
        "\n",
        "# standardize data\n",
        "standardizer = get_standardizer(df_regular)\n",
        "\n",
        "df_regular_normal = standardization(df_regular, standardizer)\n",
        "df_rec1_normal = standardization(df_rec1, standardizer)\n",
        "df_rec5_normal = standardization(df_rec5, standardizer)"
      ],
      "metadata": {
        "id": "C1VGD-AEqlg7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_regular_normal.sort_index().head(2000).tail(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        },
        "id": "JLkhXvZJId6r",
        "outputId": "833963bc-1584-4d77-b3b0-2c57f1782ca7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                         machine_nameKuka Robot_apparent_power  \\\n",
              "time                                                             \n",
              "2022-08-11 13:12:04.619                              -1.078706   \n",
              "2022-08-11 13:12:04.719                              -1.078706   \n",
              "2022-08-11 13:12:04.819                              -1.078706   \n",
              "2022-08-11 13:12:04.919                              -1.078706   \n",
              "2022-08-11 13:12:05.019                              -1.078706   \n",
              "2022-08-11 13:12:05.119                              -1.078706   \n",
              "2022-08-11 13:12:05.219                              -1.078706   \n",
              "2022-08-11 13:12:05.319                              -1.078706   \n",
              "2022-08-11 13:12:05.419                              -1.078706   \n",
              "2022-08-11 13:12:05.519                              -1.078706   \n",
              "\n",
              "                         machine_nameKuka Robot_current  \\\n",
              "time                                                      \n",
              "2022-08-11 13:12:04.619                       -1.941294   \n",
              "2022-08-11 13:12:04.719                       -1.941294   \n",
              "2022-08-11 13:12:04.819                       -1.941294   \n",
              "2022-08-11 13:12:04.919                       -1.941294   \n",
              "2022-08-11 13:12:05.019                       -1.941294   \n",
              "2022-08-11 13:12:05.119                       -1.941294   \n",
              "2022-08-11 13:12:05.219                       -1.941294   \n",
              "2022-08-11 13:12:05.319                       -1.941294   \n",
              "2022-08-11 13:12:05.419                       -1.941294   \n",
              "2022-08-11 13:12:05.519                       -1.941294   \n",
              "\n",
              "                         machine_nameKuka Robot_export_reactive_energy  \\\n",
              "time                                                                     \n",
              "2022-08-11 13:12:04.619                                      -1.696565   \n",
              "2022-08-11 13:12:04.719                                      -1.696565   \n",
              "2022-08-11 13:12:04.819                                      -1.696565   \n",
              "2022-08-11 13:12:04.919                                      -1.696565   \n",
              "2022-08-11 13:12:05.019                                      -1.696565   \n",
              "2022-08-11 13:12:05.119                                      -1.696565   \n",
              "2022-08-11 13:12:05.219                                      -1.696565   \n",
              "2022-08-11 13:12:05.319                                      -1.696565   \n",
              "2022-08-11 13:12:05.419                                      -1.696565   \n",
              "2022-08-11 13:12:05.519                                      -1.696565   \n",
              "\n",
              "                         machine_nameKuka Robot_frequency  \\\n",
              "time                                                        \n",
              "2022-08-11 13:12:04.619                          0.373132   \n",
              "2022-08-11 13:12:04.719                          0.373132   \n",
              "2022-08-11 13:12:04.819                          0.373132   \n",
              "2022-08-11 13:12:04.919                          0.373132   \n",
              "2022-08-11 13:12:05.019                          0.373132   \n",
              "2022-08-11 13:12:05.119                          0.373132   \n",
              "2022-08-11 13:12:05.219                          0.373132   \n",
              "2022-08-11 13:12:05.319                         -1.284248   \n",
              "2022-08-11 13:12:05.419                         -1.284248   \n",
              "2022-08-11 13:12:05.519                         -1.284248   \n",
              "\n",
              "                         machine_nameKuka Robot_import_active_energy  \\\n",
              "time                                                                   \n",
              "2022-08-11 13:12:04.619                                    -1.716024   \n",
              "2022-08-11 13:12:04.719                                    -1.716024   \n",
              "2022-08-11 13:12:04.819                                    -1.716024   \n",
              "2022-08-11 13:12:04.919                                    -1.716024   \n",
              "2022-08-11 13:12:05.019                                    -1.716024   \n",
              "2022-08-11 13:12:05.119                                    -1.716024   \n",
              "2022-08-11 13:12:05.219                                    -1.716024   \n",
              "2022-08-11 13:12:05.319                                    -1.716024   \n",
              "2022-08-11 13:12:05.419                                    -1.716024   \n",
              "2022-08-11 13:12:05.519                                    -1.716024   \n",
              "\n",
              "                         machine_nameKuka Robot_phase_angle  \\\n",
              "time                                                          \n",
              "2022-08-11 13:12:04.619                            0.417577   \n",
              "2022-08-11 13:12:04.719                            0.417577   \n",
              "2022-08-11 13:12:04.819                            0.417577   \n",
              "2022-08-11 13:12:04.919                            0.417577   \n",
              "2022-08-11 13:12:05.019                            0.417577   \n",
              "2022-08-11 13:12:05.119                            0.417577   \n",
              "2022-08-11 13:12:05.219                            0.417577   \n",
              "2022-08-11 13:12:05.319                            0.417577   \n",
              "2022-08-11 13:12:05.419                            0.417577   \n",
              "2022-08-11 13:12:05.519                            0.417577   \n",
              "\n",
              "                         machine_nameKuka Robot_power  \\\n",
              "time                                                    \n",
              "2022-08-11 13:12:04.619                     -0.830938   \n",
              "2022-08-11 13:12:04.719                     -0.830938   \n",
              "2022-08-11 13:12:04.819                     -0.830938   \n",
              "2022-08-11 13:12:04.919                     -0.830938   \n",
              "2022-08-11 13:12:05.019                     -0.830938   \n",
              "2022-08-11 13:12:05.119                     -0.830938   \n",
              "2022-08-11 13:12:05.219                     -0.830938   \n",
              "2022-08-11 13:12:05.319                     -0.830938   \n",
              "2022-08-11 13:12:05.419                     -0.830938   \n",
              "2022-08-11 13:12:05.519                     -0.830938   \n",
              "\n",
              "                         machine_nameKuka Robot_power_factor  \\\n",
              "time                                                           \n",
              "2022-08-11 13:12:04.619                             0.443463   \n",
              "2022-08-11 13:12:04.719                             0.443463   \n",
              "2022-08-11 13:12:04.819                             0.443463   \n",
              "2022-08-11 13:12:04.919                             0.443463   \n",
              "2022-08-11 13:12:05.019                             0.443463   \n",
              "2022-08-11 13:12:05.119                             0.443463   \n",
              "2022-08-11 13:12:05.219                             0.443463   \n",
              "2022-08-11 13:12:05.319                             0.443463   \n",
              "2022-08-11 13:12:05.419                             0.443463   \n",
              "2022-08-11 13:12:05.519                             0.443463   \n",
              "\n",
              "                         machine_nameKuka Robot_reactive_power  \\\n",
              "time                                                             \n",
              "2022-08-11 13:12:04.619                               2.486926   \n",
              "2022-08-11 13:12:04.719                               2.486926   \n",
              "2022-08-11 13:12:04.819                               2.486926   \n",
              "2022-08-11 13:12:04.919                               2.486926   \n",
              "2022-08-11 13:12:05.019                               2.486926   \n",
              "2022-08-11 13:12:05.119                               2.486926   \n",
              "2022-08-11 13:12:05.219                               2.486926   \n",
              "2022-08-11 13:12:05.319                               2.486926   \n",
              "2022-08-11 13:12:05.419                               2.486926   \n",
              "2022-08-11 13:12:05.519                               2.486926   \n",
              "\n",
              "                         machine_nameKuka Robot_voltage  ...  \\\n",
              "time                                                     ...   \n",
              "2022-08-11 13:12:04.619                       -0.435902  ...   \n",
              "2022-08-11 13:12:04.719                       -0.435902  ...   \n",
              "2022-08-11 13:12:04.819                       -0.435902  ...   \n",
              "2022-08-11 13:12:04.919                       -0.435902  ...   \n",
              "2022-08-11 13:12:05.019                       -0.435902  ...   \n",
              "2022-08-11 13:12:05.119                       -0.435902  ...   \n",
              "2022-08-11 13:12:05.219                       -0.435902  ...   \n",
              "2022-08-11 13:12:05.319                       -0.435902  ...   \n",
              "2022-08-11 13:12:05.419                       -0.435902  ...   \n",
              "2022-08-11 13:12:05.519                       -0.435902  ...   \n",
              "\n",
              "                         sensor_id4_GyroZ  sensor_id5_AccX  sensor_id5_AccY  \\\n",
              "time                                                                          \n",
              "2022-08-11 13:12:04.619         -0.700328        -0.251223         0.095296   \n",
              "2022-08-11 13:12:04.719         -0.700328        -0.251424         0.095296   \n",
              "2022-08-11 13:12:04.819         -0.700328        -0.251223         0.095059   \n",
              "2022-08-11 13:12:04.919         -0.700328        -0.251223         0.095059   \n",
              "2022-08-11 13:12:05.019          1.442750        -0.253036         0.094585   \n",
              "2022-08-11 13:12:05.119         -0.700328        -0.250820         0.095296   \n",
              "2022-08-11 13:12:05.219         -0.700328        -0.252230         0.094822   \n",
              "2022-08-11 13:12:05.319         -0.700328        -0.250820         0.094822   \n",
              "2022-08-11 13:12:05.419         -0.690812         6.040356         0.076572   \n",
              "2022-08-11 13:12:05.519         -0.672038         6.035723         0.113309   \n",
              "\n",
              "                         sensor_id5_AccZ  sensor_id5_AngX  sensor_id5_AngY  \\\n",
              "time                                                                         \n",
              "2022-08-11 13:12:04.619         0.078541        -0.176864         1.093616   \n",
              "2022-08-11 13:12:04.719         0.078036        -0.176864         1.093995   \n",
              "2022-08-11 13:12:04.819         0.078288        -0.176263         1.094373   \n",
              "2022-08-11 13:12:04.919         0.078036        -0.176263         1.094373   \n",
              "2022-08-11 13:12:05.019         0.077783        -0.176263         1.094751   \n",
              "2022-08-11 13:12:05.119         0.078794        -0.176864         1.094751   \n",
              "2022-08-11 13:12:05.219         0.076771        -0.176864         1.095130   \n",
              "2022-08-11 13:12:05.319         0.078288        -0.176263         1.095130   \n",
              "2022-08-11 13:12:05.419         0.126338        -0.164252         1.079615   \n",
              "2022-08-11 13:12:05.519         0.108383        -0.116809         0.977065   \n",
              "\n",
              "                         sensor_id5_AngZ  sensor_id5_GyroX  sensor_id5_GyroY  \\\n",
              "time                                                                           \n",
              "2022-08-11 13:12:04.619         0.517093          1.236690         -0.728666   \n",
              "2022-08-11 13:12:04.719         0.516707         -0.816528         -0.728697   \n",
              "2022-08-11 13:12:04.819         0.516321         -0.816497         -0.728634   \n",
              "2022-08-11 13:12:04.919         0.516031         -0.816528         -0.728666   \n",
              "2022-08-11 13:12:05.019         0.515741          1.236628         -0.728697   \n",
              "2022-08-11 13:12:05.119         0.515548         -0.816558         -0.728697   \n",
              "2022-08-11 13:12:05.219         0.515259         -0.816558         -0.728697   \n",
              "2022-08-11 13:12:05.319         0.514969         -0.816558         -0.728697   \n",
              "2022-08-11 13:12:05.419         0.513618         -0.815619         -0.722438   \n",
              "2022-08-11 13:12:05.519         0.510239         -0.813458         -0.710431   \n",
              "\n",
              "                         sensor_id5_GyroZ  \n",
              "time                                       \n",
              "2022-08-11 13:12:04.619         -0.784789  \n",
              "2022-08-11 13:12:04.719         -0.784789  \n",
              "2022-08-11 13:12:04.819         -0.784789  \n",
              "2022-08-11 13:12:04.919         -0.784789  \n",
              "2022-08-11 13:12:05.019         -0.784789  \n",
              "2022-08-11 13:12:05.119         -0.784789  \n",
              "2022-08-11 13:12:05.219         -0.784789  \n",
              "2022-08-11 13:12:05.319         -0.784789  \n",
              "2022-08-11 13:12:05.419          1.289187  \n",
              "2022-08-11 13:12:05.519          1.276633  \n",
              "\n",
              "[10 rows x 55 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3179c635-afc6-4d3f-b93b-76a3455462a2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>machine_nameKuka Robot_apparent_power</th>\n",
              "      <th>machine_nameKuka Robot_current</th>\n",
              "      <th>machine_nameKuka Robot_export_reactive_energy</th>\n",
              "      <th>machine_nameKuka Robot_frequency</th>\n",
              "      <th>machine_nameKuka Robot_import_active_energy</th>\n",
              "      <th>machine_nameKuka Robot_phase_angle</th>\n",
              "      <th>machine_nameKuka Robot_power</th>\n",
              "      <th>machine_nameKuka Robot_power_factor</th>\n",
              "      <th>machine_nameKuka Robot_reactive_power</th>\n",
              "      <th>machine_nameKuka Robot_voltage</th>\n",
              "      <th>...</th>\n",
              "      <th>sensor_id4_GyroZ</th>\n",
              "      <th>sensor_id5_AccX</th>\n",
              "      <th>sensor_id5_AccY</th>\n",
              "      <th>sensor_id5_AccZ</th>\n",
              "      <th>sensor_id5_AngX</th>\n",
              "      <th>sensor_id5_AngY</th>\n",
              "      <th>sensor_id5_AngZ</th>\n",
              "      <th>sensor_id5_GyroX</th>\n",
              "      <th>sensor_id5_GyroY</th>\n",
              "      <th>sensor_id5_GyroZ</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>time</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2022-08-11 13:12:04.619</th>\n",
              "      <td>-1.078706</td>\n",
              "      <td>-1.941294</td>\n",
              "      <td>-1.696565</td>\n",
              "      <td>0.373132</td>\n",
              "      <td>-1.716024</td>\n",
              "      <td>0.417577</td>\n",
              "      <td>-0.830938</td>\n",
              "      <td>0.443463</td>\n",
              "      <td>2.486926</td>\n",
              "      <td>-0.435902</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.700328</td>\n",
              "      <td>-0.251223</td>\n",
              "      <td>0.095296</td>\n",
              "      <td>0.078541</td>\n",
              "      <td>-0.176864</td>\n",
              "      <td>1.093616</td>\n",
              "      <td>0.517093</td>\n",
              "      <td>1.236690</td>\n",
              "      <td>-0.728666</td>\n",
              "      <td>-0.784789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-08-11 13:12:04.719</th>\n",
              "      <td>-1.078706</td>\n",
              "      <td>-1.941294</td>\n",
              "      <td>-1.696565</td>\n",
              "      <td>0.373132</td>\n",
              "      <td>-1.716024</td>\n",
              "      <td>0.417577</td>\n",
              "      <td>-0.830938</td>\n",
              "      <td>0.443463</td>\n",
              "      <td>2.486926</td>\n",
              "      <td>-0.435902</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.700328</td>\n",
              "      <td>-0.251424</td>\n",
              "      <td>0.095296</td>\n",
              "      <td>0.078036</td>\n",
              "      <td>-0.176864</td>\n",
              "      <td>1.093995</td>\n",
              "      <td>0.516707</td>\n",
              "      <td>-0.816528</td>\n",
              "      <td>-0.728697</td>\n",
              "      <td>-0.784789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-08-11 13:12:04.819</th>\n",
              "      <td>-1.078706</td>\n",
              "      <td>-1.941294</td>\n",
              "      <td>-1.696565</td>\n",
              "      <td>0.373132</td>\n",
              "      <td>-1.716024</td>\n",
              "      <td>0.417577</td>\n",
              "      <td>-0.830938</td>\n",
              "      <td>0.443463</td>\n",
              "      <td>2.486926</td>\n",
              "      <td>-0.435902</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.700328</td>\n",
              "      <td>-0.251223</td>\n",
              "      <td>0.095059</td>\n",
              "      <td>0.078288</td>\n",
              "      <td>-0.176263</td>\n",
              "      <td>1.094373</td>\n",
              "      <td>0.516321</td>\n",
              "      <td>-0.816497</td>\n",
              "      <td>-0.728634</td>\n",
              "      <td>-0.784789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-08-11 13:12:04.919</th>\n",
              "      <td>-1.078706</td>\n",
              "      <td>-1.941294</td>\n",
              "      <td>-1.696565</td>\n",
              "      <td>0.373132</td>\n",
              "      <td>-1.716024</td>\n",
              "      <td>0.417577</td>\n",
              "      <td>-0.830938</td>\n",
              "      <td>0.443463</td>\n",
              "      <td>2.486926</td>\n",
              "      <td>-0.435902</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.700328</td>\n",
              "      <td>-0.251223</td>\n",
              "      <td>0.095059</td>\n",
              "      <td>0.078036</td>\n",
              "      <td>-0.176263</td>\n",
              "      <td>1.094373</td>\n",
              "      <td>0.516031</td>\n",
              "      <td>-0.816528</td>\n",
              "      <td>-0.728666</td>\n",
              "      <td>-0.784789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-08-11 13:12:05.019</th>\n",
              "      <td>-1.078706</td>\n",
              "      <td>-1.941294</td>\n",
              "      <td>-1.696565</td>\n",
              "      <td>0.373132</td>\n",
              "      <td>-1.716024</td>\n",
              "      <td>0.417577</td>\n",
              "      <td>-0.830938</td>\n",
              "      <td>0.443463</td>\n",
              "      <td>2.486926</td>\n",
              "      <td>-0.435902</td>\n",
              "      <td>...</td>\n",
              "      <td>1.442750</td>\n",
              "      <td>-0.253036</td>\n",
              "      <td>0.094585</td>\n",
              "      <td>0.077783</td>\n",
              "      <td>-0.176263</td>\n",
              "      <td>1.094751</td>\n",
              "      <td>0.515741</td>\n",
              "      <td>1.236628</td>\n",
              "      <td>-0.728697</td>\n",
              "      <td>-0.784789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-08-11 13:12:05.119</th>\n",
              "      <td>-1.078706</td>\n",
              "      <td>-1.941294</td>\n",
              "      <td>-1.696565</td>\n",
              "      <td>0.373132</td>\n",
              "      <td>-1.716024</td>\n",
              "      <td>0.417577</td>\n",
              "      <td>-0.830938</td>\n",
              "      <td>0.443463</td>\n",
              "      <td>2.486926</td>\n",
              "      <td>-0.435902</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.700328</td>\n",
              "      <td>-0.250820</td>\n",
              "      <td>0.095296</td>\n",
              "      <td>0.078794</td>\n",
              "      <td>-0.176864</td>\n",
              "      <td>1.094751</td>\n",
              "      <td>0.515548</td>\n",
              "      <td>-0.816558</td>\n",
              "      <td>-0.728697</td>\n",
              "      <td>-0.784789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-08-11 13:12:05.219</th>\n",
              "      <td>-1.078706</td>\n",
              "      <td>-1.941294</td>\n",
              "      <td>-1.696565</td>\n",
              "      <td>0.373132</td>\n",
              "      <td>-1.716024</td>\n",
              "      <td>0.417577</td>\n",
              "      <td>-0.830938</td>\n",
              "      <td>0.443463</td>\n",
              "      <td>2.486926</td>\n",
              "      <td>-0.435902</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.700328</td>\n",
              "      <td>-0.252230</td>\n",
              "      <td>0.094822</td>\n",
              "      <td>0.076771</td>\n",
              "      <td>-0.176864</td>\n",
              "      <td>1.095130</td>\n",
              "      <td>0.515259</td>\n",
              "      <td>-0.816558</td>\n",
              "      <td>-0.728697</td>\n",
              "      <td>-0.784789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-08-11 13:12:05.319</th>\n",
              "      <td>-1.078706</td>\n",
              "      <td>-1.941294</td>\n",
              "      <td>-1.696565</td>\n",
              "      <td>-1.284248</td>\n",
              "      <td>-1.716024</td>\n",
              "      <td>0.417577</td>\n",
              "      <td>-0.830938</td>\n",
              "      <td>0.443463</td>\n",
              "      <td>2.486926</td>\n",
              "      <td>-0.435902</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.700328</td>\n",
              "      <td>-0.250820</td>\n",
              "      <td>0.094822</td>\n",
              "      <td>0.078288</td>\n",
              "      <td>-0.176263</td>\n",
              "      <td>1.095130</td>\n",
              "      <td>0.514969</td>\n",
              "      <td>-0.816558</td>\n",
              "      <td>-0.728697</td>\n",
              "      <td>-0.784789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-08-11 13:12:05.419</th>\n",
              "      <td>-1.078706</td>\n",
              "      <td>-1.941294</td>\n",
              "      <td>-1.696565</td>\n",
              "      <td>-1.284248</td>\n",
              "      <td>-1.716024</td>\n",
              "      <td>0.417577</td>\n",
              "      <td>-0.830938</td>\n",
              "      <td>0.443463</td>\n",
              "      <td>2.486926</td>\n",
              "      <td>-0.435902</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.690812</td>\n",
              "      <td>6.040356</td>\n",
              "      <td>0.076572</td>\n",
              "      <td>0.126338</td>\n",
              "      <td>-0.164252</td>\n",
              "      <td>1.079615</td>\n",
              "      <td>0.513618</td>\n",
              "      <td>-0.815619</td>\n",
              "      <td>-0.722438</td>\n",
              "      <td>1.289187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-08-11 13:12:05.519</th>\n",
              "      <td>-1.078706</td>\n",
              "      <td>-1.941294</td>\n",
              "      <td>-1.696565</td>\n",
              "      <td>-1.284248</td>\n",
              "      <td>-1.716024</td>\n",
              "      <td>0.417577</td>\n",
              "      <td>-0.830938</td>\n",
              "      <td>0.443463</td>\n",
              "      <td>2.486926</td>\n",
              "      <td>-0.435902</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.672038</td>\n",
              "      <td>6.035723</td>\n",
              "      <td>0.113309</td>\n",
              "      <td>0.108383</td>\n",
              "      <td>-0.116809</td>\n",
              "      <td>0.977065</td>\n",
              "      <td>0.510239</td>\n",
              "      <td>-0.813458</td>\n",
              "      <td>-0.710431</td>\n",
              "      <td>1.276633</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows × 55 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3179c635-afc6-4d3f-b93b-76a3455462a2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3179c635-afc6-4d3f-b93b-76a3455462a2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3179c635-afc6-4d3f-b93b-76a3455462a2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2774f4fd-779b-423f-9d3c-56e134fd3ec9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2774f4fd-779b-423f-9d3c-56e134fd3ec9')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2774f4fd-779b-423f-9d3c-56e134fd3ec9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read \"20220811_collisions_timestamp.xlsx\" and create a dataframe with a row for each anomalous time interval"
      ],
      "metadata": {
        "id": "Jltn2M5SCvKP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_anomalous_intervals(path, sheet_names):\n",
        "    # outputs dataframe with:\n",
        "    #   - index: 0, 1, 2, 3, ...\n",
        "    #   - columns: \"start_timestamp\", \"end_timestamp\"\n",
        "    # Each row in this dataframe corresponds to a certain anomaly interval\n",
        "    df_list = []\n",
        "    begin_index = 0\n",
        "    for sn in sheet_names:\n",
        "        rec_collision_timestamps_excel = pd.read_excel(path, sheet_name=sn)\n",
        "\n",
        "        starts = rec_collision_timestamps_excel.iloc[::2]\n",
        "        starts.index = [i + begin_index for i in range(len(starts.index))]\n",
        "        starts = starts.rename(columns={\"Timestamp\": \"start_timestamp\"})\n",
        "        starts['start_timestamp'] = starts['start_timestamp'] - pd.Timedelta(hours=2) # anticipate 2 hours mismatch\n",
        "\n",
        "        stops = rec_collision_timestamps_excel.iloc[1::2]\n",
        "        stops.index = [i + begin_index for i in range(len(stops.index))]\n",
        "        stops = stops.rename(columns={\"Timestamp\": \"end_timestamp\"})\n",
        "        stops['end_timestamp'] = stops['end_timestamp'] - pd.Timedelta(hours=2) # anticipate 2 hours mismatch\n",
        "\n",
        "        anomalous_intervals = pd.concat([starts, stops], axis=1)\n",
        "\n",
        "        anomalous_intervals.drop('Inizio/fine', axis=1, inplace=True)\n",
        "        df_list.append(anomalous_intervals)\n",
        "\n",
        "        begin_index += len(stops.index)\n",
        "\n",
        "    all_anomalous_intervals = pd.concat(df_list)\n",
        "    return all_anomalous_intervals\n",
        "\n",
        "anomalous_intervals = get_anomalous_intervals(\"./csv_20220811-20220927T082743Z-001/csv_20220811/20220811_collisions_timestamp.xlsx\", [\"rec1\", \"rec5\"])\n",
        "\n",
        "anomalous_intervals"
      ],
      "metadata": {
        "id": "z9bsUKtdyxlz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "61ba54a4-cc89-4e63-c29f-898102093ec4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            start_timestamp           end_timestamp\n",
              "0   2022-08-11 14:02:17.450 2022-08-11 14:02:21.460\n",
              "1   2022-08-11 14:02:28.320 2022-08-11 14:02:31.420\n",
              "2   2022-08-11 14:02:45.770 2022-08-11 14:02:49.660\n",
              "3   2022-08-11 14:02:57.490 2022-08-11 14:02:59.390\n",
              "4   2022-08-11 14:03:56.960 2022-08-11 14:03:58.700\n",
              "..                      ...                     ...\n",
              "102 2022-08-11 17:01:56.990 2022-08-11 17:02:01.160\n",
              "103 2022-08-11 17:02:11.180 2022-08-11 17:02:15.340\n",
              "104 2022-08-11 17:02:58.080 2022-08-11 17:03:02.080\n",
              "105 2022-08-11 17:03:44.090 2022-08-11 17:03:48.150\n",
              "106 2022-08-11 17:04:10.600 2022-08-11 17:04:14.610\n",
              "\n",
              "[107 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-30588358-0e1d-4402-a150-8a9fd95fb13b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>start_timestamp</th>\n",
              "      <th>end_timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2022-08-11 14:02:17.450</td>\n",
              "      <td>2022-08-11 14:02:21.460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2022-08-11 14:02:28.320</td>\n",
              "      <td>2022-08-11 14:02:31.420</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2022-08-11 14:02:45.770</td>\n",
              "      <td>2022-08-11 14:02:49.660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2022-08-11 14:02:57.490</td>\n",
              "      <td>2022-08-11 14:02:59.390</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2022-08-11 14:03:56.960</td>\n",
              "      <td>2022-08-11 14:03:58.700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>2022-08-11 17:01:56.990</td>\n",
              "      <td>2022-08-11 17:02:01.160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>2022-08-11 17:02:11.180</td>\n",
              "      <td>2022-08-11 17:02:15.340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>2022-08-11 17:02:58.080</td>\n",
              "      <td>2022-08-11 17:03:02.080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105</th>\n",
              "      <td>2022-08-11 17:03:44.090</td>\n",
              "      <td>2022-08-11 17:03:48.150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>2022-08-11 17:04:10.600</td>\n",
              "      <td>2022-08-11 17:04:14.610</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>107 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-30588358-0e1d-4402-a150-8a9fd95fb13b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-30588358-0e1d-4402-a150-8a9fd95fb13b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-30588358-0e1d-4402-a150-8a9fd95fb13b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4e82eccb-a253-403a-92e6-2395d126bac5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4e82eccb-a253-403a-92e6-2395d126bac5')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4e82eccb-a253-403a-92e6-2395d126bac5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def label_timestamps(df, anomalous_intervals):\n",
        "\n",
        "  cumulative_flag = np.array([False for d in df.index])\n",
        "\n",
        "  for interval in anomalous_intervals.values:\n",
        "    flag = np.array([(interval[0] < d and interval[1] > d) for d in df.index])\n",
        "    cumulative_flag = cumulative_flag + flag  # element-wise OR operation\n",
        "\n",
        "  df_label = df.copy()\n",
        "  df_label.insert(0, \"anomaly\", [0 for _ in range(len(df.index))], True)\n",
        "  df_label.loc[cumulative_flag.tolist(), \"anomaly\"] = 1\n",
        "\n",
        "  return df_label\n",
        "\n",
        "df_regular_labelled = label_timestamps(df_regular_normal, anomalous_intervals)\n",
        "df_rec1_labelled = label_timestamps(df_rec1_normal, anomalous_intervals)\n",
        "df_rec5_labelled = label_timestamps(df_rec5_normal, anomalous_intervals)\n",
        "\n",
        "df_rec1_labelled.loc[df_rec1_labelled['anomaly']==0]"
      ],
      "metadata": {
        "id": "dyVlXEQet1pZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        },
        "outputId": "c242417e-4726-40b4-9ce7-2698e49c1fec"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                         anomaly  machine_nameKuka Robot_apparent_power  \\\n",
              "time                                                                      \n",
              "2022-08-11 14:01:34.644        0                              -1.659778   \n",
              "2022-08-11 14:01:34.744        0                              -1.659778   \n",
              "2022-08-11 14:01:34.844        0                              -1.659778   \n",
              "2022-08-11 14:01:34.944        0                              -1.659778   \n",
              "2022-08-11 14:01:35.044        0                              -1.659778   \n",
              "...                          ...                                    ...   \n",
              "2022-08-11 14:30:30.744        0                               0.967267   \n",
              "2022-08-11 14:30:30.844        0                               0.967267   \n",
              "2022-08-11 14:30:30.944        0                               0.967267   \n",
              "2022-08-11 14:30:31.044        0                               0.967267   \n",
              "2022-08-11 14:30:31.144        0                               0.967267   \n",
              "\n",
              "                         machine_nameKuka Robot_current  \\\n",
              "time                                                      \n",
              "2022-08-11 14:01:34.644                       -1.249082   \n",
              "2022-08-11 14:01:34.744                       -1.249082   \n",
              "2022-08-11 14:01:34.844                       -1.249082   \n",
              "2022-08-11 14:01:34.944                       -1.249082   \n",
              "2022-08-11 14:01:35.044                       -1.249082   \n",
              "...                                                 ...   \n",
              "2022-08-11 14:30:30.744                        1.377899   \n",
              "2022-08-11 14:30:30.844                        1.377899   \n",
              "2022-08-11 14:30:30.944                        1.377899   \n",
              "2022-08-11 14:30:31.044                        1.377899   \n",
              "2022-08-11 14:30:31.144                        1.377899   \n",
              "\n",
              "                         machine_nameKuka Robot_export_reactive_energy  \\\n",
              "time                                                                     \n",
              "2022-08-11 14:01:34.644                                      -0.902503   \n",
              "2022-08-11 14:01:34.744                                      -0.902503   \n",
              "2022-08-11 14:01:34.844                                      -0.902503   \n",
              "2022-08-11 14:01:34.944                                      -0.902503   \n",
              "2022-08-11 14:01:35.044                                      -0.902503   \n",
              "...                                                                ...   \n",
              "2022-08-11 14:30:30.744                                      -0.442150   \n",
              "2022-08-11 14:30:30.844                                      -0.442150   \n",
              "2022-08-11 14:30:30.944                                      -0.442150   \n",
              "2022-08-11 14:30:31.044                                      -0.442150   \n",
              "2022-08-11 14:30:31.144                                      -0.442150   \n",
              "\n",
              "                         machine_nameKuka Robot_frequency  \\\n",
              "time                                                        \n",
              "2022-08-11 14:01:34.644                          0.373132   \n",
              "2022-08-11 14:01:34.744                          0.373132   \n",
              "2022-08-11 14:01:34.844                          0.373132   \n",
              "2022-08-11 14:01:34.944                          0.373132   \n",
              "2022-08-11 14:01:35.044                          0.373132   \n",
              "...                                                   ...   \n",
              "2022-08-11 14:30:30.744                          0.373132   \n",
              "2022-08-11 14:30:30.844                          0.373132   \n",
              "2022-08-11 14:30:30.944                          0.373132   \n",
              "2022-08-11 14:30:31.044                          0.373132   \n",
              "2022-08-11 14:30:31.144                          0.373132   \n",
              "\n",
              "                         machine_nameKuka Robot_import_active_energy  \\\n",
              "time                                                                   \n",
              "2022-08-11 14:01:34.644                                    -0.903120   \n",
              "2022-08-11 14:01:34.744                                    -0.903120   \n",
              "2022-08-11 14:01:34.844                                    -0.903120   \n",
              "2022-08-11 14:01:34.944                                    -0.903120   \n",
              "2022-08-11 14:01:35.044                                    -0.903120   \n",
              "...                                                              ...   \n",
              "2022-08-11 14:30:30.744                                    -0.428394   \n",
              "2022-08-11 14:30:30.844                                    -0.428394   \n",
              "2022-08-11 14:30:30.944                                    -0.428394   \n",
              "2022-08-11 14:30:31.044                                    -0.428394   \n",
              "2022-08-11 14:30:31.144                                    -0.428394   \n",
              "\n",
              "                         machine_nameKuka Robot_phase_angle  \\\n",
              "time                                                          \n",
              "2022-08-11 14:01:34.644                           -2.896849   \n",
              "2022-08-11 14:01:34.744                           -2.896849   \n",
              "2022-08-11 14:01:34.844                           -2.896849   \n",
              "2022-08-11 14:01:34.944                           -2.896849   \n",
              "2022-08-11 14:01:35.044                           -2.896849   \n",
              "...                                                     ...   \n",
              "2022-08-11 14:30:30.744                            0.596178   \n",
              "2022-08-11 14:30:30.844                            0.596178   \n",
              "2022-08-11 14:30:30.944                            0.596178   \n",
              "2022-08-11 14:30:31.044                            0.596178   \n",
              "2022-08-11 14:30:31.144                            0.596178   \n",
              "\n",
              "                         machine_nameKuka Robot_power  \\\n",
              "time                                                    \n",
              "2022-08-11 14:01:34.644                     -1.879994   \n",
              "2022-08-11 14:01:34.744                     -1.879994   \n",
              "2022-08-11 14:01:34.844                     -1.879994   \n",
              "2022-08-11 14:01:34.944                     -1.879994   \n",
              "2022-08-11 14:01:35.044                     -1.879994   \n",
              "...                                               ...   \n",
              "2022-08-11 14:30:30.744                      0.911731   \n",
              "2022-08-11 14:30:30.844                      0.911731   \n",
              "2022-08-11 14:30:30.944                      0.911731   \n",
              "2022-08-11 14:30:31.044                      0.911731   \n",
              "2022-08-11 14:30:31.144                      0.911731   \n",
              "\n",
              "                         machine_nameKuka Robot_power_factor  \\\n",
              "time                                                           \n",
              "2022-08-11 14:01:34.644                            -3.157673   \n",
              "2022-08-11 14:01:34.744                            -3.157673   \n",
              "2022-08-11 14:01:34.844                            -3.157673   \n",
              "2022-08-11 14:01:34.944                            -3.157673   \n",
              "2022-08-11 14:01:35.044                            -3.157673   \n",
              "...                                                      ...   \n",
              "2022-08-11 14:30:30.744                             0.607155   \n",
              "2022-08-11 14:30:30.844                             0.607155   \n",
              "2022-08-11 14:30:30.944                             0.607155   \n",
              "2022-08-11 14:30:31.044                             0.607155   \n",
              "2022-08-11 14:30:31.144                             0.607155   \n",
              "\n",
              "                         machine_nameKuka Robot_reactive_power  ...  \\\n",
              "time                                                            ...   \n",
              "2022-08-11 14:01:34.644                               0.130060  ...   \n",
              "2022-08-11 14:01:34.744                               0.130060  ...   \n",
              "2022-08-11 14:01:34.844                               0.130060  ...   \n",
              "2022-08-11 14:01:34.944                               0.130060  ...   \n",
              "2022-08-11 14:01:35.044                               0.130060  ...   \n",
              "...                                                        ...  ...   \n",
              "2022-08-11 14:30:30.744                              -1.151908  ...   \n",
              "2022-08-11 14:30:30.844                              -1.151908  ...   \n",
              "2022-08-11 14:30:30.944                              -1.151908  ...   \n",
              "2022-08-11 14:30:31.044                              -1.151908  ...   \n",
              "2022-08-11 14:30:31.144                              -1.151908  ...   \n",
              "\n",
              "                         sensor_id4_GyroZ  sensor_id5_AccX  sensor_id5_AccY  \\\n",
              "time                                                                          \n",
              "2022-08-11 14:01:34.644         -0.700328        -0.250820         0.095296   \n",
              "2022-08-11 14:01:34.744         -0.700328        -0.251021         0.095296   \n",
              "2022-08-11 14:01:34.844         -0.700328        -0.250820         0.095059   \n",
              "2022-08-11 14:01:34.944         -0.700328        -0.251424         0.095770   \n",
              "2022-08-11 14:01:35.044         -0.700328        -0.251021         0.095296   \n",
              "...                                   ...              ...              ...   \n",
              "2022-08-11 14:30:30.744          1.422573         6.045191         0.125160   \n",
              "2022-08-11 14:30:30.844          1.424142        -0.257468         0.109043   \n",
              "2022-08-11 14:30:30.944          1.436010        -0.233696         0.079653   \n",
              "2022-08-11 14:30:31.044         -0.699771        -0.252230         0.092215   \n",
              "2022-08-11 14:30:31.144          1.442718        -0.250820         0.095059   \n",
              "\n",
              "                         sensor_id5_AccZ  sensor_id5_AngX  sensor_id5_AngY  \\\n",
              "time                                                                         \n",
              "2022-08-11 14:01:34.644         0.078288        -0.175062         1.097400   \n",
              "2022-08-11 14:01:34.744         0.078288        -0.175062         1.097400   \n",
              "2022-08-11 14:01:34.844         0.078288        -0.175062         1.097400   \n",
              "2022-08-11 14:01:34.944         0.078036        -0.175062         1.097400   \n",
              "2022-08-11 14:01:35.044         0.078036        -0.175062         1.097400   \n",
              "...                                  ...              ...              ...   \n",
              "2022-08-11 14:30:30.744         0.078036        -0.057356         0.761747   \n",
              "2022-08-11 14:30:30.844         0.163513        -0.175062         0.964199   \n",
              "2022-08-11 14:30:30.944         0.121027        -0.205690         1.047071   \n",
              "2022-08-11 14:30:31.044         0.072472        -0.184070         1.061829   \n",
              "2022-08-11 14:30:31.144         0.078036        -0.173261         1.063343   \n",
              "\n",
              "                         sensor_id5_AngZ  sensor_id5_GyroX  sensor_id5_GyroY  \\\n",
              "time                                                                           \n",
              "2022-08-11 14:01:34.644         1.480228         -0.816558         -0.728697   \n",
              "2022-08-11 14:01:34.744         1.480228         -0.816558         -0.728697   \n",
              "2022-08-11 14:01:34.844         1.480228         -0.816558         -0.728697   \n",
              "2022-08-11 14:01:34.944         1.480228         -0.816558         -0.728697   \n",
              "2022-08-11 14:01:35.044         1.480228         -0.816558         -0.728697   \n",
              "...                                  ...               ...               ...   \n",
              "2022-08-11 14:30:30.744         1.586996          1.225725          1.358975   \n",
              "2022-08-11 14:30:30.844         1.603697          1.230612          1.364754   \n",
              "2022-08-11 14:30:30.944         1.614895          1.233559          1.376755   \n",
              "2022-08-11 14:30:31.044         1.617019          1.236531         -0.728375   \n",
              "2022-08-11 14:30:31.144         1.616536         -0.816558          1.385854   \n",
              "\n",
              "                         sensor_id5_GyroZ  \n",
              "time                                       \n",
              "2022-08-11 14:01:34.644         -0.784789  \n",
              "2022-08-11 14:01:34.744         -0.784789  \n",
              "2022-08-11 14:01:34.844         -0.784789  \n",
              "2022-08-11 14:01:34.944         -0.784789  \n",
              "2022-08-11 14:01:35.044         -0.784789  \n",
              "...                                   ...  \n",
              "2022-08-11 14:30:30.744         -0.767006  \n",
              "2022-08-11 14:30:30.844         -0.776864  \n",
              "2022-08-11 14:30:30.944         -0.783076  \n",
              "2022-08-11 14:30:31.044          1.292578  \n",
              "2022-08-11 14:30:31.144         -0.784789  \n",
              "\n",
              "[16235 rows x 56 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5fbabe66-4db9-4d78-8e5b-af47042c4088\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>anomaly</th>\n",
              "      <th>machine_nameKuka Robot_apparent_power</th>\n",
              "      <th>machine_nameKuka Robot_current</th>\n",
              "      <th>machine_nameKuka Robot_export_reactive_energy</th>\n",
              "      <th>machine_nameKuka Robot_frequency</th>\n",
              "      <th>machine_nameKuka Robot_import_active_energy</th>\n",
              "      <th>machine_nameKuka Robot_phase_angle</th>\n",
              "      <th>machine_nameKuka Robot_power</th>\n",
              "      <th>machine_nameKuka Robot_power_factor</th>\n",
              "      <th>machine_nameKuka Robot_reactive_power</th>\n",
              "      <th>...</th>\n",
              "      <th>sensor_id4_GyroZ</th>\n",
              "      <th>sensor_id5_AccX</th>\n",
              "      <th>sensor_id5_AccY</th>\n",
              "      <th>sensor_id5_AccZ</th>\n",
              "      <th>sensor_id5_AngX</th>\n",
              "      <th>sensor_id5_AngY</th>\n",
              "      <th>sensor_id5_AngZ</th>\n",
              "      <th>sensor_id5_GyroX</th>\n",
              "      <th>sensor_id5_GyroY</th>\n",
              "      <th>sensor_id5_GyroZ</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>time</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2022-08-11 14:01:34.644</th>\n",
              "      <td>0</td>\n",
              "      <td>-1.659778</td>\n",
              "      <td>-1.249082</td>\n",
              "      <td>-0.902503</td>\n",
              "      <td>0.373132</td>\n",
              "      <td>-0.903120</td>\n",
              "      <td>-2.896849</td>\n",
              "      <td>-1.879994</td>\n",
              "      <td>-3.157673</td>\n",
              "      <td>0.130060</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.700328</td>\n",
              "      <td>-0.250820</td>\n",
              "      <td>0.095296</td>\n",
              "      <td>0.078288</td>\n",
              "      <td>-0.175062</td>\n",
              "      <td>1.097400</td>\n",
              "      <td>1.480228</td>\n",
              "      <td>-0.816558</td>\n",
              "      <td>-0.728697</td>\n",
              "      <td>-0.784789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-08-11 14:01:34.744</th>\n",
              "      <td>0</td>\n",
              "      <td>-1.659778</td>\n",
              "      <td>-1.249082</td>\n",
              "      <td>-0.902503</td>\n",
              "      <td>0.373132</td>\n",
              "      <td>-0.903120</td>\n",
              "      <td>-2.896849</td>\n",
              "      <td>-1.879994</td>\n",
              "      <td>-3.157673</td>\n",
              "      <td>0.130060</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.700328</td>\n",
              "      <td>-0.251021</td>\n",
              "      <td>0.095296</td>\n",
              "      <td>0.078288</td>\n",
              "      <td>-0.175062</td>\n",
              "      <td>1.097400</td>\n",
              "      <td>1.480228</td>\n",
              "      <td>-0.816558</td>\n",
              "      <td>-0.728697</td>\n",
              "      <td>-0.784789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-08-11 14:01:34.844</th>\n",
              "      <td>0</td>\n",
              "      <td>-1.659778</td>\n",
              "      <td>-1.249082</td>\n",
              "      <td>-0.902503</td>\n",
              "      <td>0.373132</td>\n",
              "      <td>-0.903120</td>\n",
              "      <td>-2.896849</td>\n",
              "      <td>-1.879994</td>\n",
              "      <td>-3.157673</td>\n",
              "      <td>0.130060</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.700328</td>\n",
              "      <td>-0.250820</td>\n",
              "      <td>0.095059</td>\n",
              "      <td>0.078288</td>\n",
              "      <td>-0.175062</td>\n",
              "      <td>1.097400</td>\n",
              "      <td>1.480228</td>\n",
              "      <td>-0.816558</td>\n",
              "      <td>-0.728697</td>\n",
              "      <td>-0.784789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-08-11 14:01:34.944</th>\n",
              "      <td>0</td>\n",
              "      <td>-1.659778</td>\n",
              "      <td>-1.249082</td>\n",
              "      <td>-0.902503</td>\n",
              "      <td>0.373132</td>\n",
              "      <td>-0.903120</td>\n",
              "      <td>-2.896849</td>\n",
              "      <td>-1.879994</td>\n",
              "      <td>-3.157673</td>\n",
              "      <td>0.130060</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.700328</td>\n",
              "      <td>-0.251424</td>\n",
              "      <td>0.095770</td>\n",
              "      <td>0.078036</td>\n",
              "      <td>-0.175062</td>\n",
              "      <td>1.097400</td>\n",
              "      <td>1.480228</td>\n",
              "      <td>-0.816558</td>\n",
              "      <td>-0.728697</td>\n",
              "      <td>-0.784789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-08-11 14:01:35.044</th>\n",
              "      <td>0</td>\n",
              "      <td>-1.659778</td>\n",
              "      <td>-1.249082</td>\n",
              "      <td>-0.902503</td>\n",
              "      <td>0.373132</td>\n",
              "      <td>-0.903120</td>\n",
              "      <td>-2.896849</td>\n",
              "      <td>-1.879994</td>\n",
              "      <td>-3.157673</td>\n",
              "      <td>0.130060</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.700328</td>\n",
              "      <td>-0.251021</td>\n",
              "      <td>0.095296</td>\n",
              "      <td>0.078036</td>\n",
              "      <td>-0.175062</td>\n",
              "      <td>1.097400</td>\n",
              "      <td>1.480228</td>\n",
              "      <td>-0.816558</td>\n",
              "      <td>-0.728697</td>\n",
              "      <td>-0.784789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-08-11 14:30:30.744</th>\n",
              "      <td>0</td>\n",
              "      <td>0.967267</td>\n",
              "      <td>1.377899</td>\n",
              "      <td>-0.442150</td>\n",
              "      <td>0.373132</td>\n",
              "      <td>-0.428394</td>\n",
              "      <td>0.596178</td>\n",
              "      <td>0.911731</td>\n",
              "      <td>0.607155</td>\n",
              "      <td>-1.151908</td>\n",
              "      <td>...</td>\n",
              "      <td>1.422573</td>\n",
              "      <td>6.045191</td>\n",
              "      <td>0.125160</td>\n",
              "      <td>0.078036</td>\n",
              "      <td>-0.057356</td>\n",
              "      <td>0.761747</td>\n",
              "      <td>1.586996</td>\n",
              "      <td>1.225725</td>\n",
              "      <td>1.358975</td>\n",
              "      <td>-0.767006</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-08-11 14:30:30.844</th>\n",
              "      <td>0</td>\n",
              "      <td>0.967267</td>\n",
              "      <td>1.377899</td>\n",
              "      <td>-0.442150</td>\n",
              "      <td>0.373132</td>\n",
              "      <td>-0.428394</td>\n",
              "      <td>0.596178</td>\n",
              "      <td>0.911731</td>\n",
              "      <td>0.607155</td>\n",
              "      <td>-1.151908</td>\n",
              "      <td>...</td>\n",
              "      <td>1.424142</td>\n",
              "      <td>-0.257468</td>\n",
              "      <td>0.109043</td>\n",
              "      <td>0.163513</td>\n",
              "      <td>-0.175062</td>\n",
              "      <td>0.964199</td>\n",
              "      <td>1.603697</td>\n",
              "      <td>1.230612</td>\n",
              "      <td>1.364754</td>\n",
              "      <td>-0.776864</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-08-11 14:30:30.944</th>\n",
              "      <td>0</td>\n",
              "      <td>0.967267</td>\n",
              "      <td>1.377899</td>\n",
              "      <td>-0.442150</td>\n",
              "      <td>0.373132</td>\n",
              "      <td>-0.428394</td>\n",
              "      <td>0.596178</td>\n",
              "      <td>0.911731</td>\n",
              "      <td>0.607155</td>\n",
              "      <td>-1.151908</td>\n",
              "      <td>...</td>\n",
              "      <td>1.436010</td>\n",
              "      <td>-0.233696</td>\n",
              "      <td>0.079653</td>\n",
              "      <td>0.121027</td>\n",
              "      <td>-0.205690</td>\n",
              "      <td>1.047071</td>\n",
              "      <td>1.614895</td>\n",
              "      <td>1.233559</td>\n",
              "      <td>1.376755</td>\n",
              "      <td>-0.783076</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-08-11 14:30:31.044</th>\n",
              "      <td>0</td>\n",
              "      <td>0.967267</td>\n",
              "      <td>1.377899</td>\n",
              "      <td>-0.442150</td>\n",
              "      <td>0.373132</td>\n",
              "      <td>-0.428394</td>\n",
              "      <td>0.596178</td>\n",
              "      <td>0.911731</td>\n",
              "      <td>0.607155</td>\n",
              "      <td>-1.151908</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.699771</td>\n",
              "      <td>-0.252230</td>\n",
              "      <td>0.092215</td>\n",
              "      <td>0.072472</td>\n",
              "      <td>-0.184070</td>\n",
              "      <td>1.061829</td>\n",
              "      <td>1.617019</td>\n",
              "      <td>1.236531</td>\n",
              "      <td>-0.728375</td>\n",
              "      <td>1.292578</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-08-11 14:30:31.144</th>\n",
              "      <td>0</td>\n",
              "      <td>0.967267</td>\n",
              "      <td>1.377899</td>\n",
              "      <td>-0.442150</td>\n",
              "      <td>0.373132</td>\n",
              "      <td>-0.428394</td>\n",
              "      <td>0.596178</td>\n",
              "      <td>0.911731</td>\n",
              "      <td>0.607155</td>\n",
              "      <td>-1.151908</td>\n",
              "      <td>...</td>\n",
              "      <td>1.442718</td>\n",
              "      <td>-0.250820</td>\n",
              "      <td>0.095059</td>\n",
              "      <td>0.078036</td>\n",
              "      <td>-0.173261</td>\n",
              "      <td>1.063343</td>\n",
              "      <td>1.616536</td>\n",
              "      <td>-0.816558</td>\n",
              "      <td>1.385854</td>\n",
              "      <td>-0.784789</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>16235 rows × 56 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5fbabe66-4db9-4d78-8e5b-af47042c4088')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5fbabe66-4db9-4d78-8e5b-af47042c4088 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5fbabe66-4db9-4d78-8e5b-af47042c4088');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e8e34c87-b998-47c4-b9df-bd6318ec3ba1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e8e34c87-b998-47c4-b9df-bd6318ec3ba1')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e8e34c87-b998-47c4-b9df-bd6318ec3ba1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameters"
      ],
      "metadata": {
        "id": "EwQFEZv4rT0O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_FREQUENCY = 10 #Hz\n",
        "WINDOW_TIME = 6 #seconds\n",
        "WINDOW_SIZE = DATASET_FREQUENCY * WINDOW_TIME # nr of samples in a window\n",
        "SAMPLE_SIZE = 55# df_regular_labelled.iloc[0].shape[0] - 1 # df_regular_labelled has column \"anomaly\", which shall not be used for training\n",
        "LATENT_VAR_SIZE = 32 #SAMPLE_SIZE\n",
        "TRAIN_BATCH_SIZE = 32\n",
        "TEST_BATCH_SIZE = 1\n",
        "EPOCHS = 20\n",
        "LAMBDA = 0.1\n",
        "NR_LATENT_MAP_ITERS = 50\n",
        "\n",
        "training_loss = tf.keras.losses.BinaryCrossentropy()\n",
        "#discr_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
        "#gen_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
        "\n",
        "discr_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
        "gen_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
        "\n",
        "z_optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=0.0002) # optimizer for used for mapping to latent space\n"
      ],
      "metadata": {
        "id": "qRTR4Q8wrXMs"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SAMPLE_SIZE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7wYTTHbLoZ0",
        "outputId": "890acce5-f73b-4ea5-eb2e-5d1787f1c861"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "55"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Window the data"
      ],
      "metadata": {
        "id": "jyMX8k7dM90-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def window_data(df, window_size, shift=1): # window_size refers to the nr of samples in a window\n",
        "  df.sort_index(inplace=True)\n",
        "  #df.index = [i for i in range(len(df.index))]\n",
        "\n",
        "  windows_list = []\n",
        "  label_list = []\n",
        "\n",
        "  for i in range(0, len(df.index), shift):\n",
        "    if i + window_size <= len(df.index):\n",
        "      window = df.iloc[i : i + window_size].copy()\n",
        "\n",
        "      nr_anomalies = window['anomaly'].sum()\n",
        "\n",
        "      if nr_anomalies > 0:\n",
        "        #print(f\"This happened! nr_anomalies={nr_anomalies}\")\n",
        "        label_list.append(1)\n",
        "      else:\n",
        "        label_list.append(0)\n",
        "\n",
        "      window = window.drop([\"anomaly\"], axis=1).to_numpy()\n",
        "\n",
        "      windows_list.append(window)\n",
        "      #print(len(windows_list))\n",
        "\n",
        "  return np.array(windows_list), np.array(label_list)\n",
        "  #return windows_list, label_list\n",
        "\n"
      ],
      "metadata": {
        "id": "ScNE1HgAJzz2"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "windows_regular, labels_regular = window_data(df_regular_labelled, WINDOW_SIZE, 1)\n",
        "print()\n",
        "windows_rec1, labels_rec1 = window_data(df_rec1_labelled, WINDOW_SIZE, WINDOW_SIZE)\n",
        "windows_rec5, labels_rec5 = window_data(df_rec5_labelled, WINDOW_SIZE, WINDOW_SIZE)"
      ],
      "metadata": {
        "id": "a2TATZwuAkZo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a5661a7-2c1c-4067-d608-da7d5d95536e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Nr samples in df_regular_labelled: {df_regular_labelled.shape}\")\n",
        "print(f\"Nr of windows in windows_regular: {windows_regular.shape}\\n\")\n",
        "\n",
        "print(f\"Nr samples in df_rec1_labelled: {df_rec1_labelled.shape}\")\n",
        "print(f\"Nr of windows in windows_rec1: {windows_rec1.shape}\\n\")\n",
        "\n",
        "print(f\"Nr samples in df_rec5_labelled: {df_rec5_labelled.shape}\")\n",
        "print(f\"Nr of windows in windows_rec5: {windows_rec5.shape}\\n\")\n",
        "\n",
        "print(f\"Nr of anomalous windows in windows_regular: {windows_regular[labels_regular==1].shape[0]}\")\n",
        "print(f\"Nr of anomalous windows in windows_rec1: {windows_rec1[labels_rec1==1].shape[0]}\")\n",
        "print(f\"Nr of anomalous windows in windows_rec5: {windows_rec5[labels_rec5==1].shape[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5DUavbD_aST",
        "outputId": "843938c7-5076-4b81-9e53-5484ce4ffc8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nr samples in df_regular_labelled: (95815, 56)\n",
            "Nr of windows in windows_regular: (95756, 60, 55)\n",
            "\n",
            "Nr samples in df_rec1_labelled: (17366, 56)\n",
            "Nr of windows in windows_rec1: (289, 60, 55)\n",
            "\n",
            "Nr samples in df_rec5_labelled: (16909, 56)\n",
            "Nr of windows in windows_rec5: (281, 60, 55)\n",
            "\n",
            "Nr of anomalous windows in windows_regular: 0\n",
            "Nr of anomalous windows in windows_rec1: 53\n",
            "Nr of anomalous windows in windows_rec5: 121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#overlapped_windows_rec1, overlapped_labels_rec1 = window_data(df_rec1_labelled, WINDOW_SIZE, 1)\n",
        "#overlapped_windows_rec5, overlapped_labels_rec5 = window_data(df_rec5_labelled, WINDOW_SIZE, 1)\n",
        "\n",
        "del df_regular, df_regular_normal, df_regular_labelled, df_rec1, df_rec1_normal, df_rec1_labelled, df_rec5, df_rec5_normal, df_rec5_labelled"
      ],
      "metadata": {
        "id": "vLJ_WnpbHEx3"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "Fptm3aOX3rBR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make TensorFlow Dataset"
      ],
      "metadata": {
        "id": "I718YhNTUFHY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((windows_regular, labels_regular)).map(lambda x, y: (tf.cast(x, tf.float32), y)).batch(TRAIN_BATCH_SIZE)\n",
        "validation_dataset = tf.data.Dataset.from_tensor_slices((windows_rec5, labels_rec5)).map(lambda x, y: (tf.cast(x, tf.float32), y)).batch(TEST_BATCH_SIZE)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((windows_rec1, labels_rec1)).map(lambda x, y: (tf.cast(x, tf.float32), y)).batch(TEST_BATCH_SIZE)"
      ],
      "metadata": {
        "id": "iP1KcY-XUIBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generator and Discriminator instantiation"
      ],
      "metadata": {
        "id": "dGBGeY7i2usT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generator = init_generator(in_dim=(WINDOW_SIZE, LATENT_VAR_SIZE), out_dim=(WINDOW_SIZE, SAMPLE_SIZE))\n",
        "discriminator = init_discriminator(in_dim=(WINDOW_SIZE, SAMPLE_SIZE), out_dim=1)"
      ],
      "metadata": {
        "id": "TW6EROxz1aeh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "UTHopsOqyo5P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def adversarial_training(generator, discriminator, data, batch_size, windows_size, latent_size, loss_fn, discr_optimizer, gen_optimizer, checkpoints_backup_path, num_epochs=1):\n",
        "\n",
        "# setup checkpoint saving\n",
        "  directory_path = \"./checkpoints\"\n",
        "\n",
        "  filepath_generator = directory_path + \"/generator/\"\n",
        "  filepath_discriminator = directory_path + \"/discriminator/\"\n",
        "\n",
        "  if not os.path.isdir('checkpoints'):\n",
        "    ! mkdir checkpoints\n",
        "\n",
        "    ! mkdir {filepath_generator}\n",
        "    ! mkdir {filepath_discriminator}\n",
        "\n",
        "  real_label = 0\n",
        "  fake_label = 1\n",
        "\n",
        "  print(\"epoch: 0/%d\")\n",
        "  for epoch in range(num_epochs):\n",
        "    for i, (time_sequences, labels) in enumerate(data):\n",
        "      # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
        "\n",
        "      #Train with real data\n",
        "      with tf.GradientTape() as tape:\n",
        "        scores = discriminator(time_sequences)\n",
        "        discr_real_loss = loss_fn(labels, scores)\n",
        "\n",
        "      gradients = tape.gradient(discr_real_loss, discriminator.trainable_weights)\n",
        "      discr_optimizer.apply_gradients(zip(gradients, discriminator.trainable_weights))\n",
        "\n",
        "      #Train with fake data\n",
        "      noise = tf.random.normal((time_sequences.shape[0], time_sequences.shape[1], latent_size), mean=0, stddev=1)\n",
        "      fake_sequences = generator(noise)\n",
        "      fake_labels = tf.ones(labels.shape) * fake_label\n",
        "\n",
        "      with tf.GradientTape() as tape:\n",
        "          scores = discriminator(fake_sequences)\n",
        "          discr_fake_loss = loss_fn(fake_labels, scores)\n",
        "\n",
        "      gradients = tape.gradient(discr_fake_loss, discriminator.trainable_weights)\n",
        "      discr_optimizer.apply_gradients(zip(gradients, discriminator.trainable_weights))\n",
        "\n",
        "\n",
        "      # (2) Update G network: maximize log(D(G(z)))\n",
        "\n",
        "      noise = tf.random.normal((time_sequences.shape[0], time_sequences.shape[1], latent_size), mean=0, stddev=1)\n",
        "      with tf.GradientTape() as tape:\n",
        "        fake_sequences = generator(noise)\n",
        "        #real_labels = tf.ones(noise.shape)\n",
        "        discriminator_output = discriminator(fake_sequences)    # discriminator tells which fake sequences it considers to be real and which not\n",
        "        generator_loss = loss_fn(labels, discriminator_output)\n",
        "\n",
        "      gradients = tape.gradient(generator_loss, generator.trainable_weights)\n",
        "      gen_optimizer.apply_gradients(zip(gradients, generator.trainable_weights))\n",
        "\n",
        "      print(\n",
        "          f\"epoch: {epoch}/{num_epochs},    batch: {i}/{len(data)}    Discriminator_loss: {discr_real_loss+discr_fake_loss}  Generator_loss: {generator_loss}\"\n",
        "      )\n",
        "\n",
        "    generator.save_weights(filepath_generator + f\"gen_epoch{epoch}.h5\")\n",
        "    discriminator.save_weights(filepath_discriminator + f\"discr_epoch{epoch}.h5\")\n",
        "\n",
        "    # zip and move a copy of the checkpoints\n",
        "    now = datetime.datetime.now()\n",
        "    zip_name = f\"checkpoints_{str(now.date())+'_'+str(now.time())}.zip\"\n",
        "\n",
        "    !zip -r {zip_name} ./checkpoints\n",
        "    !cp {zip_name} {checkpoints_backup_path}\n"
      ],
      "metadata": {
        "id": "hCCNeaFthFX9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "adversarial_training(generator, discriminator, train_dataset, TRAIN_BATCH_SIZE, WINDOW_SIZE, LATENT_VAR_SIZE, training_loss, discr_optimizer, gen_optimizer, \"./drive/MyDrive/ml-applications/TimeSeriesAnomalyDetection_project/saved_checkpoints\", 20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qef-oXZAyn_V",
        "outputId": "ec8d2932-3748-4fe2-8362-f82b4ee44ad4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0/%d\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7abbc1ed12d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function _BaseOptimizer._update_step_xla at 0x7abbc1ed39a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "epoch: 18/20,    batch: 1070/2993    Discriminator_loss: 0.0007189430762082338  Generator_loss: 8.134445190429688\n",
            "epoch: 18/20,    batch: 1071/2993    Discriminator_loss: 0.00036440457915887237  Generator_loss: 8.134140014648438\n",
            "epoch: 18/20,    batch: 1072/2993    Discriminator_loss: 0.0003102745395153761  Generator_loss: 8.13317584991455\n",
            "epoch: 18/20,    batch: 1073/2993    Discriminator_loss: 0.0003130091936327517  Generator_loss: 8.131021499633789\n",
            "epoch: 18/20,    batch: 1074/2993    Discriminator_loss: 0.0003119141038041562  Generator_loss: 8.128454208374023\n",
            "epoch: 18/20,    batch: 1075/2993    Discriminator_loss: 0.00043001584708690643  Generator_loss: 8.125303268432617\n",
            "epoch: 18/20,    batch: 1076/2993    Discriminator_loss: 0.0003050115774385631  Generator_loss: 8.122111320495605\n",
            "epoch: 18/20,    batch: 1077/2993    Discriminator_loss: 0.0006619088817387819  Generator_loss: 8.119303703308105\n",
            "epoch: 18/20,    batch: 1078/2993    Discriminator_loss: 0.07971126586198807  Generator_loss: 8.071327209472656\n",
            "epoch: 18/20,    batch: 1079/2993    Discriminator_loss: 0.00032728665973991156  Generator_loss: 8.033310890197754\n",
            "epoch: 18/20,    batch: 1080/2993    Discriminator_loss: 0.0005264281644485891  Generator_loss: 8.003786087036133\n",
            "epoch: 18/20,    batch: 1081/2993    Discriminator_loss: 0.0005902450066059828  Generator_loss: 7.981343746185303\n",
            "epoch: 18/20,    batch: 1082/2993    Discriminator_loss: 0.00035588355967774987  Generator_loss: 7.965190887451172\n",
            "epoch: 18/20,    batch: 1083/2993    Discriminator_loss: 0.0004974979674443603  Generator_loss: 7.954958438873291\n",
            "epoch: 18/20,    batch: 1084/2993    Discriminator_loss: 0.0005948628531768918  Generator_loss: 7.949611663818359\n",
            "epoch: 18/20,    batch: 1085/2993    Discriminator_loss: 0.00036983026075176895  Generator_loss: 7.948587417602539\n",
            "epoch: 18/20,    batch: 1086/2993    Discriminator_loss: 0.000605669803917408  Generator_loss: 7.951196193695068\n",
            "epoch: 18/20,    batch: 1087/2993    Discriminator_loss: 0.0004037915787193924  Generator_loss: 7.956562519073486\n",
            "epoch: 18/20,    batch: 1088/2993    Discriminator_loss: 0.00038538454100489616  Generator_loss: 7.96417236328125\n",
            "epoch: 18/20,    batch: 1089/2993    Discriminator_loss: 0.0006246694829314947  Generator_loss: 7.973916053771973\n",
            "epoch: 18/20,    batch: 1090/2993    Discriminator_loss: 0.00035503495018929243  Generator_loss: 7.985100269317627\n",
            "epoch: 18/20,    batch: 1091/2993    Discriminator_loss: 0.0003933623374905437  Generator_loss: 7.997440338134766\n",
            "epoch: 18/20,    batch: 1092/2993    Discriminator_loss: 0.0004291513469070196  Generator_loss: 8.010452270507812\n",
            "epoch: 18/20,    batch: 1093/2993    Discriminator_loss: 0.0003444785834290087  Generator_loss: 8.023906707763672\n",
            "epoch: 18/20,    batch: 1094/2993    Discriminator_loss: 0.00034209477598778903  Generator_loss: 8.037210464477539\n",
            "epoch: 18/20,    batch: 1095/2993    Discriminator_loss: 0.00037841181620024145  Generator_loss: 8.049993515014648\n",
            "epoch: 18/20,    batch: 1096/2993    Discriminator_loss: 0.00042581759043969214  Generator_loss: 8.061759948730469\n",
            "epoch: 18/20,    batch: 1097/2993    Discriminator_loss: 0.00033587025245651603  Generator_loss: 8.07295036315918\n",
            "epoch: 18/20,    batch: 1098/2993    Discriminator_loss: 0.0004341110761743039  Generator_loss: 8.082938194274902\n",
            "epoch: 18/20,    batch: 1099/2993    Discriminator_loss: 0.0003410973004065454  Generator_loss: 8.092016220092773\n",
            "epoch: 18/20,    batch: 1100/2993    Discriminator_loss: 0.0003140888293273747  Generator_loss: 8.099655151367188\n",
            "epoch: 18/20,    batch: 1101/2993    Discriminator_loss: 0.00033788252039812505  Generator_loss: 8.106462478637695\n",
            "epoch: 18/20,    batch: 1102/2993    Discriminator_loss: 0.0004614732170011848  Generator_loss: 8.11211109161377\n",
            "epoch: 18/20,    batch: 1103/2993    Discriminator_loss: 0.0003099297173321247  Generator_loss: 8.117379188537598\n",
            "epoch: 18/20,    batch: 1104/2993    Discriminator_loss: 0.00034693002817220986  Generator_loss: 8.122462272644043\n",
            "epoch: 18/20,    batch: 1105/2993    Discriminator_loss: 0.0010576844215393066  Generator_loss: 8.127785682678223\n",
            "epoch: 18/20,    batch: 1106/2993    Discriminator_loss: 0.00030181260081008077  Generator_loss: 8.133569717407227\n",
            "epoch: 18/20,    batch: 1107/2993    Discriminator_loss: 0.0003239783982280642  Generator_loss: 8.140063285827637\n",
            "epoch: 18/20,    batch: 1108/2993    Discriminator_loss: 0.000390832923585549  Generator_loss: 8.147319793701172\n",
            "epoch: 18/20,    batch: 1109/2993    Discriminator_loss: 0.00029505480779334903  Generator_loss: 8.155614852905273\n",
            "epoch: 18/20,    batch: 1110/2993    Discriminator_loss: 0.0003860568976961076  Generator_loss: 8.164738655090332\n",
            "epoch: 18/20,    batch: 1111/2993    Discriminator_loss: 0.0005747357499785721  Generator_loss: 8.17447566986084\n",
            "epoch: 18/20,    batch: 1112/2993    Discriminator_loss: 0.00028777867555618286  Generator_loss: 8.184707641601562\n",
            "epoch: 18/20,    batch: 1113/2993    Discriminator_loss: 0.00046164955710992217  Generator_loss: 8.195520401000977\n",
            "epoch: 18/20,    batch: 1114/2993    Discriminator_loss: 0.0004525681142695248  Generator_loss: 8.206066131591797\n",
            "epoch: 18/20,    batch: 1115/2993    Discriminator_loss: 0.0002909897011704743  Generator_loss: 8.216588020324707\n",
            "epoch: 18/20,    batch: 1116/2993    Discriminator_loss: 0.0009270838927477598  Generator_loss: 8.226720809936523\n",
            "epoch: 18/20,    batch: 1117/2993    Discriminator_loss: 0.0003792562347371131  Generator_loss: 8.236730575561523\n",
            "epoch: 18/20,    batch: 1118/2993    Discriminator_loss: 0.00028353853849694133  Generator_loss: 8.246146202087402\n",
            "epoch: 18/20,    batch: 1119/2993    Discriminator_loss: 0.0005553540540859103  Generator_loss: 8.255178451538086\n",
            "epoch: 18/20,    batch: 1120/2993    Discriminator_loss: 0.00027080223662778735  Generator_loss: 8.263641357421875\n",
            "epoch: 18/20,    batch: 1121/2993    Discriminator_loss: 0.00029875023756176233  Generator_loss: 8.271697998046875\n",
            "epoch: 18/20,    batch: 1122/2993    Discriminator_loss: 0.0004975744523108006  Generator_loss: 8.279317855834961\n",
            "epoch: 18/20,    batch: 1123/2993    Discriminator_loss: 0.0002583672758191824  Generator_loss: 8.286094665527344\n",
            "epoch: 18/20,    batch: 1124/2993    Discriminator_loss: 0.0003287279687356204  Generator_loss: 8.292293548583984\n",
            "epoch: 18/20,    batch: 1125/2993    Discriminator_loss: 0.00035589709295891225  Generator_loss: 8.297588348388672\n",
            "epoch: 18/20,    batch: 1126/2993    Discriminator_loss: 0.00025713504874147475  Generator_loss: 8.301979064941406\n",
            "epoch: 18/20,    batch: 1127/2993    Discriminator_loss: 0.00027565984055399895  Generator_loss: 8.305152893066406\n",
            "epoch: 18/20,    batch: 1128/2993    Discriminator_loss: 0.0003014979884028435  Generator_loss: 8.30699348449707\n",
            "epoch: 18/20,    batch: 1129/2993    Discriminator_loss: 0.0003158740291837603  Generator_loss: 8.307234764099121\n",
            "epoch: 18/20,    batch: 1130/2993    Discriminator_loss: 0.00031353801023215055  Generator_loss: 8.305816650390625\n",
            "epoch: 18/20,    batch: 1131/2993    Discriminator_loss: 0.000282543885987252  Generator_loss: 8.302639961242676\n",
            "epoch: 18/20,    batch: 1132/2993    Discriminator_loss: 0.000271405529929325  Generator_loss: 8.297737121582031\n",
            "epoch: 18/20,    batch: 1133/2993    Discriminator_loss: 0.0002588846837170422  Generator_loss: 8.291312217712402\n",
            "epoch: 18/20,    batch: 1134/2993    Discriminator_loss: 0.0002882561821024865  Generator_loss: 8.28364372253418\n",
            "epoch: 18/20,    batch: 1135/2993    Discriminator_loss: 0.0003607158432714641  Generator_loss: 8.274951934814453\n",
            "epoch: 18/20,    batch: 1136/2993    Discriminator_loss: 0.0002679519820958376  Generator_loss: 8.265783309936523\n",
            "epoch: 18/20,    batch: 1137/2993    Discriminator_loss: 0.0003291640314273536  Generator_loss: 8.256484031677246\n",
            "epoch: 18/20,    batch: 1138/2993    Discriminator_loss: 0.0002862057008314878  Generator_loss: 8.247312545776367\n",
            "epoch: 18/20,    batch: 1139/2993    Discriminator_loss: 0.0002709676045924425  Generator_loss: 8.238688468933105\n",
            "epoch: 18/20,    batch: 1140/2993    Discriminator_loss: 0.0002895726356655359  Generator_loss: 8.230908393859863\n",
            "epoch: 18/20,    batch: 1141/2993    Discriminator_loss: 0.0004042340733576566  Generator_loss: 8.224313735961914\n",
            "epoch: 18/20,    batch: 1142/2993    Discriminator_loss: 0.0002781906514428556  Generator_loss: 8.218618392944336\n",
            "epoch: 18/20,    batch: 1143/2993    Discriminator_loss: 0.00041541908285580575  Generator_loss: 8.214288711547852\n",
            "epoch: 18/20,    batch: 1144/2993    Discriminator_loss: 0.00044282551971264184  Generator_loss: 8.211648941040039\n",
            "epoch: 18/20,    batch: 1145/2993    Discriminator_loss: 0.0002920888946391642  Generator_loss: 8.21037483215332\n",
            "epoch: 18/20,    batch: 1146/2993    Discriminator_loss: 0.0006257374188862741  Generator_loss: 8.210785865783691\n",
            "epoch: 18/20,    batch: 1147/2993    Discriminator_loss: 0.0003600202617235482  Generator_loss: 8.212775230407715\n",
            "epoch: 18/20,    batch: 1148/2993    Discriminator_loss: 0.0002920214901678264  Generator_loss: 8.21658706665039\n",
            "epoch: 18/20,    batch: 1149/2993    Discriminator_loss: 0.0005362826632335782  Generator_loss: 8.221994400024414\n",
            "epoch: 18/20,    batch: 1150/2993    Discriminator_loss: 0.00029336533043533564  Generator_loss: 8.228728294372559\n",
            "epoch: 18/20,    batch: 1151/2993    Discriminator_loss: 0.0009953335393220186  Generator_loss: 8.237068176269531\n",
            "epoch: 18/20,    batch: 1152/2993    Discriminator_loss: 0.0006230136496014893  Generator_loss: 8.24662971496582\n",
            "epoch: 18/20,    batch: 1153/2993    Discriminator_loss: 0.00027336220955476165  Generator_loss: 8.25721549987793\n",
            "epoch: 18/20,    batch: 1154/2993    Discriminator_loss: 0.0003633549204096198  Generator_loss: 8.268597602844238\n",
            "epoch: 18/20,    batch: 1155/2993    Discriminator_loss: 0.0003654273459687829  Generator_loss: 8.280860900878906\n",
            "epoch: 18/20,    batch: 1156/2993    Discriminator_loss: 0.00025661225663498044  Generator_loss: 8.293632507324219\n",
            "epoch: 18/20,    batch: 1157/2993    Discriminator_loss: 0.00028645736165344715  Generator_loss: 8.306812286376953\n",
            "epoch: 18/20,    batch: 1158/2993    Discriminator_loss: 0.0002824368712026626  Generator_loss: 8.320274353027344\n",
            "epoch: 18/20,    batch: 1159/2993    Discriminator_loss: 0.00024796329671517015  Generator_loss: 8.334013938903809\n",
            "epoch: 18/20,    batch: 1160/2993    Discriminator_loss: 0.00026748099480755627  Generator_loss: 8.347408294677734\n",
            "epoch: 18/20,    batch: 1161/2993    Discriminator_loss: 0.0003088949015364051  Generator_loss: 8.360684394836426\n",
            "epoch: 18/20,    batch: 1162/2993    Discriminator_loss: 0.00029330101097002625  Generator_loss: 8.37376594543457\n",
            "epoch: 18/20,    batch: 1163/2993    Discriminator_loss: 0.0002365739201195538  Generator_loss: 8.386237144470215\n",
            "epoch: 18/20,    batch: 1164/2993    Discriminator_loss: 0.00027922572917304933  Generator_loss: 8.398088455200195\n",
            "epoch: 18/20,    batch: 1165/2993    Discriminator_loss: 0.00026096482179127634  Generator_loss: 8.408978462219238\n",
            "epoch: 18/20,    batch: 1166/2993    Discriminator_loss: 0.0002261375921079889  Generator_loss: 8.419075012207031\n",
            "epoch: 18/20,    batch: 1167/2993    Discriminator_loss: 0.00024217121244873852  Generator_loss: 8.427946090698242\n",
            "epoch: 18/20,    batch: 1168/2993    Discriminator_loss: 0.0003242696984671056  Generator_loss: 8.435761451721191\n",
            "epoch: 18/20,    batch: 1169/2993    Discriminator_loss: 0.00025441552861593664  Generator_loss: 8.442359924316406\n",
            "epoch: 18/20,    batch: 1170/2993    Discriminator_loss: 0.0002275165606988594  Generator_loss: 8.447713851928711\n",
            "epoch: 18/20,    batch: 1171/2993    Discriminator_loss: 0.00027572151157073677  Generator_loss: 8.452051162719727\n",
            "epoch: 18/20,    batch: 1172/2993    Discriminator_loss: 0.0002536610118113458  Generator_loss: 8.455703735351562\n",
            "epoch: 18/20,    batch: 1173/2993    Discriminator_loss: 0.00021738302893936634  Generator_loss: 8.458581924438477\n",
            "epoch: 18/20,    batch: 1174/2993    Discriminator_loss: 0.00023270526435226202  Generator_loss: 8.461483001708984\n",
            "epoch: 18/20,    batch: 1175/2993    Discriminator_loss: 0.004366040695458651  Generator_loss: 8.464181900024414\n",
            "epoch: 18/20,    batch: 1176/2993    Discriminator_loss: 0.0002371678565395996  Generator_loss: 8.467721939086914\n",
            "epoch: 18/20,    batch: 1177/2993    Discriminator_loss: 0.00023089995374903083  Generator_loss: 8.471309661865234\n",
            "epoch: 18/20,    batch: 1178/2993    Discriminator_loss: 0.0003802708233706653  Generator_loss: 8.475820541381836\n",
            "epoch: 18/20,    batch: 1179/2993    Discriminator_loss: 0.00023864043760113418  Generator_loss: 8.480603218078613\n",
            "epoch: 18/20,    batch: 1180/2993    Discriminator_loss: 0.00025141341029666364  Generator_loss: 8.48613166809082\n",
            "epoch: 18/20,    batch: 1181/2993    Discriminator_loss: 0.0003222795785404742  Generator_loss: 8.491618156433105\n",
            "epoch: 18/20,    batch: 1182/2993    Discriminator_loss: 0.0002099585981341079  Generator_loss: 8.497299194335938\n",
            "epoch: 18/20,    batch: 1183/2993    Discriminator_loss: 0.00023772033455315977  Generator_loss: 8.502589225769043\n",
            "epoch: 18/20,    batch: 1184/2993    Discriminator_loss: 0.0003651826991699636  Generator_loss: 8.507467269897461\n",
            "epoch: 18/20,    batch: 1185/2993    Discriminator_loss: 0.00020563293946906924  Generator_loss: 8.51129150390625\n",
            "epoch: 18/20,    batch: 1186/2993    Discriminator_loss: 0.0002445394347887486  Generator_loss: 8.514110565185547\n",
            "epoch: 18/20,    batch: 1187/2993    Discriminator_loss: 0.0003624819219112396  Generator_loss: 8.515708923339844\n",
            "epoch: 18/20,    batch: 1188/2993    Discriminator_loss: 0.00020498826052062213  Generator_loss: 8.515430450439453\n",
            "epoch: 18/20,    batch: 1189/2993    Discriminator_loss: 0.00028019092860631645  Generator_loss: 8.513331413269043\n",
            "epoch: 18/20,    batch: 1190/2993    Discriminator_loss: 0.0003925387281924486  Generator_loss: 8.509275436401367\n",
            "epoch: 18/20,    batch: 1191/2993    Discriminator_loss: 0.00021188249229453504  Generator_loss: 8.502902030944824\n",
            "epoch: 18/20,    batch: 1192/2993    Discriminator_loss: 0.00028400187147781253  Generator_loss: 8.494308471679688\n",
            "epoch: 18/20,    batch: 1193/2993    Discriminator_loss: 0.0002314005105290562  Generator_loss: 8.483427047729492\n",
            "epoch: 18/20,    batch: 1194/2993    Discriminator_loss: 0.0002149963693227619  Generator_loss: 8.470580101013184\n",
            "epoch: 18/20,    batch: 1195/2993    Discriminator_loss: 0.0002661312755662948  Generator_loss: 8.455915451049805\n",
            "epoch: 18/20,    batch: 1196/2993    Discriminator_loss: 0.00042980548460036516  Generator_loss: 8.439632415771484\n",
            "epoch: 18/20,    batch: 1197/2993    Discriminator_loss: 0.00022479990730062127  Generator_loss: 8.422475814819336\n",
            "epoch: 18/20,    batch: 1198/2993    Discriminator_loss: 0.0002600188890937716  Generator_loss: 8.405107498168945\n",
            "epoch: 18/20,    batch: 1199/2993    Discriminator_loss: 0.00027513012173585594  Generator_loss: 8.388069152832031\n",
            "epoch: 18/20,    batch: 1200/2993    Discriminator_loss: 0.0002364236570429057  Generator_loss: 8.371959686279297\n",
            "epoch: 18/20,    batch: 1201/2993    Discriminator_loss: 0.0002503945434000343  Generator_loss: 8.357646942138672\n",
            "epoch: 18/20,    batch: 1202/2993    Discriminator_loss: 0.0004285642644390464  Generator_loss: 8.34549331665039\n",
            "epoch: 18/20,    batch: 1203/2993    Discriminator_loss: 0.00024654189473949373  Generator_loss: 8.335596084594727\n",
            "epoch: 18/20,    batch: 1204/2993    Discriminator_loss: 0.0002760735806077719  Generator_loss: 8.328414916992188\n",
            "epoch: 18/20,    batch: 1205/2993    Discriminator_loss: 0.00031355652026832104  Generator_loss: 8.324305534362793\n",
            "epoch: 18/20,    batch: 1206/2993    Discriminator_loss: 0.0002542225120123476  Generator_loss: 8.322663307189941\n",
            "epoch: 18/20,    batch: 1207/2993    Discriminator_loss: 0.00027022860012948513  Generator_loss: 8.323338508605957\n",
            "epoch: 18/20,    batch: 1208/2993    Discriminator_loss: 0.00045081746065989137  Generator_loss: 8.326412200927734\n",
            "epoch: 18/20,    batch: 1209/2993    Discriminator_loss: 0.0002954774536192417  Generator_loss: 8.331194877624512\n",
            "epoch: 18/20,    batch: 1210/2993    Discriminator_loss: 0.00028413612744770944  Generator_loss: 8.337601661682129\n",
            "epoch: 18/20,    batch: 1211/2993    Discriminator_loss: 0.0006415244424715638  Generator_loss: 8.34528923034668\n",
            "epoch: 18/20,    batch: 1212/2993    Discriminator_loss: 0.00025947895483113825  Generator_loss: 8.353763580322266\n",
            "epoch: 18/20,    batch: 1213/2993    Discriminator_loss: 0.000287872098851949  Generator_loss: 8.363107681274414\n",
            "epoch: 18/20,    batch: 1214/2993    Discriminator_loss: 0.0005954002263024449  Generator_loss: 8.372734069824219\n",
            "epoch: 18/20,    batch: 1215/2993    Discriminator_loss: 0.00023466491256840527  Generator_loss: 8.382699012756348\n",
            "epoch: 18/20,    batch: 1216/2993    Discriminator_loss: 0.000287346716504544  Generator_loss: 8.392877578735352\n",
            "epoch: 18/20,    batch: 1217/2993    Discriminator_loss: 0.0006589647382497787  Generator_loss: 8.403011322021484\n",
            "epoch: 18/20,    batch: 1218/2993    Discriminator_loss: 0.00022871771943755448  Generator_loss: 8.413166046142578\n",
            "epoch: 18/20,    batch: 1219/2993    Discriminator_loss: 0.0003839373239316046  Generator_loss: 8.42311954498291\n",
            "epoch: 18/20,    batch: 1220/2993    Discriminator_loss: 0.0003858571872115135  Generator_loss: 8.432727813720703\n",
            "epoch: 18/20,    batch: 1221/2993    Discriminator_loss: 0.00022888780222274363  Generator_loss: 8.442100524902344\n",
            "epoch: 18/20,    batch: 1222/2993    Discriminator_loss: 0.0004499899805523455  Generator_loss: 8.45103931427002\n",
            "epoch: 18/20,    batch: 1223/2993    Discriminator_loss: 0.0002714311413001269  Generator_loss: 8.459389686584473\n",
            "epoch: 18/20,    batch: 1224/2993    Discriminator_loss: 0.00023034343030303717  Generator_loss: 8.467013359069824\n",
            "epoch: 18/20,    batch: 1225/2993    Discriminator_loss: 0.00038865706301294267  Generator_loss: 8.474160194396973\n",
            "epoch: 18/20,    batch: 1226/2993    Discriminator_loss: 0.00022541031648870558  Generator_loss: 8.48105239868164\n",
            "epoch: 18/20,    batch: 1227/2993    Discriminator_loss: 0.00021397876844275743  Generator_loss: 8.487577438354492\n",
            "epoch: 18/20,    batch: 1228/2993    Discriminator_loss: 0.0004522032104432583  Generator_loss: 8.494199752807617\n",
            "epoch: 18/20,    batch: 1229/2993    Discriminator_loss: 0.000526358257047832  Generator_loss: 8.50115966796875\n",
            "epoch: 18/20,    batch: 1230/2993    Discriminator_loss: 0.00021044444292783737  Generator_loss: 8.508869171142578\n",
            "epoch: 18/20,    batch: 1231/2993    Discriminator_loss: 0.0004433176072780043  Generator_loss: 8.516881942749023\n",
            "epoch: 18/20,    batch: 1232/2993    Discriminator_loss: 0.0002433282497804612  Generator_loss: 8.525859832763672\n",
            "epoch: 18/20,    batch: 1233/2993    Discriminator_loss: 0.00020157336257398129  Generator_loss: 8.535318374633789\n",
            "epoch: 18/20,    batch: 1234/2993    Discriminator_loss: 0.00023063884873408824  Generator_loss: 8.544902801513672\n",
            "epoch: 18/20,    batch: 1235/2993    Discriminator_loss: 0.0005013745394535363  Generator_loss: 8.554910659790039\n",
            "epoch: 18/20,    batch: 1236/2993    Discriminator_loss: 0.0001958632201422006  Generator_loss: 8.564414978027344\n",
            "epoch: 18/20,    batch: 1237/2993    Discriminator_loss: 0.0003270412562415004  Generator_loss: 8.573890686035156\n",
            "epoch: 18/20,    batch: 1238/2993    Discriminator_loss: 0.00029664550675079226  Generator_loss: 8.582263946533203\n",
            "epoch: 18/20,    batch: 1239/2993    Discriminator_loss: 0.00019087223336100578  Generator_loss: 8.589607238769531\n",
            "epoch: 18/20,    batch: 1240/2993    Discriminator_loss: 0.0002024560235440731  Generator_loss: 8.595352172851562\n",
            "epoch: 18/20,    batch: 1241/2993    Discriminator_loss: 0.0005267235683277249  Generator_loss: 8.600918769836426\n",
            "epoch: 18/20,    batch: 1242/2993    Discriminator_loss: 0.00019505005911923945  Generator_loss: 8.603888511657715\n",
            "epoch: 18/20,    batch: 1243/2993    Discriminator_loss: 0.00027237675385549664  Generator_loss: 8.607919692993164\n",
            "epoch: 18/20,    batch: 1244/2993    Discriminator_loss: 0.000378166267182678  Generator_loss: 8.608589172363281\n",
            "epoch: 18/20,    batch: 1245/2993    Discriminator_loss: 0.00018725803238339722  Generator_loss: 8.608099937438965\n",
            "epoch: 18/20,    batch: 1246/2993    Discriminator_loss: 0.00024935088003985584  Generator_loss: 8.6052885055542\n",
            "epoch: 18/20,    batch: 1247/2993    Discriminator_loss: 0.00043334433576092124  Generator_loss: 8.60074234008789\n",
            "epoch: 18/20,    batch: 1248/2993    Discriminator_loss: 0.00019000034080818295  Generator_loss: 8.59448528289795\n",
            "epoch: 18/20,    batch: 1249/2993    Discriminator_loss: 0.000467258709250018  Generator_loss: 8.586408615112305\n",
            "epoch: 18/20,    batch: 1250/2993    Discriminator_loss: 0.00043844658648595214  Generator_loss: 8.576831817626953\n",
            "epoch: 18/20,    batch: 1251/2993    Discriminator_loss: 0.00020613244851119816  Generator_loss: 8.565098762512207\n",
            "epoch: 18/20,    batch: 1252/2993    Discriminator_loss: 0.00036000681575387716  Generator_loss: 8.550703048706055\n",
            "epoch: 18/20,    batch: 1253/2993    Discriminator_loss: 0.00029621587600558996  Generator_loss: 8.53274154663086\n",
            "epoch: 18/20,    batch: 1254/2993    Discriminator_loss: 0.0002255789004266262  Generator_loss: 8.509737968444824\n",
            "epoch: 18/20,    batch: 1255/2993    Discriminator_loss: 0.0005779865896329284  Generator_loss: 8.47999382019043\n",
            "epoch: 18/20,    batch: 1256/2993    Discriminator_loss: 0.00023070220777299255  Generator_loss: 8.442117691040039\n",
            "epoch: 18/20,    batch: 1257/2993    Discriminator_loss: 0.00027680653147399426  Generator_loss: 8.39521598815918\n",
            "epoch: 18/20,    batch: 1258/2993    Discriminator_loss: 0.0003296455251984298  Generator_loss: 8.34050178527832\n",
            "epoch: 18/20,    batch: 1259/2993    Discriminator_loss: 0.0002834063197951764  Generator_loss: 8.281434059143066\n",
            "epoch: 18/20,    batch: 1260/2993    Discriminator_loss: 0.00027766136918216944  Generator_loss: 8.224966049194336\n",
            "epoch: 18/20,    batch: 1261/2993    Discriminator_loss: 0.0003281922254245728  Generator_loss: 8.178568840026855\n",
            "epoch: 18/20,    batch: 1262/2993    Discriminator_loss: 0.000354299001628533  Generator_loss: 8.14175033569336\n",
            "epoch: 18/20,    batch: 1263/2993    Discriminator_loss: 0.00032144394936040044  Generator_loss: 8.106400489807129\n",
            "epoch: 18/20,    batch: 1264/2993    Discriminator_loss: 0.00045622236211784184  Generator_loss: 8.049386024475098\n",
            "epoch: 18/20,    batch: 1265/2993    Discriminator_loss: 0.0004074073222000152  Generator_loss: 7.950488090515137\n",
            "epoch: 18/20,    batch: 1266/2993    Discriminator_loss: 0.0004581804387271404  Generator_loss: 7.737621784210205\n",
            "epoch: 18/20,    batch: 1267/2993    Discriminator_loss: 0.0007059365161694586  Generator_loss: 7.338088035583496\n",
            "epoch: 18/20,    batch: 1268/2993    Discriminator_loss: 0.0009026049519889057  Generator_loss: 7.167792320251465\n",
            "epoch: 18/20,    batch: 1269/2993    Discriminator_loss: 0.0007540431106463075  Generator_loss: 7.214962482452393\n",
            "epoch: 18/20,    batch: 1270/2993    Discriminator_loss: 0.0008139206329360604  Generator_loss: 7.242007255554199\n",
            "epoch: 18/20,    batch: 1271/2993    Discriminator_loss: 0.0007822745246812701  Generator_loss: 7.244315147399902\n",
            "epoch: 18/20,    batch: 1272/2993    Discriminator_loss: 0.0007393202977254987  Generator_loss: 7.238505840301514\n",
            "epoch: 18/20,    batch: 1273/2993    Discriminator_loss: 0.0007897548493929207  Generator_loss: 7.232606887817383\n",
            "epoch: 18/20,    batch: 1274/2993    Discriminator_loss: 0.0008510016486980021  Generator_loss: 7.229733943939209\n",
            "epoch: 18/20,    batch: 1275/2993    Discriminator_loss: 0.0007475685561075807  Generator_loss: 7.231029987335205\n",
            "epoch: 18/20,    batch: 1276/2993    Discriminator_loss: 0.0007864488288760185  Generator_loss: 7.236392021179199\n",
            "epoch: 18/20,    batch: 1277/2993    Discriminator_loss: 0.0009618497570045292  Generator_loss: 7.245588302612305\n",
            "epoch: 18/20,    batch: 1278/2993    Discriminator_loss: 0.0007306536426767707  Generator_loss: 7.257968902587891\n",
            "epoch: 18/20,    batch: 1279/2993    Discriminator_loss: 0.0007951993029564619  Generator_loss: 7.27316427230835\n",
            "epoch: 18/20,    batch: 1280/2993    Discriminator_loss: 0.0008214467670768499  Generator_loss: 7.29031229019165\n",
            "epoch: 18/20,    batch: 1281/2993    Discriminator_loss: 0.000709223560988903  Generator_loss: 7.309016704559326\n",
            "epoch: 18/20,    batch: 1282/2993    Discriminator_loss: 0.0008867467986419797  Generator_loss: 7.328639030456543\n",
            "epoch: 18/20,    batch: 1283/2993    Discriminator_loss: 0.0007138134678825736  Generator_loss: 7.349349498748779\n",
            "epoch: 18/20,    batch: 1284/2993    Discriminator_loss: 0.0006732770125381649  Generator_loss: 7.370739936828613\n",
            "epoch: 18/20,    batch: 1285/2993    Discriminator_loss: 0.0008155633113346994  Generator_loss: 7.3926897048950195\n",
            "epoch: 18/20,    batch: 1286/2993    Discriminator_loss: 0.0006522855255752802  Generator_loss: 7.415459632873535\n",
            "epoch: 18/20,    batch: 1287/2993    Discriminator_loss: 0.0006349860923364758  Generator_loss: 7.4389753341674805\n",
            "epoch: 18/20,    batch: 1288/2993    Discriminator_loss: 0.17911729216575623  Generator_loss: 5.607715129852295\n",
            "epoch: 18/20,    batch: 1289/2993    Discriminator_loss: 0.01068094465881586  Generator_loss: 3.61942720413208\n",
            "epoch: 18/20,    batch: 1290/2993    Discriminator_loss: 0.07434745877981186  Generator_loss: 3.027348041534424\n",
            "epoch: 18/20,    batch: 1291/2993    Discriminator_loss: 0.04075150191783905  Generator_loss: 4.203588485717773\n",
            "epoch: 18/20,    batch: 1292/2993    Discriminator_loss: 0.008532791398465633  Generator_loss: 5.357625961303711\n",
            "epoch: 18/20,    batch: 1293/2993    Discriminator_loss: 0.003579117823392153  Generator_loss: 5.893948554992676\n",
            "epoch: 18/20,    batch: 1294/2993    Discriminator_loss: 0.002583365887403488  Generator_loss: 6.130630016326904\n",
            "epoch: 18/20,    batch: 1295/2993    Discriminator_loss: 0.002312141004949808  Generator_loss: 6.229523658752441\n",
            "epoch: 18/20,    batch: 1296/2993    Discriminator_loss: 0.002283247420564294  Generator_loss: 6.220807075500488\n",
            "epoch: 18/20,    batch: 1297/2993    Discriminator_loss: 0.0019028268288820982  Generator_loss: 6.4009108543396\n",
            "epoch: 18/20,    batch: 1298/2993    Discriminator_loss: 0.0015998033341020346  Generator_loss: 6.564549446105957\n",
            "epoch: 18/20,    batch: 1299/2993    Discriminator_loss: 0.0013621931429952383  Generator_loss: 6.678853988647461\n",
            "epoch: 18/20,    batch: 1300/2993    Discriminator_loss: 0.0012407628819346428  Generator_loss: 6.756975173950195\n",
            "epoch: 18/20,    batch: 1301/2993    Discriminator_loss: 0.001178367412649095  Generator_loss: 6.809288024902344\n",
            "epoch: 18/20,    batch: 1302/2993    Discriminator_loss: 0.0012229338753968477  Generator_loss: 6.842809200286865\n",
            "epoch: 18/20,    batch: 1303/2993    Discriminator_loss: 0.0010885572992265224  Generator_loss: 6.862331867218018\n",
            "epoch: 18/20,    batch: 1304/2993    Discriminator_loss: 0.001099381479434669  Generator_loss: 6.871106147766113\n",
            "epoch: 18/20,    batch: 1305/2993    Discriminator_loss: 0.0011114678345620632  Generator_loss: 6.871343612670898\n",
            "epoch: 18/20,    batch: 1306/2993    Discriminator_loss: 0.0010782716562971473  Generator_loss: 6.86476993560791\n",
            "epoch: 18/20,    batch: 1307/2993    Discriminator_loss: 0.001088334247469902  Generator_loss: 6.852762699127197\n",
            "epoch: 18/20,    batch: 1308/2993    Discriminator_loss: 0.0011215360136702657  Generator_loss: 6.8357648849487305\n",
            "epoch: 18/20,    batch: 1309/2993    Discriminator_loss: 0.001180664636194706  Generator_loss: 6.814964771270752\n",
            "epoch: 18/20,    batch: 1310/2993    Discriminator_loss: 0.00115253496915102  Generator_loss: 6.790774345397949\n",
            "epoch: 18/20,    batch: 1311/2993    Discriminator_loss: 0.0013714556116610765  Generator_loss: 6.763003349304199\n",
            "epoch: 18/20,    batch: 1312/2993    Discriminator_loss: 0.0013125810073688626  Generator_loss: 6.732276916503906\n",
            "epoch: 18/20,    batch: 1313/2993    Discriminator_loss: 0.001271724351681769  Generator_loss: 6.6985063552856445\n",
            "epoch: 18/20,    batch: 1314/2993    Discriminator_loss: 0.00135915691498667  Generator_loss: 6.662359237670898\n",
            "epoch: 18/20,    batch: 1315/2993    Discriminator_loss: 0.0013956408947706223  Generator_loss: 6.625578880310059\n",
            "epoch: 18/20,    batch: 1316/2993    Discriminator_loss: 0.0014129932969808578  Generator_loss: 6.590816974639893\n",
            "epoch: 18/20,    batch: 1317/2993    Discriminator_loss: 0.001548887463286519  Generator_loss: 6.561650276184082\n",
            "epoch: 18/20,    batch: 1318/2993    Discriminator_loss: 0.0014904155395925045  Generator_loss: 6.540485382080078\n",
            "epoch: 18/20,    batch: 1319/2993    Discriminator_loss: 0.0015117883449420333  Generator_loss: 6.527195930480957\n",
            "epoch: 18/20,    batch: 1320/2993    Discriminator_loss: 0.0015895359683781862  Generator_loss: 6.517319679260254\n",
            "epoch: 18/20,    batch: 1321/2993    Discriminator_loss: 0.001542794518172741  Generator_loss: 6.504880905151367\n",
            "epoch: 18/20,    batch: 1322/2993    Discriminator_loss: 0.0015830682823434472  Generator_loss: 6.486883163452148\n",
            "epoch: 18/20,    batch: 1323/2993    Discriminator_loss: 0.0016975476173684  Generator_loss: 6.4641265869140625\n",
            "epoch: 18/20,    batch: 1324/2993    Discriminator_loss: 0.0016566159902140498  Generator_loss: 6.439599514007568\n",
            "epoch: 18/20,    batch: 1325/2993    Discriminator_loss: 0.0017087331507354975  Generator_loss: 6.41790771484375\n",
            "epoch: 18/20,    batch: 1326/2993    Discriminator_loss: 0.0017575324745848775  Generator_loss: 6.401930332183838\n",
            "epoch: 18/20,    batch: 1327/2993    Discriminator_loss: 0.0017425068654119968  Generator_loss: 6.393118381500244\n",
            "epoch: 18/20,    batch: 1328/2993    Discriminator_loss: 0.0017512731719762087  Generator_loss: 6.391254425048828\n",
            "epoch: 18/20,    batch: 1329/2993    Discriminator_loss: 0.0018245960818603635  Generator_loss: 6.3954949378967285\n",
            "epoch: 18/20,    batch: 1330/2993    Discriminator_loss: 0.0018369819736108184  Generator_loss: 6.403713226318359\n",
            "epoch: 18/20,    batch: 1331/2993    Discriminator_loss: 0.0017216214910149574  Generator_loss: 6.414974212646484\n",
            "epoch: 18/20,    batch: 1332/2993    Discriminator_loss: 0.001741565065458417  Generator_loss: 6.427080154418945\n",
            "epoch: 18/20,    batch: 1333/2993    Discriminator_loss: 0.0016870413674041629  Generator_loss: 6.4388885498046875\n",
            "epoch: 18/20,    batch: 1334/2993    Discriminator_loss: 0.001658278633840382  Generator_loss: 6.449501991271973\n",
            "epoch: 18/20,    batch: 1335/2993    Discriminator_loss: 0.001655304804444313  Generator_loss: 6.457841873168945\n",
            "epoch: 18/20,    batch: 1336/2993    Discriminator_loss: 0.0017413978930562735  Generator_loss: 6.463977813720703\n",
            "epoch: 18/20,    batch: 1337/2993    Discriminator_loss: 0.0016310748178511858  Generator_loss: 6.466772079467773\n",
            "epoch: 18/20,    batch: 1338/2993    Discriminator_loss: 0.0016527321422472596  Generator_loss: 6.46700382232666\n",
            "epoch: 18/20,    batch: 1339/2993    Discriminator_loss: 0.0016623632982373238  Generator_loss: 6.46531867980957\n",
            "epoch: 18/20,    batch: 1340/2993    Discriminator_loss: 0.0016411886317655444  Generator_loss: 6.461489200592041\n",
            "epoch: 18/20,    batch: 1341/2993    Discriminator_loss: 0.001659883069805801  Generator_loss: 6.453225612640381\n",
            "epoch: 18/20,    batch: 1342/2993    Discriminator_loss: 0.001792000257410109  Generator_loss: 6.438500881195068\n",
            "epoch: 18/20,    batch: 1343/2993    Discriminator_loss: 0.0017470641760155559  Generator_loss: 6.406305313110352\n",
            "epoch: 18/20,    batch: 1344/2993    Discriminator_loss: 0.0018121508182957768  Generator_loss: 6.3757405281066895\n",
            "epoch: 18/20,    batch: 1345/2993    Discriminator_loss: 0.0018514178227633238  Generator_loss: 6.401851654052734\n",
            "epoch: 18/20,    batch: 1346/2993    Discriminator_loss: 0.0017038187943398952  Generator_loss: 6.433287620544434\n",
            "epoch: 18/20,    batch: 1347/2993    Discriminator_loss: 0.001678771455772221  Generator_loss: 6.453639030456543\n",
            "epoch: 18/20,    batch: 1348/2993    Discriminator_loss: 0.0017637870041653514  Generator_loss: 6.465467929840088\n",
            "epoch: 18/20,    batch: 1349/2993    Discriminator_loss: 0.0016526647377759218  Generator_loss: 6.465752601623535\n",
            "epoch: 18/20,    batch: 1350/2993    Discriminator_loss: 0.0016945841489359736  Generator_loss: 6.4577202796936035\n",
            "epoch: 18/20,    batch: 1351/2993    Discriminator_loss: 0.0017558409599587321  Generator_loss: 6.444266319274902\n",
            "epoch: 18/20,    batch: 1352/2993    Discriminator_loss: 0.0017257502768188715  Generator_loss: 6.425169944763184\n",
            "epoch: 18/20,    batch: 1353/2993    Discriminator_loss: 0.0018517752178013325  Generator_loss: 6.401309967041016\n",
            "epoch: 18/20,    batch: 1354/2993    Discriminator_loss: 0.0019283033907413483  Generator_loss: 6.369084358215332\n",
            "epoch: 18/20,    batch: 1355/2993    Discriminator_loss: 0.0019191681640222669  Generator_loss: 6.327692985534668\n",
            "epoch: 18/20,    batch: 1356/2993    Discriminator_loss: 0.002141137607395649  Generator_loss: 6.273223876953125\n",
            "epoch: 18/20,    batch: 1357/2993    Discriminator_loss: 0.002206275472417474  Generator_loss: 6.205095291137695\n",
            "epoch: 18/20,    batch: 1358/2993    Discriminator_loss: 0.0024303013924509287  Generator_loss: 6.116860389709473\n",
            "epoch: 18/20,    batch: 1359/2993    Discriminator_loss: 0.002591766184195876  Generator_loss: 6.074060440063477\n",
            "epoch: 18/20,    batch: 1360/2993    Discriminator_loss: 0.0028868908993899822  Generator_loss: 5.973629951477051\n",
            "epoch: 18/20,    batch: 1361/2993    Discriminator_loss: 0.0031011071987450123  Generator_loss: 5.912839889526367\n",
            "epoch: 18/20,    batch: 1362/2993    Discriminator_loss: 0.003345085307955742  Generator_loss: 5.856281280517578\n",
            "epoch: 18/20,    batch: 1363/2993    Discriminator_loss: 0.00367159117013216  Generator_loss: 5.794588565826416\n",
            "epoch: 18/20,    batch: 1364/2993    Discriminator_loss: 0.004134165123105049  Generator_loss: 5.704708576202393\n",
            "epoch: 18/20,    batch: 1365/2993    Discriminator_loss: 0.005374533589929342  Generator_loss: 5.5034942626953125\n",
            "epoch: 18/20,    batch: 1366/2993    Discriminator_loss: 0.006543771363794804  Generator_loss: 5.3950371742248535\n",
            "epoch: 18/20,    batch: 1367/2993    Discriminator_loss: 0.00698360800743103  Generator_loss: 5.407497882843018\n",
            "epoch: 18/20,    batch: 1368/2993    Discriminator_loss: 0.0071970680728554726  Generator_loss: 5.442899227142334\n",
            "epoch: 18/20,    batch: 1369/2993    Discriminator_loss: 0.014486808329820633  Generator_loss: 5.18792724609375\n",
            "epoch: 18/20,    batch: 1370/2993    Discriminator_loss: 0.07414063066244125  Generator_loss: 5.515139579772949\n",
            "epoch: 18/20,    batch: 1371/2993    Discriminator_loss: 0.039472535252571106  Generator_loss: 6.503830909729004\n",
            "epoch: 18/20,    batch: 1372/2993    Discriminator_loss: 0.00015520669694524258  Generator_loss: 10.507455825805664\n",
            "epoch: 18/20,    batch: 1373/2993    Discriminator_loss: 0.7858531475067139  Generator_loss: 13.051482200622559\n",
            "epoch: 18/20,    batch: 1374/2993    Discriminator_loss: 2.333189513592515e-05  Generator_loss: 14.177849769592285\n",
            "epoch: 18/20,    batch: 1375/2993    Discriminator_loss: 1.2610129260792746e-06  Generator_loss: 14.556530952453613\n",
            "epoch: 18/20,    batch: 1376/2993    Discriminator_loss: 8.39319091028301e-06  Generator_loss: 14.214933395385742\n",
            "epoch: 18/20,    batch: 1377/2993    Discriminator_loss: 5.10501122334972e-05  Generator_loss: 14.015499114990234\n",
            "epoch: 18/20,    batch: 1378/2993    Discriminator_loss: 3.94699236494489e-06  Generator_loss: 13.766979217529297\n",
            "epoch: 18/20,    batch: 1379/2993    Discriminator_loss: 1.035638342727907e-05  Generator_loss: 13.589496612548828\n",
            "epoch: 18/20,    batch: 1380/2993    Discriminator_loss: 8.012048783712089e-05  Generator_loss: 13.504091262817383\n",
            "epoch: 18/20,    batch: 1381/2993    Discriminator_loss: 1.5515845461777644e-06  Generator_loss: 13.360008239746094\n",
            "epoch: 18/20,    batch: 1382/2993    Discriminator_loss: 1.581595279276371e-05  Generator_loss: 13.141654014587402\n",
            "epoch: 18/20,    batch: 1383/2993    Discriminator_loss: 0.00013477586617227644  Generator_loss: 12.782381057739258\n",
            "epoch: 18/20,    batch: 1384/2993    Discriminator_loss: 4.258014996594284e-06  Generator_loss: 12.376617431640625\n",
            "epoch: 18/20,    batch: 1385/2993    Discriminator_loss: 2.504204530850984e-05  Generator_loss: 12.136568069458008\n",
            "epoch: 18/20,    batch: 1386/2993    Discriminator_loss: 8.568738849135116e-05  Generator_loss: 11.892374992370605\n",
            "epoch: 18/20,    batch: 1387/2993    Discriminator_loss: 1.0615267456159927e-05  Generator_loss: 11.654224395751953\n",
            "epoch: 18/20,    batch: 1388/2993    Discriminator_loss: 0.00011454615741968155  Generator_loss: 11.434366226196289\n",
            "epoch: 18/20,    batch: 1389/2993    Discriminator_loss: 2.4345114070456475e-05  Generator_loss: 11.195039749145508\n",
            "epoch: 18/20,    batch: 1390/2993    Discriminator_loss: 2.2174997866386548e-05  Generator_loss: 10.811626434326172\n",
            "epoch: 18/20,    batch: 1391/2993    Discriminator_loss: 0.00011796352919191122  Generator_loss: 10.649731636047363\n",
            "epoch: 18/20,    batch: 1392/2993    Discriminator_loss: 5.2349496399983764e-05  Generator_loss: 10.260200500488281\n",
            "epoch: 18/20,    batch: 1393/2993    Discriminator_loss: 5.251092807156965e-05  Generator_loss: 9.989115715026855\n",
            "epoch: 18/20,    batch: 1394/2993    Discriminator_loss: 8.366481051780283e-05  Generator_loss: 9.704864501953125\n",
            "epoch: 18/20,    batch: 1395/2993    Discriminator_loss: 9.00996383279562e-05  Generator_loss: 9.402706146240234\n",
            "epoch: 18/20,    batch: 1396/2993    Discriminator_loss: 0.00010545889381319284  Generator_loss: 9.190876007080078\n",
            "epoch: 18/20,    batch: 1397/2993    Discriminator_loss: 0.00013226734881754965  Generator_loss: 8.959615707397461\n",
            "epoch: 18/20,    batch: 1398/2993    Discriminator_loss: 0.000230367761105299  Generator_loss: 8.692535400390625\n",
            "epoch: 18/20,    batch: 1399/2993    Discriminator_loss: 0.00021334590564947575  Generator_loss: 8.4586820602417\n",
            "epoch: 18/20,    batch: 1400/2993    Discriminator_loss: 0.0002843218680936843  Generator_loss: 8.205129623413086\n",
            "epoch: 18/20,    batch: 1401/2993    Discriminator_loss: 0.0003553427231963724  Generator_loss: 7.999615669250488\n",
            "epoch: 18/20,    batch: 1402/2993    Discriminator_loss: 0.00041584274731576443  Generator_loss: 7.807924270629883\n",
            "epoch: 18/20,    batch: 1403/2993    Discriminator_loss: 0.0004916059551760554  Generator_loss: 7.628262042999268\n",
            "epoch: 18/20,    batch: 1404/2993    Discriminator_loss: 0.0005910209729336202  Generator_loss: 7.446637153625488\n",
            "epoch: 18/20,    batch: 1405/2993    Discriminator_loss: 0.0007667841273359954  Generator_loss: 7.262375354766846\n",
            "epoch: 18/20,    batch: 1406/2993    Discriminator_loss: 0.0008406389970332384  Generator_loss: 7.086114406585693\n",
            "epoch: 18/20,    batch: 1407/2993    Discriminator_loss: 0.001031481777317822  Generator_loss: 6.890781879425049\n",
            "epoch: 18/20,    batch: 1408/2993    Discriminator_loss: 0.0013159445952624083  Generator_loss: 6.6546406745910645\n",
            "epoch: 18/20,    batch: 1409/2993    Discriminator_loss: 0.0017208941280841827  Generator_loss: 6.380633354187012\n",
            "epoch: 18/20,    batch: 1410/2993    Discriminator_loss: 0.0024964758194983006  Generator_loss: 6.008505821228027\n",
            "epoch: 18/20,    batch: 1411/2993    Discriminator_loss: 0.004584232345223427  Generator_loss: 5.448668479919434\n",
            "epoch: 18/20,    batch: 1412/2993    Discriminator_loss: 0.010698848403990269  Generator_loss: 4.751832485198975\n",
            "epoch: 18/20,    batch: 1413/2993    Discriminator_loss: 0.024488849565386772  Generator_loss: 4.298181533813477\n",
            "epoch: 18/20,    batch: 1414/2993    Discriminator_loss: 0.030404547229409218  Generator_loss: 4.480442047119141\n",
            "epoch: 18/20,    batch: 1415/2993    Discriminator_loss: 0.018197162076830864  Generator_loss: 5.031774997711182\n",
            "epoch: 18/20,    batch: 1416/2993    Discriminator_loss: 0.00919773057103157  Generator_loss: 5.558498382568359\n",
            "epoch: 18/20,    batch: 1417/2993    Discriminator_loss: 0.004022090695798397  Generator_loss: 6.154824256896973\n",
            "epoch: 18/20,    batch: 1418/2993    Discriminator_loss: 0.002410620916634798  Generator_loss: 6.488476276397705\n",
            "epoch: 18/20,    batch: 1419/2993    Discriminator_loss: 0.0017790560377761722  Generator_loss: 6.667732238769531\n",
            "epoch: 18/20,    batch: 1420/2993    Discriminator_loss: 0.0015680128708481789  Generator_loss: 6.752006530761719\n",
            "epoch: 18/20,    batch: 1421/2993    Discriminator_loss: 0.001454968354664743  Generator_loss: 6.763250350952148\n",
            "epoch: 18/20,    batch: 1422/2993    Discriminator_loss: 0.0014647857751697302  Generator_loss: 6.7187371253967285\n",
            "epoch: 18/20,    batch: 1423/2993    Discriminator_loss: 0.0016588767757639289  Generator_loss: 6.625199317932129\n",
            "epoch: 18/20,    batch: 1424/2993    Discriminator_loss: 0.0017809137934818864  Generator_loss: 6.489910125732422\n",
            "epoch: 18/20,    batch: 1425/2993    Discriminator_loss: 0.00212119217030704  Generator_loss: 6.315115928649902\n",
            "epoch: 18/20,    batch: 1426/2993    Discriminator_loss: 0.0027291513979434967  Generator_loss: 6.106630325317383\n",
            "epoch: 18/20,    batch: 1427/2993    Discriminator_loss: 0.0033336414489895105  Generator_loss: 5.874749183654785\n",
            "epoch: 18/20,    batch: 1428/2993    Discriminator_loss: 0.004385690204799175  Generator_loss: 5.634864807128906\n",
            "epoch: 18/20,    batch: 1429/2993    Discriminator_loss: 0.0056993537582457066  Generator_loss: 5.426732063293457\n",
            "epoch: 18/20,    batch: 1430/2993    Discriminator_loss: 0.006976668257266283  Generator_loss: 5.271515846252441\n",
            "epoch: 18/20,    batch: 1431/2993    Discriminator_loss: 0.007829534821212292  Generator_loss: 5.216493606567383\n",
            "epoch: 18/20,    batch: 1432/2993    Discriminator_loss: 0.00787859596312046  Generator_loss: 5.2584967613220215\n",
            "epoch: 18/20,    batch: 1433/2993    Discriminator_loss: 0.007183878216892481  Generator_loss: 5.367917537689209\n",
            "epoch: 18/20,    batch: 1434/2993    Discriminator_loss: 0.006149373948574066  Generator_loss: 5.513449192047119\n",
            "epoch: 18/20,    batch: 1435/2993    Discriminator_loss: 0.00522176967933774  Generator_loss: 5.662974834442139\n",
            "epoch: 18/20,    batch: 1436/2993    Discriminator_loss: 0.0043243300169706345  Generator_loss: 5.809195518493652\n",
            "epoch: 18/20,    batch: 1437/2993    Discriminator_loss: 0.0038359402678906918  Generator_loss: 5.89043664932251\n",
            "epoch: 18/20,    batch: 1438/2993    Discriminator_loss: 0.0033539552241563797  Generator_loss: 6.008601188659668\n",
            "epoch: 18/20,    batch: 1439/2993    Discriminator_loss: 0.0032842259388417006  Generator_loss: 6.006925582885742\n",
            "epoch: 18/20,    batch: 1440/2993    Discriminator_loss: 0.003142012283205986  Generator_loss: 6.013873100280762\n",
            "epoch: 18/20,    batch: 1441/2993    Discriminator_loss: 0.003178925486281514  Generator_loss: 5.994513511657715\n",
            "epoch: 18/20,    batch: 1442/2993    Discriminator_loss: 0.0032533234916627407  Generator_loss: 5.958712100982666\n",
            "epoch: 18/20,    batch: 1443/2993    Discriminator_loss: 0.003374415449798107  Generator_loss: 5.912898063659668\n",
            "epoch: 18/20,    batch: 1444/2993    Discriminator_loss: 0.0035461089573800564  Generator_loss: 5.86464786529541\n",
            "epoch: 18/20,    batch: 1445/2993    Discriminator_loss: 0.003744719550013542  Generator_loss: 5.820838451385498\n",
            "epoch: 18/20,    batch: 1446/2993    Discriminator_loss: 0.003831821260973811  Generator_loss: 5.7857208251953125\n",
            "epoch: 18/20,    batch: 1447/2993    Discriminator_loss: 0.0039565605111420155  Generator_loss: 5.760865211486816\n",
            "epoch: 18/20,    batch: 1448/2993    Discriminator_loss: 0.004040692467242479  Generator_loss: 5.746503829956055\n",
            "epoch: 18/20,    batch: 1449/2993    Discriminator_loss: 0.00402614613994956  Generator_loss: 5.7416672706604\n",
            "epoch: 18/20,    batch: 1450/2993    Discriminator_loss: 0.004132612142711878  Generator_loss: 5.743304252624512\n",
            "epoch: 18/20,    batch: 1451/2993    Discriminator_loss: 0.004016480408608913  Generator_loss: 5.751252174377441\n",
            "epoch: 18/20,    batch: 1452/2993    Discriminator_loss: 0.0039261323399841785  Generator_loss: 5.763514518737793\n",
            "epoch: 18/20,    batch: 1453/2993    Discriminator_loss: 0.003918259870260954  Generator_loss: 5.780371189117432\n",
            "epoch: 18/20,    batch: 1454/2993    Discriminator_loss: 0.003744829911738634  Generator_loss: 5.800915718078613\n",
            "epoch: 18/20,    batch: 1455/2993    Discriminator_loss: 0.0036365357227623463  Generator_loss: 5.825628280639648\n",
            "epoch: 18/20,    batch: 1456/2993    Discriminator_loss: 0.003636149223893881  Generator_loss: 5.853457450866699\n",
            "epoch: 18/20,    batch: 1457/2993    Discriminator_loss: 0.0033790115267038345  Generator_loss: 5.8829545974731445\n",
            "epoch: 18/20,    batch: 1458/2993    Discriminator_loss: 0.0032742535695433617  Generator_loss: 5.913668632507324\n",
            "epoch: 18/20,    batch: 1459/2993    Discriminator_loss: 0.0032004716340452433  Generator_loss: 5.943456172943115\n",
            "epoch: 18/20,    batch: 1460/2993    Discriminator_loss: 0.003016832284629345  Generator_loss: 5.9725565910339355\n",
            "epoch: 18/20,    batch: 1461/2993    Discriminator_loss: 0.002922807587310672  Generator_loss: 6.000304222106934\n",
            "epoch: 18/20,    batch: 1462/2993    Discriminator_loss: 0.0028835146222263575  Generator_loss: 6.025497913360596\n",
            "epoch: 18/20,    batch: 1463/2993    Discriminator_loss: 0.0027462884318083525  Generator_loss: 6.049282073974609\n",
            "epoch: 18/20,    batch: 1464/2993    Discriminator_loss: 0.0026688063517212868  Generator_loss: 6.070697784423828\n",
            "epoch: 18/20,    batch: 1465/2993    Discriminator_loss: 0.0026214441750198603  Generator_loss: 6.090550422668457\n",
            "epoch: 18/20,    batch: 1466/2993    Discriminator_loss: 0.002583273220807314  Generator_loss: 6.109156608581543\n",
            "epoch: 18/20,    batch: 1467/2993    Discriminator_loss: 0.0024863160215318203  Generator_loss: 6.126750469207764\n",
            "epoch: 18/20,    batch: 1468/2993    Discriminator_loss: 0.002467823913320899  Generator_loss: 6.1425604820251465\n",
            "epoch: 18/20,    batch: 1469/2993    Discriminator_loss: 0.0024387219455093145  Generator_loss: 6.158651351928711\n",
            "epoch: 18/20,    batch: 1470/2993    Discriminator_loss: 0.0023405421525239944  Generator_loss: 6.177361488342285\n",
            "epoch: 18/20,    batch: 1471/2993    Discriminator_loss: 0.002302492968738079  Generator_loss: 6.193438529968262\n",
            "epoch: 18/20,    batch: 1472/2993    Discriminator_loss: 0.0023043446708470583  Generator_loss: 6.204326629638672\n",
            "epoch: 18/20,    batch: 1473/2993    Discriminator_loss: 0.002247435273602605  Generator_loss: 6.216941833496094\n",
            "epoch: 18/20,    batch: 1474/2993    Discriminator_loss: 0.0022022228222340345  Generator_loss: 6.22770357131958\n",
            "epoch: 18/20,    batch: 1475/2993    Discriminator_loss: 0.002201138297095895  Generator_loss: 6.236822605133057\n",
            "epoch: 18/20,    batch: 1476/2993    Discriminator_loss: 0.0021777597721666098  Generator_loss: 6.243843078613281\n",
            "epoch: 18/20,    batch: 1477/2993    Discriminator_loss: 0.002145885257050395  Generator_loss: 6.248181343078613\n",
            "epoch: 18/20,    batch: 1478/2993    Discriminator_loss: 0.0021457590628415346  Generator_loss: 6.250858306884766\n",
            "epoch: 18/20,    batch: 1479/2993    Discriminator_loss: 0.002184802433475852  Generator_loss: 6.251285552978516\n",
            "epoch: 18/20,    batch: 1480/2993    Discriminator_loss: 0.0021616409067064524  Generator_loss: 6.249720096588135\n",
            "epoch: 18/20,    batch: 1481/2993    Discriminator_loss: 0.002166247460991144  Generator_loss: 6.24607515335083\n",
            "epoch: 18/20,    batch: 1482/2993    Discriminator_loss: 0.002204753225669265  Generator_loss: 6.240842819213867\n",
            "epoch: 18/20,    batch: 1483/2993    Discriminator_loss: 0.0022102927323430777  Generator_loss: 6.234311103820801\n",
            "epoch: 18/20,    batch: 1484/2993    Discriminator_loss: 0.0022386768832802773  Generator_loss: 6.226290702819824\n",
            "epoch: 18/20,    batch: 1485/2993    Discriminator_loss: 0.0022870649117976427  Generator_loss: 6.217499732971191\n",
            "epoch: 18/20,    batch: 1486/2993    Discriminator_loss: 0.002292463555932045  Generator_loss: 6.207807540893555\n",
            "epoch: 18/20,    batch: 1487/2993    Discriminator_loss: 0.0023641129955649376  Generator_loss: 6.198596954345703\n",
            "epoch: 18/20,    batch: 1488/2993    Discriminator_loss: 0.0024995040148496628  Generator_loss: 6.187385559082031\n",
            "epoch: 18/20,    batch: 1489/2993    Discriminator_loss: 0.0025131788570433855  Generator_loss: 6.170880317687988\n",
            "epoch: 18/20,    batch: 1490/2993    Discriminator_loss: 0.0026839266065508127  Generator_loss: 6.168262004852295\n",
            "epoch: 18/20,    batch: 1491/2993    Discriminator_loss: 0.0028141248039901257  Generator_loss: 6.190993309020996\n",
            "epoch: 18/20,    batch: 1492/2993    Discriminator_loss: 0.0027554037515074015  Generator_loss: 6.237143516540527\n",
            "epoch: 18/20,    batch: 1493/2993    Discriminator_loss: 0.0028393722604960203  Generator_loss: 6.296382904052734\n",
            "epoch: 18/20,    batch: 1494/2993    Discriminator_loss: 0.0027201406192034483  Generator_loss: 6.392444610595703\n",
            "epoch: 18/20,    batch: 1495/2993    Discriminator_loss: 0.0025280816480517387  Generator_loss: 6.500055313110352\n",
            "epoch: 18/20,    batch: 1496/2993    Discriminator_loss: 0.002361476654186845  Generator_loss: 6.614181995391846\n",
            "epoch: 18/20,    batch: 1497/2993    Discriminator_loss: 0.002267364179715514  Generator_loss: 6.726940631866455\n",
            "epoch: 18/20,    batch: 1498/2993    Discriminator_loss: 0.0022122745867818594  Generator_loss: 6.848800182342529\n",
            "epoch: 18/20,    batch: 1499/2993    Discriminator_loss: 0.002131315413862467  Generator_loss: 6.969505310058594\n",
            "epoch: 18/20,    batch: 1500/2993    Discriminator_loss: 0.0019469374092295766  Generator_loss: 7.082187652587891\n",
            "epoch: 18/20,    batch: 1501/2993    Discriminator_loss: 0.0018889640923589468  Generator_loss: 7.184863090515137\n",
            "epoch: 18/20,    batch: 1502/2993    Discriminator_loss: 0.0028080823831260204  Generator_loss: 7.401210784912109\n",
            "epoch: 18/20,    batch: 1503/2993    Discriminator_loss: 0.0008935020887292922  Generator_loss: 7.599817276000977\n",
            "epoch: 18/20,    batch: 1504/2993    Discriminator_loss: 0.0006859445129521191  Generator_loss: 7.667471408843994\n",
            "epoch: 18/20,    batch: 1505/2993    Discriminator_loss: 0.0006769039900973439  Generator_loss: 7.665287971496582\n",
            "epoch: 18/20,    batch: 1506/2993    Discriminator_loss: 0.0027152770198881626  Generator_loss: 7.823305130004883\n",
            "epoch: 18/20,    batch: 1507/2993    Discriminator_loss: 0.0004458448674995452  Generator_loss: 8.051261901855469\n",
            "epoch: 18/20,    batch: 1508/2993    Discriminator_loss: 0.00036661658668890595  Generator_loss: 8.162261009216309\n",
            "epoch: 18/20,    batch: 1509/2993    Discriminator_loss: 0.00033884283038787544  Generator_loss: 8.200790405273438\n",
            "epoch: 18/20,    batch: 1510/2993    Discriminator_loss: 0.00032954709604382515  Generator_loss: 8.198583602905273\n",
            "epoch: 18/20,    batch: 1511/2993    Discriminator_loss: 0.0003429640782997012  Generator_loss: 8.147529602050781\n",
            "epoch: 18/20,    batch: 1512/2993    Discriminator_loss: 0.00040045258356258273  Generator_loss: 8.013105392456055\n",
            "epoch: 18/20,    batch: 1513/2993    Discriminator_loss: 5.741787433624268  Generator_loss: 10.043785095214844\n",
            "epoch: 18/20,    batch: 1514/2993    Discriminator_loss: 3.682492024381645e-05  Generator_loss: 12.85589599609375\n",
            "epoch: 18/20,    batch: 1515/2993    Discriminator_loss: 3.774158903979696e-05  Generator_loss: 14.019763946533203\n",
            "epoch: 18/20,    batch: 1516/2993    Discriminator_loss: 4.763454489875585e-05  Generator_loss: 14.597209930419922\n",
            "epoch: 18/20,    batch: 1517/2993    Discriminator_loss: 6.0807884437963367e-05  Generator_loss: 14.597209930419922\n",
            "epoch: 18/20,    batch: 1518/2993    Discriminator_loss: 7.631547487108037e-05  Generator_loss: 14.898982048034668\n",
            "epoch: 18/20,    batch: 1519/2993    Discriminator_loss: 9.469762881053612e-05  Generator_loss: 14.898982048034668\n",
            "epoch: 18/20,    batch: 1520/2993    Discriminator_loss: 0.00011201270535821095  Generator_loss: 14.898982048034668\n",
            "epoch: 18/20,    batch: 1521/2993    Discriminator_loss: 0.00013378597213886678  Generator_loss: 14.898982048034668\n",
            "epoch: 18/20,    batch: 1522/2993    Discriminator_loss: 0.00016139072249643505  Generator_loss: 14.898982048034668\n",
            "epoch: 18/20,    batch: 1523/2993    Discriminator_loss: 0.0001982590911211446  Generator_loss: 14.898982048034668\n",
            "epoch: 18/20,    batch: 1524/2993    Discriminator_loss: 0.00024208560353145003  Generator_loss: 14.898982048034668\n",
            "epoch: 18/20,    batch: 1525/2993    Discriminator_loss: 0.0003187792026437819  Generator_loss: 14.898982048034668\n",
            "epoch: 18/20,    batch: 1526/2993    Discriminator_loss: 0.00037956362939439714  Generator_loss: 14.898982048034668\n",
            "epoch: 18/20,    batch: 1527/2993    Discriminator_loss: 0.0004370869428385049  Generator_loss: 14.898982048034668\n",
            "epoch: 18/20,    batch: 1528/2993    Discriminator_loss: 0.0004959944635629654  Generator_loss: 14.898982048034668\n",
            "epoch: 18/20,    batch: 1529/2993    Discriminator_loss: 0.0008157625561580062  Generator_loss: 14.898982048034668\n",
            "epoch: 18/20,    batch: 1530/2993    Discriminator_loss: 0.00019065912056248635  Generator_loss: 14.898982048034668\n",
            "epoch: 18/20,    batch: 1531/2993    Discriminator_loss: 6.213328742887825e-05  Generator_loss: 14.898982048034668\n",
            "epoch: 18/20,    batch: 1532/2993    Discriminator_loss: 6.0443799156928435e-06  Generator_loss: 14.898982048034668\n",
            "epoch: 18/20,    batch: 1533/2993    Discriminator_loss: 4.4245796743780375e-05  Generator_loss: 14.898982048034668\n",
            "epoch: 18/20,    batch: 1534/2993    Discriminator_loss: 0.0001718188141239807  Generator_loss: 14.898982048034668\n",
            "epoch: 18/20,    batch: 1535/2993    Discriminator_loss: 9.614849113859236e-05  Generator_loss: 14.898982048034668\n",
            "epoch: 18/20,    batch: 1536/2993    Discriminator_loss: 0.013869444839656353  Generator_loss: 14.898982048034668\n",
            "epoch: 18/20,    batch: 1537/2993    Discriminator_loss: 7.687628385610878e-05  Generator_loss: 14.898982048034668\n",
            "epoch: 18/20,    batch: 1538/2993    Discriminator_loss: 1.7660118828644045e-05  Generator_loss: 14.898982048034668\n",
            "epoch: 18/20,    batch: 1539/2993    Discriminator_loss: 4.814266139874235e-05  Generator_loss: 14.898982048034668\n",
            "epoch: 18/20,    batch: 1540/2993    Discriminator_loss: 0.09331503510475159  Generator_loss: 14.898982048034668\n",
            "epoch: 18/20,    batch: 1541/2993    Discriminator_loss: 0.00021434895461425185  Generator_loss: 14.898982048034668\n",
            "epoch: 18/20,    batch: 1542/2993    Discriminator_loss: 2.6436317057232372e-05  Generator_loss: 14.898982048034668\n",
            "epoch: 18/20,    batch: 1543/2993    Discriminator_loss: 0.1487409472465515  Generator_loss: 14.898982048034668\n",
            "epoch: 18/20,    batch: 1544/2993    Discriminator_loss: 0.00018635109881870449  Generator_loss: 14.898982048034668\n",
            "epoch: 18/20,    batch: 1545/2993    Discriminator_loss: 2.287214738316834e-05  Generator_loss: 14.898982048034668\n",
            "epoch: 18/20,    batch: 1546/2993    Discriminator_loss: 1.6063261032104492  Generator_loss: 14.898982048034668\n",
            "epoch: 18/20,    batch: 1547/2993    Discriminator_loss: 1.5925847037578933e-05  Generator_loss: 14.898982048034668\n",
            "epoch: 18/20,    batch: 1548/2993    Discriminator_loss: 0.00011678547161864117  Generator_loss: 14.898982048034668\n",
            "epoch: 18/20,    batch: 1549/2993    Discriminator_loss: 7.731949153821915e-06  Generator_loss: 14.898982048034668\n",
            "epoch: 18/20,    batch: 1550/2993    Discriminator_loss: 0.10695724934339523  Generator_loss: 14.606639862060547\n",
            "epoch: 18/20,    batch: 1551/2993    Discriminator_loss: 0.0006798257236368954  Generator_loss: 14.597209930419922\n",
            "epoch: 18/20,    batch: 1552/2993    Discriminator_loss: 5.040353244112339e-06  Generator_loss: 14.597209930419922\n",
            "epoch: 18/20,    batch: 1553/2993    Discriminator_loss: 7.308544445550069e-05  Generator_loss: 14.597209930419922\n",
            "epoch: 18/20,    batch: 1554/2993    Discriminator_loss: 0.00014223158359527588  Generator_loss: 14.597209930419922\n",
            "epoch: 18/20,    batch: 1555/2993    Discriminator_loss: 9.555486940371338e-06  Generator_loss: 14.597209930419922\n",
            "epoch: 18/20,    batch: 1556/2993    Discriminator_loss: 0.002764700446277857  Generator_loss: 14.597209930419922\n",
            "epoch: 18/20,    batch: 1557/2993    Discriminator_loss: 0.00035497872158885  Generator_loss: 14.597209930419922\n",
            "epoch: 18/20,    batch: 1558/2993    Discriminator_loss: 1.722230445011519e-05  Generator_loss: 14.597209930419922\n",
            "epoch: 18/20,    batch: 1559/2993    Discriminator_loss: 0.00021311358432285488  Generator_loss: 14.597209930419922\n",
            "epoch: 18/20,    batch: 1560/2993    Discriminator_loss: 3.076149005210027e-05  Generator_loss: 14.597209930419922\n",
            "epoch: 18/20,    batch: 1561/2993    Discriminator_loss: 2.0711080651381053e-05  Generator_loss: 14.597209930419922\n",
            "epoch: 18/20,    batch: 1562/2993    Discriminator_loss: 0.0005479154642671347  Generator_loss: 14.597209930419922\n",
            "epoch: 18/20,    batch: 1563/2993    Discriminator_loss: 6.96267670718953e-06  Generator_loss: 14.597209930419922\n",
            "epoch: 18/20,    batch: 1564/2993    Discriminator_loss: 9.662064258009195e-05  Generator_loss: 14.597209930419922\n",
            "epoch: 18/20,    batch: 1565/2993    Discriminator_loss: 0.00025374640244990587  Generator_loss: 14.597209930419922\n",
            "epoch: 18/20,    batch: 1566/2993    Discriminator_loss: 1.2208022781123873e-05  Generator_loss: 14.597209930419922\n",
            "epoch: 18/20,    batch: 1567/2993    Discriminator_loss: 1.3767010386800393e-05  Generator_loss: 14.597209930419922\n",
            "epoch: 18/20,    batch: 1568/2993    Discriminator_loss: 4.888689727522433e-05  Generator_loss: 14.597209930419922\n",
            "epoch: 18/20,    batch: 1569/2993    Discriminator_loss: 7.387956429738551e-05  Generator_loss: 14.597209930419922\n",
            "epoch: 18/20,    batch: 1570/2993    Discriminator_loss: 6.338183447951451e-05  Generator_loss: 14.597209930419922\n",
            "epoch: 18/20,    batch: 1571/2993    Discriminator_loss: 0.00010106863919645548  Generator_loss: 14.597209930419922\n",
            "epoch: 18/20,    batch: 1572/2993    Discriminator_loss: 2.6414978492539376e-05  Generator_loss: 14.597209930419922\n",
            "epoch: 18/20,    batch: 1573/2993    Discriminator_loss: 5.854331902810372e-06  Generator_loss: 14.597209930419922\n",
            "epoch: 18/20,    batch: 1574/2993    Discriminator_loss: 4.340513260103762e-05  Generator_loss: 14.597209930419922\n",
            "epoch: 18/20,    batch: 1575/2993    Discriminator_loss: 0.0004811968537978828  Generator_loss: 14.597209930419922\n",
            "epoch: 18/20,    batch: 1576/2993    Discriminator_loss: 8.32982641441049e-06  Generator_loss: 14.597209930419922\n",
            "epoch: 18/20,    batch: 1577/2993    Discriminator_loss: 8.935522782849148e-05  Generator_loss: 14.597209930419922\n",
            "epoch: 18/20,    batch: 1578/2993    Discriminator_loss: 5.7096487580565736e-05  Generator_loss: 14.597209930419922\n",
            "epoch: 18/20,    batch: 1579/2993    Discriminator_loss: 5.794749540655175e-06  Generator_loss: 14.430816650390625\n",
            "epoch: 18/20,    batch: 1580/2993    Discriminator_loss: 3.6045676097273827e-05  Generator_loss: 14.365705490112305\n",
            "epoch: 18/20,    batch: 1581/2993    Discriminator_loss: 0.00014308714889921248  Generator_loss: 14.365705490112305\n",
            "epoch: 18/20,    batch: 1582/2993    Discriminator_loss: 2.4605651560705155e-06  Generator_loss: 14.365705490112305\n",
            "epoch: 18/20,    batch: 1583/2993    Discriminator_loss: 0.000543354544788599  Generator_loss: 14.365705490112305\n",
            "epoch: 18/20,    batch: 1584/2993    Discriminator_loss: 0.0011168341152369976  Generator_loss: 14.365705490112305\n",
            "epoch: 18/20,    batch: 1585/2993    Discriminator_loss: 4.110846930416301e-05  Generator_loss: 14.365705490112305\n",
            "epoch: 18/20,    batch: 1586/2993    Discriminator_loss: 0.01850639097392559  Generator_loss: 14.365705490112305\n",
            "epoch: 18/20,    batch: 1587/2993    Discriminator_loss: 0.00014227646170184016  Generator_loss: 14.365705490112305\n",
            "epoch: 18/20,    batch: 1588/2993    Discriminator_loss: 7.050162821542472e-06  Generator_loss: 14.365705490112305\n",
            "epoch: 18/20,    batch: 1589/2993    Discriminator_loss: 0.00015648255066480488  Generator_loss: 14.365705490112305\n",
            "epoch: 18/20,    batch: 1590/2993    Discriminator_loss: 2.8011218091705814e-05  Generator_loss: 14.365705490112305\n",
            "epoch: 18/20,    batch: 1591/2993    Discriminator_loss: 1.5404246369143948e-05  Generator_loss: 14.365705490112305\n",
            "epoch: 18/20,    batch: 1592/2993    Discriminator_loss: 0.0001914163149194792  Generator_loss: 14.365705490112305\n",
            "epoch: 18/20,    batch: 1593/2993    Discriminator_loss: 1.0150147318199743e-05  Generator_loss: 14.365705490112305\n",
            "epoch: 18/20,    batch: 1594/2993    Discriminator_loss: 6.774517532903701e-05  Generator_loss: 14.365705490112305\n",
            "epoch: 18/20,    batch: 1595/2993    Discriminator_loss: 0.00018480057769920677  Generator_loss: 14.365705490112305\n",
            "epoch: 18/20,    batch: 1596/2993    Discriminator_loss: 1.855437585618347e-05  Generator_loss: 14.365705490112305\n",
            "epoch: 18/20,    batch: 1597/2993    Discriminator_loss: 0.0001436815655324608  Generator_loss: 14.365705490112305\n",
            "epoch: 18/20,    batch: 1598/2993    Discriminator_loss: 6.066687637940049e-05  Generator_loss: 14.365705490112305\n",
            "epoch: 18/20,    batch: 1599/2993    Discriminator_loss: 1.8889921193476766e-05  Generator_loss: 14.365705490112305\n",
            "epoch: 18/20,    batch: 1600/2993    Discriminator_loss: 1.5717228961875662e-05  Generator_loss: 14.365705490112305\n",
            "epoch: 18/20,    batch: 1601/2993    Discriminator_loss: 3.290646418463439e-05  Generator_loss: 14.365705490112305\n",
            "epoch: 18/20,    batch: 1602/2993    Discriminator_loss: 7.727577030891553e-05  Generator_loss: 14.365705490112305\n",
            "epoch: 18/20,    batch: 1603/2993    Discriminator_loss: 0.0005817697965539992  Generator_loss: 14.365705490112305\n",
            "epoch: 18/20,    batch: 1604/2993    Discriminator_loss: 0.7846150398254395  Generator_loss: 14.365705490112305\n",
            "epoch: 18/20,    batch: 1605/2993    Discriminator_loss: 0.0021339687518775463  Generator_loss: 14.365705490112305\n",
            "epoch: 18/20,    batch: 1606/2993    Discriminator_loss: 0.0011452215258032084  Generator_loss: 14.177849769592285\n",
            "epoch: 18/20,    batch: 1607/2993    Discriminator_loss: 0.010527896694839  Generator_loss: 14.177849769592285\n",
            "epoch: 18/20,    batch: 1608/2993    Discriminator_loss: 0.0005176368285901845  Generator_loss: 14.177849769592285\n",
            "epoch: 18/20,    batch: 1609/2993    Discriminator_loss: 0.00081768783275038  Generator_loss: 14.177849769592285\n",
            "epoch: 18/20,    batch: 1610/2993    Discriminator_loss: 0.017739227041602135  Generator_loss: 14.177849769592285\n",
            "epoch: 18/20,    batch: 1611/2993    Discriminator_loss: 0.000782205315772444  Generator_loss: 14.177849769592285\n",
            "epoch: 18/20,    batch: 1612/2993    Discriminator_loss: 7.735982217127457e-05  Generator_loss: 14.177849769592285\n",
            "epoch: 18/20,    batch: 1613/2993    Discriminator_loss: 5.964280262560351e-06  Generator_loss: 14.177849769592285\n",
            "epoch: 18/20,    batch: 1614/2993    Discriminator_loss: 3.2191052014240995e-05  Generator_loss: 14.177849769592285\n",
            "epoch: 18/20,    batch: 1615/2993    Discriminator_loss: 9.412737563252449e-05  Generator_loss: 14.177849769592285\n",
            "epoch: 18/20,    batch: 1616/2993    Discriminator_loss: 5.4718777391826734e-05  Generator_loss: 14.177849769592285\n",
            "epoch: 18/20,    batch: 1617/2993    Discriminator_loss: 1.8949089280795306e-05  Generator_loss: 14.177849769592285\n",
            "epoch: 18/20,    batch: 1618/2993    Discriminator_loss: 0.0015388083411380649  Generator_loss: 14.177849769592285\n",
            "epoch: 18/20,    batch: 1619/2993    Discriminator_loss: 5.72652425034903e-05  Generator_loss: 14.177849769592285\n",
            "epoch: 18/20,    batch: 1620/2993    Discriminator_loss: 2.1275582184898667e-05  Generator_loss: 14.019763946533203\n",
            "epoch: 18/20,    batch: 1621/2993    Discriminator_loss: 0.0008173759561032057  Generator_loss: 14.019763946533203\n",
            "epoch: 18/20,    batch: 1622/2993    Discriminator_loss: 4.731162789539667e-06  Generator_loss: 14.019763946533203\n",
            "epoch: 18/20,    batch: 1623/2993    Discriminator_loss: 0.0025215838104486465  Generator_loss: 14.019763946533203\n",
            "epoch: 18/20,    batch: 1624/2993    Discriminator_loss: 0.0003664471732918173  Generator_loss: 14.019763946533203\n",
            "epoch: 18/20,    batch: 1625/2993    Discriminator_loss: 8.498616807628423e-05  Generator_loss: 14.019763946533203\n",
            "epoch: 18/20,    batch: 1626/2993    Discriminator_loss: 0.0004659746482502669  Generator_loss: 14.019763946533203\n",
            "epoch: 18/20,    batch: 1627/2993    Discriminator_loss: 0.00015988221275620162  Generator_loss: 14.019763946533203\n",
            "epoch: 18/20,    batch: 1628/2993    Discriminator_loss: 4.867118150286842e-06  Generator_loss: 14.019763946533203\n",
            "epoch: 18/20,    batch: 1629/2993    Discriminator_loss: 6.72590103931725e-05  Generator_loss: 13.917409896850586\n",
            "epoch: 18/20,    batch: 1630/2993    Discriminator_loss: 0.00015258044004440308  Generator_loss: 13.883291244506836\n",
            "epoch: 18/20,    batch: 1631/2993    Discriminator_loss: 7.0892874646233395e-06  Generator_loss: 13.883291244506836\n",
            "epoch: 18/20,    batch: 1632/2993    Discriminator_loss: 0.00030366823193617165  Generator_loss: 13.883291244506836\n",
            "epoch: 18/20,    batch: 1633/2993    Discriminator_loss: 5.2615534514188766e-05  Generator_loss: 13.883291244506836\n",
            "epoch: 18/20,    batch: 1634/2993    Discriminator_loss: 1.8932474631583318e-05  Generator_loss: 13.883291244506836\n",
            "epoch: 18/20,    batch: 1635/2993    Discriminator_loss: 4.4124069972895086e-05  Generator_loss: 13.883291244506836\n",
            "epoch: 18/20,    batch: 1636/2993    Discriminator_loss: 5.5523392802570015e-05  Generator_loss: 13.883291244506836\n",
            "epoch: 18/20,    batch: 1637/2993    Discriminator_loss: 8.896102372091264e-05  Generator_loss: 13.763227462768555\n",
            "epoch: 18/20,    batch: 1638/2993    Discriminator_loss: 1.0253931577608455e-05  Generator_loss: 13.763227462768555\n",
            "epoch: 18/20,    batch: 1639/2993    Discriminator_loss: 0.0009751015459187329  Generator_loss: 13.763227462768555\n",
            "epoch: 18/20,    batch: 1640/2993    Discriminator_loss: 2.4058448616415262e-05  Generator_loss: 13.763227462768555\n",
            "epoch: 18/20,    batch: 1641/2993    Discriminator_loss: 4.0375107346335426e-05  Generator_loss: 13.763227462768555\n",
            "epoch: 18/20,    batch: 1642/2993    Discriminator_loss: 1.818525925045833e-05  Generator_loss: 13.656044960021973\n",
            "epoch: 18/20,    batch: 1643/2993    Discriminator_loss: 0.0001614924694877118  Generator_loss: 13.656044960021973\n",
            "epoch: 18/20,    batch: 1644/2993    Discriminator_loss: 5.47398449270986e-05  Generator_loss: 13.656044960021973\n",
            "epoch: 18/20,    batch: 1645/2993    Discriminator_loss: 0.0032053119502961636  Generator_loss: 13.656044960021973\n",
            "epoch: 18/20,    batch: 1646/2993    Discriminator_loss: 5.7655215641716495e-05  Generator_loss: 13.559247016906738\n",
            "epoch: 18/20,    batch: 1647/2993    Discriminator_loss: 2.7126519853482023e-05  Generator_loss: 13.559247016906738\n",
            "epoch: 18/20,    batch: 1648/2993    Discriminator_loss: 1.6220248653553426e-05  Generator_loss: 13.559247016906738\n",
            "epoch: 18/20,    batch: 1649/2993    Discriminator_loss: 1.675481144047808e-05  Generator_loss: 13.559247016906738\n",
            "epoch: 18/20,    batch: 1650/2993    Discriminator_loss: 0.00028702212148346007  Generator_loss: 13.47099781036377\n",
            "epoch: 18/20,    batch: 1651/2993    Discriminator_loss: 8.656885620439425e-05  Generator_loss: 13.47099781036377\n",
            "epoch: 18/20,    batch: 1652/2993    Discriminator_loss: 0.10645489394664764  Generator_loss: 13.389908790588379\n",
            "epoch: 18/20,    batch: 1653/2993    Discriminator_loss: 0.00011326074309181422  Generator_loss: 13.389908790588379\n",
            "epoch: 18/20,    batch: 1654/2993    Discriminator_loss: 3.1851363928581122e-06  Generator_loss: 13.31490421295166\n",
            "epoch: 18/20,    batch: 1655/2993    Discriminator_loss: 6.235163164092228e-05  Generator_loss: 13.31490421295166\n",
            "epoch: 18/20,    batch: 1656/2993    Discriminator_loss: 0.00016870320541784167  Generator_loss: 13.245135307312012\n",
            "epoch: 18/20,    batch: 1657/2993    Discriminator_loss: 1.2437064469850156e-05  Generator_loss: 13.245135307312012\n",
            "epoch: 18/20,    batch: 1658/2993    Discriminator_loss: 6.16348916082643e-05  Generator_loss: 13.17991828918457\n",
            "epoch: 18/20,    batch: 1659/2993    Discriminator_loss: 0.0001429347030352801  Generator_loss: 13.17991828918457\n",
            "epoch: 18/20,    batch: 1660/2993    Discriminator_loss: 7.912582077551633e-06  Generator_loss: 13.118696212768555\n",
            "epoch: 18/20,    batch: 1661/2993    Discriminator_loss: 0.00025856366846710443  Generator_loss: 13.118696212768555\n",
            "epoch: 18/20,    batch: 1662/2993    Discriminator_loss: 8.787716797087342e-05  Generator_loss: 13.061005592346191\n",
            "epoch: 18/20,    batch: 1663/2993    Discriminator_loss: 9.04505213839002e-06  Generator_loss: 13.006463050842285\n",
            "epoch: 18/20,    batch: 1664/2993    Discriminator_loss: 0.00015314291522372514  Generator_loss: 13.006463050842285\n",
            "epoch: 18/20,    batch: 1665/2993    Discriminator_loss: 0.00010062369983643293  Generator_loss: 12.954742431640625\n",
            "epoch: 18/20,    batch: 1666/2993    Discriminator_loss: 1.8934051695396192e-05  Generator_loss: 12.90556526184082\n",
            "epoch: 18/20,    batch: 1667/2993    Discriminator_loss: 6.070585732231848e-05  Generator_loss: 12.858694076538086\n",
            "epoch: 18/20,    batch: 1668/2993    Discriminator_loss: 1.6434350982308388e-05  Generator_loss: 12.858694076538086\n",
            "epoch: 18/20,    batch: 1669/2993    Discriminator_loss: 2.1264322640490718e-05  Generator_loss: 12.813921928405762\n",
            "epoch: 18/20,    batch: 1670/2993    Discriminator_loss: 0.0048743984661996365  Generator_loss: 12.771068572998047\n",
            "epoch: 18/20,    batch: 1671/2993    Discriminator_loss: 0.00012828086619265378  Generator_loss: 12.729975700378418\n",
            "epoch: 18/20,    batch: 1672/2993    Discriminator_loss: 4.585842361848336e-06  Generator_loss: 12.690505981445312\n",
            "epoch: 18/20,    batch: 1673/2993    Discriminator_loss: 0.0003179517516400665  Generator_loss: 12.690505981445312\n",
            "epoch: 18/20,    batch: 1674/2993    Discriminator_loss: 0.00021403418213594705  Generator_loss: 12.652534484863281\n",
            "epoch: 18/20,    batch: 1675/2993    Discriminator_loss: 2.4217457394115627e-05  Generator_loss: 12.615952491760254\n",
            "epoch: 18/20,    batch: 1676/2993    Discriminator_loss: 3.367612589499913e-05  Generator_loss: 12.615952491760254\n",
            "epoch: 18/20,    batch: 1677/2993    Discriminator_loss: 0.00011185608309460804  Generator_loss: 12.58066177368164\n",
            "epoch: 18/20,    batch: 1678/2993    Discriminator_loss: 7.52689375076443e-05  Generator_loss: 12.58066177368164\n",
            "epoch: 18/20,    batch: 1679/2993    Discriminator_loss: 2.998173476953525e-05  Generator_loss: 12.58066177368164\n",
            "epoch: 18/20,    batch: 1680/2993    Discriminator_loss: 8.535513188689947e-05  Generator_loss: 12.546573638916016\n",
            "epoch: 18/20,    batch: 1681/2993    Discriminator_loss: 1.1652839020825922e-05  Generator_loss: 12.546573638916016\n",
            "epoch: 18/20,    batch: 1682/2993    Discriminator_loss: 1.5497338608838618e-05  Generator_loss: 12.513609886169434\n",
            "epoch: 18/20,    batch: 1683/2993    Discriminator_loss: 6.206091347848997e-05  Generator_loss: 12.513609886169434\n",
            "epoch: 18/20,    batch: 1684/2993    Discriminator_loss: 0.00010339627624489367  Generator_loss: 12.513609886169434\n",
            "epoch: 18/20,    batch: 1685/2993    Discriminator_loss: 1.4417034435609821e-05  Generator_loss: 12.481698036193848\n",
            "epoch: 18/20,    batch: 1686/2993    Discriminator_loss: 0.0011073790956288576  Generator_loss: 12.481698036193848\n",
            "epoch: 18/20,    batch: 1687/2993    Discriminator_loss: 7.382289186352864e-05  Generator_loss: 12.481698036193848\n",
            "epoch: 18/20,    batch: 1688/2993    Discriminator_loss: 1.3036749805905856e-05  Generator_loss: 12.481698036193848\n",
            "epoch: 18/20,    batch: 1689/2993    Discriminator_loss: 0.002628948772326112  Generator_loss: 12.450772285461426\n",
            "epoch: 18/20,    batch: 1690/2993    Discriminator_loss: 0.00014256844588089734  Generator_loss: 12.450772285461426\n",
            "epoch: 18/20,    batch: 1691/2993    Discriminator_loss: 2.392043825238943e-05  Generator_loss: 12.450772285461426\n",
            "epoch: 18/20,    batch: 1692/2993    Discriminator_loss: 0.00010433981515234336  Generator_loss: 12.420775413513184\n",
            "epoch: 18/20,    batch: 1693/2993    Discriminator_loss: 7.87157205195399e-06  Generator_loss: 12.420775413513184\n",
            "epoch: 18/20,    batch: 1694/2993    Discriminator_loss: 8.15671228338033e-05  Generator_loss: 12.420775413513184\n",
            "epoch: 18/20,    batch: 1695/2993    Discriminator_loss: 0.00011903727136086673  Generator_loss: 12.420775413513184\n",
            "epoch: 18/20,    batch: 1696/2993    Discriminator_loss: 7.443156391673256e-06  Generator_loss: 12.39165210723877\n",
            "epoch: 18/20,    batch: 1697/2993    Discriminator_loss: 4.6237066271714866e-05  Generator_loss: 12.39165210723877\n",
            "epoch: 18/20,    batch: 1698/2993    Discriminator_loss: 0.00011724987416528165  Generator_loss: 12.39165210723877\n",
            "epoch: 18/20,    batch: 1699/2993    Discriminator_loss: 1.1894950148416683e-05  Generator_loss: 12.39165210723877\n",
            "epoch: 18/20,    batch: 1700/2993    Discriminator_loss: 4.977573189535178e-05  Generator_loss: 12.39165210723877\n",
            "epoch: 18/20,    batch: 1701/2993    Discriminator_loss: 4.579238884616643e-05  Generator_loss: 12.36335277557373\n",
            "epoch: 18/20,    batch: 1702/2993    Discriminator_loss: 6.385185770341195e-06  Generator_loss: 12.36335277557373\n",
            "epoch: 18/20,    batch: 1703/2993    Discriminator_loss: 2.550926001276821e-05  Generator_loss: 12.36335277557373\n",
            "epoch: 18/20,    batch: 1704/2993    Discriminator_loss: 5.592935485765338e-05  Generator_loss: 12.36335277557373\n",
            "epoch: 18/20,    batch: 1705/2993    Discriminator_loss: 3.063774056499824e-05  Generator_loss: 12.335831642150879\n",
            "epoch: 18/20,    batch: 1706/2993    Discriminator_loss: 4.990280285710469e-05  Generator_loss: 12.335831642150879\n",
            "epoch: 18/20,    batch: 1707/2993    Discriminator_loss: 0.001539759337902069  Generator_loss: 12.335831642150879\n",
            "epoch: 18/20,    batch: 1708/2993    Discriminator_loss: 0.0001024263328872621  Generator_loss: 12.335831642150879\n",
            "epoch: 18/20,    batch: 1709/2993    Discriminator_loss: 8.696734766999725e-06  Generator_loss: 12.309048652648926\n",
            "epoch: 18/20,    batch: 1710/2993    Discriminator_loss: 5.9260295529384166e-05  Generator_loss: 12.309048652648926\n",
            "epoch: 18/20,    batch: 1711/2993    Discriminator_loss: 0.0001004872246994637  Generator_loss: 12.309048652648926\n",
            "epoch: 18/20,    batch: 1712/2993    Discriminator_loss: 3.094706335105002e-05  Generator_loss: 12.309048652648926\n",
            "epoch: 18/20,    batch: 1713/2993    Discriminator_loss: 6.654639582848176e-05  Generator_loss: 12.282963752746582\n",
            "epoch: 18/20,    batch: 1714/2993    Discriminator_loss: 0.3166640102863312  Generator_loss: 12.257542610168457\n",
            "epoch: 18/20,    batch: 1715/2993    Discriminator_loss: 5.220072853262536e-05  Generator_loss: 12.23275089263916\n",
            "epoch: 18/20,    batch: 1716/2993    Discriminator_loss: 3.399270644877106e-05  Generator_loss: 12.2085599899292\n",
            "epoch: 18/20,    batch: 1717/2993    Discriminator_loss: 2.8996502805966884e-05  Generator_loss: 12.18493938446045\n",
            "epoch: 18/20,    batch: 1718/2993    Discriminator_loss: 7.68933241488412e-05  Generator_loss: 12.161864280700684\n",
            "epoch: 18/20,    batch: 1719/2993    Discriminator_loss: 2.2161217202665284e-05  Generator_loss: 12.139309883117676\n",
            "epoch: 18/20,    batch: 1720/2993    Discriminator_loss: 0.03416728228330612  Generator_loss: 12.139309883117676\n",
            "epoch: 18/20,    batch: 1721/2993    Discriminator_loss: 0.03464379534125328  Generator_loss: 12.095671653747559\n",
            "epoch: 18/20,    batch: 1722/2993    Discriminator_loss: 1.782597064448055e-05  Generator_loss: 12.074546813964844\n",
            "epoch: 18/20,    batch: 1723/2993    Discriminator_loss: 6.472975655924529e-05  Generator_loss: 12.053858757019043\n",
            "epoch: 18/20,    batch: 1724/2993    Discriminator_loss: 6.494602712336928e-05  Generator_loss: 12.053858757019043\n",
            "epoch: 18/20,    batch: 1725/2993    Discriminator_loss: 1.657041320868302e-05  Generator_loss: 12.033590316772461\n",
            "epoch: 18/20,    batch: 1726/2993    Discriminator_loss: 0.0013969182036817074  Generator_loss: 12.013724327087402\n",
            "epoch: 18/20,    batch: 1727/2993    Discriminator_loss: 0.00011715615983121097  Generator_loss: 12.013724327087402\n",
            "epoch: 18/20,    batch: 1728/2993    Discriminator_loss: 7.065702811814845e-05  Generator_loss: 11.994245529174805\n",
            "epoch: 18/20,    batch: 1729/2993    Discriminator_loss: 4.1396531742066145e-05  Generator_loss: 11.994245529174805\n",
            "epoch: 18/20,    batch: 1730/2993    Discriminator_loss: 6.878290150780231e-05  Generator_loss: 11.975138664245605\n",
            "epoch: 18/20,    batch: 1731/2993    Discriminator_loss: 1.4443039617617615e-05  Generator_loss: 11.975138664245605\n",
            "epoch: 18/20,    batch: 1732/2993    Discriminator_loss: 5.961395436315797e-05  Generator_loss: 11.956389427185059\n",
            "epoch: 18/20,    batch: 1733/2993    Discriminator_loss: 5.720786430174485e-05  Generator_loss: 11.956389427185059\n",
            "epoch: 18/20,    batch: 1734/2993    Discriminator_loss: 1.418414649378974e-05  Generator_loss: 11.956389427185059\n",
            "epoch: 18/20,    batch: 1735/2993    Discriminator_loss: 0.0004446640668902546  Generator_loss: 11.937986373901367\n",
            "epoch: 18/20,    batch: 1736/2993    Discriminator_loss: 2.9840135539416224e-05  Generator_loss: 11.937986373901367\n",
            "epoch: 18/20,    batch: 1737/2993    Discriminator_loss: 1.8086480849888176e-05  Generator_loss: 11.937986373901367\n",
            "epoch: 18/20,    batch: 1738/2993    Discriminator_loss: 3.87141844839789e-05  Generator_loss: 11.940353393554688\n",
            "epoch: 18/20,    batch: 1739/2993    Discriminator_loss: 5.35164144821465e-05  Generator_loss: 11.919915199279785\n",
            "epoch: 18/20,    batch: 1740/2993    Discriminator_loss: 3.026343256351538e-05  Generator_loss: 11.919915199279785\n",
            "epoch: 18/20,    batch: 1741/2993    Discriminator_loss: 6.432558438973501e-05  Generator_loss: 11.919915199279785\n",
            "epoch: 18/20,    batch: 1742/2993    Discriminator_loss: 4.939374412060715e-05  Generator_loss: 11.919915199279785\n",
            "epoch: 18/20,    batch: 1743/2993    Discriminator_loss: 1.1827864000224508e-05  Generator_loss: 11.902165412902832\n",
            "epoch: 18/20,    batch: 1744/2993    Discriminator_loss: 1.911086837935727e-05  Generator_loss: 11.902165412902832\n",
            "epoch: 18/20,    batch: 1745/2993    Discriminator_loss: 9.352046618005261e-05  Generator_loss: 11.902165412902832\n",
            "epoch: 18/20,    batch: 1746/2993    Discriminator_loss: 7.17679358785972e-06  Generator_loss: 11.902165412902832\n",
            "epoch: 18/20,    batch: 1747/2993    Discriminator_loss: 0.00022874896239954978  Generator_loss: 11.884724617004395\n",
            "epoch: 18/20,    batch: 1748/2993    Discriminator_loss: 0.0001683373557170853  Generator_loss: 11.884724617004395\n",
            "epoch: 18/20,    batch: 1749/2993    Discriminator_loss: 1.097106905945111e-05  Generator_loss: 11.884724617004395\n",
            "epoch: 18/20,    batch: 1750/2993    Discriminator_loss: 1.4210188965080306e-05  Generator_loss: 11.884724617004395\n",
            "epoch: 18/20,    batch: 1751/2993    Discriminator_loss: 5.8474317484069616e-05  Generator_loss: 11.884724617004395\n",
            "epoch: 18/20,    batch: 1752/2993    Discriminator_loss: 4.620961772161536e-05  Generator_loss: 11.867582321166992\n",
            "epoch: 18/20,    batch: 1753/2993    Discriminator_loss: 4.440100019564852e-05  Generator_loss: 11.867582321166992\n",
            "epoch: 18/20,    batch: 1754/2993    Discriminator_loss: 9.028096246765926e-05  Generator_loss: 11.867582321166992\n",
            "epoch: 18/20,    batch: 1755/2993    Discriminator_loss: 1.7037886209436692e-05  Generator_loss: 11.867582321166992\n",
            "epoch: 18/20,    batch: 1756/2993    Discriminator_loss: 5.942855932516977e-05  Generator_loss: 11.867582321166992\n",
            "epoch: 18/20,    batch: 1757/2993    Discriminator_loss: 0.00013603769184555858  Generator_loss: 11.850729942321777\n",
            "epoch: 18/20,    batch: 1758/2993    Discriminator_loss: 9.853426490735728e-06  Generator_loss: 11.850729942321777\n",
            "epoch: 18/20,    batch: 1759/2993    Discriminator_loss: 6.158976611914113e-05  Generator_loss: 11.850729942321777\n",
            "epoch: 18/20,    batch: 1760/2993    Discriminator_loss: 0.00012171803246019408  Generator_loss: 11.850729942321777\n",
            "epoch: 18/20,    batch: 1761/2993    Discriminator_loss: 1.3584340194938704e-05  Generator_loss: 11.850729942321777\n",
            "epoch: 18/20,    batch: 1762/2993    Discriminator_loss: 3.794867734541185e-05  Generator_loss: 11.834156036376953\n",
            "epoch: 18/20,    batch: 1763/2993    Discriminator_loss: 4.123434700886719e-05  Generator_loss: 11.834156036376953\n",
            "epoch: 18/20,    batch: 1764/2993    Discriminator_loss: 1.3526583643397316e-05  Generator_loss: 11.834156036376953\n",
            "epoch: 18/20,    batch: 1765/2993    Discriminator_loss: 5.8537676522973925e-05  Generator_loss: 11.834156036376953\n",
            "epoch: 18/20,    batch: 1766/2993    Discriminator_loss: 9.091104584513232e-05  Generator_loss: 11.834156036376953\n",
            "epoch: 18/20,    batch: 1767/2993    Discriminator_loss: 2.5358396669616923e-05  Generator_loss: 11.834156036376953\n",
            "epoch: 18/20,    batch: 1768/2993    Discriminator_loss: 0.00011406748672015965  Generator_loss: 11.817852973937988\n",
            "epoch: 18/20,    batch: 1769/2993    Discriminator_loss: 1.7818232663557865e-05  Generator_loss: 11.817852973937988\n",
            "epoch: 18/20,    batch: 1770/2993    Discriminator_loss: 1.437968785467092e-05  Generator_loss: 11.817852973937988\n",
            "epoch: 18/20,    batch: 1771/2993    Discriminator_loss: 3.330651452415623e-05  Generator_loss: 11.817852973937988\n",
            "epoch: 18/20,    batch: 1772/2993    Discriminator_loss: 0.00013146959827281535  Generator_loss: 11.817852973937988\n",
            "epoch: 18/20,    batch: 1773/2993    Discriminator_loss: 1.348749083263101e-05  Generator_loss: 11.801811218261719\n",
            "epoch: 18/20,    batch: 1774/2993    Discriminator_loss: 5.213162876316346e-05  Generator_loss: 11.801811218261719\n",
            "epoch: 18/20,    batch: 1775/2993    Discriminator_loss: 3.509477392071858e-05  Generator_loss: 11.801811218261719\n",
            "epoch: 18/20,    batch: 1776/2993    Discriminator_loss: 1.2530074855021667e-05  Generator_loss: 11.801811218261719\n",
            "epoch: 18/20,    batch: 1777/2993    Discriminator_loss: 3.405416646273807e-05  Generator_loss: 11.801811218261719\n",
            "epoch: 18/20,    batch: 1778/2993    Discriminator_loss: 0.00013232194760348648  Generator_loss: 11.786023139953613\n",
            "epoch: 18/20,    batch: 1779/2993    Discriminator_loss: 1.0630157703417353e-05  Generator_loss: 11.786023139953613\n",
            "epoch: 18/20,    batch: 1780/2993    Discriminator_loss: 4.669999907491729e-05  Generator_loss: 11.786023139953613\n",
            "epoch: 18/20,    batch: 1781/2993    Discriminator_loss: 5.259343015495688e-05  Generator_loss: 11.786023139953613\n",
            "epoch: 18/20,    batch: 1782/2993    Discriminator_loss: 8.877398613549303e-06  Generator_loss: 11.773394584655762\n",
            "epoch: 18/20,    batch: 1783/2993    Discriminator_loss: 2.3188356863101944e-05  Generator_loss: 11.770480155944824\n",
            "epoch: 18/20,    batch: 1784/2993    Discriminator_loss: 9.4583272584714e-05  Generator_loss: 11.770480155944824\n",
            "epoch: 18/20,    batch: 1785/2993    Discriminator_loss: 3.117852975265123e-05  Generator_loss: 11.770480155944824\n",
            "epoch: 18/20,    batch: 1786/2993    Discriminator_loss: 3.7140405765967444e-05  Generator_loss: 11.770480155944824\n",
            "epoch: 18/20,    batch: 1787/2993    Discriminator_loss: 8.55144317029044e-05  Generator_loss: 11.75517463684082\n",
            "epoch: 18/20,    batch: 1788/2993    Discriminator_loss: 9.585206498741172e-06  Generator_loss: 11.75517463684082\n",
            "epoch: 18/20,    batch: 1789/2993    Discriminator_loss: 4.944936517858878e-05  Generator_loss: 11.75517463684082\n",
            "epoch: 18/20,    batch: 1790/2993    Discriminator_loss: 8.206303755287081e-05  Generator_loss: 11.75517463684082\n",
            "epoch: 18/20,    batch: 1791/2993    Discriminator_loss: 1.3258367289381567e-05  Generator_loss: 11.740100860595703\n",
            "epoch: 18/20,    batch: 1792/2993    Discriminator_loss: 5.444182170322165e-05  Generator_loss: 11.740100860595703\n",
            "epoch: 18/20,    batch: 1793/2993    Discriminator_loss: 5.461269392981194e-05  Generator_loss: 11.740100860595703\n",
            "epoch: 18/20,    batch: 1794/2993    Discriminator_loss: 1.8108756194123998e-05  Generator_loss: 11.740100860595703\n",
            "epoch: 18/20,    batch: 1795/2993    Discriminator_loss: 3.7849738873774186e-05  Generator_loss: 11.725250244140625\n",
            "epoch: 18/20,    batch: 1796/2993    Discriminator_loss: 1.9235912986914627e-05  Generator_loss: 11.725250244140625\n",
            "epoch: 18/20,    batch: 1797/2993    Discriminator_loss: 2.4490384021191858e-05  Generator_loss: 11.725250244140625\n",
            "epoch: 18/20,    batch: 1798/2993    Discriminator_loss: 7.289453060366213e-05  Generator_loss: 11.710617065429688\n",
            "epoch: 18/20,    batch: 1799/2993    Discriminator_loss: 1.8585727957542986e-05  Generator_loss: 11.710617065429688\n",
            "epoch: 18/20,    batch: 1800/2993    Discriminator_loss: 5.514328950084746e-05  Generator_loss: 11.710617065429688\n",
            "epoch: 18/20,    batch: 1801/2993    Discriminator_loss: 4.2545620090095326e-05  Generator_loss: 11.710166931152344\n",
            "epoch: 18/20,    batch: 1802/2993    Discriminator_loss: 1.4562248907168396e-05  Generator_loss: 11.696194648742676\n",
            "epoch: 18/20,    batch: 1803/2993    Discriminator_loss: 1.406118281011004e-05  Generator_loss: 11.696194648742676\n",
            "epoch: 18/20,    batch: 1804/2993    Discriminator_loss: 2.7085035981144756e-05  Generator_loss: 11.696194648742676\n",
            "epoch: 18/20,    batch: 1805/2993    Discriminator_loss: 6.191655847942457e-05  Generator_loss: 11.681977272033691\n",
            "epoch: 18/20,    batch: 1806/2993    Discriminator_loss: 1.3122415111865848e-05  Generator_loss: 11.681977272033691\n",
            "epoch: 18/20,    batch: 1807/2993    Discriminator_loss: 4.041222564410418e-05  Generator_loss: 11.681977272033691\n",
            "epoch: 18/20,    batch: 1808/2993    Discriminator_loss: 3.6508397897705436e-05  Generator_loss: 11.667959213256836\n",
            "epoch: 18/20,    batch: 1809/2993    Discriminator_loss: 1.0529578503337689e-05  Generator_loss: 11.667959213256836\n",
            "epoch: 18/20,    batch: 1810/2993    Discriminator_loss: 1.9945331587223336e-05  Generator_loss: 11.667959213256836\n",
            "epoch: 18/20,    batch: 1811/2993    Discriminator_loss: 3.8350699469447136e-05  Generator_loss: 11.654135704040527\n",
            "epoch: 18/20,    batch: 1812/2993    Discriminator_loss: 7.703907613176852e-05  Generator_loss: 11.654135704040527\n",
            "epoch: 18/20,    batch: 1813/2993    Discriminator_loss: 1.83285737875849e-05  Generator_loss: 11.654135704040527\n",
            "epoch: 18/20,    batch: 1814/2993    Discriminator_loss: 0.0005281391786411405  Generator_loss: 11.64050006866455\n",
            "epoch: 18/20,    batch: 1815/2993    Discriminator_loss: 4.779288428835571e-05  Generator_loss: 11.64050006866455\n",
            "epoch: 18/20,    batch: 1816/2993    Discriminator_loss: 1.0807123544509523e-05  Generator_loss: 11.64050006866455\n",
            "epoch: 18/20,    batch: 1817/2993    Discriminator_loss: 1.7408394342055544e-05  Generator_loss: 11.627047538757324\n",
            "epoch: 18/20,    batch: 1818/2993    Discriminator_loss: 3.9890110201667994e-05  Generator_loss: 11.627047538757324\n",
            "epoch: 18/20,    batch: 1819/2993    Discriminator_loss: 7.106376870069653e-05  Generator_loss: 11.627047538757324\n",
            "epoch: 18/20,    batch: 1820/2993    Discriminator_loss: 1.7820075299823657e-05  Generator_loss: 11.613774299621582\n",
            "epoch: 18/20,    batch: 1821/2993    Discriminator_loss: 8.63584500621073e-05  Generator_loss: 11.613774299621582\n",
            "epoch: 18/20,    batch: 1822/2993    Discriminator_loss: 7.483068475266919e-05  Generator_loss: 11.613774299621582\n",
            "epoch: 18/20,    batch: 1823/2993    Discriminator_loss: 1.4815556824032683e-05  Generator_loss: 11.600674629211426\n",
            "epoch: 18/20,    batch: 1824/2993    Discriminator_loss: 0.00010254046355839819  Generator_loss: 11.600674629211426\n",
            "epoch: 18/20,    batch: 1825/2993    Discriminator_loss: 2.7886499083251692e-05  Generator_loss: 11.600674629211426\n",
            "epoch: 18/20,    batch: 1826/2993    Discriminator_loss: 2.4721357476664707e-05  Generator_loss: 11.58774471282959\n",
            "epoch: 18/20,    batch: 1827/2993    Discriminator_loss: 0.0001623830321477726  Generator_loss: 11.58774471282959\n",
            "epoch: 18/20,    batch: 1828/2993    Discriminator_loss: 4.323077155277133e-05  Generator_loss: 11.586946487426758\n",
            "epoch: 18/20,    batch: 1829/2993    Discriminator_loss: 6.833563384134322e-05  Generator_loss: 11.574978828430176\n",
            "epoch: 18/20,    batch: 1830/2993    Discriminator_loss: 0.00012135184078942984  Generator_loss: 11.574978828430176\n",
            "epoch: 18/20,    batch: 1831/2993    Discriminator_loss: 1.1406903468014207e-05  Generator_loss: 11.56237506866455\n",
            "epoch: 18/20,    batch: 1832/2993    Discriminator_loss: 2.6339943360653706e-05  Generator_loss: 11.56237506866455\n",
            "epoch: 18/20,    batch: 1833/2993    Discriminator_loss: 0.00011072428605984896  Generator_loss: 11.56237506866455\n",
            "epoch: 18/20,    batch: 1834/2993    Discriminator_loss: 1.3824628695147112e-05  Generator_loss: 11.549927711486816\n",
            "epoch: 18/20,    batch: 1835/2993    Discriminator_loss: 0.00010002406634157524  Generator_loss: 11.549927711486816\n",
            "epoch: 18/20,    batch: 1836/2993    Discriminator_loss: 0.00018835616356227547  Generator_loss: 11.549543380737305\n",
            "epoch: 18/20,    batch: 1837/2993    Discriminator_loss: 1.1775695384130813e-05  Generator_loss: 11.537632942199707\n",
            "epoch: 18/20,    batch: 1838/2993    Discriminator_loss: 3.977763481088914e-05  Generator_loss: 11.537632942199707\n",
            "epoch: 18/20,    batch: 1839/2993    Discriminator_loss: 0.0001397649321006611  Generator_loss: 11.525487899780273\n",
            "epoch: 18/20,    batch: 1840/2993    Discriminator_loss: 1.710506694507785e-05  Generator_loss: 11.525487899780273\n",
            "epoch: 18/20,    batch: 1841/2993    Discriminator_loss: 3.847369225695729e-05  Generator_loss: 11.519113540649414\n",
            "epoch: 18/20,    batch: 1842/2993    Discriminator_loss: 7.59795366320759e-05  Generator_loss: 11.51348876953125\n",
            "epoch: 18/20,    batch: 1843/2993    Discriminator_loss: 2.614856930449605e-05  Generator_loss: 11.51348876953125\n",
            "epoch: 18/20,    batch: 1844/2993    Discriminator_loss: 2.1169114916119725e-05  Generator_loss: 11.501631736755371\n",
            "epoch: 18/20,    batch: 1845/2993    Discriminator_loss: 7.330179505515844e-05  Generator_loss: 11.5027437210083\n",
            "epoch: 18/20,    batch: 1846/2993    Discriminator_loss: 4.390323010738939e-05  Generator_loss: 11.495772361755371\n",
            "epoch: 18/20,    batch: 1847/2993    Discriminator_loss: 2.5360253857797943e-05  Generator_loss: 11.489912986755371\n",
            "epoch: 18/20,    batch: 1848/2993    Discriminator_loss: 0.00011253451521042734  Generator_loss: 11.489912986755371\n",
            "epoch: 18/20,    batch: 1849/2993    Discriminator_loss: 3.9840011595515534e-05  Generator_loss: 11.47905445098877\n",
            "epoch: 18/20,    batch: 1850/2993    Discriminator_loss: 1.7378573829773813e-05  Generator_loss: 11.478330612182617\n",
            "epoch: 18/20,    batch: 1851/2993    Discriminator_loss: 8.946928574005142e-05  Generator_loss: 11.471531867980957\n",
            "epoch: 18/20,    batch: 1852/2993    Discriminator_loss: 0.00014597091649193317  Generator_loss: 11.466880798339844\n",
            "epoch: 18/20,    batch: 1853/2993    Discriminator_loss: 1.4262342119764071e-05  Generator_loss: 11.466880798339844\n",
            "epoch: 18/20,    batch: 1854/2993    Discriminator_loss: 0.00023826851975172758  Generator_loss: 11.456622123718262\n",
            "epoch: 18/20,    batch: 1855/2993    Discriminator_loss: 4.379537494969554e-05  Generator_loss: 11.455914497375488\n",
            "epoch: 18/20,    batch: 1856/2993    Discriminator_loss: 5.290864282869734e-05  Generator_loss: 11.44576644897461\n",
            "epoch: 18/20,    batch: 1857/2993    Discriminator_loss: 0.0001917125773616135  Generator_loss: 11.444717407226562\n",
            "epoch: 18/20,    batch: 1858/2993    Discriminator_loss: 1.4547384125762619e-05  Generator_loss: 11.442292213439941\n",
            "epoch: 18/20,    batch: 1859/2993    Discriminator_loss: 3.928640944650397e-05  Generator_loss: 11.43364429473877\n",
            "epoch: 18/20,    batch: 1860/2993    Discriminator_loss: 0.00028167717391625047  Generator_loss: 11.433298110961914\n",
            "epoch: 18/20,    batch: 1861/2993    Discriminator_loss: 1.5011159121058881e-05  Generator_loss: 11.42303466796875\n",
            "epoch: 18/20,    batch: 1862/2993    Discriminator_loss: 3.651768929557875e-05  Generator_loss: 11.42234992980957\n",
            "epoch: 18/20,    batch: 1863/2993    Discriminator_loss: 0.00016017428424675018  Generator_loss: 11.412874221801758\n",
            "epoch: 18/20,    batch: 1864/2993    Discriminator_loss: 1.5625819287379272e-05  Generator_loss: 11.412535667419434\n",
            "epoch: 18/20,    batch: 1865/2993    Discriminator_loss: 7.030813867459074e-05  Generator_loss: 11.404823303222656\n",
            "epoch: 18/20,    batch: 1866/2993    Discriminator_loss: 0.00019449679530225694  Generator_loss: 11.401141166687012\n",
            "epoch: 18/20,    batch: 1867/2993    Discriminator_loss: 1.682164474914316e-05  Generator_loss: 11.394844055175781\n",
            "epoch: 18/20,    batch: 1868/2993    Discriminator_loss: 0.0006045724730938673  Generator_loss: 11.390206336975098\n",
            "epoch: 18/20,    batch: 1869/2993    Discriminator_loss: 0.00023522463743574917  Generator_loss: 11.383325576782227\n",
            "epoch: 18/20,    batch: 1870/2993    Discriminator_loss: 1.7946702428162098e-05  Generator_loss: 11.381356239318848\n",
            "epoch: 18/20,    batch: 1871/2993    Discriminator_loss: 0.00034950271947309375  Generator_loss: 11.373558044433594\n",
            "epoch: 18/20,    batch: 1872/2993    Discriminator_loss: 0.00039494800148531795  Generator_loss: 11.369661331176758\n",
            "epoch: 18/20,    batch: 1873/2993    Discriminator_loss: 1.5584852008032613e-05  Generator_loss: 11.362598419189453\n",
            "epoch: 18/20,    batch: 1874/2993    Discriminator_loss: 7.773819379508495e-05  Generator_loss: 11.359704971313477\n",
            "epoch: 18/20,    batch: 1875/2993    Discriminator_loss: 0.0002692757116165012  Generator_loss: 11.350801467895508\n",
            "epoch: 18/20,    batch: 1876/2993    Discriminator_loss: 1.4146868124953471e-05  Generator_loss: 11.347639083862305\n",
            "epoch: 18/20,    batch: 1877/2993    Discriminator_loss: 9.640106145525351e-05  Generator_loss: 11.340404510498047\n",
            "epoch: 18/20,    batch: 1878/2993    Discriminator_loss: 0.00047977559734135866  Generator_loss: 11.33104133605957\n",
            "epoch: 18/20,    batch: 1879/2993    Discriminator_loss: 5.069795952294953e-05  Generator_loss: 11.329795837402344\n",
            "epoch: 18/20,    batch: 1880/2993    Discriminator_loss: 4.362984327599406e-05  Generator_loss: 11.319918632507324\n",
            "epoch: 18/20,    batch: 1881/2993    Discriminator_loss: 0.00018744953558780253  Generator_loss: 11.313814163208008\n",
            "epoch: 18/20,    batch: 1882/2993    Discriminator_loss: 4.600493048201315e-05  Generator_loss: 11.310443878173828\n",
            "epoch: 18/20,    batch: 1883/2993    Discriminator_loss: 3.268061118433252e-05  Generator_loss: 11.300149917602539\n",
            "epoch: 18/20,    batch: 1884/2993    Discriminator_loss: 0.00039929195190779865  Generator_loss: 11.292057037353516\n",
            "epoch: 18/20,    batch: 1885/2993    Discriminator_loss: 0.00010548623686190695  Generator_loss: 11.286996841430664\n",
            "epoch: 18/20,    batch: 1886/2993    Discriminator_loss: 2.3143567887018435e-05  Generator_loss: 11.281657218933105\n",
            "epoch: 18/20,    batch: 1887/2993    Discriminator_loss: 9.883177699521184e-05  Generator_loss: 11.271358489990234\n",
            "epoch: 18/20,    batch: 1888/2993    Discriminator_loss: 2.4972887331387028e-05  Generator_loss: 11.264076232910156\n",
            "epoch: 18/20,    batch: 1889/2993    Discriminator_loss: 3.411858779145405e-05  Generator_loss: 11.25741958618164\n",
            "epoch: 18/20,    batch: 1890/2993    Discriminator_loss: 9.121490438701585e-05  Generator_loss: 11.253093719482422\n",
            "epoch: 18/20,    batch: 1891/2993    Discriminator_loss: 0.008509132079780102  Generator_loss: 11.244514465332031\n",
            "epoch: 18/20,    batch: 1892/2993    Discriminator_loss: 7.958151400089264e-05  Generator_loss: 11.236006736755371\n",
            "epoch: 18/20,    batch: 1893/2993    Discriminator_loss: 0.000100761215435341  Generator_loss: 11.22785472869873\n",
            "epoch: 18/20,    batch: 1894/2993    Discriminator_loss: 1.7063797713490203e-05  Generator_loss: 11.220040321350098\n",
            "epoch: 18/20,    batch: 1895/2993    Discriminator_loss: 4.5431163016473874e-05  Generator_loss: 11.216423988342285\n",
            "epoch: 18/20,    batch: 1896/2993    Discriminator_loss: 6.981928163440898e-05  Generator_loss: 11.208152770996094\n",
            "epoch: 18/20,    batch: 1897/2993    Discriminator_loss: 9.451493679080158e-05  Generator_loss: 11.19940185546875\n",
            "epoch: 18/20,    batch: 1898/2993    Discriminator_loss: 0.0003139592881780118  Generator_loss: 11.19289779663086\n",
            "epoch: 18/20,    batch: 1899/2993    Discriminator_loss: 0.00014349225966725498  Generator_loss: 11.183738708496094\n",
            "epoch: 18/20,    batch: 1900/2993    Discriminator_loss: 2.111510548274964e-05  Generator_loss: 11.180523872375488\n",
            "epoch: 18/20,    batch: 1901/2993    Discriminator_loss: 0.0001454934972571209  Generator_loss: 11.173333168029785\n",
            "epoch: 18/20,    batch: 1902/2993    Discriminator_loss: 7.969407306518406e-05  Generator_loss: 11.165672302246094\n",
            "epoch: 18/20,    batch: 1903/2993    Discriminator_loss: 1.81813957169652e-05  Generator_loss: 11.156761169433594\n",
            "epoch: 18/20,    batch: 1904/2993    Discriminator_loss: 5.8954465202987194e-05  Generator_loss: 11.150530815124512\n",
            "epoch: 18/20,    batch: 1905/2993    Discriminator_loss: 8.762101060710847e-05  Generator_loss: 11.142263412475586\n",
            "epoch: 18/20,    batch: 1906/2993    Discriminator_loss: 2.1947731511318125e-05  Generator_loss: 11.138921737670898\n",
            "epoch: 18/20,    batch: 1907/2993    Discriminator_loss: 5.040114774601534e-05  Generator_loss: 11.131511688232422\n",
            "epoch: 18/20,    batch: 1908/2993    Discriminator_loss: 0.00012128172966185957  Generator_loss: 11.123910903930664\n",
            "epoch: 18/20,    batch: 1909/2993    Discriminator_loss: 1.6356001651729457e-05  Generator_loss: 11.115865707397461\n",
            "epoch: 18/20,    batch: 1910/2993    Discriminator_loss: 4.315650949138217e-05  Generator_loss: 11.108379364013672\n",
            "epoch: 18/20,    batch: 1911/2993    Discriminator_loss: 7.818203448550776e-05  Generator_loss: 11.101198196411133\n",
            "epoch: 18/20,    batch: 1912/2993    Discriminator_loss: 2.006647082453128e-05  Generator_loss: 11.093823432922363\n",
            "epoch: 18/20,    batch: 1913/2993    Discriminator_loss: 4.427055682754144e-05  Generator_loss: 11.09138298034668\n",
            "epoch: 18/20,    batch: 1914/2993    Discriminator_loss: 0.00023227007477544248  Generator_loss: 11.084066390991211\n",
            "epoch: 18/20,    batch: 1915/2993    Discriminator_loss: 3.13903292408213e-05  Generator_loss: 11.076090812683105\n",
            "epoch: 18/20,    batch: 1916/2993    Discriminator_loss: 4.7251600335584953e-05  Generator_loss: 11.069379806518555\n",
            "epoch: 18/20,    batch: 1917/2993    Discriminator_loss: 9.372059139423072e-05  Generator_loss: 11.061756134033203\n",
            "epoch: 18/20,    batch: 1918/2993    Discriminator_loss: 5.508386675501242e-05  Generator_loss: 11.053956985473633\n",
            "epoch: 18/20,    batch: 1919/2993    Discriminator_loss: 3.65978958143387e-05  Generator_loss: 11.046920776367188\n",
            "epoch: 18/20,    batch: 1920/2993    Discriminator_loss: 7.533338794019073e-05  Generator_loss: 11.041563034057617\n",
            "epoch: 18/20,    batch: 1921/2993    Discriminator_loss: 3.029697109013796e-05  Generator_loss: 11.033456802368164\n",
            "epoch: 18/20,    batch: 1922/2993    Discriminator_loss: 9.374154615215957e-05  Generator_loss: 11.026103019714355\n",
            "epoch: 18/20,    batch: 1923/2993    Discriminator_loss: 9.252391464542598e-05  Generator_loss: 11.02039909362793\n",
            "epoch: 18/20,    batch: 1924/2993    Discriminator_loss: 2.9858598281862214e-05  Generator_loss: 11.013815879821777\n",
            "epoch: 18/20,    batch: 1925/2993    Discriminator_loss: 8.730513218324631e-05  Generator_loss: 11.009527206420898\n",
            "epoch: 18/20,    batch: 1926/2993    Discriminator_loss: 5.70418887946289e-05  Generator_loss: 11.001893997192383\n",
            "epoch: 18/20,    batch: 1927/2993    Discriminator_loss: 1.8818444004864432e-05  Generator_loss: 10.994769096374512\n",
            "epoch: 18/20,    batch: 1928/2993    Discriminator_loss: 7.785786146996543e-05  Generator_loss: 10.988136291503906\n",
            "epoch: 18/20,    batch: 1929/2993    Discriminator_loss: 4.8888778110267594e-05  Generator_loss: 10.980668067932129\n",
            "epoch: 18/20,    batch: 1930/2993    Discriminator_loss: 2.372842027398292e-05  Generator_loss: 10.973691940307617\n",
            "epoch: 18/20,    batch: 1931/2993    Discriminator_loss: 5.351511936169118e-05  Generator_loss: 10.96697998046875\n",
            "epoch: 18/20,    batch: 1932/2993    Discriminator_loss: 7.909837586339563e-05  Generator_loss: 10.960959434509277\n",
            "epoch: 18/20,    batch: 1933/2993    Discriminator_loss: 3.4917589800897986e-05  Generator_loss: 10.954974174499512\n",
            "epoch: 18/20,    batch: 1934/2993    Discriminator_loss: 8.410195005126297e-05  Generator_loss: 10.947111129760742\n",
            "epoch: 18/20,    batch: 1935/2993    Discriminator_loss: 3.7143581721466035e-05  Generator_loss: 10.943525314331055\n",
            "epoch: 18/20,    batch: 1936/2993    Discriminator_loss: 2.6254263502778485e-05  Generator_loss: 10.938474655151367\n",
            "epoch: 18/20,    batch: 1937/2993    Discriminator_loss: 4.817677472601645e-05  Generator_loss: 10.933034896850586\n",
            "epoch: 18/20,    batch: 1938/2993    Discriminator_loss: 0.00010429888789076358  Generator_loss: 10.926173210144043\n",
            "epoch: 18/20,    batch: 1939/2993    Discriminator_loss: 2.0897236026939936e-05  Generator_loss: 10.919771194458008\n",
            "epoch: 18/20,    batch: 1940/2993    Discriminator_loss: 4.731972876470536e-05  Generator_loss: 10.913412094116211\n",
            "epoch: 18/20,    batch: 1941/2993    Discriminator_loss: 5.795257311547175e-05  Generator_loss: 10.910564422607422\n",
            "epoch: 18/20,    batch: 1942/2993    Discriminator_loss: 4.1306841012556106e-05  Generator_loss: 10.906686782836914\n",
            "epoch: 18/20,    batch: 1943/2993    Discriminator_loss: 3.825204839813523e-05  Generator_loss: 10.90060806274414\n",
            "epoch: 18/20,    batch: 1944/2993    Discriminator_loss: 3.556789306458086e-05  Generator_loss: 10.893562316894531\n",
            "epoch: 18/20,    batch: 1945/2993    Discriminator_loss: 8.327692921739072e-05  Generator_loss: 10.889364242553711\n",
            "epoch: 18/20,    batch: 1946/2993    Discriminator_loss: 1.9159338989993557e-05  Generator_loss: 10.887166023254395\n",
            "epoch: 18/20,    batch: 1947/2993    Discriminator_loss: 6.774552457500249e-05  Generator_loss: 10.881410598754883\n",
            "epoch: 18/20,    batch: 1948/2993    Discriminator_loss: 5.357831105357036e-05  Generator_loss: 10.8746919631958\n",
            "epoch: 18/20,    batch: 1949/2993    Discriminator_loss: 2.3912856704555452e-05  Generator_loss: 10.86978816986084\n",
            "epoch: 18/20,    batch: 1950/2993    Discriminator_loss: 3.079549060203135e-05  Generator_loss: 10.868219375610352\n",
            "epoch: 18/20,    batch: 1951/2993    Discriminator_loss: 0.0026915043126791716  Generator_loss: 10.861982345581055\n",
            "epoch: 18/20,    batch: 1952/2993    Discriminator_loss: 7.501379877794534e-05  Generator_loss: 10.855978012084961\n",
            "epoch: 18/20,    batch: 1953/2993    Discriminator_loss: 2.4084218239295296e-05  Generator_loss: 10.850393295288086\n",
            "epoch: 18/20,    batch: 1954/2993    Discriminator_loss: 0.0027273129671812057  Generator_loss: 10.844650268554688\n",
            "epoch: 18/20,    batch: 1955/2993    Discriminator_loss: 0.0001241533027496189  Generator_loss: 10.839900970458984\n",
            "epoch: 18/20,    batch: 1956/2993    Discriminator_loss: 2.6814990633283742e-05  Generator_loss: 10.837416648864746\n",
            "epoch: 18/20,    batch: 1957/2993    Discriminator_loss: 7.411967089865357e-05  Generator_loss: 10.831368446350098\n",
            "epoch: 18/20,    batch: 1958/2993    Discriminator_loss: 0.00010199718235526234  Generator_loss: 10.825356483459473\n",
            "epoch: 18/20,    batch: 1959/2993    Discriminator_loss: 3.633161395555362e-05  Generator_loss: 10.821063041687012\n",
            "epoch: 18/20,    batch: 1960/2993    Discriminator_loss: 0.0001783016778063029  Generator_loss: 10.819380760192871\n",
            "epoch: 18/20,    batch: 1961/2993    Discriminator_loss: 5.8355144574306905e-05  Generator_loss: 10.813440322875977\n",
            "epoch: 18/20,    batch: 1962/2993    Discriminator_loss: 3.8652266084682196e-05  Generator_loss: 10.807535171508789\n",
            "epoch: 18/20,    batch: 1963/2993    Discriminator_loss: 0.00011210164666408673  Generator_loss: 10.803865432739258\n",
            "epoch: 18/20,    batch: 1964/2993    Discriminator_loss: 2.7943846362177283e-05  Generator_loss: 10.801664352416992\n",
            "epoch: 18/20,    batch: 1965/2993    Discriminator_loss: 3.7039142625872046e-05  Generator_loss: 10.795827865600586\n",
            "epoch: 18/20,    batch: 1966/2993    Discriminator_loss: 0.0001601480762474239  Generator_loss: 10.79002571105957\n",
            "epoch: 18/20,    batch: 1967/2993    Discriminator_loss: 2.2610867745243013e-05  Generator_loss: 10.784255981445312\n",
            "epoch: 18/20,    batch: 1968/2993    Discriminator_loss: 4.4005686504533514e-05  Generator_loss: 10.784076690673828\n",
            "epoch: 18/20,    batch: 1969/2993    Discriminator_loss: 9.95359368971549e-05  Generator_loss: 10.778520584106445\n",
            "epoch: 18/20,    batch: 1970/2993    Discriminator_loss: 2.6576502932584845e-05  Generator_loss: 10.772817611694336\n",
            "epoch: 18/20,    batch: 1971/2993    Discriminator_loss: 3.8233265513554215e-05  Generator_loss: 10.767499923706055\n",
            "epoch: 18/20,    batch: 1972/2993    Discriminator_loss: 4.752264794660732e-05  Generator_loss: 10.761859893798828\n",
            "epoch: 18/20,    batch: 1973/2993    Discriminator_loss: 8.13136575743556e-05  Generator_loss: 10.757652282714844\n",
            "epoch: 18/20,    batch: 1974/2993    Discriminator_loss: 0.0005368272541090846  Generator_loss: 10.755900382995605\n",
            "epoch: 18/20,    batch: 1975/2993    Discriminator_loss: 9.37178629101254e-05  Generator_loss: 10.750324249267578\n",
            "epoch: 18/20,    batch: 1976/2993    Discriminator_loss: 2.8759532142430544e-05  Generator_loss: 10.744778633117676\n",
            "epoch: 18/20,    batch: 1977/2993    Discriminator_loss: 2.84913185168989e-05  Generator_loss: 10.739264488220215\n",
            "epoch: 18/20,    batch: 1978/2993    Discriminator_loss: 2.9593988074338995e-05  Generator_loss: 10.733779907226562\n",
            "epoch: 18/20,    batch: 1979/2993    Discriminator_loss: 0.00014701203326694667  Generator_loss: 10.728325843811035\n",
            "epoch: 18/20,    batch: 1980/2993    Discriminator_loss: 2.8625421691685915e-05  Generator_loss: 10.722900390625\n",
            "epoch: 18/20,    batch: 1981/2993    Discriminator_loss: 0.00011748261022148654  Generator_loss: 10.71750545501709\n",
            "epoch: 18/20,    batch: 1982/2993    Discriminator_loss: 3.968972305301577e-05  Generator_loss: 10.712138175964355\n",
            "epoch: 18/20,    batch: 1983/2993    Discriminator_loss: 2.4624421712360345e-05  Generator_loss: 10.70680046081543\n",
            "epoch: 18/20,    batch: 1984/2993    Discriminator_loss: 4.26943734055385e-05  Generator_loss: 10.701491355895996\n",
            "epoch: 18/20,    batch: 1985/2993    Discriminator_loss: 0.00014722318155691028  Generator_loss: 10.691120147705078\n",
            "epoch: 18/20,    batch: 1986/2993    Discriminator_loss: 2.414759001112543e-05  Generator_loss: 10.685729026794434\n",
            "epoch: 18/20,    batch: 1987/2993    Discriminator_loss: 8.352849545190111e-05  Generator_loss: 10.680530548095703\n",
            "epoch: 18/20,    batch: 1988/2993    Discriminator_loss: 0.00012950945529155433  Generator_loss: 10.670212745666504\n",
            "epoch: 18/20,    batch: 1989/2993    Discriminator_loss: 2.9208455089246854e-05  Generator_loss: 10.665093421936035\n",
            "epoch: 18/20,    batch: 1990/2993    Discriminator_loss: 0.00012413768854457885  Generator_loss: 10.654932022094727\n",
            "epoch: 18/20,    batch: 1991/2993    Discriminator_loss: 7.959443610161543e-05  Generator_loss: 10.649889945983887\n",
            "epoch: 18/20,    batch: 1992/2993    Discriminator_loss: 3.269724402343854e-05  Generator_loss: 10.63988208770752\n",
            "epoch: 18/20,    batch: 1993/2993    Discriminator_loss: 0.00021998072043061256  Generator_loss: 10.629973411560059\n",
            "epoch: 18/20,    batch: 1994/2993    Discriminator_loss: 3.255392948631197e-05  Generator_loss: 10.624595642089844\n",
            "epoch: 18/20,    batch: 1995/2993    Discriminator_loss: 3.4749908081721514e-05  Generator_loss: 10.615291595458984\n",
            "epoch: 18/20,    batch: 1996/2993    Discriminator_loss: 0.0006963548366911709  Generator_loss: 10.605622291564941\n",
            "epoch: 18/20,    batch: 1997/2993    Discriminator_loss: 3.703053153003566e-05  Generator_loss: 10.59604549407959\n",
            "epoch: 18/20,    batch: 1998/2993    Discriminator_loss: 4.847274249186739e-05  Generator_loss: 10.587150573730469\n",
            "epoch: 18/20,    batch: 1999/2993    Discriminator_loss: 0.00011628278298303485  Generator_loss: 10.581850051879883\n",
            "epoch: 18/20,    batch: 2000/2993    Discriminator_loss: 2.7474343369249254e-05  Generator_loss: 10.57249641418457\n",
            "epoch: 18/20,    batch: 2001/2993    Discriminator_loss: 4.3461630411911756e-05  Generator_loss: 10.565397262573242\n",
            "epoch: 18/20,    batch: 2002/2993    Discriminator_loss: 6.257498898776248e-05  Generator_loss: 10.558629989624023\n",
            "epoch: 18/20,    batch: 2003/2993    Discriminator_loss: 3.598500188672915e-05  Generator_loss: 10.550060272216797\n",
            "epoch: 18/20,    batch: 2004/2993    Discriminator_loss: 3.3062340662581846e-05  Generator_loss: 10.544951438903809\n",
            "epoch: 18/20,    batch: 2005/2993    Discriminator_loss: 3.87882100767456e-05  Generator_loss: 10.540433883666992\n",
            "epoch: 18/20,    batch: 2006/2993    Discriminator_loss: 9.106472134590149e-05  Generator_loss: 10.531458854675293\n",
            "epoch: 18/20,    batch: 2007/2993    Discriminator_loss: 4.3623858800856397e-05  Generator_loss: 10.52700138092041\n",
            "epoch: 18/20,    batch: 2008/2993    Discriminator_loss: 0.00038736610440537333  Generator_loss: 10.522287368774414\n",
            "epoch: 18/20,    batch: 2009/2993    Discriminator_loss: 7.361760071944445e-05  Generator_loss: 10.51374626159668\n",
            "epoch: 18/20,    batch: 2010/2993    Discriminator_loss: 2.9053911930532195e-05  Generator_loss: 10.509366989135742\n",
            "epoch: 18/20,    batch: 2011/2993    Discriminator_loss: 5.578763739322312e-05  Generator_loss: 10.505006790161133\n",
            "epoch: 18/20,    batch: 2012/2993    Discriminator_loss: 0.0001537382777314633  Generator_loss: 10.49755859375\n",
            "epoch: 18/20,    batch: 2013/2993    Discriminator_loss: 9.924449113896117e-05  Generator_loss: 10.492443084716797\n",
            "epoch: 18/20,    batch: 2014/2993    Discriminator_loss: 4.646816523745656e-05  Generator_loss: 10.487886428833008\n",
            "epoch: 18/20,    batch: 2015/2993    Discriminator_loss: 7.4580661021173e-05  Generator_loss: 10.483617782592773\n",
            "epoch: 18/20,    batch: 2016/2993    Discriminator_loss: 0.0002833061444107443  Generator_loss: 10.478443145751953\n",
            "epoch: 18/20,    batch: 2017/2993    Discriminator_loss: 2.9206674298620783e-05  Generator_loss: 10.470791816711426\n",
            "epoch: 18/20,    batch: 2018/2993    Discriminator_loss: 4.236642416799441e-05  Generator_loss: 10.466595649719238\n",
            "epoch: 18/20,    batch: 2019/2993    Discriminator_loss: 9.841759310802445e-05  Generator_loss: 10.462417602539062\n",
            "epoch: 18/20,    batch: 2020/2993    Discriminator_loss: 4.9307353037875146e-05  Generator_loss: 10.454633712768555\n",
            "epoch: 18/20,    batch: 2021/2993    Discriminator_loss: 5.2577794122044e-05  Generator_loss: 10.450116157531738\n",
            "epoch: 18/20,    batch: 2022/2993    Discriminator_loss: 0.11467483639717102  Generator_loss: 10.421819686889648\n",
            "epoch: 18/20,    batch: 2023/2993    Discriminator_loss: 4.1245322790928185e-05  Generator_loss: 10.398694038391113\n",
            "epoch: 18/20,    batch: 2024/2993    Discriminator_loss: 4.910763163934462e-05  Generator_loss: 10.3784818649292\n",
            "epoch: 18/20,    batch: 2025/2993    Discriminator_loss: 0.000972829875536263  Generator_loss: 10.359613418579102\n",
            "epoch: 18/20,    batch: 2026/2993    Discriminator_loss: 3.349832695676014e-05  Generator_loss: 10.344560623168945\n",
            "epoch: 18/20,    batch: 2027/2993    Discriminator_loss: 5.843623875989579e-05  Generator_loss: 10.326314926147461\n",
            "epoch: 18/20,    batch: 2028/2993    Discriminator_loss: 0.00012563553173094988  Generator_loss: 10.311751365661621\n",
            "epoch: 18/20,    batch: 2029/2993    Discriminator_loss: 3.464389737928286e-05  Generator_loss: 10.294861793518066\n",
            "epoch: 18/20,    batch: 2030/2993    Discriminator_loss: 5.94382690906059e-05  Generator_loss: 10.279984474182129\n",
            "epoch: 18/20,    batch: 2031/2993    Discriminator_loss: 0.000121312725241296  Generator_loss: 10.262977600097656\n",
            "epoch: 18/20,    batch: 2032/2993    Discriminator_loss: 4.350839299149811e-05  Generator_loss: 10.24898910522461\n",
            "epoch: 18/20,    batch: 2033/2993    Discriminator_loss: 0.00011128200276289135  Generator_loss: 10.232491493225098\n",
            "epoch: 18/20,    batch: 2034/2993    Discriminator_loss: 9.031083027366549e-05  Generator_loss: 10.216266632080078\n",
            "epoch: 18/20,    batch: 2035/2993    Discriminator_loss: 4.261616413714364e-05  Generator_loss: 10.203110694885254\n",
            "epoch: 18/20,    batch: 2036/2993    Discriminator_loss: 0.00011525191075634211  Generator_loss: 10.188539505004883\n",
            "epoch: 18/20,    batch: 2037/2993    Discriminator_loss: 6.661906081717461e-05  Generator_loss: 10.175252914428711\n",
            "epoch: 18/20,    batch: 2038/2993    Discriminator_loss: 4.4540382077684626e-05  Generator_loss: 10.165813446044922\n",
            "epoch: 18/20,    batch: 2039/2993    Discriminator_loss: 6.084275810280815e-05  Generator_loss: 10.155120849609375\n",
            "epoch: 18/20,    batch: 2040/2993    Discriminator_loss: 6.885667244205251e-05  Generator_loss: 10.145963668823242\n",
            "epoch: 18/20,    batch: 2041/2993    Discriminator_loss: 7.52798659959808e-05  Generator_loss: 10.137829780578613\n",
            "epoch: 18/20,    batch: 2042/2993    Discriminator_loss: 0.00013185839634388685  Generator_loss: 10.130232810974121\n",
            "epoch: 18/20,    batch: 2043/2993    Discriminator_loss: 0.00019945407984778285  Generator_loss: 10.123059272766113\n",
            "epoch: 18/20,    batch: 2044/2993    Discriminator_loss: 6.684058462269604e-05  Generator_loss: 10.116952896118164\n",
            "epoch: 18/20,    batch: 2045/2993    Discriminator_loss: 4.580705353873782e-05  Generator_loss: 10.11115837097168\n",
            "epoch: 18/20,    batch: 2046/2993    Discriminator_loss: 7.12907494744286e-05  Generator_loss: 10.105306625366211\n",
            "epoch: 18/20,    batch: 2047/2993    Discriminator_loss: 0.0016522511141374707  Generator_loss: 10.099580764770508\n",
            "epoch: 18/20,    batch: 2048/2993    Discriminator_loss: 4.582762994687073e-05  Generator_loss: 10.094518661499023\n",
            "epoch: 18/20,    batch: 2049/2993    Discriminator_loss: 5.1655821152962744e-05  Generator_loss: 10.088493347167969\n",
            "epoch: 18/20,    batch: 2050/2993    Discriminator_loss: 0.00010180677782045677  Generator_loss: 10.084466934204102\n",
            "epoch: 18/20,    batch: 2051/2993    Discriminator_loss: 6.774593202862889e-05  Generator_loss: 10.079745292663574\n",
            "epoch: 18/20,    batch: 2052/2993    Discriminator_loss: 5.9840578614966944e-05  Generator_loss: 10.07469367980957\n",
            "epoch: 18/20,    batch: 2053/2993    Discriminator_loss: 5.81267595407553e-05  Generator_loss: 10.069403648376465\n",
            "epoch: 18/20,    batch: 2054/2993    Discriminator_loss: 0.00014009392180014402  Generator_loss: 10.065450668334961\n",
            "epoch: 18/20,    batch: 2055/2993    Discriminator_loss: 4.906511458102614e-05  Generator_loss: 10.060297012329102\n",
            "epoch: 18/20,    batch: 2056/2993    Discriminator_loss: 6.414894596673548e-05  Generator_loss: 10.056215286254883\n",
            "epoch: 18/20,    batch: 2057/2993    Discriminator_loss: 0.00010011762788053602  Generator_loss: 10.05179214477539\n",
            "epoch: 18/20,    batch: 2058/2993    Discriminator_loss: 4.7314002586063e-05  Generator_loss: 10.046621322631836\n",
            "epoch: 18/20,    batch: 2059/2993    Discriminator_loss: 9.131389379035681e-05  Generator_loss: 10.041732788085938\n",
            "epoch: 18/20,    batch: 2060/2993    Discriminator_loss: 0.0001460054627386853  Generator_loss: 10.03797435760498\n",
            "epoch: 18/20,    batch: 2061/2993    Discriminator_loss: 5.199119550525211e-05  Generator_loss: 10.032703399658203\n",
            "epoch: 18/20,    batch: 2062/2993    Discriminator_loss: 0.0001036363682942465  Generator_loss: 10.028812408447266\n",
            "epoch: 18/20,    batch: 2063/2993    Discriminator_loss: 0.0001076361004379578  Generator_loss: 10.024849891662598\n",
            "epoch: 18/20,    batch: 2064/2993    Discriminator_loss: 5.228179361438379e-05  Generator_loss: 10.01990032196045\n",
            "epoch: 18/20,    batch: 2065/2993    Discriminator_loss: 0.00016232996131293476  Generator_loss: 10.014556884765625\n",
            "epoch: 18/20,    batch: 2066/2993    Discriminator_loss: 8.878477819962427e-05  Generator_loss: 10.011899948120117\n",
            "epoch: 18/20,    batch: 2067/2993    Discriminator_loss: 5.395632979343645e-05  Generator_loss: 10.006099700927734\n",
            "epoch: 18/20,    batch: 2068/2993    Discriminator_loss: 0.0001259082928299904  Generator_loss: 10.000995635986328\n",
            "epoch: 18/20,    batch: 2069/2993    Discriminator_loss: 9.809844777919352e-05  Generator_loss: 9.997060775756836\n",
            "epoch: 18/20,    batch: 2070/2993    Discriminator_loss: 0.00011704771895892918  Generator_loss: 9.992733001708984\n",
            "epoch: 18/20,    batch: 2071/2993    Discriminator_loss: 0.000106206294731237  Generator_loss: 9.98793888092041\n",
            "epoch: 18/20,    batch: 2072/2993    Discriminator_loss: 6.268869765335694e-05  Generator_loss: 9.982522010803223\n",
            "epoch: 18/20,    batch: 2073/2993    Discriminator_loss: 5.6159962696256116e-05  Generator_loss: 9.978017807006836\n",
            "epoch: 18/20,    batch: 2074/2993    Discriminator_loss: 0.00016948292613960803  Generator_loss: 9.973692893981934\n",
            "epoch: 18/20,    batch: 2075/2993    Discriminator_loss: 0.0014524023281410336  Generator_loss: 9.968273162841797\n",
            "epoch: 18/20,    batch: 2076/2993    Discriminator_loss: 4.850438199355267e-05  Generator_loss: 9.962722778320312\n",
            "epoch: 18/20,    batch: 2077/2993    Discriminator_loss: 9.859190322458744e-05  Generator_loss: 9.958704948425293\n",
            "epoch: 18/20,    batch: 2078/2993    Discriminator_loss: 0.00012011601938866079  Generator_loss: 9.953046798706055\n",
            "epoch: 18/20,    batch: 2079/2993    Discriminator_loss: 5.066137237008661e-05  Generator_loss: 9.947737693786621\n",
            "epoch: 18/20,    batch: 2080/2993    Discriminator_loss: 6.225088145583868e-05  Generator_loss: 9.941911697387695\n",
            "epoch: 18/20,    batch: 2081/2993    Discriminator_loss: 9.244491229765117e-05  Generator_loss: 9.937740325927734\n",
            "epoch: 18/20,    batch: 2082/2993    Discriminator_loss: 0.0003886687627527863  Generator_loss: 9.933431625366211\n",
            "epoch: 18/20,    batch: 2083/2993    Discriminator_loss: 9.260250226361677e-05  Generator_loss: 9.92723274230957\n",
            "epoch: 18/20,    batch: 2084/2993    Discriminator_loss: 0.0001627636083867401  Generator_loss: 9.92297077178955\n",
            "epoch: 18/20,    batch: 2085/2993    Discriminator_loss: 6.210585706867278e-05  Generator_loss: 9.916983604431152\n",
            "epoch: 18/20,    batch: 2086/2993    Discriminator_loss: 7.209939212771133e-05  Generator_loss: 9.912463188171387\n",
            "epoch: 18/20,    batch: 2087/2993    Discriminator_loss: 8.42105146148242e-05  Generator_loss: 9.908713340759277\n",
            "epoch: 18/20,    batch: 2088/2993    Discriminator_loss: 0.00014522421406581998  Generator_loss: 9.903335571289062\n",
            "epoch: 18/20,    batch: 2089/2993    Discriminator_loss: 7.056284812279046e-05  Generator_loss: 9.898504257202148\n",
            "epoch: 18/20,    batch: 2090/2993    Discriminator_loss: 0.00015954207628965378  Generator_loss: 9.89406681060791\n",
            "epoch: 18/20,    batch: 2091/2993    Discriminator_loss: 5.355048779165372e-05  Generator_loss: 9.888838768005371\n",
            "epoch: 18/20,    batch: 2092/2993    Discriminator_loss: 8.433962648268789e-05  Generator_loss: 9.884664535522461\n",
            "epoch: 18/20,    batch: 2093/2993    Discriminator_loss: 0.00015992840053513646  Generator_loss: 9.881410598754883\n",
            "epoch: 18/20,    batch: 2094/2993    Discriminator_loss: 5.609866639133543e-05  Generator_loss: 9.875275611877441\n",
            "epoch: 18/20,    batch: 2095/2993    Discriminator_loss: 8.572323713451624e-05  Generator_loss: 9.872455596923828\n",
            "epoch: 18/20,    batch: 2096/2993    Discriminator_loss: 0.0001381423498969525  Generator_loss: 9.867843627929688\n",
            "epoch: 18/20,    batch: 2097/2993    Discriminator_loss: 5.9725280152633786e-05  Generator_loss: 9.86404037475586\n",
            "epoch: 18/20,    batch: 2098/2993    Discriminator_loss: 9.146778756985441e-05  Generator_loss: 9.85960865020752\n",
            "epoch: 18/20,    batch: 2099/2993    Discriminator_loss: 9.773841156857088e-05  Generator_loss: 9.855339050292969\n",
            "epoch: 18/20,    batch: 2100/2993    Discriminator_loss: 5.889827662031166e-05  Generator_loss: 9.852714538574219\n",
            "epoch: 18/20,    batch: 2101/2993    Discriminator_loss: 0.0001251541543751955  Generator_loss: 9.847135543823242\n",
            "epoch: 18/20,    batch: 2102/2993    Discriminator_loss: 8.335610618814826e-05  Generator_loss: 9.84432315826416\n",
            "epoch: 18/20,    batch: 2103/2993    Discriminator_loss: 6.291233148658648e-05  Generator_loss: 9.839071273803711\n",
            "epoch: 18/20,    batch: 2104/2993    Discriminator_loss: 0.00013164170377422124  Generator_loss: 9.836627960205078\n",
            "epoch: 18/20,    batch: 2105/2993    Discriminator_loss: 0.0004934033495374024  Generator_loss: 9.833011627197266\n",
            "epoch: 18/20,    batch: 2106/2993    Discriminator_loss: 6.198107439558953e-05  Generator_loss: 9.828369140625\n",
            "epoch: 18/20,    batch: 2107/2993    Discriminator_loss: 8.062100096140057e-05  Generator_loss: 9.825332641601562\n",
            "epoch: 18/20,    batch: 2108/2993    Discriminator_loss: 0.00012265756959095597  Generator_loss: 9.821138381958008\n",
            "epoch: 18/20,    batch: 2109/2993    Discriminator_loss: 6.376746750902385e-05  Generator_loss: 9.817781448364258\n",
            "epoch: 18/20,    batch: 2110/2993    Discriminator_loss: 0.011594063602387905  Generator_loss: 9.813891410827637\n",
            "epoch: 18/20,    batch: 2111/2993    Discriminator_loss: 0.0023722697515040636  Generator_loss: 9.808523178100586\n",
            "epoch: 18/20,    batch: 2112/2993    Discriminator_loss: 0.00017694325651973486  Generator_loss: 9.803995132446289\n",
            "epoch: 18/20,    batch: 2113/2993    Discriminator_loss: 0.00022288881882559508  Generator_loss: 9.799755096435547\n",
            "epoch: 18/20,    batch: 2114/2993    Discriminator_loss: 0.00040717338561080396  Generator_loss: 9.794795989990234\n",
            "epoch: 18/20,    batch: 2115/2993    Discriminator_loss: 0.0002470451290719211  Generator_loss: 9.790594100952148\n",
            "epoch: 18/20,    batch: 2116/2993    Discriminator_loss: 0.00044517163769342005  Generator_loss: 9.786742210388184\n",
            "epoch: 18/20,    batch: 2117/2993    Discriminator_loss: 0.00030183250783011317  Generator_loss: 9.781716346740723\n",
            "epoch: 18/20,    batch: 2118/2993    Discriminator_loss: 0.00018393524806015193  Generator_loss: 9.776846885681152\n",
            "epoch: 18/20,    batch: 2119/2993    Discriminator_loss: 7.825763896107674e-05  Generator_loss: 9.772066116333008\n",
            "epoch: 18/20,    batch: 2120/2993    Discriminator_loss: 7.761661254335195e-05  Generator_loss: 9.766983032226562\n",
            "epoch: 18/20,    batch: 2121/2993    Discriminator_loss: 7.340131560340524e-05  Generator_loss: 9.760891914367676\n",
            "epoch: 18/20,    batch: 2122/2993    Discriminator_loss: 0.00017352087888866663  Generator_loss: 9.756507873535156\n",
            "epoch: 18/20,    batch: 2123/2993    Discriminator_loss: 6.663420208496973e-05  Generator_loss: 9.750800132751465\n",
            "epoch: 18/20,    batch: 2124/2993    Discriminator_loss: 0.0021478731650859118  Generator_loss: 9.744297981262207\n",
            "epoch: 18/20,    batch: 2125/2993    Discriminator_loss: 0.00013075239257887006  Generator_loss: 9.738722801208496\n",
            "epoch: 18/20,    batch: 2126/2993    Discriminator_loss: 6.092328476370312e-05  Generator_loss: 9.732109069824219\n",
            "epoch: 18/20,    batch: 2127/2993    Discriminator_loss: 9.833610965870321e-05  Generator_loss: 9.726163864135742\n",
            "epoch: 18/20,    batch: 2128/2993    Discriminator_loss: 0.00011094896035501733  Generator_loss: 9.720439910888672\n",
            "epoch: 18/20,    batch: 2129/2993    Discriminator_loss: 6.867390038678423e-05  Generator_loss: 9.715303421020508\n",
            "epoch: 18/20,    batch: 2130/2993    Discriminator_loss: 0.00016492060967721045  Generator_loss: 9.710376739501953\n",
            "epoch: 18/20,    batch: 2131/2993    Discriminator_loss: 9.07571375137195e-05  Generator_loss: 9.704375267028809\n",
            "epoch: 18/20,    batch: 2132/2993    Discriminator_loss: 6.804247095715255e-05  Generator_loss: 9.700536727905273\n",
            "epoch: 18/20,    batch: 2133/2993    Discriminator_loss: 9.693889296613634e-05  Generator_loss: 9.695199012756348\n",
            "epoch: 18/20,    batch: 2134/2993    Discriminator_loss: 7.291715883184224e-05  Generator_loss: 9.691093444824219\n",
            "epoch: 18/20,    batch: 2135/2993    Discriminator_loss: 0.0003078982699662447  Generator_loss: 9.68718433380127\n",
            "epoch: 18/20,    batch: 2136/2993    Discriminator_loss: 0.00039056033710949123  Generator_loss: 9.683231353759766\n",
            "epoch: 18/20,    batch: 2137/2993    Discriminator_loss: 6.944709457457066e-05  Generator_loss: 9.679532051086426\n",
            "epoch: 18/20,    batch: 2138/2993    Discriminator_loss: 0.00011665422061923891  Generator_loss: 9.675965309143066\n",
            "epoch: 18/20,    batch: 2139/2993    Discriminator_loss: 0.0001180702238343656  Generator_loss: 9.673416137695312\n",
            "epoch: 18/20,    batch: 2140/2993    Discriminator_loss: 7.58994574425742e-05  Generator_loss: 9.669988632202148\n",
            "epoch: 18/20,    batch: 2141/2993    Discriminator_loss: 7.386528886854649e-05  Generator_loss: 9.666338920593262\n",
            "epoch: 18/20,    batch: 2142/2993    Discriminator_loss: 0.00012415190576575696  Generator_loss: 9.664108276367188\n",
            "epoch: 18/20,    batch: 2143/2993    Discriminator_loss: 9.563606727169827e-05  Generator_loss: 9.660419464111328\n",
            "epoch: 18/20,    batch: 2144/2993    Discriminator_loss: 8.158992568496615e-05  Generator_loss: 9.657211303710938\n",
            "epoch: 18/20,    batch: 2145/2993    Discriminator_loss: 0.00013585443957708776  Generator_loss: 9.654884338378906\n",
            "epoch: 18/20,    batch: 2146/2993    Discriminator_loss: 9.043086174642667e-05  Generator_loss: 9.651229858398438\n",
            "epoch: 18/20,    batch: 2147/2993    Discriminator_loss: 7.612104673171416e-05  Generator_loss: 9.649206161499023\n",
            "epoch: 18/20,    batch: 2148/2993    Discriminator_loss: 8.300409535877407e-05  Generator_loss: 9.64586067199707\n",
            "epoch: 18/20,    batch: 2149/2993    Discriminator_loss: 0.00013250249321572483  Generator_loss: 9.642583847045898\n",
            "epoch: 18/20,    batch: 2150/2993    Discriminator_loss: 7.234178337967023e-05  Generator_loss: 9.640119552612305\n",
            "epoch: 18/20,    batch: 2151/2993    Discriminator_loss: 0.00012950734526384622  Generator_loss: 9.636632919311523\n",
            "epoch: 18/20,    batch: 2152/2993    Discriminator_loss: 8.964245353126898e-05  Generator_loss: 9.634523391723633\n",
            "epoch: 18/20,    batch: 2153/2993    Discriminator_loss: 7.258762343553826e-05  Generator_loss: 9.631000518798828\n",
            "epoch: 18/20,    batch: 2154/2993    Discriminator_loss: 7.249074405990541e-05  Generator_loss: 9.627431869506836\n",
            "epoch: 18/20,    batch: 2155/2993    Discriminator_loss: 0.0001763258478604257  Generator_loss: 9.624947547912598\n",
            "epoch: 18/20,    batch: 2156/2993    Discriminator_loss: 6.731445319019258e-05  Generator_loss: 9.621906280517578\n",
            "epoch: 18/20,    batch: 2157/2993    Discriminator_loss: 0.00010296280379407108  Generator_loss: 9.618314743041992\n",
            "epoch: 18/20,    batch: 2158/2993    Discriminator_loss: 0.00013554829638451338  Generator_loss: 9.614904403686523\n",
            "epoch: 18/20,    batch: 2159/2993    Discriminator_loss: 9.228209819411859e-05  Generator_loss: 9.611448287963867\n",
            "epoch: 18/20,    batch: 2160/2993    Discriminator_loss: 9.651976870372891e-05  Generator_loss: 9.60772705078125\n",
            "epoch: 18/20,    batch: 2161/2993    Discriminator_loss: 9.863303421298042e-05  Generator_loss: 9.604408264160156\n",
            "epoch: 18/20,    batch: 2162/2993    Discriminator_loss: 8.151570364134386e-05  Generator_loss: 9.600658416748047\n",
            "epoch: 18/20,    batch: 2163/2993    Discriminator_loss: 0.00015289068687707186  Generator_loss: 9.597031593322754\n",
            "epoch: 18/20,    batch: 2164/2993    Discriminator_loss: 9.373604552820325e-05  Generator_loss: 9.592217445373535\n",
            "epoch: 18/20,    batch: 2165/2993    Discriminator_loss: 8.310444536618888e-05  Generator_loss: 9.588458061218262\n",
            "epoch: 18/20,    batch: 2166/2993    Discriminator_loss: 0.00011975308007095009  Generator_loss: 9.584280967712402\n",
            "epoch: 18/20,    batch: 2167/2993    Discriminator_loss: 7.86769378464669e-05  Generator_loss: 9.579689025878906\n",
            "epoch: 18/20,    batch: 2168/2993    Discriminator_loss: 0.00014898469089530408  Generator_loss: 9.574634552001953\n",
            "epoch: 18/20,    batch: 2169/2993    Discriminator_loss: 0.00012475583935156465  Generator_loss: 9.570621490478516\n",
            "epoch: 18/20,    batch: 2170/2993    Discriminator_loss: 7.292500959010795e-05  Generator_loss: 9.565932273864746\n",
            "epoch: 18/20,    batch: 2171/2993    Discriminator_loss: 9.420061542186886e-05  Generator_loss: 9.56100082397461\n",
            "epoch: 18/20,    batch: 2172/2993    Discriminator_loss: 0.00020143947040196508  Generator_loss: 9.555883407592773\n",
            "epoch: 18/20,    batch: 2173/2993    Discriminator_loss: 7.38862290745601e-05  Generator_loss: 9.550999641418457\n",
            "epoch: 18/20,    batch: 2174/2993    Discriminator_loss: 9.038046118803322e-05  Generator_loss: 9.54593276977539\n",
            "epoch: 18/20,    batch: 2175/2993    Discriminator_loss: 0.0002959845878649503  Generator_loss: 9.541150093078613\n",
            "epoch: 18/20,    batch: 2176/2993    Discriminator_loss: 0.00011589511996135116  Generator_loss: 9.537164688110352\n",
            "epoch: 18/20,    batch: 2177/2993    Discriminator_loss: 0.00011599781282711774  Generator_loss: 9.532526016235352\n",
            "epoch: 18/20,    batch: 2178/2993    Discriminator_loss: 0.00013135914923623204  Generator_loss: 9.527706146240234\n",
            "epoch: 18/20,    batch: 2179/2993    Discriminator_loss: 9.416946704732254e-05  Generator_loss: 9.52336597442627\n",
            "epoch: 18/20,    batch: 2180/2993    Discriminator_loss: 9.165624214801937e-05  Generator_loss: 9.519500732421875\n",
            "epoch: 18/20,    batch: 2181/2993    Discriminator_loss: 0.00010759977158159018  Generator_loss: 9.515095710754395\n",
            "epoch: 18/20,    batch: 2182/2993    Discriminator_loss: 0.00012979294115211815  Generator_loss: 9.511615753173828\n",
            "epoch: 18/20,    batch: 2183/2993    Discriminator_loss: 8.539592090528458e-05  Generator_loss: 9.508097648620605\n",
            "epoch: 18/20,    batch: 2184/2993    Discriminator_loss: 0.00016087977564893663  Generator_loss: 9.503791809082031\n",
            "epoch: 18/20,    batch: 2185/2993    Discriminator_loss: 9.645662794355303e-05  Generator_loss: 9.50045108795166\n",
            "epoch: 18/20,    batch: 2186/2993    Discriminator_loss: 8.13371007097885e-05  Generator_loss: 9.496971130371094\n",
            "epoch: 18/20,    batch: 2187/2993    Discriminator_loss: 0.0001101289308280684  Generator_loss: 9.493799209594727\n",
            "epoch: 18/20,    batch: 2188/2993    Discriminator_loss: 0.0001893544103950262  Generator_loss: 9.490541458129883\n",
            "epoch: 18/20,    batch: 2189/2993    Discriminator_loss: 8.119193080347031e-05  Generator_loss: 9.48714542388916\n",
            "epoch: 18/20,    batch: 2190/2993    Discriminator_loss: 0.00011510259355418384  Generator_loss: 9.483320236206055\n",
            "epoch: 18/20,    batch: 2191/2993    Discriminator_loss: 0.00012565424549393356  Generator_loss: 9.479900360107422\n",
            "epoch: 18/20,    batch: 2192/2993    Discriminator_loss: 0.00010489611304365098  Generator_loss: 9.476783752441406\n",
            "epoch: 18/20,    batch: 2193/2993    Discriminator_loss: 0.00011736794840544462  Generator_loss: 9.473433494567871\n",
            "epoch: 18/20,    batch: 2194/2993    Discriminator_loss: 0.00010826923971762881  Generator_loss: 9.47038459777832\n",
            "epoch: 18/20,    batch: 2195/2993    Discriminator_loss: 8.677814912516624e-05  Generator_loss: 9.467201232910156\n",
            "epoch: 18/20,    batch: 2196/2993    Discriminator_loss: 0.00014604534953832626  Generator_loss: 9.463594436645508\n",
            "epoch: 18/20,    batch: 2197/2993    Discriminator_loss: 9.175029117614031e-05  Generator_loss: 9.459810256958008\n",
            "epoch: 18/20,    batch: 2198/2993    Discriminator_loss: 9.96347371255979e-05  Generator_loss: 9.456518173217773\n",
            "epoch: 18/20,    batch: 2199/2993    Discriminator_loss: 0.00014987941540312022  Generator_loss: 9.453140258789062\n",
            "epoch: 18/20,    batch: 2200/2993    Discriminator_loss: 8.164657629095018e-05  Generator_loss: 9.448969841003418\n",
            "epoch: 18/20,    batch: 2201/2993    Discriminator_loss: 0.0003988567041233182  Generator_loss: 9.445899963378906\n",
            "epoch: 18/20,    batch: 2202/2993    Discriminator_loss: 0.00014438678044825792  Generator_loss: 9.441431045532227\n",
            "epoch: 18/20,    batch: 2203/2993    Discriminator_loss: 8.742837235331535e-05  Generator_loss: 9.43847942352295\n",
            "epoch: 18/20,    batch: 2204/2993    Discriminator_loss: 0.00013921501522418112  Generator_loss: 9.434088706970215\n",
            "epoch: 18/20,    batch: 2205/2993    Discriminator_loss: 0.000162197626195848  Generator_loss: 9.430183410644531\n",
            "epoch: 18/20,    batch: 2206/2993    Discriminator_loss: 8.128906483761966e-05  Generator_loss: 9.426477432250977\n",
            "epoch: 18/20,    batch: 2207/2993    Discriminator_loss: 9.65778817771934e-05  Generator_loss: 9.422140121459961\n",
            "epoch: 18/20,    batch: 2208/2993    Discriminator_loss: 0.00011844483378808945  Generator_loss: 9.417776107788086\n",
            "epoch: 18/20,    batch: 2209/2993    Discriminator_loss: 0.00011759372137021273  Generator_loss: 9.413795471191406\n",
            "epoch: 18/20,    batch: 2210/2993    Discriminator_loss: 9.047766798175871e-05  Generator_loss: 9.410331726074219\n",
            "epoch: 18/20,    batch: 2211/2993    Discriminator_loss: 0.00012911313388030976  Generator_loss: 9.405926704406738\n",
            "epoch: 18/20,    batch: 2212/2993    Discriminator_loss: 0.00013966046390123665  Generator_loss: 9.401678085327148\n",
            "epoch: 18/20,    batch: 2213/2993    Discriminator_loss: 8.630723459646106e-05  Generator_loss: 9.39731216430664\n",
            "epoch: 18/20,    batch: 2214/2993    Discriminator_loss: 9.840162965701893e-05  Generator_loss: 9.393054962158203\n",
            "epoch: 18/20,    batch: 2215/2993    Discriminator_loss: 0.0001679909328231588  Generator_loss: 9.388771057128906\n",
            "epoch: 18/20,    batch: 2216/2993    Discriminator_loss: 8.541324496036395e-05  Generator_loss: 9.384504318237305\n",
            "epoch: 18/20,    batch: 2217/2993    Discriminator_loss: 0.00012052961392328143  Generator_loss: 9.380212783813477\n",
            "epoch: 18/20,    batch: 2218/2993    Discriminator_loss: 0.00015589971735607833  Generator_loss: 9.37585163116455\n",
            "epoch: 18/20,    batch: 2219/2993    Discriminator_loss: 8.881456597009674e-05  Generator_loss: 9.37089729309082\n",
            "epoch: 18/20,    batch: 2220/2993    Discriminator_loss: 9.914304973790422e-05  Generator_loss: 9.366532325744629\n",
            "epoch: 18/20,    batch: 2221/2993    Discriminator_loss: 0.00011198472930118442  Generator_loss: 9.362186431884766\n",
            "epoch: 18/20,    batch: 2222/2993    Discriminator_loss: 0.0001365716743748635  Generator_loss: 9.3580322265625\n",
            "epoch: 18/20,    batch: 2223/2993    Discriminator_loss: 9.684277029009536e-05  Generator_loss: 9.353723526000977\n",
            "epoch: 18/20,    batch: 2224/2993    Discriminator_loss: 0.000228798424359411  Generator_loss: 9.349475860595703\n",
            "epoch: 18/20,    batch: 2225/2993    Discriminator_loss: 0.0001138453881139867  Generator_loss: 9.345160484313965\n",
            "epoch: 18/20,    batch: 2226/2993    Discriminator_loss: 0.00010774919064715505  Generator_loss: 9.340356826782227\n",
            "epoch: 18/20,    batch: 2227/2993    Discriminator_loss: 0.00017468332953285426  Generator_loss: 9.336078643798828\n",
            "epoch: 18/20,    batch: 2228/2993    Discriminator_loss: 9.238928760169074e-05  Generator_loss: 9.331991195678711\n",
            "epoch: 18/20,    batch: 2229/2993    Discriminator_loss: 0.00012561489711515605  Generator_loss: 9.327875137329102\n",
            "epoch: 18/20,    batch: 2230/2993    Discriminator_loss: 0.0001405676594004035  Generator_loss: 9.32336139678955\n",
            "epoch: 18/20,    batch: 2231/2993    Discriminator_loss: 9.139097528532147e-05  Generator_loss: 9.318574905395508\n",
            "epoch: 18/20,    batch: 2232/2993    Discriminator_loss: 0.00011866464046761394  Generator_loss: 9.314516067504883\n",
            "epoch: 18/20,    batch: 2233/2993    Discriminator_loss: 0.00015797873493283987  Generator_loss: 9.309401512145996\n",
            "epoch: 18/20,    batch: 2234/2993    Discriminator_loss: 0.00010078081686515361  Generator_loss: 9.304396629333496\n",
            "epoch: 18/20,    batch: 2235/2993    Discriminator_loss: 0.39187464118003845  Generator_loss: 9.284662246704102\n",
            "epoch: 18/20,    batch: 2236/2993    Discriminator_loss: 0.0067377942614257336  Generator_loss: 9.264245986938477\n",
            "epoch: 18/20,    batch: 2237/2993    Discriminator_loss: 0.009101632982492447  Generator_loss: 9.244200706481934\n",
            "epoch: 18/20,    batch: 2238/2993    Discriminator_loss: 0.006607602350413799  Generator_loss: 9.223642349243164\n",
            "epoch: 18/20,    batch: 2239/2993    Discriminator_loss: 0.004529119003564119  Generator_loss: 9.203387260437012\n",
            "epoch: 18/20,    batch: 2240/2993    Discriminator_loss: 0.003961946349591017  Generator_loss: 9.184732437133789\n",
            "epoch: 18/20,    batch: 2241/2993    Discriminator_loss: 0.0035048292484134436  Generator_loss: 9.167381286621094\n",
            "epoch: 18/20,    batch: 2242/2993    Discriminator_loss: 0.0021752123720943928  Generator_loss: 9.151520729064941\n",
            "epoch: 18/20,    batch: 2243/2993    Discriminator_loss: 0.001833848305977881  Generator_loss: 9.137117385864258\n",
            "epoch: 18/20,    batch: 2244/2993    Discriminator_loss: 0.0013983140233904123  Generator_loss: 9.12435531616211\n",
            "epoch: 18/20,    batch: 2245/2993    Discriminator_loss: 0.0014763249782845378  Generator_loss: 9.112833023071289\n",
            "epoch: 18/20,    batch: 2246/2993    Discriminator_loss: 0.0013602916151285172  Generator_loss: 9.10207748413086\n",
            "epoch: 18/20,    batch: 2247/2993    Discriminator_loss: 0.0013523856177926064  Generator_loss: 9.092463493347168\n",
            "epoch: 18/20,    batch: 2248/2993    Discriminator_loss: 0.0011683428892865777  Generator_loss: 9.08411979675293\n",
            "epoch: 18/20,    batch: 2249/2993    Discriminator_loss: 0.0010925314854830503  Generator_loss: 9.075944900512695\n",
            "epoch: 18/20,    batch: 2250/2993    Discriminator_loss: 0.0011242557084187865  Generator_loss: 9.068675994873047\n",
            "epoch: 18/20,    batch: 2251/2993    Discriminator_loss: 0.0070101916790008545  Generator_loss: 9.061139106750488\n",
            "epoch: 18/20,    batch: 2252/2993    Discriminator_loss: 0.00017614652460906655  Generator_loss: 9.054327011108398\n",
            "epoch: 18/20,    batch: 2253/2993    Discriminator_loss: 0.00014030189777258784  Generator_loss: 9.0479736328125\n",
            "epoch: 18/20,    batch: 2254/2993    Discriminator_loss: 0.00012643034278880805  Generator_loss: 9.042383193969727\n",
            "epoch: 18/20,    batch: 2255/2993    Discriminator_loss: 0.00012939015869051218  Generator_loss: 9.036981582641602\n",
            "epoch: 18/20,    batch: 2256/2993    Discriminator_loss: 0.00020969593606423587  Generator_loss: 9.03210735321045\n",
            "epoch: 18/20,    batch: 2257/2993    Discriminator_loss: 0.00012373525532893836  Generator_loss: 9.027813911437988\n",
            "epoch: 18/20,    batch: 2258/2993    Discriminator_loss: 0.0003511397517286241  Generator_loss: 9.02316951751709\n",
            "epoch: 18/20,    batch: 2259/2993    Discriminator_loss: 0.00016394382691942155  Generator_loss: 9.018945693969727\n",
            "epoch: 18/20,    batch: 2260/2993    Discriminator_loss: 0.00012424394662957639  Generator_loss: 9.014923095703125\n",
            "epoch: 18/20,    batch: 2261/2993    Discriminator_loss: 0.00012739749217871577  Generator_loss: 9.01058292388916\n",
            "epoch: 18/20,    batch: 2262/2993    Discriminator_loss: 0.00013652835332322866  Generator_loss: 9.006654739379883\n",
            "epoch: 18/20,    batch: 2263/2993    Discriminator_loss: 0.0002185081975767389  Generator_loss: 9.002500534057617\n",
            "epoch: 18/20,    batch: 2264/2993    Discriminator_loss: 0.00013775602565146983  Generator_loss: 8.998483657836914\n",
            "epoch: 18/20,    batch: 2265/2993    Discriminator_loss: 0.000156770707690157  Generator_loss: 8.994393348693848\n",
            "epoch: 18/20,    batch: 2266/2993    Discriminator_loss: 0.00015448690101038665  Generator_loss: 8.989990234375\n",
            "epoch: 18/20,    batch: 2267/2993    Discriminator_loss: 0.00012666953261941671  Generator_loss: 8.98587417602539\n",
            "epoch: 18/20,    batch: 2268/2993    Discriminator_loss: 0.00013157584180589765  Generator_loss: 8.98147964477539\n",
            "epoch: 18/20,    batch: 2269/2993    Discriminator_loss: 0.00015300067025236785  Generator_loss: 8.976601600646973\n",
            "epoch: 18/20,    batch: 2270/2993    Discriminator_loss: 0.00017887372814584523  Generator_loss: 8.97183609008789\n",
            "epoch: 18/20,    batch: 2271/2993    Discriminator_loss: 0.00012976184370927513  Generator_loss: 8.966917037963867\n",
            "epoch: 18/20,    batch: 2272/2993    Discriminator_loss: 0.00019253829668741673  Generator_loss: 8.961645126342773\n",
            "epoch: 18/20,    batch: 2273/2993    Discriminator_loss: 0.00019221639377065003  Generator_loss: 8.956083297729492\n",
            "epoch: 18/20,    batch: 2274/2993    Discriminator_loss: 0.00013459756155498326  Generator_loss: 8.95046615600586\n",
            "epoch: 18/20,    batch: 2275/2993    Discriminator_loss: 0.0002388891443843022  Generator_loss: 8.944337844848633\n",
            "epoch: 18/20,    batch: 2276/2993    Discriminator_loss: 0.00014353312144521624  Generator_loss: 8.938159942626953\n",
            "epoch: 18/20,    batch: 2277/2993    Discriminator_loss: 0.0001456809404771775  Generator_loss: 8.931512832641602\n",
            "epoch: 18/20,    batch: 2278/2993    Discriminator_loss: 0.00021989442757330835  Generator_loss: 8.924995422363281\n",
            "epoch: 18/20,    batch: 2279/2993    Discriminator_loss: 0.00013699164264835417  Generator_loss: 8.917906761169434\n",
            "epoch: 18/20,    batch: 2280/2993    Discriminator_loss: 0.0001636455999687314  Generator_loss: 8.910731315612793\n",
            "epoch: 18/20,    batch: 2281/2993    Discriminator_loss: 0.00024447584291920066  Generator_loss: 8.903030395507812\n",
            "epoch: 18/20,    batch: 2282/2993    Discriminator_loss: 0.0001375750289298594  Generator_loss: 8.895225524902344\n",
            "epoch: 18/20,    batch: 2283/2993    Discriminator_loss: 0.00017041323008015752  Generator_loss: 8.88791275024414\n",
            "epoch: 18/20,    batch: 2284/2993    Discriminator_loss: 0.00027526909252628684  Generator_loss: 8.880197525024414\n",
            "epoch: 18/20,    batch: 2285/2993    Discriminator_loss: 0.00014665245544165373  Generator_loss: 8.872594833374023\n",
            "epoch: 18/20,    batch: 2286/2993    Discriminator_loss: 0.00024699472123757005  Generator_loss: 8.865102767944336\n",
            "epoch: 18/20,    batch: 2287/2993    Discriminator_loss: 0.00019815179985016584  Generator_loss: 8.857796669006348\n",
            "epoch: 18/20,    batch: 2288/2993    Discriminator_loss: 0.00014565048331860453  Generator_loss: 8.850776672363281\n",
            "epoch: 18/20,    batch: 2289/2993    Discriminator_loss: 0.00018581670883577317  Generator_loss: 8.844220161437988\n",
            "epoch: 18/20,    batch: 2290/2993    Discriminator_loss: 0.00016779654833953828  Generator_loss: 8.83827018737793\n",
            "epoch: 18/20,    batch: 2291/2993    Discriminator_loss: 0.0002625992929097265  Generator_loss: 8.832331657409668\n",
            "epoch: 18/20,    batch: 2292/2993    Discriminator_loss: 0.00016523890371900052  Generator_loss: 8.826933860778809\n",
            "epoch: 18/20,    batch: 2293/2993    Discriminator_loss: 0.004047705326229334  Generator_loss: 8.820734024047852\n",
            "epoch: 18/20,    batch: 2294/2993    Discriminator_loss: 0.0002289911062689498  Generator_loss: 8.815248489379883\n",
            "epoch: 18/20,    batch: 2295/2993    Discriminator_loss: 0.00015247605915647  Generator_loss: 8.810142517089844\n",
            "epoch: 18/20,    batch: 2296/2993    Discriminator_loss: 0.00017183329327963293  Generator_loss: 8.805458068847656\n",
            "epoch: 18/20,    batch: 2297/2993    Discriminator_loss: 0.000244402646785602  Generator_loss: 8.801292419433594\n",
            "epoch: 18/20,    batch: 2298/2993    Discriminator_loss: 0.0001852688001235947  Generator_loss: 8.797365188598633\n",
            "epoch: 18/20,    batch: 2299/2993    Discriminator_loss: 0.0001617152738617733  Generator_loss: 8.793675422668457\n",
            "epoch: 18/20,    batch: 2300/2993    Discriminator_loss: 0.00022224172425922006  Generator_loss: 8.790315628051758\n",
            "epoch: 18/20,    batch: 2301/2993    Discriminator_loss: 0.00017667273641563952  Generator_loss: 8.787261962890625\n",
            "epoch: 18/20,    batch: 2302/2993    Discriminator_loss: 0.00015525573689956218  Generator_loss: 8.784191131591797\n",
            "epoch: 18/20,    batch: 2303/2993    Discriminator_loss: 0.00018359308887738734  Generator_loss: 8.781713485717773\n",
            "epoch: 18/20,    batch: 2304/2993    Discriminator_loss: 0.0002693538262974471  Generator_loss: 8.779144287109375\n",
            "epoch: 18/20,    batch: 2305/2993    Discriminator_loss: 0.0002019340026890859  Generator_loss: 8.776533126831055\n",
            "epoch: 18/20,    batch: 2306/2993    Discriminator_loss: 0.00018708562129177153  Generator_loss: 8.774169921875\n",
            "epoch: 18/20,    batch: 2307/2993    Discriminator_loss: 0.0016140113584697247  Generator_loss: 8.771644592285156\n",
            "epoch: 18/20,    batch: 2308/2993    Discriminator_loss: 0.00019172037718817592  Generator_loss: 8.768884658813477\n",
            "epoch: 18/20,    batch: 2309/2993    Discriminator_loss: 0.00017293478595092893  Generator_loss: 8.766373634338379\n",
            "epoch: 18/20,    batch: 2310/2993    Discriminator_loss: 0.00021921025472693145  Generator_loss: 8.764129638671875\n",
            "epoch: 18/20,    batch: 2311/2993    Discriminator_loss: 0.00017466043937020004  Generator_loss: 8.762175559997559\n",
            "epoch: 18/20,    batch: 2312/2993    Discriminator_loss: 0.0001817865704651922  Generator_loss: 8.76015567779541\n",
            "epoch: 18/20,    batch: 2313/2993    Discriminator_loss: 0.0007285132305696607  Generator_loss: 8.757996559143066\n",
            "epoch: 18/20,    batch: 2314/2993    Discriminator_loss: 0.00017118611140176654  Generator_loss: 8.756386756896973\n",
            "epoch: 18/20,    batch: 2315/2993    Discriminator_loss: 0.00024227815447375178  Generator_loss: 8.754329681396484\n",
            "epoch: 18/20,    batch: 2316/2993    Discriminator_loss: 0.00028747826581820846  Generator_loss: 8.752678871154785\n",
            "epoch: 18/20,    batch: 2317/2993    Discriminator_loss: 0.00020005268743261695  Generator_loss: 8.75110149383545\n",
            "epoch: 18/20,    batch: 2318/2993    Discriminator_loss: 0.00022953127336222678  Generator_loss: 8.749618530273438\n",
            "epoch: 18/20,    batch: 2319/2993    Discriminator_loss: 0.00020117788517381996  Generator_loss: 8.748069763183594\n",
            "epoch: 18/20,    batch: 2320/2993    Discriminator_loss: 0.00016246883023995906  Generator_loss: 8.746452331542969\n",
            "epoch: 18/20,    batch: 2321/2993    Discriminator_loss: 0.00026886994601227343  Generator_loss: 8.745046615600586\n",
            "epoch: 18/20,    batch: 2322/2993    Discriminator_loss: 0.00023514285567216575  Generator_loss: 8.743620872497559\n",
            "epoch: 18/20,    batch: 2323/2993    Discriminator_loss: 0.00016391996177844703  Generator_loss: 8.742103576660156\n",
            "epoch: 18/20,    batch: 2324/2993    Discriminator_loss: 0.00019351304217707366  Generator_loss: 8.740589141845703\n",
            "epoch: 18/20,    batch: 2325/2993    Discriminator_loss: 0.00020036200294271111  Generator_loss: 8.73917007446289\n",
            "epoch: 18/20,    batch: 2326/2993    Discriminator_loss: 0.0002210328821092844  Generator_loss: 8.73770523071289\n",
            "epoch: 18/20,    batch: 2327/2993    Discriminator_loss: 0.00019405694911256433  Generator_loss: 8.736150741577148\n",
            "epoch: 18/20,    batch: 2328/2993    Discriminator_loss: 0.0021719159558415413  Generator_loss: 8.73471450805664\n",
            "epoch: 18/20,    batch: 2329/2993    Discriminator_loss: 0.00024216009478550404  Generator_loss: 8.732839584350586\n",
            "epoch: 18/20,    batch: 2330/2993    Discriminator_loss: 0.0001650601625442505  Generator_loss: 8.731040000915527\n",
            "epoch: 18/20,    batch: 2331/2993    Discriminator_loss: 0.00017907508299686015  Generator_loss: 8.72951889038086\n",
            "epoch: 18/20,    batch: 2332/2993    Discriminator_loss: 0.0002371227601543069  Generator_loss: 8.728046417236328\n",
            "epoch: 18/20,    batch: 2333/2993    Discriminator_loss: 0.00024993185070343316  Generator_loss: 8.726482391357422\n",
            "epoch: 18/20,    batch: 2334/2993    Discriminator_loss: 0.0001857529568951577  Generator_loss: 8.724624633789062\n",
            "epoch: 18/20,    batch: 2335/2993    Discriminator_loss: 0.00047758204163983464  Generator_loss: 8.723044395446777\n",
            "epoch: 18/20,    batch: 2336/2993    Discriminator_loss: 0.0002829634759109467  Generator_loss: 8.721443176269531\n",
            "epoch: 18/20,    batch: 2337/2993    Discriminator_loss: 0.00016617990331724286  Generator_loss: 8.719709396362305\n",
            "epoch: 18/20,    batch: 2338/2993    Discriminator_loss: 0.00025928590912371874  Generator_loss: 8.71790885925293\n",
            "epoch: 18/20,    batch: 2339/2993    Discriminator_loss: 0.00026774138677865267  Generator_loss: 8.716361999511719\n",
            "epoch: 18/20,    batch: 2340/2993    Discriminator_loss: 0.00021230417769402266  Generator_loss: 8.714225769042969\n",
            "epoch: 18/20,    batch: 2341/2993    Discriminator_loss: 0.00019802464521490037  Generator_loss: 8.712732315063477\n",
            "epoch: 18/20,    batch: 2342/2993    Discriminator_loss: 0.0008140804129652679  Generator_loss: 8.71053695678711\n",
            "epoch: 18/20,    batch: 2343/2993    Discriminator_loss: 0.00018539601296652108  Generator_loss: 8.70834732055664\n",
            "epoch: 18/20,    batch: 2344/2993    Discriminator_loss: 0.00019032998534385115  Generator_loss: 8.70625114440918\n",
            "epoch: 18/20,    batch: 2345/2993    Discriminator_loss: 0.000280526204733178  Generator_loss: 8.70413875579834\n",
            "epoch: 18/20,    batch: 2346/2993    Discriminator_loss: 0.00017699346062727273  Generator_loss: 8.701873779296875\n",
            "epoch: 18/20,    batch: 2347/2993    Discriminator_loss: 0.00019073982548434287  Generator_loss: 8.699210166931152\n",
            "epoch: 18/20,    batch: 2348/2993    Discriminator_loss: 0.0002421369426883757  Generator_loss: 8.696911811828613\n",
            "epoch: 18/20,    batch: 2349/2993    Discriminator_loss: 0.00018721408559940755  Generator_loss: 8.694084167480469\n",
            "epoch: 18/20,    batch: 2350/2993    Discriminator_loss: 0.00023290564422495663  Generator_loss: 8.691398620605469\n",
            "epoch: 18/20,    batch: 2351/2993    Discriminator_loss: 0.00021619514154735953  Generator_loss: 8.688852310180664\n",
            "epoch: 18/20,    batch: 2352/2993    Discriminator_loss: 0.00019266820163466036  Generator_loss: 8.686091423034668\n",
            "epoch: 18/20,    batch: 2353/2993    Discriminator_loss: 0.00048697448801249266  Generator_loss: 8.68303108215332\n",
            "epoch: 18/20,    batch: 2354/2993    Discriminator_loss: 0.0001989125448744744  Generator_loss: 8.680242538452148\n",
            "epoch: 18/20,    batch: 2355/2993    Discriminator_loss: 0.0001768969086697325  Generator_loss: 8.677220344543457\n",
            "epoch: 18/20,    batch: 2356/2993    Discriminator_loss: 0.00024289151770062745  Generator_loss: 8.674383163452148\n",
            "epoch: 18/20,    batch: 2357/2993    Discriminator_loss: 0.0002008089068112895  Generator_loss: 8.671684265136719\n",
            "epoch: 18/20,    batch: 2358/2993    Discriminator_loss: 0.00018303659453522414  Generator_loss: 8.669036865234375\n",
            "epoch: 18/20,    batch: 2359/2993    Discriminator_loss: 0.0001955167972482741  Generator_loss: 8.666675567626953\n",
            "epoch: 18/20,    batch: 2360/2993    Discriminator_loss: 0.00022537994664162397  Generator_loss: 8.664083480834961\n",
            "epoch: 18/20,    batch: 2361/2993    Discriminator_loss: 0.00019193720072507858  Generator_loss: 8.662229537963867\n",
            "epoch: 18/20,    batch: 2362/2993    Discriminator_loss: 0.0001899566559586674  Generator_loss: 8.659906387329102\n",
            "epoch: 18/20,    batch: 2363/2993    Discriminator_loss: 0.0003384771407581866  Generator_loss: 8.657953262329102\n",
            "epoch: 18/20,    batch: 2364/2993    Discriminator_loss: 0.00018406694289296865  Generator_loss: 8.656003952026367\n",
            "epoch: 18/20,    batch: 2365/2993    Discriminator_loss: 0.00018702319357544184  Generator_loss: 8.654165267944336\n",
            "epoch: 18/20,    batch: 2366/2993    Discriminator_loss: 0.0001941142836585641  Generator_loss: 8.652670860290527\n",
            "epoch: 18/20,    batch: 2367/2993    Discriminator_loss: 0.00024279241915792227  Generator_loss: 8.651243209838867\n",
            "epoch: 18/20,    batch: 2368/2993    Discriminator_loss: 0.00018019092385657132  Generator_loss: 8.649689674377441\n",
            "epoch: 18/20,    batch: 2369/2993    Discriminator_loss: 0.00021122631733305752  Generator_loss: 8.648521423339844\n",
            "epoch: 18/20,    batch: 2370/2993    Discriminator_loss: 0.00024672364816069603  Generator_loss: 8.647162437438965\n",
            "epoch: 18/20,    batch: 2371/2993    Discriminator_loss: 0.00018689480202738196  Generator_loss: 8.645933151245117\n",
            "epoch: 18/20,    batch: 2372/2993    Discriminator_loss: 0.00019938799960073084  Generator_loss: 8.644874572753906\n",
            "epoch: 18/20,    batch: 2373/2993    Discriminator_loss: 0.00018364815332461149  Generator_loss: 8.643815994262695\n",
            "epoch: 18/20,    batch: 2374/2993    Discriminator_loss: 0.00022121399524621665  Generator_loss: 8.642887115478516\n",
            "epoch: 18/20,    batch: 2375/2993    Discriminator_loss: 0.00017958947864826769  Generator_loss: 8.641788482666016\n",
            "epoch: 18/20,    batch: 2376/2993    Discriminator_loss: 0.0002533095539547503  Generator_loss: 8.641029357910156\n",
            "epoch: 18/20,    batch: 2377/2993    Discriminator_loss: 0.0003103787894360721  Generator_loss: 8.639829635620117\n",
            "epoch: 18/20,    batch: 2378/2993    Discriminator_loss: 0.00018124360940419137  Generator_loss: 8.639070510864258\n",
            "epoch: 18/20,    batch: 2379/2993    Discriminator_loss: 0.00021049911447335035  Generator_loss: 8.638019561767578\n",
            "epoch: 18/20,    batch: 2380/2993    Discriminator_loss: 0.00026297621661797166  Generator_loss: 8.637011528015137\n",
            "epoch: 18/20,    batch: 2381/2993    Discriminator_loss: 0.0001810611574910581  Generator_loss: 8.636276245117188\n",
            "epoch: 18/20,    batch: 2382/2993    Discriminator_loss: 0.00020752259297296405  Generator_loss: 8.635059356689453\n",
            "epoch: 18/20,    batch: 2383/2993    Discriminator_loss: 0.0002538407570682466  Generator_loss: 8.634431838989258\n",
            "epoch: 18/20,    batch: 2384/2993    Discriminator_loss: 0.00019004693604074419  Generator_loss: 8.6333646774292\n",
            "epoch: 18/20,    batch: 2385/2993    Discriminator_loss: 0.0002361998922424391  Generator_loss: 8.632381439208984\n",
            "epoch: 18/20,    batch: 2386/2993    Discriminator_loss: 0.00019946912652812898  Generator_loss: 8.631296157836914\n",
            "epoch: 18/20,    batch: 2387/2993    Discriminator_loss: 0.00018505485786590725  Generator_loss: 8.630439758300781\n",
            "epoch: 18/20,    batch: 2388/2993    Discriminator_loss: 0.0002682326012291014  Generator_loss: 8.629188537597656\n",
            "epoch: 18/20,    batch: 2389/2993    Discriminator_loss: 0.00019754888489842415  Generator_loss: 8.628293991088867\n",
            "epoch: 18/20,    batch: 2390/2993    Discriminator_loss: 0.00019614164193626493  Generator_loss: 8.62702465057373\n",
            "epoch: 18/20,    batch: 2391/2993    Discriminator_loss: 0.0002151712542399764  Generator_loss: 8.625799179077148\n",
            "epoch: 18/20,    batch: 2392/2993    Discriminator_loss: 0.00018556168652139604  Generator_loss: 8.62478256225586\n",
            "epoch: 18/20,    batch: 2393/2993    Discriminator_loss: 0.00020779500482603908  Generator_loss: 8.623641967773438\n",
            "epoch: 18/20,    batch: 2394/2993    Discriminator_loss: 0.0001918277848744765  Generator_loss: 8.622461318969727\n",
            "epoch: 18/20,    batch: 2395/2993    Discriminator_loss: 0.0002770588034763932  Generator_loss: 8.621034622192383\n",
            "epoch: 18/20,    batch: 2396/2993    Discriminator_loss: 0.0001818570017348975  Generator_loss: 8.619712829589844\n",
            "epoch: 18/20,    batch: 2397/2993    Discriminator_loss: 0.00021306099370121956  Generator_loss: 8.618392944335938\n",
            "epoch: 18/20,    batch: 2398/2993    Discriminator_loss: 0.00020351629063952714  Generator_loss: 8.617033004760742\n",
            "epoch: 18/20,    batch: 2399/2993    Discriminator_loss: 0.00018164666835218668  Generator_loss: 8.615592956542969\n",
            "epoch: 18/20,    batch: 2400/2993    Discriminator_loss: 0.00019638228695839643  Generator_loss: 8.613992691040039\n",
            "epoch: 18/20,    batch: 2401/2993    Discriminator_loss: 0.00023087678709998727  Generator_loss: 8.612495422363281\n",
            "epoch: 18/20,    batch: 2402/2993    Discriminator_loss: 0.0001930430589709431  Generator_loss: 8.611103057861328\n",
            "epoch: 18/20,    batch: 2403/2993    Discriminator_loss: 0.00019952849834226072  Generator_loss: 8.609407424926758\n",
            "epoch: 18/20,    batch: 2404/2993    Discriminator_loss: 0.000211546866921708  Generator_loss: 8.607854843139648\n",
            "epoch: 18/20,    batch: 2405/2993    Discriminator_loss: 0.00018620301852934062  Generator_loss: 8.606000900268555\n",
            "epoch: 18/20,    batch: 2406/2993    Discriminator_loss: 0.00019485890516079962  Generator_loss: 8.60457706451416\n",
            "epoch: 18/20,    batch: 2407/2993    Discriminator_loss: 0.0002131718210875988  Generator_loss: 8.60270881652832\n",
            "epoch: 18/20,    batch: 2408/2993    Discriminator_loss: 0.00021901019499637187  Generator_loss: 8.60080337524414\n",
            "epoch: 18/20,    batch: 2409/2993    Discriminator_loss: 0.00019854909623973072  Generator_loss: 8.598759651184082\n",
            "epoch: 18/20,    batch: 2410/2993    Discriminator_loss: 0.00024796751677058637  Generator_loss: 8.596841812133789\n",
            "epoch: 18/20,    batch: 2411/2993    Discriminator_loss: 0.0001901206123875454  Generator_loss: 8.594805717468262\n",
            "epoch: 18/20,    batch: 2412/2993    Discriminator_loss: 0.00020547863095998764  Generator_loss: 8.592636108398438\n",
            "epoch: 18/20,    batch: 2413/2993    Discriminator_loss: 0.0002449919702485204  Generator_loss: 8.590167999267578\n",
            "epoch: 18/20,    batch: 2414/2993    Discriminator_loss: 0.0001877608010545373  Generator_loss: 8.587706565856934\n",
            "epoch: 18/20,    batch: 2415/2993    Discriminator_loss: 0.0002272769925184548  Generator_loss: 8.584872245788574\n",
            "epoch: 18/20,    batch: 2416/2993    Discriminator_loss: 0.0002397387142991647  Generator_loss: 8.58210563659668\n",
            "epoch: 18/20,    batch: 2417/2993    Discriminator_loss: 0.00019040795450564474  Generator_loss: 8.578910827636719\n",
            "epoch: 18/20,    batch: 2418/2993    Discriminator_loss: 0.00022388642537407577  Generator_loss: 8.575350761413574\n",
            "epoch: 18/20,    batch: 2419/2993    Discriminator_loss: 0.00024616491282358766  Generator_loss: 8.571704864501953\n",
            "epoch: 18/20,    batch: 2420/2993    Discriminator_loss: 0.00020232218957971781  Generator_loss: 8.567583084106445\n",
            "epoch: 18/20,    batch: 2421/2993    Discriminator_loss: 0.0002471688494551927  Generator_loss: 8.563204765319824\n",
            "epoch: 18/20,    batch: 2422/2993    Discriminator_loss: 0.0002173103712266311  Generator_loss: 8.558612823486328\n",
            "epoch: 18/20,    batch: 2423/2993    Discriminator_loss: 0.00020429686992429197  Generator_loss: 8.553692817687988\n",
            "epoch: 18/20,    batch: 2424/2993    Discriminator_loss: 0.0002547735348343849  Generator_loss: 8.548490524291992\n",
            "epoch: 18/20,    batch: 2425/2993    Discriminator_loss: 0.00020555262744892389  Generator_loss: 8.543391227722168\n",
            "epoch: 18/20,    batch: 2426/2993    Discriminator_loss: 0.00019808353681582958  Generator_loss: 8.53835678100586\n",
            "epoch: 18/20,    batch: 2427/2993    Discriminator_loss: 0.00020336435409262776  Generator_loss: 8.53353500366211\n",
            "epoch: 18/20,    batch: 2428/2993    Discriminator_loss: 0.00025881617330014706  Generator_loss: 8.528945922851562\n",
            "epoch: 18/20,    batch: 2429/2993    Discriminator_loss: 0.00020128223695792258  Generator_loss: 8.524845123291016\n",
            "epoch: 18/20,    batch: 2430/2993    Discriminator_loss: 0.0005885370774194598  Generator_loss: 8.521210670471191\n",
            "epoch: 18/20,    batch: 2431/2993    Discriminator_loss: 0.0002613755059428513  Generator_loss: 8.518017768859863\n",
            "epoch: 18/20,    batch: 2432/2993    Discriminator_loss: 0.00020630618382710963  Generator_loss: 8.515151023864746\n",
            "epoch: 18/20,    batch: 2433/2993    Discriminator_loss: 0.00020217490964569151  Generator_loss: 8.512774467468262\n",
            "epoch: 18/20,    batch: 2434/2993    Discriminator_loss: 0.00021519322763197124  Generator_loss: 8.510904312133789\n",
            "epoch: 18/20,    batch: 2435/2993    Discriminator_loss: 0.00025511428248137236  Generator_loss: 8.509109497070312\n",
            "epoch: 18/20,    batch: 2436/2993    Discriminator_loss: 0.0002037602534983307  Generator_loss: 8.50741195678711\n",
            "epoch: 18/20,    batch: 2437/2993    Discriminator_loss: 0.0006620018975809216  Generator_loss: 8.506157875061035\n",
            "epoch: 18/20,    batch: 2438/2993    Discriminator_loss: 0.00024465846945531666  Generator_loss: 8.505016326904297\n",
            "epoch: 18/20,    batch: 2439/2993    Discriminator_loss: 0.00020717649022117257  Generator_loss: 8.503839492797852\n",
            "epoch: 18/20,    batch: 2440/2993    Discriminator_loss: 0.00020593787485267967  Generator_loss: 8.502662658691406\n",
            "epoch: 18/20,    batch: 2441/2993    Discriminator_loss: 0.00021654402371495962  Generator_loss: 8.502058029174805\n",
            "epoch: 18/20,    batch: 2442/2993    Discriminator_loss: 0.0003026992199011147  Generator_loss: 8.500957489013672\n",
            "epoch: 18/20,    batch: 2443/2993    Discriminator_loss: 0.00020534936629701406  Generator_loss: 8.500297546386719\n",
            "epoch: 18/20,    batch: 2444/2993    Discriminator_loss: 0.00023241988674271852  Generator_loss: 8.499693870544434\n",
            "epoch: 18/20,    batch: 2445/2993    Discriminator_loss: 0.0002538331027608365  Generator_loss: 8.49910831451416\n",
            "epoch: 18/20,    batch: 2446/2993    Discriminator_loss: 0.00020547797612380236  Generator_loss: 8.498523712158203\n",
            "epoch: 18/20,    batch: 2447/2993    Discriminator_loss: 0.0002383995015406981  Generator_loss: 8.49793815612793\n",
            "epoch: 18/20,    batch: 2448/2993    Discriminator_loss: 0.00025287101743742824  Generator_loss: 8.497353553771973\n",
            "epoch: 18/20,    batch: 2449/2993    Discriminator_loss: 0.0002076871314784512  Generator_loss: 8.496769905090332\n",
            "epoch: 18/20,    batch: 2450/2993    Discriminator_loss: 0.00026142611750401556  Generator_loss: 8.496186256408691\n",
            "epoch: 18/20,    batch: 2451/2993    Discriminator_loss: 0.0002587568887975067  Generator_loss: 8.49560260772705\n",
            "epoch: 18/20,    batch: 2452/2993    Discriminator_loss: 0.00021053336968179792  Generator_loss: 8.49505615234375\n",
            "epoch: 18/20,    batch: 2453/2993    Discriminator_loss: 0.00027106935158371925  Generator_loss: 8.494436264038086\n",
            "epoch: 18/20,    batch: 2454/2993    Discriminator_loss: 0.0002264115319121629  Generator_loss: 8.493853569030762\n",
            "epoch: 18/20,    batch: 2455/2993    Discriminator_loss: 0.00021462759468704462  Generator_loss: 8.493271827697754\n",
            "epoch: 18/20,    batch: 2456/2993    Discriminator_loss: 0.0003704950213432312  Generator_loss: 8.49276351928711\n",
            "epoch: 18/20,    batch: 2457/2993    Discriminator_loss: 0.00020753088756464422  Generator_loss: 8.492108345031738\n",
            "epoch: 18/20,    batch: 2458/2993    Discriminator_loss: 0.00024388419114984572  Generator_loss: 8.491545677185059\n",
            "epoch: 18/20,    batch: 2459/2993    Discriminator_loss: 0.00024132276303134859  Generator_loss: 8.490964889526367\n",
            "epoch: 18/20,    batch: 2460/2993    Discriminator_loss: 0.00021283213573042303  Generator_loss: 8.490365982055664\n",
            "epoch: 18/20,    batch: 2461/2993    Discriminator_loss: 0.00021415273658931255  Generator_loss: 8.489731788635254\n",
            "epoch: 18/20,    batch: 2462/2993    Discriminator_loss: 0.0002797748311422765  Generator_loss: 8.489006996154785\n",
            "epoch: 18/20,    batch: 2463/2993    Discriminator_loss: 0.0002299829211551696  Generator_loss: 8.488228797912598\n",
            "epoch: 18/20,    batch: 2464/2993    Discriminator_loss: 0.0002140765282092616  Generator_loss: 8.487523078918457\n",
            "epoch: 18/20,    batch: 2465/2993    Discriminator_loss: 0.00027297844644635916  Generator_loss: 8.48699951171875\n",
            "epoch: 18/20,    batch: 2466/2993    Discriminator_loss: 0.00021830108016729355  Generator_loss: 8.486403465270996\n",
            "epoch: 18/20,    batch: 2467/2993    Discriminator_loss: 0.00021009785996284336  Generator_loss: 8.485879898071289\n",
            "epoch: 18/20,    batch: 2468/2993    Discriminator_loss: 0.00023945586872287095  Generator_loss: 8.485391616821289\n",
            "epoch: 18/20,    batch: 2469/2993    Discriminator_loss: 0.0002754133893176913  Generator_loss: 8.485067367553711\n",
            "epoch: 18/20,    batch: 2470/2993    Discriminator_loss: 0.00021085416665300727  Generator_loss: 8.484598159790039\n",
            "epoch: 18/20,    batch: 2471/2993    Discriminator_loss: 0.0002605030604172498  Generator_loss: 8.48402214050293\n",
            "epoch: 18/20,    batch: 2472/2993    Discriminator_loss: 0.00022193339827936143  Generator_loss: 8.483516693115234\n",
            "epoch: 18/20,    batch: 2473/2993    Discriminator_loss: 0.00020798385958187282  Generator_loss: 8.483102798461914\n",
            "epoch: 18/20,    batch: 2474/2993    Discriminator_loss: 0.00021983974147588015  Generator_loss: 8.482869148254395\n",
            "epoch: 18/20,    batch: 2475/2993    Discriminator_loss: 0.00026993706705980003  Generator_loss: 8.482329368591309\n",
            "epoch: 18/20,    batch: 2476/2993    Discriminator_loss: 0.0002085296728182584  Generator_loss: 8.482275009155273\n",
            "epoch: 18/20,    batch: 2477/2993    Discriminator_loss: 0.00022563280072063208  Generator_loss: 8.481880187988281\n",
            "epoch: 18/20,    batch: 2478/2993    Discriminator_loss: 0.00029118964448571205  Generator_loss: 8.48169994354248\n",
            "epoch: 18/20,    batch: 2479/2993    Discriminator_loss: 0.0002083154977299273  Generator_loss: 8.481287002563477\n",
            "epoch: 18/20,    batch: 2480/2993    Discriminator_loss: 0.00022589170839637518  Generator_loss: 8.481124877929688\n",
            "epoch: 18/20,    batch: 2481/2993    Discriminator_loss: 0.0002999169228132814  Generator_loss: 8.481070518493652\n",
            "epoch: 18/20,    batch: 2482/2993    Discriminator_loss: 0.00020853159367106855  Generator_loss: 8.480693817138672\n",
            "epoch: 18/20,    batch: 2483/2993    Discriminator_loss: 0.00024696625769138336  Generator_loss: 8.480549812316895\n",
            "epoch: 18/20,    batch: 2484/2993    Discriminator_loss: 0.000254918762948364  Generator_loss: 8.480621337890625\n",
            "epoch: 18/20,    batch: 2485/2993    Discriminator_loss: 0.00021439531701616943  Generator_loss: 8.480388641357422\n",
            "epoch: 18/20,    batch: 2486/2993    Discriminator_loss: 0.0004059027414768934  Generator_loss: 8.480047225952148\n",
            "epoch: 18/20,    batch: 2487/2993    Discriminator_loss: 0.00023167981998994946  Generator_loss: 8.480010986328125\n",
            "epoch: 18/20,    batch: 2488/2993    Discriminator_loss: 0.00021438967087306082  Generator_loss: 8.480029106140137\n",
            "epoch: 18/20,    batch: 2489/2993    Discriminator_loss: 0.0002632805844768882  Generator_loss: 8.479975700378418\n",
            "epoch: 18/20,    batch: 2490/2993    Discriminator_loss: 0.00023314569261856377  Generator_loss: 8.479975700378418\n",
            "epoch: 18/20,    batch: 2491/2993    Discriminator_loss: 0.0002410474990028888  Generator_loss: 8.47979736328125\n",
            "epoch: 18/20,    batch: 2492/2993    Discriminator_loss: 0.00023064922424964607  Generator_loss: 8.479598999023438\n",
            "epoch: 18/20,    batch: 2493/2993    Discriminator_loss: 0.0002096082316711545  Generator_loss: 8.47952651977539\n",
            "epoch: 18/20,    batch: 2494/2993    Discriminator_loss: 0.0002169229555875063  Generator_loss: 8.479419708251953\n",
            "epoch: 18/20,    batch: 2495/2993    Discriminator_loss: 0.0002317763864994049  Generator_loss: 8.479473114013672\n",
            "epoch: 18/20,    batch: 2496/2993    Discriminator_loss: 0.00026790137053467333  Generator_loss: 8.480145454406738\n",
            "epoch: 18/20,    batch: 2497/2993    Discriminator_loss: 0.00021556130377575755  Generator_loss: 8.479436874389648\n",
            "epoch: 18/20,    batch: 2498/2993    Discriminator_loss: 0.00025434207054786384  Generator_loss: 8.479401588439941\n",
            "epoch: 18/20,    batch: 2499/2993    Discriminator_loss: 0.0002132385561708361  Generator_loss: 8.479455947875977\n",
            "epoch: 18/20,    batch: 2500/2993    Discriminator_loss: 0.00021407118765637279  Generator_loss: 8.479419708251953\n",
            "epoch: 18/20,    batch: 2501/2993    Discriminator_loss: 0.00021749666484538466  Generator_loss: 8.479436874389648\n",
            "epoch: 18/20,    batch: 2502/2993    Discriminator_loss: 0.0002707380335777998  Generator_loss: 8.479455947875977\n",
            "epoch: 18/20,    batch: 2503/2993    Discriminator_loss: 0.00020975165534764528  Generator_loss: 8.479419708251953\n",
            "epoch: 18/20,    batch: 2504/2993    Discriminator_loss: 0.00026706026983447373  Generator_loss: 8.47945499420166\n",
            "epoch: 18/20,    batch: 2505/2993    Discriminator_loss: 0.0002491837658453733  Generator_loss: 8.479401588439941\n",
            "epoch: 18/20,    batch: 2506/2993    Discriminator_loss: 0.0002105861494783312  Generator_loss: 8.47945499420166\n",
            "epoch: 18/20,    batch: 2507/2993    Discriminator_loss: 0.00023139643599279225  Generator_loss: 8.47945499420166\n",
            "epoch: 18/20,    batch: 2508/2993    Discriminator_loss: 0.00025929167168214917  Generator_loss: 8.479527473449707\n",
            "epoch: 18/20,    batch: 2509/2993    Discriminator_loss: 0.00020935677457600832  Generator_loss: 8.479455947875977\n",
            "epoch: 18/20,    batch: 2510/2993    Discriminator_loss: 0.0002340059436392039  Generator_loss: 8.479545593261719\n",
            "epoch: 18/20,    batch: 2511/2993    Discriminator_loss: 0.00042545906035229564  Generator_loss: 8.479544639587402\n",
            "epoch: 18/20,    batch: 2512/2993    Discriminator_loss: 0.00021616672165691853  Generator_loss: 8.479652404785156\n",
            "epoch: 18/20,    batch: 2513/2993    Discriminator_loss: 0.0002268809184897691  Generator_loss: 8.479724884033203\n",
            "epoch: 18/20,    batch: 2514/2993    Discriminator_loss: 0.00048018619418144226  Generator_loss: 8.479886054992676\n",
            "epoch: 18/20,    batch: 2515/2993    Discriminator_loss: 0.00021581277542281896  Generator_loss: 8.479957580566406\n",
            "epoch: 18/20,    batch: 2516/2993    Discriminator_loss: 0.00023983076971489936  Generator_loss: 8.479975700378418\n",
            "epoch: 18/20,    batch: 2517/2993    Discriminator_loss: 0.00021816168737132102  Generator_loss: 8.479975700378418\n",
            "epoch: 18/20,    batch: 2518/2993    Discriminator_loss: 0.00021514964464586228  Generator_loss: 8.480029106140137\n",
            "epoch: 18/20,    batch: 2519/2993    Discriminator_loss: 0.00041399727342650294  Generator_loss: 8.480010986328125\n",
            "epoch: 18/20,    batch: 2520/2993    Discriminator_loss: 0.00023618464183527976  Generator_loss: 8.479975700378418\n",
            "epoch: 18/20,    batch: 2521/2993    Discriminator_loss: 0.00023102722479961812  Generator_loss: 8.479975700378418\n",
            "epoch: 18/20,    batch: 2522/2993    Discriminator_loss: 0.0002651188988238573  Generator_loss: 8.480029106140137\n",
            "epoch: 18/20,    batch: 2523/2993    Discriminator_loss: 0.000213266524951905  Generator_loss: 8.47999382019043\n",
            "epoch: 18/20,    batch: 2524/2993    Discriminator_loss: 0.0005484915454871953  Generator_loss: 8.479975700378418\n",
            "epoch: 18/20,    batch: 2525/2993    Discriminator_loss: 0.00038790341932326555  Generator_loss: 8.479957580566406\n",
            "epoch: 18/20,    batch: 2526/2993    Discriminator_loss: 0.0002105451567331329  Generator_loss: 8.47988510131836\n",
            "epoch: 18/20,    batch: 2527/2993    Discriminator_loss: 0.00021946177002973855  Generator_loss: 8.479581832885742\n",
            "epoch: 18/20,    batch: 2528/2993    Discriminator_loss: 0.0002487461897544563  Generator_loss: 8.479527473449707\n",
            "epoch: 18/20,    batch: 2529/2993    Discriminator_loss: 0.00021935392578598112  Generator_loss: 8.479419708251953\n",
            "epoch: 18/20,    batch: 2530/2993    Discriminator_loss: 0.00022123880626168102  Generator_loss: 8.479150772094727\n",
            "epoch: 18/20,    batch: 2531/2993    Discriminator_loss: 0.00024114924599416554  Generator_loss: 8.478862762451172\n",
            "epoch: 18/20,    batch: 2532/2993    Discriminator_loss: 0.00021634747099597007  Generator_loss: 8.478647232055664\n",
            "epoch: 18/20,    batch: 2533/2993    Discriminator_loss: 0.00021773698972538114  Generator_loss: 8.478307723999023\n",
            "epoch: 18/20,    batch: 2534/2993    Discriminator_loss: 0.00022573349997401237  Generator_loss: 8.47780704498291\n",
            "epoch: 18/20,    batch: 2535/2993    Discriminator_loss: 0.00024084048345685005  Generator_loss: 8.477609634399414\n",
            "epoch: 18/20,    batch: 2536/2993    Discriminator_loss: 0.00021334856864996254  Generator_loss: 8.477126121520996\n",
            "epoch: 18/20,    batch: 2537/2993    Discriminator_loss: 0.00024627786478959024  Generator_loss: 8.47653579711914\n",
            "epoch: 18/20,    batch: 2538/2993    Discriminator_loss: 0.00022335322864819318  Generator_loss: 8.475981712341309\n",
            "epoch: 18/20,    batch: 2539/2993    Discriminator_loss: 0.00021094955445732921  Generator_loss: 8.475410461425781\n",
            "epoch: 18/20,    batch: 2540/2993    Discriminator_loss: 0.00022188163711689413  Generator_loss: 8.474748611450195\n",
            "epoch: 18/20,    batch: 2541/2993    Discriminator_loss: 0.00026240135775879025  Generator_loss: 8.473981857299805\n",
            "epoch: 18/20,    batch: 2542/2993    Discriminator_loss: 0.00021397843374870718  Generator_loss: 8.473304748535156\n",
            "epoch: 18/20,    batch: 2543/2993    Discriminator_loss: 0.0004050564602948725  Generator_loss: 8.472591400146484\n",
            "epoch: 18/20,    batch: 2544/2993    Discriminator_loss: 0.0002375846088398248  Generator_loss: 8.471700668334961\n",
            "epoch: 18/20,    batch: 2545/2993    Discriminator_loss: 0.00021534562984015793  Generator_loss: 8.47089958190918\n",
            "epoch: 18/20,    batch: 2546/2993    Discriminator_loss: 0.0005394268082454801  Generator_loss: 8.470331192016602\n",
            "epoch: 18/20,    batch: 2547/2993    Discriminator_loss: 0.00025644118431955576  Generator_loss: 8.469496726989746\n",
            "epoch: 18/20,    batch: 2548/2993    Discriminator_loss: 0.00021874321100767702  Generator_loss: 8.468732833862305\n",
            "epoch: 18/20,    batch: 2549/2993    Discriminator_loss: 0.00023854582104831934  Generator_loss: 8.468059539794922\n",
            "epoch: 18/20,    batch: 2550/2993    Discriminator_loss: 0.00022428132069762796  Generator_loss: 8.4676513671875\n",
            "epoch: 18/20,    batch: 2551/2993    Discriminator_loss: 0.00022147208801470697  Generator_loss: 8.466924667358398\n",
            "epoch: 18/20,    batch: 2552/2993    Discriminator_loss: 0.00027149650850333273  Generator_loss: 8.46646499633789\n",
            "epoch: 18/20,    batch: 2553/2993    Discriminator_loss: 0.0002134459064109251  Generator_loss: 8.4661283493042\n",
            "epoch: 18/20,    batch: 2554/2993    Discriminator_loss: 0.00027347379364073277  Generator_loss: 8.465721130371094\n",
            "epoch: 18/20,    batch: 2555/2993    Discriminator_loss: 0.00023492657055612653  Generator_loss: 8.465295791625977\n",
            "epoch: 18/20,    batch: 2556/2993    Discriminator_loss: 0.00021395072690211236  Generator_loss: 8.465208053588867\n",
            "epoch: 18/20,    batch: 2557/2993    Discriminator_loss: 0.00024032106739468873  Generator_loss: 8.464855194091797\n",
            "epoch: 18/20,    batch: 2558/2993    Discriminator_loss: 0.0003019133291672915  Generator_loss: 8.464642524719238\n",
            "epoch: 18/20,    batch: 2559/2993    Discriminator_loss: 0.00021183103672228754  Generator_loss: 8.46458911895752\n",
            "epoch: 18/20,    batch: 2560/2993    Discriminator_loss: 0.00022650138998869807  Generator_loss: 8.46446418762207\n",
            "epoch: 18/20,    batch: 2561/2993    Discriminator_loss: 0.00028246757574379444  Generator_loss: 8.464200019836426\n",
            "epoch: 18/20,    batch: 2562/2993    Discriminator_loss: 0.00021355587523430586  Generator_loss: 8.464147567749023\n",
            "epoch: 18/20,    batch: 2563/2993    Discriminator_loss: 0.00023022873210720718  Generator_loss: 8.464147567749023\n",
            "epoch: 18/20,    batch: 2564/2993    Discriminator_loss: 0.0003190928837284446  Generator_loss: 8.464111328125\n",
            "epoch: 18/20,    batch: 2565/2993    Discriminator_loss: 0.0002174563123844564  Generator_loss: 8.464040756225586\n",
            "epoch: 18/20,    batch: 2566/2993    Discriminator_loss: 0.00023910458548925817  Generator_loss: 8.464129447937012\n",
            "epoch: 18/20,    batch: 2567/2993    Discriminator_loss: 0.0002774175663944334  Generator_loss: 8.464094161987305\n",
            "epoch: 18/20,    batch: 2568/2993    Discriminator_loss: 0.00022766426263842732  Generator_loss: 8.464164733886719\n",
            "epoch: 18/20,    batch: 2569/2993    Discriminator_loss: 0.00022471885313279927  Generator_loss: 8.464111328125\n",
            "epoch: 18/20,    batch: 2570/2993    Discriminator_loss: 0.00030341767705976963  Generator_loss: 8.464181900024414\n",
            "epoch: 18/20,    batch: 2571/2993    Discriminator_loss: 0.00022457372688222677  Generator_loss: 8.46407699584961\n",
            "epoch: 18/20,    batch: 2572/2993    Discriminator_loss: 0.00022178330982569605  Generator_loss: 8.464094161987305\n",
            "epoch: 18/20,    batch: 2573/2993    Discriminator_loss: 0.0004097783239558339  Generator_loss: 8.464111328125\n",
            "epoch: 18/20,    batch: 2574/2993    Discriminator_loss: 0.00040628755232319236  Generator_loss: 8.46407699584961\n",
            "epoch: 18/20,    batch: 2575/2993    Discriminator_loss: 0.0002229996316600591  Generator_loss: 8.464058876037598\n",
            "epoch: 18/20,    batch: 2576/2993    Discriminator_loss: 0.0009063641191460192  Generator_loss: 8.464040756225586\n",
            "epoch: 18/20,    batch: 2577/2993    Discriminator_loss: 0.0002530955243855715  Generator_loss: 8.46402359008789\n",
            "epoch: 18/20,    batch: 2578/2993    Discriminator_loss: 0.00022635805362369865  Generator_loss: 8.463882446289062\n",
            "epoch: 18/20,    batch: 2579/2993    Discriminator_loss: 0.0002832255559042096  Generator_loss: 8.463617324829102\n",
            "epoch: 18/20,    batch: 2580/2993    Discriminator_loss: 0.00023551615595351905  Generator_loss: 8.463494300842285\n",
            "epoch: 18/20,    batch: 2581/2993    Discriminator_loss: 0.0002624412009026855  Generator_loss: 8.463494300842285\n",
            "epoch: 18/20,    batch: 2582/2993    Discriminator_loss: 0.0005465361173264682  Generator_loss: 8.463141441345215\n",
            "epoch: 18/20,    batch: 2583/2993    Discriminator_loss: 0.00021575957362074405  Generator_loss: 8.462911605834961\n",
            "epoch: 18/20,    batch: 2584/2993    Discriminator_loss: 0.000292191281914711  Generator_loss: 8.462911605834961\n",
            "epoch: 18/20,    batch: 2585/2993    Discriminator_loss: 0.00024684445816092193  Generator_loss: 8.462383270263672\n",
            "epoch: 18/20,    batch: 2586/2993    Discriminator_loss: 0.00021371616458054632  Generator_loss: 8.462312698364258\n",
            "epoch: 18/20,    batch: 2587/2993    Discriminator_loss: 0.0002526140306144953  Generator_loss: 8.46181869506836\n",
            "epoch: 18/20,    batch: 2588/2993    Discriminator_loss: 0.00029890352743677795  Generator_loss: 8.461341857910156\n",
            "epoch: 18/20,    batch: 2589/2993    Discriminator_loss: 0.00021606501832138747  Generator_loss: 8.461113929748535\n",
            "epoch: 18/20,    batch: 2590/2993    Discriminator_loss: 0.00028360914438962936  Generator_loss: 8.460657119750977\n",
            "epoch: 18/20,    batch: 2591/2993    Discriminator_loss: 0.00024396859225817025  Generator_loss: 8.460075378417969\n",
            "epoch: 18/20,    batch: 2592/2993    Discriminator_loss: 0.00021859646949451417  Generator_loss: 8.459566116333008\n",
            "epoch: 18/20,    batch: 2593/2993    Discriminator_loss: 0.00024510646471753716  Generator_loss: 8.45905590057373\n",
            "epoch: 18/20,    batch: 2594/2993    Discriminator_loss: 0.0004512662999331951  Generator_loss: 8.458528518676758\n",
            "epoch: 18/20,    batch: 2595/2993    Discriminator_loss: 0.00021363436826504767  Generator_loss: 8.457931518554688\n",
            "epoch: 18/20,    batch: 2596/2993    Discriminator_loss: 0.0002402355457888916  Generator_loss: 8.457352638244629\n",
            "epoch: 18/20,    batch: 2597/2993    Discriminator_loss: 0.0003017180715687573  Generator_loss: 8.456756591796875\n",
            "epoch: 18/20,    batch: 2598/2993    Discriminator_loss: 0.00021422677673399448  Generator_loss: 8.45614242553711\n",
            "epoch: 18/20,    batch: 2599/2993    Discriminator_loss: 0.0002221896720584482  Generator_loss: 8.455353736877441\n",
            "epoch: 18/20,    batch: 2600/2993    Discriminator_loss: 0.0002920672413893044  Generator_loss: 8.454514503479004\n",
            "epoch: 18/20,    batch: 2601/2993    Discriminator_loss: 0.0002209214580943808  Generator_loss: 8.453657150268555\n",
            "epoch: 18/20,    batch: 2602/2993    Discriminator_loss: 0.00023305314243771136  Generator_loss: 8.452783584594727\n",
            "epoch: 18/20,    batch: 2603/2993    Discriminator_loss: 0.0002775268512777984  Generator_loss: 8.451666831970215\n",
            "epoch: 18/20,    batch: 2604/2993    Discriminator_loss: 0.00022371929662767798  Generator_loss: 8.45055103302002\n",
            "epoch: 18/20,    batch: 2605/2993    Discriminator_loss: 0.00023266786593012512  Generator_loss: 8.449227333068848\n",
            "epoch: 18/20,    batch: 2606/2993    Discriminator_loss: 0.00042765328544192016  Generator_loss: 8.447766304016113\n",
            "epoch: 18/20,    batch: 2607/2993    Discriminator_loss: 0.00023571751080453396  Generator_loss: 8.446117401123047\n",
            "epoch: 18/20,    batch: 2608/2993    Discriminator_loss: 0.00022752858058083802  Generator_loss: 8.44447135925293\n",
            "epoch: 18/20,    batch: 2609/2993    Discriminator_loss: 0.0002828400465659797  Generator_loss: 8.442670822143555\n",
            "epoch: 18/20,    batch: 2610/2993    Discriminator_loss: 0.0002464095887262374  Generator_loss: 8.440563201904297\n",
            "epoch: 18/20,    batch: 2611/2993    Discriminator_loss: 0.0002493982028681785  Generator_loss: 8.43835735321045\n",
            "epoch: 18/20,    batch: 2612/2993    Discriminator_loss: 0.0002899757237173617  Generator_loss: 8.436156272888184\n",
            "epoch: 18/20,    batch: 2613/2993    Discriminator_loss: 0.00022076764435041696  Generator_loss: 8.433807373046875\n",
            "epoch: 18/20,    batch: 2614/2993    Discriminator_loss: 0.0002593337558209896  Generator_loss: 8.431272506713867\n",
            "epoch: 18/20,    batch: 2615/2993    Discriminator_loss: 0.000275983678875491  Generator_loss: 8.429037094116211\n",
            "epoch: 18/20,    batch: 2616/2993    Discriminator_loss: 0.000221557667828165  Generator_loss: 8.42685604095459\n",
            "epoch: 18/20,    batch: 2617/2993    Discriminator_loss: 0.0002552935329731554  Generator_loss: 8.424833297729492\n",
            "epoch: 18/20,    batch: 2618/2993    Discriminator_loss: 0.0003397517139092088  Generator_loss: 8.423051834106445\n",
            "epoch: 18/20,    batch: 2619/2993    Discriminator_loss: 0.00022435937717091292  Generator_loss: 8.421424865722656\n",
            "epoch: 18/20,    batch: 2620/2993    Discriminator_loss: 0.0002943178405985236  Generator_loss: 8.420241355895996\n",
            "epoch: 18/20,    batch: 2621/2993    Discriminator_loss: 0.0003553953138180077  Generator_loss: 8.419109344482422\n",
            "epoch: 18/20,    batch: 2622/2993    Discriminator_loss: 0.00023095522192306817  Generator_loss: 8.418180465698242\n",
            "epoch: 18/20,    batch: 2623/2993    Discriminator_loss: 0.0003811987699009478  Generator_loss: 8.417304039001465\n",
            "epoch: 18/20,    batch: 2624/2993    Discriminator_loss: 0.00023081747349351645  Generator_loss: 8.416866302490234\n",
            "epoch: 18/20,    batch: 2625/2993    Discriminator_loss: 0.00022299612464848906  Generator_loss: 8.4165620803833\n",
            "epoch: 18/20,    batch: 2626/2993    Discriminator_loss: 0.00023802802024874836  Generator_loss: 8.416023254394531\n",
            "epoch: 18/20,    batch: 2627/2993    Discriminator_loss: 0.00031255025533027947  Generator_loss: 8.416023254394531\n",
            "epoch: 18/20,    batch: 2628/2993    Discriminator_loss: 0.00022311163775157183  Generator_loss: 8.415922164916992\n",
            "epoch: 18/20,    batch: 2629/2993    Discriminator_loss: 0.0002768294361885637  Generator_loss: 8.415771484375\n",
            "epoch: 18/20,    batch: 2630/2993    Discriminator_loss: 0.00027217715978622437  Generator_loss: 8.415888786315918\n",
            "epoch: 18/20,    batch: 2631/2993    Discriminator_loss: 0.00022219707898329943  Generator_loss: 8.415973663330078\n",
            "epoch: 18/20,    batch: 2632/2993    Discriminator_loss: 0.00022872195404488593  Generator_loss: 8.416023254394531\n",
            "epoch: 18/20,    batch: 2633/2993    Discriminator_loss: 0.00032870599534362555  Generator_loss: 8.416023254394531\n",
            "epoch: 18/20,    batch: 2634/2993    Discriminator_loss: 0.00022279495897237211  Generator_loss: 8.416056632995605\n",
            "epoch: 18/20,    batch: 2635/2993    Discriminator_loss: 0.00023828676785342395  Generator_loss: 8.416528701782227\n",
            "epoch: 18/20,    batch: 2636/2993    Discriminator_loss: 0.0002665282809175551  Generator_loss: 8.4165620803833\n",
            "epoch: 18/20,    batch: 2637/2993    Discriminator_loss: 0.00022749077470507473  Generator_loss: 8.4165620803833\n",
            "epoch: 18/20,    batch: 2638/2993    Discriminator_loss: 0.00023162957222666591  Generator_loss: 8.416983604431152\n",
            "epoch: 18/20,    batch: 2639/2993    Discriminator_loss: 0.0002734133740887046  Generator_loss: 8.417101860046387\n",
            "epoch: 18/20,    batch: 2640/2993    Discriminator_loss: 0.0002520920243114233  Generator_loss: 8.417101860046387\n",
            "epoch: 18/20,    batch: 2641/2993    Discriminator_loss: 0.0002389258297625929  Generator_loss: 8.417101860046387\n",
            "epoch: 18/20,    batch: 2642/2993    Discriminator_loss: 0.0002852209145203233  Generator_loss: 8.417101860046387\n",
            "epoch: 18/20,    batch: 2643/2993    Discriminator_loss: 0.00022611796157434583  Generator_loss: 8.417152404785156\n",
            "epoch: 18/20,    batch: 2644/2993    Discriminator_loss: 0.00028731953352689743  Generator_loss: 8.41718578338623\n",
            "epoch: 18/20,    batch: 2645/2993    Discriminator_loss: 0.00026796094607561827  Generator_loss: 8.417101860046387\n",
            "epoch: 18/20,    batch: 2646/2993    Discriminator_loss: 0.00022298679687082767  Generator_loss: 8.417101860046387\n",
            "epoch: 18/20,    batch: 2647/2993    Discriminator_loss: 0.00025635151541791856  Generator_loss: 8.416967391967773\n",
            "epoch: 18/20,    batch: 2648/2993    Discriminator_loss: 0.000325207132846117  Generator_loss: 8.4165620803833\n",
            "epoch: 18/20,    batch: 2649/2993    Discriminator_loss: 0.00022486996022053063  Generator_loss: 8.416528701782227\n",
            "epoch: 18/20,    batch: 2650/2993    Discriminator_loss: 0.0002714517177082598  Generator_loss: 8.416023254394531\n",
            "epoch: 18/20,    batch: 2651/2993    Discriminator_loss: 0.00026278162840753794  Generator_loss: 8.415485382080078\n",
            "epoch: 18/20,    batch: 2652/2993    Discriminator_loss: 0.00023733342823106796  Generator_loss: 8.414946556091309\n",
            "epoch: 18/20,    batch: 2653/2993    Discriminator_loss: 0.0003289239830337465  Generator_loss: 8.414493560791016\n",
            "epoch: 18/20,    batch: 2654/2993    Discriminator_loss: 0.00024170726828742772  Generator_loss: 8.413954734802246\n",
            "epoch: 18/20,    batch: 2655/2993    Discriminator_loss: 0.00023243251780513674  Generator_loss: 8.413351058959961\n",
            "epoch: 18/20,    batch: 2656/2993    Discriminator_loss: 0.0002699337783269584  Generator_loss: 8.412796974182129\n",
            "epoch: 18/20,    batch: 2657/2993    Discriminator_loss: 0.00022587041894439608  Generator_loss: 8.412260055541992\n",
            "epoch: 18/20,    batch: 2658/2993    Discriminator_loss: 0.00022538429766427726  Generator_loss: 8.411689758300781\n",
            "epoch: 18/20,    batch: 2659/2993    Discriminator_loss: 0.00022853781410958618  Generator_loss: 8.411170959472656\n",
            "epoch: 18/20,    batch: 2660/2993    Discriminator_loss: 0.0002899209503084421  Generator_loss: 8.410651206970215\n",
            "epoch: 18/20,    batch: 2661/2993    Discriminator_loss: 0.00022684656141791493  Generator_loss: 8.410115242004395\n",
            "epoch: 18/20,    batch: 2662/2993    Discriminator_loss: 0.00024601726909168065  Generator_loss: 8.40958023071289\n",
            "epoch: 18/20,    batch: 2663/2993    Discriminator_loss: 0.0002460159594193101  Generator_loss: 8.4091796875\n",
            "epoch: 18/20,    batch: 2664/2993    Discriminator_loss: 0.00022397625434678048  Generator_loss: 8.409045219421387\n",
            "epoch: 18/20,    batch: 2665/2993    Discriminator_loss: 0.00022824360348749906  Generator_loss: 8.408910751342773\n",
            "epoch: 18/20,    batch: 2666/2993    Discriminator_loss: 0.0002755272143986076  Generator_loss: 8.408576965332031\n",
            "epoch: 18/20,    batch: 2667/2993    Discriminator_loss: 0.00026302540209144354  Generator_loss: 8.408510208129883\n",
            "epoch: 18/20,    batch: 2668/2993    Discriminator_loss: 0.0002953312359750271  Generator_loss: 8.408594131469727\n",
            "epoch: 18/20,    batch: 2669/2993    Discriminator_loss: 0.00025772119988687336  Generator_loss: 8.408878326416016\n",
            "epoch: 18/20,    batch: 2670/2993    Discriminator_loss: 0.00022679258836433291  Generator_loss: 8.409045219421387\n",
            "epoch: 18/20,    batch: 2671/2993    Discriminator_loss: 0.00022398741566576064  Generator_loss: 8.409078598022461\n",
            "epoch: 18/20,    batch: 2672/2993    Discriminator_loss: 0.00023174539091996849  Generator_loss: 8.40958023071289\n",
            "epoch: 18/20,    batch: 2673/2993    Discriminator_loss: 0.0002880640095099807  Generator_loss: 8.409947395324707\n",
            "epoch: 18/20,    batch: 2674/2993    Discriminator_loss: 0.00022414754494093359  Generator_loss: 8.410115242004395\n",
            "epoch: 18/20,    batch: 2675/2993    Discriminator_loss: 0.00033689444535411894  Generator_loss: 8.410651206970215\n",
            "epoch: 18/20,    batch: 2676/2993    Discriminator_loss: 0.00040403378079645336  Generator_loss: 8.411187171936035\n",
            "epoch: 18/20,    batch: 2677/2993    Discriminator_loss: 0.0002245498326374218  Generator_loss: 8.411672592163086\n",
            "epoch: 18/20,    batch: 2678/2993    Discriminator_loss: 0.0003204247332178056  Generator_loss: 8.412158966064453\n",
            "epoch: 18/20,    batch: 2679/2993    Discriminator_loss: 0.00038406855310313404  Generator_loss: 8.41269588470459\n",
            "epoch: 18/20,    batch: 2680/2993    Discriminator_loss: 0.00022649249876849353  Generator_loss: 8.413300514221191\n",
            "epoch: 18/20,    batch: 2681/2993    Discriminator_loss: 0.0005224490305408835  Generator_loss: 8.413870811462402\n",
            "epoch: 18/20,    batch: 2682/2993    Discriminator_loss: 0.0002665474603418261  Generator_loss: 8.414408683776855\n",
            "epoch: 18/20,    batch: 2683/2993    Discriminator_loss: 0.00024066615151241422  Generator_loss: 8.414946556091309\n",
            "epoch: 18/20,    batch: 2684/2993    Discriminator_loss: 0.00031865722849033773  Generator_loss: 8.415485382080078\n",
            "epoch: 18/20,    batch: 2685/2993    Discriminator_loss: 0.00024107994977384806  Generator_loss: 8.41614055633545\n",
            "epoch: 18/20,    batch: 2686/2993    Discriminator_loss: 0.00023783430515322834  Generator_loss: 8.417051315307617\n",
            "epoch: 18/20,    batch: 2687/2993    Discriminator_loss: 0.00033508898923173547  Generator_loss: 8.417640686035156\n",
            "epoch: 18/20,    batch: 2688/2993    Discriminator_loss: 0.00023777576279826462  Generator_loss: 8.418180465698242\n",
            "epoch: 18/20,    batch: 2689/2993    Discriminator_loss: 0.00024376879446208477  Generator_loss: 8.418721199035645\n",
            "epoch: 18/20,    batch: 2690/2993    Discriminator_loss: 0.0002464974531903863  Generator_loss: 8.41944694519043\n",
            "epoch: 18/20,    batch: 2691/2993    Discriminator_loss: 0.00022599671501666307  Generator_loss: 8.420291900634766\n",
            "epoch: 18/20,    batch: 2692/2993    Discriminator_loss: 0.000229954908718355  Generator_loss: 8.420884132385254\n",
            "epoch: 18/20,    batch: 2693/2993    Discriminator_loss: 0.0002452669432386756  Generator_loss: 8.421424865722656\n",
            "epoch: 18/20,    batch: 2694/2993    Discriminator_loss: 0.00027234971639700234  Generator_loss: 8.421966552734375\n",
            "epoch: 18/20,    batch: 2695/2993    Discriminator_loss: 0.00023032542958389968  Generator_loss: 8.422525405883789\n",
            "epoch: 18/20,    batch: 2696/2993    Discriminator_loss: 0.0002617965219542384  Generator_loss: 8.42317008972168\n",
            "epoch: 18/20,    batch: 2697/2993    Discriminator_loss: 0.0002374632895225659  Generator_loss: 8.423781394958496\n",
            "epoch: 18/20,    batch: 2698/2993    Discriminator_loss: 0.00022061713389120996  Generator_loss: 8.424509048461914\n",
            "epoch: 18/20,    batch: 2699/2993    Discriminator_loss: 0.0002339315105928108  Generator_loss: 8.4249849319458\n",
            "epoch: 18/20,    batch: 2700/2993    Discriminator_loss: 0.0002570271317381412  Generator_loss: 8.425512313842773\n",
            "epoch: 18/20,    batch: 2701/2993    Discriminator_loss: 0.00029434822499752045  Generator_loss: 8.4259033203125\n",
            "epoch: 18/20,    batch: 2702/2993    Discriminator_loss: 0.00028757081599906087  Generator_loss: 8.426362991333008\n",
            "epoch: 18/20,    batch: 2703/2993    Discriminator_loss: 0.0005016103386878967  Generator_loss: 8.42685604095459\n",
            "epoch: 18/20,    batch: 2704/2993    Discriminator_loss: 0.0002305003145011142  Generator_loss: 8.427400588989258\n",
            "epoch: 18/20,    batch: 2705/2993    Discriminator_loss: 0.00022095412714406848  Generator_loss: 8.427469253540039\n",
            "epoch: 18/20,    batch: 2706/2993    Discriminator_loss: 0.00026905679260380566  Generator_loss: 8.427946090698242\n",
            "epoch: 18/20,    batch: 2707/2993    Discriminator_loss: 0.00027729570865631104  Generator_loss: 8.42806625366211\n",
            "epoch: 18/20,    batch: 2708/2993    Discriminator_loss: 0.0002455523645039648  Generator_loss: 8.42849063873291\n",
            "epoch: 18/20,    batch: 2709/2993    Discriminator_loss: 0.00026682877796702087  Generator_loss: 8.42849063873291\n",
            "epoch: 18/20,    batch: 2710/2993    Discriminator_loss: 0.0004914329620078206  Generator_loss: 8.42849063873291\n",
            "epoch: 18/20,    batch: 2711/2993    Discriminator_loss: 0.0002234426065115258  Generator_loss: 8.42849063873291\n",
            "epoch: 18/20,    batch: 2712/2993    Discriminator_loss: 0.00023316203441936523  Generator_loss: 8.42849063873291\n",
            "epoch: 18/20,    batch: 2713/2993    Discriminator_loss: 0.0002751939173322171  Generator_loss: 8.42849063873291\n",
            "epoch: 18/20,    batch: 2714/2993    Discriminator_loss: 0.00022133968013804406  Generator_loss: 8.428065299987793\n",
            "epoch: 18/20,    batch: 2715/2993    Discriminator_loss: 0.00024217429745476693  Generator_loss: 8.427946090698242\n",
            "epoch: 18/20,    batch: 2716/2993    Discriminator_loss: 0.00034916482400149107  Generator_loss: 8.427400588989258\n",
            "epoch: 18/20,    batch: 2717/2993    Discriminator_loss: 0.0002220270544057712  Generator_loss: 8.427145004272461\n",
            "epoch: 18/20,    batch: 2718/2993    Discriminator_loss: 0.00023912641336210072  Generator_loss: 8.4266357421875\n",
            "epoch: 18/20,    batch: 2719/2993    Discriminator_loss: 0.00030810199677944183  Generator_loss: 8.425989151000977\n",
            "epoch: 18/20,    batch: 2720/2993    Discriminator_loss: 0.0002308097027707845  Generator_loss: 8.425223350524902\n",
            "epoch: 18/20,    batch: 2721/2993    Discriminator_loss: 0.000329196744132787  Generator_loss: 8.424663543701172\n",
            "epoch: 18/20,    batch: 2722/2993    Discriminator_loss: 0.00026699944282881916  Generator_loss: 8.423713684082031\n",
            "epoch: 18/20,    batch: 2723/2993    Discriminator_loss: 0.000233933562412858  Generator_loss: 8.423017501831055\n",
            "epoch: 18/20,    batch: 2724/2993    Discriminator_loss: 0.00028984990785829723  Generator_loss: 8.421966552734375\n",
            "epoch: 18/20,    batch: 2725/2993    Discriminator_loss: 0.00023251789389178157  Generator_loss: 8.420917510986328\n",
            "epoch: 18/20,    batch: 2726/2993    Discriminator_loss: 0.00022161388187669218  Generator_loss: 8.419971466064453\n",
            "epoch: 18/20,    batch: 2727/2993    Discriminator_loss: 0.00023723053163848817  Generator_loss: 8.419075012207031\n",
            "epoch: 18/20,    batch: 2728/2993    Discriminator_loss: 0.000258960179053247  Generator_loss: 8.418128967285156\n",
            "epoch: 18/20,    batch: 2729/2993    Discriminator_loss: 0.0002398430951870978  Generator_loss: 8.417101860046387\n",
            "epoch: 18/20,    batch: 2730/2993    Discriminator_loss: 0.00024017185205593705  Generator_loss: 8.416208267211914\n",
            "epoch: 18/20,    batch: 2731/2993    Discriminator_loss: 0.00027680766652338207  Generator_loss: 8.415485382080078\n",
            "epoch: 18/20,    batch: 2732/2993    Discriminator_loss: 0.00022627263388130814  Generator_loss: 8.414913177490234\n",
            "epoch: 18/20,    batch: 2733/2993    Discriminator_loss: 0.0002287016250193119  Generator_loss: 8.414408683776855\n",
            "epoch: 18/20,    batch: 2734/2993    Discriminator_loss: 0.0002362082013860345  Generator_loss: 8.413870811462402\n",
            "epoch: 18/20,    batch: 2735/2993    Discriminator_loss: 0.0002850023447535932  Generator_loss: 8.413702964782715\n",
            "epoch: 18/20,    batch: 2736/2993    Discriminator_loss: 0.0002263453498017043  Generator_loss: 8.413518905639648\n",
            "epoch: 18/20,    batch: 2737/2993    Discriminator_loss: 0.00024654821027070284  Generator_loss: 8.413602828979492\n",
            "epoch: 18/20,    batch: 2738/2993    Discriminator_loss: 0.00028109451523050666  Generator_loss: 8.413854598999023\n",
            "epoch: 18/20,    batch: 2739/2993    Discriminator_loss: 0.00022783545136917382  Generator_loss: 8.41403865814209\n",
            "epoch: 18/20,    batch: 2740/2993    Discriminator_loss: 0.0002266619703732431  Generator_loss: 8.414408683776855\n",
            "epoch: 18/20,    batch: 2741/2993    Discriminator_loss: 0.0002450469182804227  Generator_loss: 8.414946556091309\n",
            "epoch: 18/20,    batch: 2742/2993    Discriminator_loss: 0.0003017708659172058  Generator_loss: 8.415485382080078\n",
            "epoch: 18/20,    batch: 2743/2993    Discriminator_loss: 0.00022305389575194567  Generator_loss: 8.416023254394531\n",
            "epoch: 18/20,    batch: 2744/2993    Discriminator_loss: 0.00029797927709296346  Generator_loss: 8.416595458984375\n",
            "epoch: 18/20,    batch: 2745/2993    Discriminator_loss: 0.00028446136275306344  Generator_loss: 8.417573928833008\n",
            "epoch: 18/20,    batch: 2746/2993    Discriminator_loss: 0.0002235101565020159  Generator_loss: 8.418180465698242\n",
            "epoch: 18/20,    batch: 2747/2993    Discriminator_loss: 0.0002643752668518573  Generator_loss: 8.418721199035645\n",
            "epoch: 18/20,    batch: 2748/2993    Discriminator_loss: 0.0003565796068869531  Generator_loss: 8.419717788696289\n",
            "epoch: 18/20,    batch: 2749/2993    Discriminator_loss: 0.00023604033049196005  Generator_loss: 8.420342445373535\n",
            "epoch: 18/20,    batch: 2750/2993    Discriminator_loss: 0.0003313474589958787  Generator_loss: 8.420917510986328\n",
            "epoch: 18/20,    batch: 2751/2993    Discriminator_loss: 0.0003563671198207885  Generator_loss: 8.421966552734375\n",
            "epoch: 18/20,    batch: 2752/2993    Discriminator_loss: 0.00022585131227970123  Generator_loss: 8.42250919342041\n",
            "epoch: 18/20,    batch: 2753/2993    Discriminator_loss: 0.00031946771196089685  Generator_loss: 8.423561096191406\n",
            "epoch: 18/20,    batch: 2754/2993    Discriminator_loss: 0.00024958321591839194  Generator_loss: 8.424137115478516\n",
            "epoch: 18/20,    batch: 2755/2993    Discriminator_loss: 0.0002455099602229893  Generator_loss: 8.425207138061523\n",
            "epoch: 18/20,    batch: 2756/2993    Discriminator_loss: 0.0003442286979407072  Generator_loss: 8.42576789855957\n",
            "epoch: 18/20,    batch: 2757/2993    Discriminator_loss: 0.00022844031627755612  Generator_loss: 8.42685604095459\n",
            "epoch: 18/20,    batch: 2758/2993    Discriminator_loss: 0.00023463749676011503  Generator_loss: 8.427400588989258\n",
            "epoch: 18/20,    batch: 2759/2993    Discriminator_loss: 0.00026328061358071864  Generator_loss: 8.42849063873291\n",
            "epoch: 18/20,    batch: 2760/2993    Discriminator_loss: 0.00022517488105222583  Generator_loss: 8.429071426391602\n",
            "epoch: 18/20,    batch: 2761/2993    Discriminator_loss: 0.00022641911345999688  Generator_loss: 8.430129051208496\n",
            "epoch: 18/20,    batch: 2762/2993    Discriminator_loss: 0.0002504573203623295  Generator_loss: 8.431171417236328\n",
            "epoch: 18/20,    batch: 2763/2993    Discriminator_loss: 0.0002647270739544183  Generator_loss: 8.431769371032715\n",
            "epoch: 18/20,    batch: 2764/2993    Discriminator_loss: 0.00022677287051919848  Generator_loss: 8.43286418914795\n",
            "epoch: 18/20,    batch: 2765/2993    Discriminator_loss: 0.00030259042978286743  Generator_loss: 8.433960914611816\n",
            "epoch: 18/20,    batch: 2766/2993    Discriminator_loss: 0.00022624379198532552  Generator_loss: 8.434560775756836\n",
            "epoch: 18/20,    batch: 2767/2993    Discriminator_loss: 0.0002228164521511644  Generator_loss: 8.435606956481934\n",
            "epoch: 18/20,    batch: 2768/2993    Discriminator_loss: 0.00023409312416333705  Generator_loss: 8.43670654296875\n",
            "epoch: 18/20,    batch: 2769/2993    Discriminator_loss: 0.0002977016265504062  Generator_loss: 8.437601089477539\n",
            "epoch: 18/20,    batch: 2770/2993    Discriminator_loss: 0.0002234105340903625  Generator_loss: 8.43835735321045\n",
            "epoch: 18/20,    batch: 2771/2993    Discriminator_loss: 0.0002502966672182083  Generator_loss: 8.439459800720215\n",
            "epoch: 18/20,    batch: 2772/2993    Discriminator_loss: 0.00022604048717767  Generator_loss: 8.440563201904297\n",
            "epoch: 18/20,    batch: 2773/2993    Discriminator_loss: 0.0002185916673624888  Generator_loss: 8.441513061523438\n",
            "epoch: 18/20,    batch: 2774/2993    Discriminator_loss: 0.00022584854741580784  Generator_loss: 8.442221641540527\n",
            "epoch: 18/20,    batch: 2775/2993    Discriminator_loss: 0.00025285102310590446  Generator_loss: 8.443327903747559\n",
            "epoch: 18/20,    batch: 2776/2993    Discriminator_loss: 0.00021876668324694037  Generator_loss: 8.444436073303223\n",
            "epoch: 18/20,    batch: 2777/2993    Discriminator_loss: 0.00023526442237198353  Generator_loss: 8.445526123046875\n",
            "epoch: 18/20,    batch: 2778/2993    Discriminator_loss: 0.00040568236727267504  Generator_loss: 8.446324348449707\n",
            "epoch: 18/20,    batch: 2779/2993    Discriminator_loss: 0.00021694479801226407  Generator_loss: 8.447210311889648\n",
            "epoch: 18/20,    batch: 2780/2993    Discriminator_loss: 0.0003088930097874254  Generator_loss: 8.448322296142578\n",
            "epoch: 18/20,    batch: 2781/2993    Discriminator_loss: 0.0003471321542747319  Generator_loss: 8.44943618774414\n",
            "epoch: 18/20,    batch: 2782/2993    Discriminator_loss: 0.0002180361916543916  Generator_loss: 8.45021915435791\n",
            "epoch: 18/20,    batch: 2783/2993    Discriminator_loss: 0.0003057080612052232  Generator_loss: 8.451108932495117\n",
            "epoch: 18/20,    batch: 2784/2993    Discriminator_loss: 0.00023009715368971229  Generator_loss: 8.452224731445312\n",
            "epoch: 18/20,    batch: 2785/2993    Discriminator_loss: 0.0002283236535731703  Generator_loss: 8.45334243774414\n",
            "epoch: 18/20,    batch: 2786/2993    Discriminator_loss: 0.00030074326787143946  Generator_loss: 8.453971862792969\n",
            "epoch: 18/20,    batch: 2787/2993    Discriminator_loss: 0.00021838994871359318  Generator_loss: 8.455021858215332\n",
            "epoch: 18/20,    batch: 2788/2993    Discriminator_loss: 0.00023285174393095076  Generator_loss: 8.45614242553711\n",
            "epoch: 18/20,    batch: 2789/2993    Discriminator_loss: 0.0003037845599465072  Generator_loss: 8.456878662109375\n",
            "epoch: 18/20,    batch: 2790/2993    Discriminator_loss: 0.00021881828433834016  Generator_loss: 8.457826614379883\n",
            "epoch: 18/20,    batch: 2791/2993    Discriminator_loss: 0.00024180198670364916  Generator_loss: 8.45895004272461\n",
            "epoch: 18/20,    batch: 2792/2993    Discriminator_loss: 0.0002632922260090709  Generator_loss: 8.459529876708984\n",
            "epoch: 18/20,    batch: 2793/2993    Discriminator_loss: 0.00021629601542372257  Generator_loss: 8.460638999938965\n",
            "epoch: 18/20,    batch: 2794/2993    Discriminator_loss: 0.0002293031575391069  Generator_loss: 8.461677551269531\n",
            "epoch: 18/20,    batch: 2795/2993    Discriminator_loss: 0.0002340480568818748  Generator_loss: 8.462329864501953\n",
            "epoch: 18/20,    batch: 2796/2993    Discriminator_loss: 0.0002666183572728187  Generator_loss: 8.463459014892578\n",
            "epoch: 18/20,    batch: 2797/2993    Discriminator_loss: 0.0002582616580184549  Generator_loss: 8.46402359008789\n",
            "epoch: 18/20,    batch: 2798/2993    Discriminator_loss: 0.0014063246781006455  Generator_loss: 8.464731216430664\n",
            "epoch: 18/20,    batch: 2799/2993    Discriminator_loss: 0.00024283758830279112  Generator_loss: 8.465721130371094\n",
            "epoch: 18/20,    batch: 2800/2993    Discriminator_loss: 0.0002119613636750728  Generator_loss: 8.466287612915039\n",
            "epoch: 18/20,    batch: 2801/2993    Discriminator_loss: 0.0002279077743878588  Generator_loss: 8.466889381408691\n",
            "epoch: 18/20,    batch: 2802/2993    Discriminator_loss: 0.000262304674834013  Generator_loss: 8.467916488647461\n",
            "epoch: 18/20,    batch: 2803/2993    Discriminator_loss: 0.0002425321436021477  Generator_loss: 8.468555450439453\n",
            "epoch: 18/20,    batch: 2804/2993    Discriminator_loss: 0.00023326331574935466  Generator_loss: 8.469123840332031\n",
            "epoch: 18/20,    batch: 2805/2993    Discriminator_loss: 0.0002445066347718239  Generator_loss: 8.469799041748047\n",
            "epoch: 18/20,    batch: 2806/2993    Discriminator_loss: 0.00024939331342466176  Generator_loss: 8.470829010009766\n",
            "epoch: 18/20,    batch: 2807/2993    Discriminator_loss: 0.0002112757065333426  Generator_loss: 8.47139835357666\n",
            "epoch: 18/20,    batch: 2808/2993    Discriminator_loss: 0.00024058169219642878  Generator_loss: 8.471967697143555\n",
            "epoch: 18/20,    batch: 2809/2993    Discriminator_loss: 0.00023391327704302967  Generator_loss: 8.472609519958496\n",
            "epoch: 18/20,    batch: 2810/2993    Discriminator_loss: 0.00028026767540723085  Generator_loss: 8.473518371582031\n",
            "epoch: 18/20,    batch: 2811/2993    Discriminator_loss: 0.0002950457273982465  Generator_loss: 8.474248886108398\n",
            "epoch: 18/20,    batch: 2812/2993    Discriminator_loss: 0.0004084664979018271  Generator_loss: 8.474802017211914\n",
            "epoch: 18/20,    batch: 2813/2993    Discriminator_loss: 0.00024723983369767666  Generator_loss: 8.475357055664062\n",
            "epoch: 18/20,    batch: 2814/2993    Discriminator_loss: 0.00023375106684397906  Generator_loss: 8.475963592529297\n",
            "epoch: 18/20,    batch: 2815/2993    Discriminator_loss: 0.0002806435222737491  Generator_loss: 8.476517677307129\n",
            "epoch: 18/20,    batch: 2816/2993    Discriminator_loss: 0.0002372761955484748  Generator_loss: 8.477108001708984\n",
            "epoch: 18/20,    batch: 2817/2993    Discriminator_loss: 0.00022666672884952277  Generator_loss: 8.477519989013672\n",
            "epoch: 18/20,    batch: 2818/2993    Discriminator_loss: 0.0003195981262251735  Generator_loss: 8.477825164794922\n",
            "epoch: 18/20,    batch: 2819/2993    Discriminator_loss: 0.0002115902170771733  Generator_loss: 8.478272438049316\n",
            "epoch: 18/20,    batch: 2820/2993    Discriminator_loss: 0.00022694241488352418  Generator_loss: 8.478827476501465\n",
            "epoch: 18/20,    batch: 2821/2993    Discriminator_loss: 0.00031664391281083226  Generator_loss: 8.479275703430176\n",
            "epoch: 18/20,    batch: 2822/2993    Discriminator_loss: 0.00020948905148543417  Generator_loss: 8.479401588439941\n",
            "epoch: 18/20,    batch: 2823/2993    Discriminator_loss: 0.00024030727217905223  Generator_loss: 8.479975700378418\n",
            "epoch: 18/20,    batch: 2824/2993    Discriminator_loss: 0.0002782980154734105  Generator_loss: 8.479975700378418\n",
            "epoch: 18/20,    batch: 2825/2993    Discriminator_loss: 0.00021685779211111367  Generator_loss: 8.480155944824219\n",
            "epoch: 18/20,    batch: 2826/2993    Discriminator_loss: 0.00023580327979288995  Generator_loss: 8.48049545288086\n",
            "epoch: 18/20,    batch: 2827/2993    Discriminator_loss: 0.0002688630484044552  Generator_loss: 8.480496406555176\n",
            "epoch: 18/20,    batch: 2828/2993    Discriminator_loss: 0.0002136875846190378  Generator_loss: 8.480352401733398\n",
            "epoch: 18/20,    batch: 2829/2993    Discriminator_loss: 0.0002592848031781614  Generator_loss: 8.480010986328125\n",
            "epoch: 18/20,    batch: 2830/2993    Discriminator_loss: 0.00025307293981313705  Generator_loss: 8.479957580566406\n",
            "epoch: 18/20,    batch: 2831/2993    Discriminator_loss: 0.0002528306795284152  Generator_loss: 8.479491233825684\n",
            "epoch: 18/20,    batch: 2832/2993    Discriminator_loss: 0.0002473789209034294  Generator_loss: 8.478971481323242\n",
            "epoch: 18/20,    batch: 2833/2993    Discriminator_loss: 0.00045277256867848337  Generator_loss: 8.478325843811035\n",
            "epoch: 18/20,    batch: 2834/2993    Discriminator_loss: 0.00026960557443089783  Generator_loss: 8.477627754211426\n",
            "epoch: 18/20,    batch: 2835/2993    Discriminator_loss: 0.00021428553736768663  Generator_loss: 8.47653579711914\n",
            "epoch: 18/20,    batch: 2836/2993    Discriminator_loss: 0.00025939964689314365  Generator_loss: 8.475427627563477\n",
            "epoch: 18/20,    batch: 2837/2993    Discriminator_loss: 0.0002594869874883443  Generator_loss: 8.474212646484375\n",
            "epoch: 18/20,    batch: 2838/2993    Discriminator_loss: 0.00023028092982713133  Generator_loss: 8.472841262817383\n",
            "epoch: 18/20,    batch: 2839/2993    Discriminator_loss: 0.00023345848603639752  Generator_loss: 8.471363067626953\n",
            "epoch: 18/20,    batch: 2840/2993    Discriminator_loss: 0.0008051415788941085  Generator_loss: 8.469568252563477\n",
            "epoch: 18/20,    batch: 2841/2993    Discriminator_loss: 0.00026207801420241594  Generator_loss: 8.467580795288086\n",
            "epoch: 18/20,    batch: 2842/2993    Discriminator_loss: 0.00021560479945037514  Generator_loss: 8.465633392333984\n",
            "epoch: 18/20,    batch: 2843/2993    Discriminator_loss: 0.0002849096490535885  Generator_loss: 8.463423728942871\n",
            "epoch: 18/20,    batch: 2844/2993    Discriminator_loss: 0.0002692391281016171  Generator_loss: 8.461236953735352\n",
            "epoch: 18/20,    batch: 2845/2993    Discriminator_loss: 0.00022928138787392527  Generator_loss: 8.459003448486328\n",
            "epoch: 18/20,    batch: 2846/2993    Discriminator_loss: 0.0002477297675795853  Generator_loss: 8.456737518310547\n",
            "epoch: 18/20,    batch: 2847/2993    Discriminator_loss: 0.00033702465589158237  Generator_loss: 8.454391479492188\n",
            "epoch: 18/20,    batch: 2848/2993    Discriminator_loss: 0.0002287992392666638  Generator_loss: 8.452051162719727\n",
            "epoch: 18/20,    batch: 2849/2993    Discriminator_loss: 0.000245002971496433  Generator_loss: 8.449697494506836\n",
            "epoch: 18/20,    batch: 2850/2993    Discriminator_loss: 0.0002555756364017725  Generator_loss: 8.447349548339844\n",
            "epoch: 18/20,    batch: 2851/2993    Discriminator_loss: 0.0002169765648432076  Generator_loss: 8.444938659667969\n",
            "epoch: 18/20,    batch: 2852/2993    Discriminator_loss: 0.00029313351842574775  Generator_loss: 8.442619323730469\n",
            "epoch: 18/20,    batch: 2853/2993    Discriminator_loss: 0.00024136867432389408  Generator_loss: 8.44009780883789\n",
            "epoch: 18/20,    batch: 2854/2993    Discriminator_loss: 0.00023526509176008403  Generator_loss: 8.43763542175293\n",
            "epoch: 18/20,    batch: 2855/2993    Discriminator_loss: 0.00027874403167515993  Generator_loss: 8.435178756713867\n",
            "epoch: 18/20,    batch: 2856/2993    Discriminator_loss: 0.0002457635127939284  Generator_loss: 8.432641983032227\n",
            "epoch: 18/20,    batch: 2857/2993    Discriminator_loss: 0.00022630926105193794  Generator_loss: 8.430164337158203\n",
            "epoch: 18/20,    batch: 2858/2993    Discriminator_loss: 0.0002607385686133057  Generator_loss: 8.427776336669922\n",
            "epoch: 18/20,    batch: 2859/2993    Discriminator_loss: 0.00024933129316195846  Generator_loss: 8.424798965454102\n",
            "epoch: 18/20,    batch: 2860/2993    Discriminator_loss: 0.00024382276751566678  Generator_loss: 8.421865463256836\n",
            "epoch: 18/20,    batch: 2861/2993    Discriminator_loss: 0.00025954601005651057  Generator_loss: 8.419076919555664\n",
            "epoch: 18/20,    batch: 2862/2993    Discriminator_loss: 0.00024017752730287611  Generator_loss: 8.416025161743164\n",
            "epoch: 18/20,    batch: 2863/2993    Discriminator_loss: 0.00022621502284891903  Generator_loss: 8.412562370300293\n",
            "epoch: 18/20,    batch: 2864/2993    Discriminator_loss: 0.0002448419982101768  Generator_loss: 8.409162521362305\n",
            "epoch: 18/20,    batch: 2865/2993    Discriminator_loss: 0.00029527745209634304  Generator_loss: 8.405741691589355\n",
            "epoch: 18/20,    batch: 2866/2993    Discriminator_loss: 0.00023132670321501791  Generator_loss: 8.40219783782959\n",
            "epoch: 18/20,    batch: 2867/2993    Discriminator_loss: 0.0002851379686035216  Generator_loss: 8.398486137390137\n",
            "epoch: 18/20,    batch: 2868/2993    Discriminator_loss: 0.00026770427939482033  Generator_loss: 8.394770622253418\n",
            "epoch: 18/20,    batch: 2869/2993    Discriminator_loss: 0.00022961728973314166  Generator_loss: 8.390987396240234\n",
            "epoch: 18/20,    batch: 2870/2993    Discriminator_loss: 0.00023303544730879366  Generator_loss: 8.387218475341797\n",
            "epoch: 18/20,    batch: 2871/2993    Discriminator_loss: 0.00031219562515616417  Generator_loss: 8.383284568786621\n",
            "epoch: 18/20,    batch: 2872/2993    Discriminator_loss: 0.00023566969321109354  Generator_loss: 8.379657745361328\n",
            "epoch: 18/20,    batch: 2873/2993    Discriminator_loss: 0.0002733847941271961  Generator_loss: 8.376173973083496\n",
            "epoch: 18/20,    batch: 2874/2993    Discriminator_loss: 0.0002681444166228175  Generator_loss: 8.372782707214355\n",
            "epoch: 18/20,    batch: 2875/2993    Discriminator_loss: 0.00023521939874626696  Generator_loss: 8.369466781616211\n",
            "epoch: 18/20,    batch: 2876/2993    Discriminator_loss: 0.00026359979528933764  Generator_loss: 8.366482734680176\n",
            "epoch: 18/20,    batch: 2877/2993    Discriminator_loss: 0.00026687062927521765  Generator_loss: 8.363587379455566\n",
            "epoch: 18/20,    batch: 2878/2993    Discriminator_loss: 0.00024836682132445276  Generator_loss: 8.361034393310547\n",
            "epoch: 18/20,    batch: 2879/2993    Discriminator_loss: 0.0002623519394546747  Generator_loss: 8.358551979064941\n",
            "epoch: 18/20,    batch: 2880/2993    Discriminator_loss: 0.0002711123670451343  Generator_loss: 8.3565034866333\n",
            "epoch: 18/20,    batch: 2881/2993    Discriminator_loss: 0.00024602210032753646  Generator_loss: 8.354490280151367\n",
            "epoch: 18/20,    batch: 2882/2993    Discriminator_loss: 0.00032805890077725053  Generator_loss: 8.352877616882324\n",
            "epoch: 18/20,    batch: 2883/2993    Discriminator_loss: 0.0002810377918649465  Generator_loss: 8.351299285888672\n",
            "epoch: 18/20,    batch: 2884/2993    Discriminator_loss: 0.00025242986157536507  Generator_loss: 8.349879264831543\n",
            "epoch: 18/20,    batch: 2885/2993    Discriminator_loss: 0.00030256371246650815  Generator_loss: 8.3485107421875\n",
            "epoch: 18/20,    batch: 2886/2993    Discriminator_loss: 0.00026687709032557905  Generator_loss: 8.347487449645996\n",
            "epoch: 18/20,    batch: 2887/2993    Discriminator_loss: 0.00029052552417851985  Generator_loss: 8.34634017944336\n",
            "epoch: 18/20,    batch: 2888/2993    Discriminator_loss: 0.0003400979330763221  Generator_loss: 8.345367431640625\n",
            "epoch: 18/20,    batch: 2889/2993    Discriminator_loss: 0.0002577388077042997  Generator_loss: 8.344568252563477\n",
            "epoch: 18/20,    batch: 2890/2993    Discriminator_loss: 0.0002988027117680758  Generator_loss: 8.343815803527832\n",
            "epoch: 18/20,    batch: 2891/2993    Discriminator_loss: 0.00028717590612359345  Generator_loss: 8.343158721923828\n",
            "epoch: 18/20,    batch: 2892/2993    Discriminator_loss: 0.000300954474369064  Generator_loss: 8.342500686645508\n",
            "epoch: 18/20,    batch: 2893/2993    Discriminator_loss: 0.0003204357053618878  Generator_loss: 8.341890335083008\n",
            "epoch: 18/20,    batch: 2894/2993    Discriminator_loss: 0.0004975375486537814  Generator_loss: 8.341360092163086\n",
            "epoch: 18/20,    batch: 2895/2993    Discriminator_loss: 0.0002783748786896467  Generator_loss: 8.340970039367676\n",
            "epoch: 18/20,    batch: 2896/2993    Discriminator_loss: 0.0002576476545073092  Generator_loss: 8.340673446655273\n",
            "epoch: 18/20,    batch: 2897/2993    Discriminator_loss: 0.0002826471463777125  Generator_loss: 8.340267181396484\n",
            "epoch: 18/20,    batch: 2898/2993    Discriminator_loss: 0.0003217380726709962  Generator_loss: 8.339893341064453\n",
            "epoch: 18/20,    batch: 2899/2993    Discriminator_loss: 0.00027582934126257896  Generator_loss: 8.339456558227539\n",
            "epoch: 18/20,    batch: 2900/2993    Discriminator_loss: 0.00037840925506316125  Generator_loss: 8.339300155639648\n",
            "epoch: 18/20,    batch: 2901/2993    Discriminator_loss: 0.0003348971367813647  Generator_loss: 8.33883285522461\n",
            "epoch: 18/20,    batch: 2902/2993    Discriminator_loss: 0.0002544831659179181  Generator_loss: 8.33847427368164\n",
            "epoch: 18/20,    batch: 2903/2993    Discriminator_loss: 0.00027868192410096526  Generator_loss: 8.338239669799805\n",
            "epoch: 18/20,    batch: 2904/2993    Discriminator_loss: 0.0003077268193010241  Generator_loss: 8.33774185180664\n",
            "epoch: 18/20,    batch: 2905/2993    Discriminator_loss: 0.00024657038738951087  Generator_loss: 8.337198257446289\n",
            "epoch: 18/20,    batch: 2906/2993    Discriminator_loss: 0.00028966498211957514  Generator_loss: 8.336606979370117\n",
            "epoch: 18/20,    batch: 2907/2993    Discriminator_loss: 0.0004058279446326196  Generator_loss: 8.335891723632812\n",
            "epoch: 18/20,    batch: 2908/2993    Discriminator_loss: 0.000269678799668327  Generator_loss: 8.33497428894043\n",
            "epoch: 18/20,    batch: 2909/2993    Discriminator_loss: 0.00027244046214036644  Generator_loss: 8.333904266357422\n",
            "epoch: 18/20,    batch: 2910/2993    Discriminator_loss: 0.00032357574673369527  Generator_loss: 8.332757949829102\n",
            "epoch: 18/20,    batch: 2911/2993    Discriminator_loss: 0.0002879645035136491  Generator_loss: 8.331379890441895\n",
            "epoch: 18/20,    batch: 2912/2993    Discriminator_loss: 0.00028087079408578575  Generator_loss: 8.329896926879883\n",
            "epoch: 18/20,    batch: 2913/2993    Discriminator_loss: 0.00028364345780573785  Generator_loss: 8.327936172485352\n",
            "epoch: 18/20,    batch: 2914/2993    Discriminator_loss: 0.0004378260055091232  Generator_loss: 8.325965881347656\n",
            "epoch: 18/20,    batch: 2915/2993    Discriminator_loss: 0.00027481818688102067  Generator_loss: 8.323630332946777\n",
            "epoch: 18/20,    batch: 2916/2993    Discriminator_loss: 0.00034413725370541215  Generator_loss: 8.321207046508789\n",
            "epoch: 18/20,    batch: 2917/2993    Discriminator_loss: 0.0003973224083893001  Generator_loss: 8.31871509552002\n",
            "epoch: 18/20,    batch: 2918/2993    Discriminator_loss: 0.00047751585952937603  Generator_loss: 8.316122055053711\n",
            "epoch: 18/20,    batch: 2919/2993    Discriminator_loss: 0.0002862108813133091  Generator_loss: 8.31342887878418\n",
            "epoch: 18/20,    batch: 2920/2993    Discriminator_loss: 0.00033567671198397875  Generator_loss: 8.31080436706543\n",
            "epoch: 18/20,    batch: 2921/2993    Discriminator_loss: 0.00029006644035689533  Generator_loss: 8.308216094970703\n",
            "epoch: 18/20,    batch: 2922/2993    Discriminator_loss: 0.0003394873929210007  Generator_loss: 8.305862426757812\n",
            "epoch: 18/20,    batch: 2923/2993    Discriminator_loss: 0.0003263807448092848  Generator_loss: 8.303571701049805\n",
            "epoch: 18/20,    batch: 2924/2993    Discriminator_loss: 0.000323876942275092  Generator_loss: 8.301528930664062\n",
            "epoch: 18/20,    batch: 2925/2993    Discriminator_loss: 0.00026076624635607004  Generator_loss: 8.299654006958008\n",
            "epoch: 18/20,    batch: 2926/2993    Discriminator_loss: 0.00030915887327864766  Generator_loss: 8.297931671142578\n",
            "epoch: 18/20,    batch: 2927/2993    Discriminator_loss: 0.000320019549690187  Generator_loss: 8.296392440795898\n",
            "epoch: 18/20,    batch: 2928/2993    Discriminator_loss: 0.00027978140860795975  Generator_loss: 8.295003890991211\n",
            "epoch: 18/20,    batch: 2929/2993    Discriminator_loss: 0.00040065147913992405  Generator_loss: 8.293915748596191\n",
            "epoch: 18/20,    batch: 2930/2993    Discriminator_loss: 0.0002763180818874389  Generator_loss: 8.292784690856934\n",
            "epoch: 18/20,    batch: 2931/2993    Discriminator_loss: 0.000295042380457744  Generator_loss: 8.29184627532959\n",
            "epoch: 18/20,    batch: 2932/2993    Discriminator_loss: 0.0002606697380542755  Generator_loss: 8.291014671325684\n",
            "epoch: 18/20,    batch: 2933/2993    Discriminator_loss: 0.0009243997046723962  Generator_loss: 8.290138244628906\n",
            "epoch: 18/20,    batch: 2934/2993    Discriminator_loss: 0.0002875447098631412  Generator_loss: 8.289321899414062\n",
            "epoch: 18/20,    batch: 2935/2993    Discriminator_loss: 0.00026578857796266675  Generator_loss: 8.28874397277832\n",
            "epoch: 18/20,    batch: 2936/2993    Discriminator_loss: 0.0003581561613827944  Generator_loss: 8.28825569152832\n",
            "epoch: 18/20,    batch: 2937/2993    Discriminator_loss: 0.0006597181200049818  Generator_loss: 8.287307739257812\n",
            "epoch: 18/20,    batch: 2938/2993    Discriminator_loss: 0.0003066950594075024  Generator_loss: 8.286642074584961\n",
            "epoch: 18/20,    batch: 2939/2993    Discriminator_loss: 0.0002920240513049066  Generator_loss: 8.28590202331543\n",
            "epoch: 18/20,    batch: 2940/2993    Discriminator_loss: 0.0009417692781426013  Generator_loss: 8.285076141357422\n",
            "epoch: 18/20,    batch: 2941/2993    Discriminator_loss: 0.00028269633185118437  Generator_loss: 8.28441047668457\n",
            "epoch: 18/20,    batch: 2942/2993    Discriminator_loss: 0.0002636636490933597  Generator_loss: 8.283746719360352\n",
            "epoch: 18/20,    batch: 2943/2993    Discriminator_loss: 0.0003032870008610189  Generator_loss: 8.283157348632812\n",
            "epoch: 18/20,    batch: 2944/2993    Discriminator_loss: 0.00048057877575047314  Generator_loss: 8.282538414001465\n",
            "epoch: 18/20,    batch: 2945/2993    Discriminator_loss: 0.0002877078950405121  Generator_loss: 8.281698226928711\n",
            "epoch: 18/20,    batch: 2946/2993    Discriminator_loss: 0.0002822315727826208  Generator_loss: 8.281168937683105\n",
            "epoch: 18/20,    batch: 2947/2993    Discriminator_loss: 0.0002918519894592464  Generator_loss: 8.280595779418945\n",
            "epoch: 18/20,    batch: 2948/2993    Discriminator_loss: 0.0002737650356721133  Generator_loss: 8.279861450195312\n",
            "epoch: 18/20,    batch: 2949/2993    Discriminator_loss: 0.0005434212507680058  Generator_loss: 8.279214859008789\n",
            "epoch: 18/20,    batch: 2950/2993    Discriminator_loss: 0.0003628867561928928  Generator_loss: 8.278392791748047\n",
            "epoch: 18/20,    batch: 2951/2993    Discriminator_loss: 0.0002671396650839597  Generator_loss: 8.277528762817383\n",
            "epoch: 18/20,    batch: 2952/2993    Discriminator_loss: 0.0002806404372677207  Generator_loss: 8.27670669555664\n",
            "epoch: 18/20,    batch: 2953/2993    Discriminator_loss: 0.0003059519804082811  Generator_loss: 8.275697708129883\n",
            "epoch: 18/20,    batch: 2954/2993    Discriminator_loss: 0.00026425637770444155  Generator_loss: 8.27464485168457\n",
            "epoch: 18/20,    batch: 2955/2993    Discriminator_loss: 0.0003293014597147703  Generator_loss: 8.273475646972656\n",
            "epoch: 18/20,    batch: 2956/2993    Discriminator_loss: 0.00031676091020926833  Generator_loss: 8.272235870361328\n",
            "epoch: 18/20,    batch: 2957/2993    Discriminator_loss: 0.0002603486937005073  Generator_loss: 8.270706176757812\n",
            "epoch: 18/20,    batch: 2958/2993    Discriminator_loss: 0.00037802598671987653  Generator_loss: 8.26907730102539\n",
            "epoch: 18/20,    batch: 2959/2993    Discriminator_loss: 0.0002772303996607661  Generator_loss: 8.267509460449219\n",
            "epoch: 18/20,    batch: 2960/2993    Discriminator_loss: 0.0002730267297010869  Generator_loss: 8.265740394592285\n",
            "epoch: 18/20,    batch: 2961/2993    Discriminator_loss: 0.000323023326927796  Generator_loss: 8.263843536376953\n",
            "epoch: 18/20,    batch: 2962/2993    Discriminator_loss: 0.0003603846416808665  Generator_loss: 8.261865615844727\n",
            "epoch: 18/20,    batch: 2963/2993    Discriminator_loss: 0.00026519791572354734  Generator_loss: 8.259876251220703\n",
            "epoch: 18/20,    batch: 2964/2993    Discriminator_loss: 0.00029183313017711043  Generator_loss: 8.257803916931152\n",
            "epoch: 18/20,    batch: 2965/2993    Discriminator_loss: 0.00037633441388607025  Generator_loss: 8.255608558654785\n",
            "epoch: 18/20,    batch: 2966/2993    Discriminator_loss: 0.00028748769545927644  Generator_loss: 8.253445625305176\n",
            "epoch: 18/20,    batch: 2967/2993    Discriminator_loss: 0.0003203637897968292  Generator_loss: 8.25131607055664\n",
            "epoch: 18/20,    batch: 2968/2993    Discriminator_loss: 0.0003643616219051182  Generator_loss: 8.249090194702148\n",
            "epoch: 18/20,    batch: 2969/2993    Discriminator_loss: 0.00029821370844729245  Generator_loss: 8.246870994567871\n",
            "epoch: 18/20,    batch: 2970/2993    Discriminator_loss: 0.0003097592853009701  Generator_loss: 8.244754791259766\n",
            "epoch: 18/20,    batch: 2971/2993    Discriminator_loss: 0.0005835623014718294  Generator_loss: 8.242729187011719\n",
            "epoch: 18/20,    batch: 2972/2993    Discriminator_loss: 0.00031190182198770344  Generator_loss: 8.24093246459961\n",
            "epoch: 18/20,    batch: 2973/2993    Discriminator_loss: 0.0002915452350862324  Generator_loss: 8.239068984985352\n",
            "epoch: 18/20,    batch: 2974/2993    Discriminator_loss: 0.00048466658336110413  Generator_loss: 8.237632751464844\n",
            "epoch: 18/20,    batch: 2975/2993    Discriminator_loss: 0.000374413764802739  Generator_loss: 8.236407279968262\n",
            "epoch: 18/20,    batch: 2976/2993    Discriminator_loss: 0.00030417199013754725  Generator_loss: 8.235466003417969\n",
            "epoch: 18/20,    batch: 2977/2993    Discriminator_loss: 0.0003873992245644331  Generator_loss: 8.234649658203125\n",
            "epoch: 18/20,    batch: 2978/2993    Discriminator_loss: 0.0003363221767358482  Generator_loss: 8.234397888183594\n",
            "epoch: 18/20,    batch: 2979/2993    Discriminator_loss: 0.0003366981400176883  Generator_loss: 8.234103202819824\n",
            "epoch: 18/20,    batch: 2980/2993    Discriminator_loss: 0.00034971247077919543  Generator_loss: 8.23421573638916\n",
            "epoch: 18/20,    batch: 2981/2993    Discriminator_loss: 0.00029622940928675234  Generator_loss: 8.234130859375\n",
            "epoch: 18/20,    batch: 2982/2993    Discriminator_loss: 0.0002968828775919974  Generator_loss: 8.234565734863281\n",
            "epoch: 18/20,    batch: 2983/2993    Discriminator_loss: 0.0003207575064152479  Generator_loss: 8.235071182250977\n",
            "epoch: 18/20,    batch: 2984/2993    Discriminator_loss: 0.0002712643763516098  Generator_loss: 8.235662460327148\n",
            "epoch: 18/20,    batch: 2985/2993    Discriminator_loss: 0.0002927132591139525  Generator_loss: 8.236392974853516\n",
            "epoch: 18/20,    batch: 2986/2993    Discriminator_loss: 0.00033439387334510684  Generator_loss: 8.237096786499023\n",
            "epoch: 18/20,    batch: 2987/2993    Discriminator_loss: 0.00027077447157353163  Generator_loss: 8.237730026245117\n",
            "epoch: 18/20,    batch: 2988/2993    Discriminator_loss: 0.0003557356831151992  Generator_loss: 8.238590240478516\n",
            "epoch: 18/20,    batch: 2989/2993    Discriminator_loss: 0.0002915844670496881  Generator_loss: 8.23929500579834\n",
            "epoch: 18/20,    batch: 2990/2993    Discriminator_loss: 0.00027542171301320195  Generator_loss: 8.240042686462402\n",
            "epoch: 18/20,    batch: 2991/2993    Discriminator_loss: 0.00038237625267356634  Generator_loss: 8.24083423614502\n",
            "epoch: 18/20,    batch: 2992/2993    Discriminator_loss: 0.00030683123623020947  Generator_loss: 8.241483688354492\n",
            "  adding: checkpoints/ (stored 0%)\n",
            "  adding: checkpoints/generator/ (stored 0%)\n",
            "  adding: checkpoints/generator/gen_epoch0.h5 (deflated 8%)\n",
            "  adding: checkpoints/generator/gen_epoch7.h5 (deflated 8%)\n",
            "  adding: checkpoints/generator/gen_epoch4.h5 (deflated 8%)\n",
            "  adding: checkpoints/generator/gen_epoch2.h5 (deflated 8%)\n",
            "  adding: checkpoints/generator/gen_epoch12.h5 (deflated 8%)\n",
            "  adding: checkpoints/generator/gen_epoch16.h5 (deflated 8%)\n",
            "  adding: checkpoints/generator/gen_epoch13.h5 (deflated 8%)\n",
            "  adding: checkpoints/generator/gen_epoch10.h5 (deflated 8%)\n",
            "  adding: checkpoints/generator/gen_epoch15.h5 (deflated 8%)\n",
            "  adding: checkpoints/generator/gen_epoch8.h5 (deflated 8%)\n",
            "  adding: checkpoints/generator/gen_epoch11.h5 (deflated 8%)\n",
            "  adding: checkpoints/generator/gen_epoch18.h5 (deflated 8%)\n",
            "  adding: checkpoints/generator/gen_epoch14.h5 (deflated 8%)\n",
            "  adding: checkpoints/generator/gen_epoch1.h5 (deflated 8%)\n",
            "  adding: checkpoints/generator/gen_epoch6.h5 (deflated 8%)\n",
            "  adding: checkpoints/generator/gen_epoch9.h5 (deflated 8%)\n",
            "  adding: checkpoints/generator/gen_epoch3.h5 (deflated 8%)\n",
            "  adding: checkpoints/generator/gen_epoch5.h5 (deflated 8%)\n",
            "  adding: checkpoints/generator/gen_epoch17.h5 (deflated 8%)\n",
            "  adding: checkpoints/discriminator/ (stored 0%)\n",
            "  adding: checkpoints/discriminator/discr_epoch16.h5 (deflated 12%)\n",
            "  adding: checkpoints/discriminator/discr_epoch9.h5 (deflated 12%)\n",
            "  adding: checkpoints/discriminator/discr_epoch6.h5 (deflated 12%)\n",
            "  adding: checkpoints/discriminator/discr_epoch18.h5 (deflated 11%)\n",
            "  adding: checkpoints/discriminator/discr_epoch12.h5 (deflated 12%)\n",
            "  adding: checkpoints/discriminator/discr_epoch5.h5 (deflated 12%)\n",
            "  adding: checkpoints/discriminator/discr_epoch17.h5 (deflated 12%)\n",
            "  adding: checkpoints/discriminator/discr_epoch11.h5 (deflated 12%)\n",
            "  adding: checkpoints/discriminator/discr_epoch15.h5 (deflated 12%)\n",
            "  adding: checkpoints/discriminator/discr_epoch3.h5 (deflated 12%)\n",
            "  adding: checkpoints/discriminator/discr_epoch8.h5 (deflated 12%)\n",
            "  adding: checkpoints/discriminator/discr_epoch1.h5 (deflated 12%)\n",
            "  adding: checkpoints/discriminator/discr_epoch4.h5 (deflated 12%)\n",
            "  adding: checkpoints/discriminator/discr_epoch2.h5 (deflated 12%)\n",
            "  adding: checkpoints/discriminator/discr_epoch10.h5 (deflated 12%)\n",
            "  adding: checkpoints/discriminator/discr_epoch0.h5 (deflated 12%)\n",
            "  adding: checkpoints/discriminator/discr_epoch13.h5 (deflated 12%)\n",
            "  adding: checkpoints/discriminator/discr_epoch7.h5 (deflated 12%)\n",
            "  adding: checkpoints/discriminator/discr_epoch14.h5 (deflated 12%)\n",
            "epoch: 19/20,    batch: 0/2993    Discriminator_loss: 12.820805549621582  Generator_loss: 7.79592227935791\n",
            "epoch: 19/20,    batch: 1/2993    Discriminator_loss: 0.014321778900921345  Generator_loss: 7.475211143493652\n",
            "epoch: 19/20,    batch: 2/2993    Discriminator_loss: 0.005074326880276203  Generator_loss: 7.238531589508057\n",
            "epoch: 19/20,    batch: 3/2993    Discriminator_loss: 0.0030361972749233246  Generator_loss: 7.05927038192749\n",
            "epoch: 19/20,    batch: 4/2993    Discriminator_loss: 0.002293960889801383  Generator_loss: 6.918943881988525\n",
            "epoch: 19/20,    batch: 5/2993    Discriminator_loss: 0.002073268871754408  Generator_loss: 6.8058671951293945\n",
            "epoch: 19/20,    batch: 6/2993    Discriminator_loss: 0.001998795196413994  Generator_loss: 6.711856842041016\n",
            "epoch: 19/20,    batch: 7/2993    Discriminator_loss: 0.001971273683011532  Generator_loss: 6.632253646850586\n",
            "epoch: 19/20,    batch: 8/2993    Discriminator_loss: 0.0019905061926692724  Generator_loss: 6.5638017654418945\n",
            "epoch: 19/20,    batch: 9/2993    Discriminator_loss: 0.0020335884764790535  Generator_loss: 6.504344463348389\n",
            "epoch: 19/20,    batch: 10/2993    Discriminator_loss: 0.0021337377838790417  Generator_loss: 6.45190954208374\n",
            "epoch: 19/20,    batch: 11/2993    Discriminator_loss: 0.0021168699022382498  Generator_loss: 6.405035018920898\n",
            "epoch: 19/20,    batch: 12/2993    Discriminator_loss: 0.0021891493815928698  Generator_loss: 6.363043308258057\n",
            "epoch: 19/20,    batch: 13/2993    Discriminator_loss: 0.002291375771164894  Generator_loss: 6.324991703033447\n",
            "epoch: 19/20,    batch: 14/2993    Discriminator_loss: 0.0023478285875171423  Generator_loss: 6.290692329406738\n",
            "epoch: 19/20,    batch: 15/2993    Discriminator_loss: 0.0024011621717363596  Generator_loss: 6.259433746337891\n",
            "epoch: 19/20,    batch: 16/2993    Discriminator_loss: 0.0024430055636912584  Generator_loss: 6.2309370040893555\n",
            "epoch: 19/20,    batch: 17/2993    Discriminator_loss: 0.0024929901119321585  Generator_loss: 6.204655170440674\n",
            "epoch: 19/20,    batch: 18/2993    Discriminator_loss: 0.008055933751165867  Generator_loss: 6.180728435516357\n",
            "epoch: 19/20,    batch: 19/2993    Discriminator_loss: 0.024487696588039398  Generator_loss: 6.155786037445068\n",
            "epoch: 19/20,    batch: 20/2993    Discriminator_loss: 0.0027966012712568045  Generator_loss: 6.132732391357422\n",
            "epoch: 19/20,    batch: 21/2993    Discriminator_loss: 0.0023234994150698185  Generator_loss: 6.111269950866699\n",
            "epoch: 19/20,    batch: 22/2993    Discriminator_loss: 0.0026190378703176975  Generator_loss: 6.093897342681885\n",
            "epoch: 19/20,    batch: 23/2993    Discriminator_loss: 0.0023921094834804535  Generator_loss: 6.074372291564941\n",
            "epoch: 19/20,    batch: 24/2993    Discriminator_loss: 0.002735060639679432  Generator_loss: 6.058514595031738\n",
            "epoch: 19/20,    batch: 25/2993    Discriminator_loss: 0.0024333405308425426  Generator_loss: 6.042873382568359\n",
            "epoch: 19/20,    batch: 26/2993    Discriminator_loss: 0.0028732852078974247  Generator_loss: 6.028502464294434\n",
            "epoch: 19/20,    batch: 27/2993    Discriminator_loss: 0.0028242599219083786  Generator_loss: 6.013225555419922\n",
            "epoch: 19/20,    batch: 28/2993    Discriminator_loss: 0.0025338251143693924  Generator_loss: 5.999922752380371\n",
            "epoch: 19/20,    batch: 29/2993    Discriminator_loss: 0.0026109167374670506  Generator_loss: 5.985154151916504\n",
            "epoch: 19/20,    batch: 30/2993    Discriminator_loss: 0.002651492366567254  Generator_loss: 5.969120979309082\n",
            "epoch: 19/20,    batch: 31/2993    Discriminator_loss: 0.0034334654919803143  Generator_loss: 5.949389457702637\n",
            "epoch: 19/20,    batch: 32/2993    Discriminator_loss: 0.0027201154734939337  Generator_loss: 5.931937217712402\n",
            "epoch: 19/20,    batch: 33/2993    Discriminator_loss: 0.0029085720889270306  Generator_loss: 5.909775257110596\n",
            "epoch: 19/20,    batch: 34/2993    Discriminator_loss: 0.0034529846161603928  Generator_loss: 5.8862714767456055\n",
            "epoch: 19/20,    batch: 35/2993    Discriminator_loss: 0.0029315263964235783  Generator_loss: 5.864566802978516\n",
            "epoch: 19/20,    batch: 36/2993    Discriminator_loss: 0.015055572614073753  Generator_loss: 5.821850776672363\n",
            "epoch: 19/20,    batch: 37/2993    Discriminator_loss: 0.003286212682723999  Generator_loss: 5.784547805786133\n",
            "epoch: 19/20,    batch: 38/2993    Discriminator_loss: 0.006467120721936226  Generator_loss: 5.751265525817871\n",
            "epoch: 19/20,    batch: 39/2993    Discriminator_loss: 0.006113672628998756  Generator_loss: 5.720694541931152\n",
            "epoch: 19/20,    batch: 40/2993    Discriminator_loss: 0.08063922077417374  Generator_loss: 5.5478835105896\n",
            "epoch: 19/20,    batch: 41/2993    Discriminator_loss: 0.011487782001495361  Generator_loss: 5.392080783843994\n",
            "epoch: 19/20,    batch: 42/2993    Discriminator_loss: 0.006326150149106979  Generator_loss: 5.247775077819824\n",
            "epoch: 19/20,    batch: 43/2993    Discriminator_loss: 0.006902462802827358  Generator_loss: 5.128427505493164\n",
            "epoch: 19/20,    batch: 44/2993    Discriminator_loss: 0.011463209055364132  Generator_loss: 5.038500785827637\n",
            "epoch: 19/20,    batch: 45/2993    Discriminator_loss: 0.012704605236649513  Generator_loss: 4.9901323318481445\n",
            "epoch: 19/20,    batch: 46/2993    Discriminator_loss: 0.03458444029092789  Generator_loss: 4.99459171295166\n",
            "epoch: 19/20,    batch: 47/2993    Discriminator_loss: 0.007847022265195847  Generator_loss: 5.034730911254883\n",
            "epoch: 19/20,    batch: 48/2993    Discriminator_loss: 0.007647611666470766  Generator_loss: 5.106015205383301\n",
            "epoch: 19/20,    batch: 49/2993    Discriminator_loss: 0.007232835981994867  Generator_loss: 5.1936492919921875\n",
            "epoch: 19/20,    batch: 50/2993    Discriminator_loss: 0.006150029134005308  Generator_loss: 5.292045593261719\n",
            "epoch: 19/20,    batch: 51/2993    Discriminator_loss: 0.005712513811886311  Generator_loss: 5.391172885894775\n",
            "epoch: 19/20,    batch: 52/2993    Discriminator_loss: 0.009162003174424171  Generator_loss: 5.487226963043213\n",
            "epoch: 19/20,    batch: 53/2993    Discriminator_loss: 0.004578364547342062  Generator_loss: 5.574627876281738\n",
            "epoch: 19/20,    batch: 54/2993    Discriminator_loss: 0.004211318213492632  Generator_loss: 5.648486137390137\n",
            "epoch: 19/20,    batch: 55/2993    Discriminator_loss: 0.0052599734626710415  Generator_loss: 5.707547187805176\n",
            "epoch: 19/20,    batch: 56/2993    Discriminator_loss: 0.0037095118314027786  Generator_loss: 5.750001907348633\n",
            "epoch: 19/20,    batch: 57/2993    Discriminator_loss: 0.0038481070660054684  Generator_loss: 5.7772088050842285\n",
            "epoch: 19/20,    batch: 58/2993    Discriminator_loss: 0.004821814596652985  Generator_loss: 5.791539669036865\n",
            "epoch: 19/20,    batch: 59/2993    Discriminator_loss: 0.004170226864516735  Generator_loss: 5.794716835021973\n",
            "epoch: 19/20,    batch: 60/2993    Discriminator_loss: 0.003519297344610095  Generator_loss: 5.7948713302612305\n",
            "epoch: 19/20,    batch: 61/2993    Discriminator_loss: 0.0034856221172958612  Generator_loss: 5.8047943115234375\n",
            "epoch: 19/20,    batch: 62/2993    Discriminator_loss: 0.0036792908795177937  Generator_loss: 5.818295955657959\n",
            "epoch: 19/20,    batch: 63/2993    Discriminator_loss: 0.003319567535072565  Generator_loss: 5.846255302429199\n",
            "epoch: 19/20,    batch: 64/2993    Discriminator_loss: 0.0032863966189324856  Generator_loss: 5.87175178527832\n",
            "epoch: 19/20,    batch: 65/2993    Discriminator_loss: 0.003282329998910427  Generator_loss: 5.969371795654297\n",
            "epoch: 19/20,    batch: 66/2993    Discriminator_loss: 0.004042104817926884  Generator_loss: 6.083747863769531\n",
            "epoch: 19/20,    batch: 67/2993    Discriminator_loss: 0.002359761856496334  Generator_loss: 6.1701154708862305\n",
            "epoch: 19/20,    batch: 68/2993    Discriminator_loss: 0.0028665110003203154  Generator_loss: 6.248254299163818\n",
            "epoch: 19/20,    batch: 69/2993    Discriminator_loss: 0.0022519552148878574  Generator_loss: 6.31994104385376\n",
            "epoch: 19/20,    batch: 70/2993    Discriminator_loss: 0.0019306591711938381  Generator_loss: 6.383744239807129\n",
            "epoch: 19/20,    batch: 71/2993    Discriminator_loss: 0.002428276464343071  Generator_loss: 6.438401699066162\n",
            "epoch: 19/20,    batch: 72/2993    Discriminator_loss: 0.002354653086513281  Generator_loss: 6.485104560852051\n",
            "epoch: 19/20,    batch: 73/2993    Discriminator_loss: 0.0020905681885778904  Generator_loss: 6.522204875946045\n",
            "epoch: 19/20,    batch: 74/2993    Discriminator_loss: 0.0035514850169420242  Generator_loss: 6.548648834228516\n",
            "epoch: 19/20,    batch: 75/2993    Discriminator_loss: 0.0033128191716969013  Generator_loss: 6.561305046081543\n",
            "epoch: 19/20,    batch: 76/2993    Discriminator_loss: 0.001525182044133544  Generator_loss: 6.5642852783203125\n",
            "epoch: 19/20,    batch: 77/2993    Discriminator_loss: 0.0016400114400312304  Generator_loss: 6.556958198547363\n",
            "epoch: 19/20,    batch: 78/2993    Discriminator_loss: 0.002721612574532628  Generator_loss: 6.540041923522949\n",
            "epoch: 19/20,    batch: 79/2993    Discriminator_loss: 0.0015821424312889576  Generator_loss: 6.513872146606445\n",
            "epoch: 19/20,    batch: 80/2993    Discriminator_loss: 0.0018038167618215084  Generator_loss: 6.479672431945801\n",
            "epoch: 19/20,    batch: 81/2993    Discriminator_loss: 0.0021269661374390125  Generator_loss: 6.438532829284668\n",
            "epoch: 19/20,    batch: 82/2993    Discriminator_loss: 0.0017985770246014  Generator_loss: 6.391355514526367\n",
            "epoch: 19/20,    batch: 83/2993    Discriminator_loss: 0.0019087529508396983  Generator_loss: 6.339541435241699\n",
            "epoch: 19/20,    batch: 84/2993    Discriminator_loss: 0.0024586739018559456  Generator_loss: 6.283556938171387\n",
            "epoch: 19/20,    batch: 85/2993    Discriminator_loss: 0.0021398745011538267  Generator_loss: 6.225456237792969\n",
            "epoch: 19/20,    batch: 86/2993    Discriminator_loss: 0.002636569319292903  Generator_loss: 6.165217399597168\n",
            "epoch: 19/20,    batch: 87/2993    Discriminator_loss: 0.0025195868220180273  Generator_loss: 6.102952003479004\n",
            "epoch: 19/20,    batch: 88/2993    Discriminator_loss: 0.002677520737051964  Generator_loss: 6.038370132446289\n",
            "epoch: 19/20,    batch: 89/2993    Discriminator_loss: 0.003076547756791115  Generator_loss: 5.967437267303467\n",
            "epoch: 19/20,    batch: 90/2993    Discriminator_loss: 0.004275249782949686  Generator_loss: 5.807155609130859\n",
            "epoch: 19/20,    batch: 91/2993    Discriminator_loss: 0.00038177549140527844  Generator_loss: 8.084148406982422\n",
            "epoch: 19/20,    batch: 92/2993    Discriminator_loss: 0.003661562455818057  Generator_loss: 5.728062629699707\n",
            "epoch: 19/20,    batch: 93/2993    Discriminator_loss: 0.00454018684104085  Generator_loss: 5.579593658447266\n",
            "epoch: 19/20,    batch: 94/2993    Discriminator_loss: 0.00532876281067729  Generator_loss: 5.408379077911377\n",
            "epoch: 19/20,    batch: 95/2993    Discriminator_loss: 0.011364944279193878  Generator_loss: 4.670249938964844\n",
            "epoch: 19/20,    batch: 96/2993    Discriminator_loss: 0.013742540031671524  Generator_loss: 4.523810863494873\n",
            "epoch: 19/20,    batch: 97/2993    Discriminator_loss: 0.007545072119683027  Generator_loss: 5.129510879516602\n",
            "epoch: 19/20,    batch: 98/2993    Discriminator_loss: 0.009509265422821045  Generator_loss: 4.872100830078125\n",
            "epoch: 19/20,    batch: 99/2993    Discriminator_loss: 0.010329140350222588  Generator_loss: 4.85111665725708\n",
            "epoch: 19/20,    batch: 100/2993    Discriminator_loss: 0.009089521132409573  Generator_loss: 4.996914863586426\n",
            "epoch: 19/20,    batch: 101/2993    Discriminator_loss: 0.007714440580457449  Generator_loss: 5.148015975952148\n",
            "epoch: 19/20,    batch: 102/2993    Discriminator_loss: 0.006650834809988737  Generator_loss: 5.298602104187012\n",
            "epoch: 19/20,    batch: 103/2993    Discriminator_loss: 0.005733807571232319  Generator_loss: 5.43426513671875\n",
            "epoch: 19/20,    batch: 104/2993    Discriminator_loss: 0.004887203220278025  Generator_loss: 5.593916893005371\n",
            "epoch: 19/20,    batch: 105/2993    Discriminator_loss: 0.004216868430376053  Generator_loss: 5.694983959197998\n",
            "epoch: 19/20,    batch: 106/2993    Discriminator_loss: 0.0037252444308251143  Generator_loss: 5.806902885437012\n",
            "epoch: 19/20,    batch: 107/2993    Discriminator_loss: 0.0034583124797791243  Generator_loss: 5.875578880310059\n",
            "epoch: 19/20,    batch: 108/2993    Discriminator_loss: 0.0031333768274635077  Generator_loss: 5.940343856811523\n",
            "epoch: 19/20,    batch: 109/2993    Discriminator_loss: 0.0029792918357998133  Generator_loss: 5.987696170806885\n",
            "epoch: 19/20,    batch: 110/2993    Discriminator_loss: 0.0028903952334076166  Generator_loss: 6.017335891723633\n",
            "epoch: 19/20,    batch: 111/2993    Discriminator_loss: 0.0027747307904064655  Generator_loss: 6.026544570922852\n",
            "epoch: 19/20,    batch: 112/2993    Discriminator_loss: 0.0028372900560498238  Generator_loss: 6.015774726867676\n",
            "epoch: 19/20,    batch: 113/2993    Discriminator_loss: 0.00298827001824975  Generator_loss: 5.972412109375\n",
            "epoch: 19/20,    batch: 114/2993    Discriminator_loss: 0.0031866924837231636  Generator_loss: 5.886335372924805\n",
            "epoch: 19/20,    batch: 115/2993    Discriminator_loss: 0.003503344254568219  Generator_loss: 5.792745590209961\n",
            "epoch: 19/20,    batch: 116/2993    Discriminator_loss: 0.003673374420031905  Generator_loss: 5.753167152404785\n",
            "epoch: 19/20,    batch: 117/2993    Discriminator_loss: 0.003767030779272318  Generator_loss: 5.710693359375\n",
            "epoch: 19/20,    batch: 118/2993    Discriminator_loss: 0.003918888512998819  Generator_loss: 5.6821184158325195\n",
            "epoch: 19/20,    batch: 119/2993    Discriminator_loss: 0.00398997263982892  Generator_loss: 5.66844367980957\n",
            "epoch: 19/20,    batch: 120/2993    Discriminator_loss: 0.003983900882303715  Generator_loss: 5.6578369140625\n",
            "epoch: 19/20,    batch: 121/2993    Discriminator_loss: 0.004027627408504486  Generator_loss: 5.654628753662109\n",
            "epoch: 19/20,    batch: 122/2993    Discriminator_loss: 0.003945568576455116  Generator_loss: 5.659613609313965\n",
            "epoch: 19/20,    batch: 123/2993    Discriminator_loss: 0.0039021458942443132  Generator_loss: 5.672895431518555\n",
            "epoch: 19/20,    batch: 124/2993    Discriminator_loss: 0.003987429663538933  Generator_loss: 5.694073677062988\n",
            "epoch: 19/20,    batch: 125/2993    Discriminator_loss: 0.003746575443074107  Generator_loss: 5.7201642990112305\n",
            "epoch: 19/20,    batch: 126/2993    Discriminator_loss: 0.0035897893831133842  Generator_loss: 5.748940467834473\n",
            "epoch: 19/20,    batch: 127/2993    Discriminator_loss: 0.0035650429781526327  Generator_loss: 5.777473449707031\n",
            "epoch: 19/20,    batch: 128/2993    Discriminator_loss: 0.0034130874555557966  Generator_loss: 5.8021111488342285\n",
            "epoch: 19/20,    batch: 129/2993    Discriminator_loss: 0.0032969217281788588  Generator_loss: 5.820397853851318\n",
            "epoch: 19/20,    batch: 130/2993    Discriminator_loss: 0.0032810696866363287  Generator_loss: 5.831510543823242\n",
            "epoch: 19/20,    batch: 131/2993    Discriminator_loss: 0.0033209617249667645  Generator_loss: 5.8364105224609375\n",
            "epoch: 19/20,    batch: 132/2993    Discriminator_loss: 0.003202604129910469  Generator_loss: 5.837283134460449\n",
            "epoch: 19/20,    batch: 133/2993    Discriminator_loss: 0.0032567004673182964  Generator_loss: 5.835207462310791\n",
            "epoch: 19/20,    batch: 134/2993    Discriminator_loss: 0.0032875582110136747  Generator_loss: 5.832429885864258\n",
            "epoch: 19/20,    batch: 135/2993    Discriminator_loss: 0.003201670479029417  Generator_loss: 5.830125331878662\n",
            "epoch: 19/20,    batch: 136/2993    Discriminator_loss: 0.0032348164822906256  Generator_loss: 5.829513072967529\n",
            "epoch: 19/20,    batch: 137/2993    Discriminator_loss: 0.0033088873606175184  Generator_loss: 5.831364631652832\n",
            "epoch: 19/20,    batch: 138/2993    Discriminator_loss: 0.0031722597777843475  Generator_loss: 5.836427211761475\n",
            "epoch: 19/20,    batch: 139/2993    Discriminator_loss: 0.003244604216888547  Generator_loss: 5.845210075378418\n",
            "epoch: 19/20,    batch: 140/2993    Discriminator_loss: 0.003223014995455742  Generator_loss: 5.857542991638184\n",
            "epoch: 19/20,    batch: 141/2993    Discriminator_loss: 0.003078976646065712  Generator_loss: 5.873526573181152\n",
            "epoch: 19/20,    batch: 142/2993    Discriminator_loss: 0.0031963044311851263  Generator_loss: 5.892573356628418\n",
            "epoch: 19/20,    batch: 143/2993    Discriminator_loss: 0.0029804480727761984  Generator_loss: 5.913886070251465\n",
            "epoch: 19/20,    batch: 144/2993    Discriminator_loss: 0.0028447359800338745  Generator_loss: 5.935854434967041\n",
            "epoch: 19/20,    batch: 145/2993    Discriminator_loss: 0.003927831072360277  Generator_loss: 5.9537458419799805\n",
            "epoch: 19/20,    batch: 146/2993    Discriminator_loss: 0.0027784323319792747  Generator_loss: 5.971358299255371\n",
            "epoch: 19/20,    batch: 147/2993    Discriminator_loss: 0.0026811384595930576  Generator_loss: 5.987293243408203\n",
            "epoch: 19/20,    batch: 148/2993    Discriminator_loss: 0.002703438512980938  Generator_loss: 6.0006513595581055\n",
            "epoch: 19/20,    batch: 149/2993    Discriminator_loss: 0.0027195080183446407  Generator_loss: 6.011404514312744\n",
            "epoch: 19/20,    batch: 150/2993    Discriminator_loss: 0.0025875037536025047  Generator_loss: 6.0186076164245605\n",
            "epoch: 19/20,    batch: 151/2993    Discriminator_loss: 0.0026334142312407494  Generator_loss: 6.022567272186279\n",
            "epoch: 19/20,    batch: 152/2993    Discriminator_loss: 0.002592789940536022  Generator_loss: 6.024534225463867\n",
            "epoch: 19/20,    batch: 153/2993    Discriminator_loss: 0.002576724160462618  Generator_loss: 6.025108337402344\n",
            "epoch: 19/20,    batch: 154/2993    Discriminator_loss: 0.002582414075732231  Generator_loss: 6.025453090667725\n",
            "epoch: 19/20,    batch: 155/2993    Discriminator_loss: 0.0026228453498333693  Generator_loss: 6.027832508087158\n",
            "epoch: 19/20,    batch: 156/2993    Discriminator_loss: 0.0025740948040038347  Generator_loss: 6.03303861618042\n",
            "epoch: 19/20,    batch: 157/2993    Discriminator_loss: 0.002591049298644066  Generator_loss: 6.042172431945801\n",
            "epoch: 19/20,    batch: 158/2993    Discriminator_loss: 0.0025444997008889914  Generator_loss: 6.05558967590332\n",
            "epoch: 19/20,    batch: 159/2993    Discriminator_loss: 0.00246995547786355  Generator_loss: 6.07320499420166\n",
            "epoch: 19/20,    batch: 160/2993    Discriminator_loss: 0.0025016784202307463  Generator_loss: 6.094317436218262\n",
            "epoch: 19/20,    batch: 161/2993    Discriminator_loss: 0.002391340211033821  Generator_loss: 6.1178483963012695\n",
            "epoch: 19/20,    batch: 162/2993    Discriminator_loss: 0.0022584600374102592  Generator_loss: 6.143196105957031\n",
            "epoch: 19/20,    batch: 163/2993    Discriminator_loss: 0.002350206021219492  Generator_loss: 6.169371604919434\n",
            "epoch: 19/20,    batch: 164/2993    Discriminator_loss: 0.005887149833142757  Generator_loss: 6.1953325271606445\n",
            "epoch: 19/20,    batch: 165/2993    Discriminator_loss: 0.0020807951223105192  Generator_loss: 6.220921993255615\n",
            "epoch: 19/20,    batch: 166/2993    Discriminator_loss: 0.002074191579595208  Generator_loss: 6.245449542999268\n",
            "epoch: 19/20,    batch: 167/2993    Discriminator_loss: 0.0020274408161640167  Generator_loss: 6.2687883377075195\n",
            "epoch: 19/20,    batch: 168/2993    Discriminator_loss: 0.0019840847235172987  Generator_loss: 6.29066801071167\n",
            "epoch: 19/20,    batch: 169/2993    Discriminator_loss: 0.0019130379660055041  Generator_loss: 6.311249732971191\n",
            "epoch: 19/20,    batch: 170/2993    Discriminator_loss: 0.002265666611492634  Generator_loss: 6.331002235412598\n",
            "epoch: 19/20,    batch: 171/2993    Discriminator_loss: 0.0024081491865217686  Generator_loss: 6.349936485290527\n",
            "epoch: 19/20,    batch: 172/2993    Discriminator_loss: 0.001812275848351419  Generator_loss: 6.368574619293213\n",
            "epoch: 19/20,    batch: 173/2993    Discriminator_loss: 0.27515414357185364  Generator_loss: 5.9112443923950195\n",
            "epoch: 19/20,    batch: 174/2993    Discriminator_loss: 0.0034047530498355627  Generator_loss: 5.580173492431641\n",
            "epoch: 19/20,    batch: 175/2993    Discriminator_loss: 0.004411851987242699  Generator_loss: 5.339212417602539\n",
            "epoch: 19/20,    batch: 176/2993    Discriminator_loss: 0.005454246420413256  Generator_loss: 5.169338226318359\n",
            "epoch: 19/20,    batch: 177/2993    Discriminator_loss: 0.006295816041529179  Generator_loss: 5.058298110961914\n",
            "epoch: 19/20,    batch: 178/2993    Discriminator_loss: 0.0067908382043242455  Generator_loss: 4.996764183044434\n",
            "epoch: 19/20,    batch: 179/2993    Discriminator_loss: 0.0071043954230844975  Generator_loss: 4.976181983947754\n",
            "epoch: 19/20,    batch: 180/2993    Discriminator_loss: 0.0072061894461512566  Generator_loss: 4.989043712615967\n",
            "epoch: 19/20,    batch: 181/2993    Discriminator_loss: 0.006938314996659756  Generator_loss: 5.028042793273926\n",
            "epoch: 19/20,    batch: 182/2993    Discriminator_loss: 0.006917648017406464  Generator_loss: 5.086443901062012\n",
            "epoch: 19/20,    batch: 183/2993    Discriminator_loss: 0.0062369792722165585  Generator_loss: 5.1583638191223145\n",
            "epoch: 19/20,    batch: 184/2993    Discriminator_loss: 0.005741337314248085  Generator_loss: 5.238837242126465\n",
            "epoch: 19/20,    batch: 185/2993    Discriminator_loss: 0.005346914753317833  Generator_loss: 5.323602676391602\n",
            "epoch: 19/20,    batch: 186/2993    Discriminator_loss: 0.00488690473139286  Generator_loss: 5.409168720245361\n",
            "epoch: 19/20,    batch: 187/2993    Discriminator_loss: 0.004461742006242275  Generator_loss: 5.493225574493408\n",
            "epoch: 19/20,    batch: 188/2993    Discriminator_loss: 0.004150575026869774  Generator_loss: 5.573538780212402\n",
            "epoch: 19/20,    batch: 189/2993    Discriminator_loss: 0.003797843586653471  Generator_loss: 5.649165153503418\n",
            "epoch: 19/20,    batch: 190/2993    Discriminator_loss: 0.0035387391690164804  Generator_loss: 5.718745231628418\n",
            "epoch: 19/20,    batch: 191/2993    Discriminator_loss: 0.0033638901077210903  Generator_loss: 5.782329559326172\n",
            "epoch: 19/20,    batch: 192/2993    Discriminator_loss: 0.003143168753013015  Generator_loss: 5.839590072631836\n",
            "epoch: 19/20,    batch: 193/2993    Discriminator_loss: 0.0029502613469958305  Generator_loss: 5.891378402709961\n",
            "epoch: 19/20,    batch: 194/2993    Discriminator_loss: 0.0028399741277098656  Generator_loss: 5.93709659576416\n",
            "epoch: 19/20,    batch: 195/2993    Discriminator_loss: 0.0027513676322996616  Generator_loss: 5.978254318237305\n",
            "epoch: 19/20,    batch: 196/2993    Discriminator_loss: 0.0025934239383786917  Generator_loss: 6.01561164855957\n",
            "epoch: 19/20,    batch: 197/2993    Discriminator_loss: 0.0025325336027890444  Generator_loss: 6.049861907958984\n",
            "epoch: 19/20,    batch: 198/2993    Discriminator_loss: 0.002631961368024349  Generator_loss: 6.082151412963867\n",
            "epoch: 19/20,    batch: 199/2993    Discriminator_loss: 0.002338806865736842  Generator_loss: 6.113157272338867\n",
            "epoch: 19/20,    batch: 200/2993    Discriminator_loss: 0.002271568402647972  Generator_loss: 6.143377780914307\n",
            "epoch: 19/20,    batch: 201/2993    Discriminator_loss: 0.002220176625996828  Generator_loss: 6.173478603363037\n",
            "epoch: 19/20,    batch: 202/2993    Discriminator_loss: 0.002167378319427371  Generator_loss: 6.20332670211792\n",
            "epoch: 19/20,    batch: 203/2993    Discriminator_loss: 0.002066840883344412  Generator_loss: 6.232848644256592\n",
            "epoch: 19/20,    batch: 204/2993    Discriminator_loss: 0.0031757743563503027  Generator_loss: 6.257773399353027\n",
            "epoch: 19/20,    batch: 205/2993    Discriminator_loss: 0.0020009432919323444  Generator_loss: 6.282212257385254\n",
            "epoch: 19/20,    batch: 206/2993    Discriminator_loss: 0.0019002370536327362  Generator_loss: 6.305634498596191\n",
            "epoch: 19/20,    batch: 207/2993    Discriminator_loss: 0.0025700361002236605  Generator_loss: 6.326092720031738\n",
            "epoch: 19/20,    batch: 208/2993    Discriminator_loss: 0.0019278849940747023  Generator_loss: 6.345183372497559\n",
            "epoch: 19/20,    batch: 209/2993    Discriminator_loss: 0.0019410713575780392  Generator_loss: 6.36287260055542\n",
            "epoch: 19/20,    batch: 210/2993    Discriminator_loss: 0.0017740152543410659  Generator_loss: 6.379484176635742\n",
            "epoch: 19/20,    batch: 211/2993    Discriminator_loss: 0.02045421488583088  Generator_loss: 6.3253326416015625\n",
            "epoch: 19/20,    batch: 212/2993    Discriminator_loss: 0.001908210339024663  Generator_loss: 6.284048557281494\n",
            "epoch: 19/20,    batch: 213/2993    Discriminator_loss: 0.0019555867183953524  Generator_loss: 6.254271030426025\n",
            "epoch: 19/20,    batch: 214/2993    Discriminator_loss: 0.0020320189651101828  Generator_loss: 6.234673500061035\n",
            "epoch: 19/20,    batch: 215/2993    Discriminator_loss: 0.0020330073311924934  Generator_loss: 6.223686695098877\n",
            "epoch: 19/20,    batch: 216/2993    Discriminator_loss: 0.0020555274095386267  Generator_loss: 6.2201690673828125\n",
            "epoch: 19/20,    batch: 217/2993    Discriminator_loss: 0.002065233187749982  Generator_loss: 6.2229204177856445\n",
            "epoch: 19/20,    batch: 218/2993    Discriminator_loss: 0.0020616259425878525  Generator_loss: 6.23101806640625\n",
            "epoch: 19/20,    batch: 219/2993    Discriminator_loss: 0.0020351342391222715  Generator_loss: 6.24377965927124\n",
            "epoch: 19/20,    batch: 220/2993    Discriminator_loss: 0.0020203297026455402  Generator_loss: 6.261431694030762\n",
            "epoch: 19/20,    batch: 221/2993    Discriminator_loss: 0.0019524764502421021  Generator_loss: 6.281601905822754\n",
            "epoch: 19/20,    batch: 222/2993    Discriminator_loss: 0.0019430257380008698  Generator_loss: 6.298912525177002\n",
            "epoch: 19/20,    batch: 223/2993    Discriminator_loss: 0.0019047827227041125  Generator_loss: 6.317225456237793\n",
            "epoch: 19/20,    batch: 224/2993    Discriminator_loss: 0.0018186926608905196  Generator_loss: 6.349271774291992\n",
            "epoch: 19/20,    batch: 225/2993    Discriminator_loss: 0.001788382069207728  Generator_loss: 6.3740034103393555\n",
            "epoch: 19/20,    batch: 226/2993    Discriminator_loss: 0.0018740880768746138  Generator_loss: 6.402040958404541\n",
            "epoch: 19/20,    batch: 227/2993    Discriminator_loss: 0.0016711773350834846  Generator_loss: 6.434999465942383\n",
            "epoch: 19/20,    batch: 228/2993    Discriminator_loss: 0.0016427469672635198  Generator_loss: 6.461716175079346\n",
            "epoch: 19/20,    batch: 229/2993    Discriminator_loss: 0.0016575902700424194  Generator_loss: 6.485288143157959\n",
            "epoch: 19/20,    batch: 230/2993    Discriminator_loss: 0.0015521817840635777  Generator_loss: 6.515734672546387\n",
            "epoch: 19/20,    batch: 231/2993    Discriminator_loss: 0.0015215802704915404  Generator_loss: 6.539353370666504\n",
            "epoch: 19/20,    batch: 232/2993    Discriminator_loss: 0.0014944467693567276  Generator_loss: 6.564978122711182\n",
            "epoch: 19/20,    batch: 233/2993    Discriminator_loss: 0.0014264296041801572  Generator_loss: 6.5935139656066895\n",
            "epoch: 19/20,    batch: 234/2993    Discriminator_loss: 0.001432032324373722  Generator_loss: 6.614843368530273\n",
            "epoch: 19/20,    batch: 235/2993    Discriminator_loss: 0.0014430982992053032  Generator_loss: 6.631507873535156\n",
            "epoch: 19/20,    batch: 236/2993    Discriminator_loss: 0.0013820920139551163  Generator_loss: 6.65281867980957\n",
            "epoch: 19/20,    batch: 237/2993    Discriminator_loss: 0.001333376974798739  Generator_loss: 6.66789436340332\n",
            "epoch: 19/20,    batch: 238/2993    Discriminator_loss: 0.0013303225859999657  Generator_loss: 6.679182052612305\n",
            "epoch: 19/20,    batch: 239/2993    Discriminator_loss: 0.0013097268529236317  Generator_loss: 6.69118595123291\n",
            "epoch: 19/20,    batch: 240/2993    Discriminator_loss: 0.0012888293713331223  Generator_loss: 6.696140289306641\n",
            "epoch: 19/20,    batch: 241/2993    Discriminator_loss: 0.0013278358383104205  Generator_loss: 6.697337627410889\n",
            "epoch: 19/20,    batch: 242/2993    Discriminator_loss: 0.0013246419839560986  Generator_loss: 6.697206497192383\n",
            "epoch: 19/20,    batch: 243/2993    Discriminator_loss: 0.0013907839311286807  Generator_loss: 6.690973281860352\n",
            "epoch: 19/20,    batch: 244/2993    Discriminator_loss: 0.001371969934552908  Generator_loss: 6.6778788566589355\n",
            "epoch: 19/20,    batch: 245/2993    Discriminator_loss: 0.0013546281261369586  Generator_loss: 6.660836219787598\n",
            "epoch: 19/20,    batch: 246/2993    Discriminator_loss: 0.001408955780789256  Generator_loss: 6.635728359222412\n",
            "epoch: 19/20,    batch: 247/2993    Discriminator_loss: 0.001459016464650631  Generator_loss: 6.601045608520508\n",
            "epoch: 19/20,    batch: 248/2993    Discriminator_loss: 0.0015624284278601408  Generator_loss: 6.557830810546875\n",
            "epoch: 19/20,    batch: 249/2993    Discriminator_loss: 0.0016314135864377022  Generator_loss: 6.50420618057251\n",
            "epoch: 19/20,    batch: 250/2993    Discriminator_loss: 0.0016965821851044893  Generator_loss: 6.461153507232666\n",
            "epoch: 19/20,    batch: 251/2993    Discriminator_loss: 0.0018194939475506544  Generator_loss: 6.376499652862549\n",
            "epoch: 19/20,    batch: 252/2993    Discriminator_loss: 0.0020078683737665415  Generator_loss: 6.296823024749756\n",
            "epoch: 19/20,    batch: 253/2993    Discriminator_loss: 0.002260219305753708  Generator_loss: 6.197046279907227\n",
            "epoch: 19/20,    batch: 254/2993    Discriminator_loss: 0.0025060733314603567  Generator_loss: 6.099472999572754\n",
            "epoch: 19/20,    batch: 255/2993    Discriminator_loss: 0.0026470369193702936  Generator_loss: 6.073267936706543\n",
            "epoch: 19/20,    batch: 256/2993    Discriminator_loss: 0.0026631455402821302  Generator_loss: 6.09627628326416\n",
            "epoch: 19/20,    batch: 257/2993    Discriminator_loss: 0.002575597958639264  Generator_loss: 6.124032497406006\n",
            "epoch: 19/20,    batch: 258/2993    Discriminator_loss: 0.002618832280859351  Generator_loss: 6.16674280166626\n",
            "epoch: 19/20,    batch: 259/2993    Discriminator_loss: 0.0025808080099523067  Generator_loss: 6.2159223556518555\n",
            "epoch: 19/20,    batch: 260/2993    Discriminator_loss: 0.0022537074983119965  Generator_loss: 6.2650909423828125\n",
            "epoch: 19/20,    batch: 261/2993    Discriminator_loss: 0.002232021652162075  Generator_loss: 6.308329105377197\n",
            "epoch: 19/20,    batch: 262/2993    Discriminator_loss: 0.002179109025746584  Generator_loss: 6.341745376586914\n",
            "epoch: 19/20,    batch: 263/2993    Discriminator_loss: 0.002104109851643443  Generator_loss: 6.339254379272461\n",
            "epoch: 19/20,    batch: 264/2993    Discriminator_loss: 0.001675011357292533  Generator_loss: 6.585102558135986\n",
            "epoch: 19/20,    batch: 265/2993    Discriminator_loss: 0.0022650358732789755  Generator_loss: 6.365103721618652\n",
            "epoch: 19/20,    batch: 266/2993    Discriminator_loss: 0.0018827237654477358  Generator_loss: 6.432868003845215\n",
            "epoch: 19/20,    batch: 267/2993    Discriminator_loss: 0.0018500495934858918  Generator_loss: 6.471555709838867\n",
            "epoch: 19/20,    batch: 268/2993    Discriminator_loss: 0.0018370497273281217  Generator_loss: 6.489288330078125\n",
            "epoch: 19/20,    batch: 269/2993    Discriminator_loss: 0.0017933131894096732  Generator_loss: 6.482234477996826\n",
            "epoch: 19/20,    batch: 270/2993    Discriminator_loss: 0.0018571875989437103  Generator_loss: 6.448553085327148\n",
            "epoch: 19/20,    batch: 271/2993    Discriminator_loss: 0.002144550671800971  Generator_loss: 6.378623008728027\n",
            "epoch: 19/20,    batch: 272/2993    Discriminator_loss: 0.0019898787140846252  Generator_loss: 6.414958953857422\n",
            "epoch: 19/20,    batch: 273/2993    Discriminator_loss: 0.001897671027109027  Generator_loss: 6.469913482666016\n",
            "epoch: 19/20,    batch: 274/2993    Discriminator_loss: 0.001952730119228363  Generator_loss: 6.463104248046875\n",
            "epoch: 19/20,    batch: 275/2993    Discriminator_loss: 0.0019505296368151903  Generator_loss: 6.451015472412109\n",
            "epoch: 19/20,    batch: 276/2993    Discriminator_loss: 0.0019429591484367847  Generator_loss: 6.483784198760986\n",
            "epoch: 19/20,    batch: 277/2993    Discriminator_loss: 0.0018150309333577752  Generator_loss: 6.538496494293213\n",
            "epoch: 19/20,    batch: 278/2993    Discriminator_loss: 0.0016890005208551884  Generator_loss: 6.590197563171387\n",
            "epoch: 19/20,    batch: 279/2993    Discriminator_loss: 0.0016527031548321247  Generator_loss: 6.629292011260986\n",
            "epoch: 19/20,    batch: 280/2993    Discriminator_loss: 0.0016496195457875729  Generator_loss: 6.655572891235352\n",
            "epoch: 19/20,    batch: 281/2993    Discriminator_loss: 0.0015644602244719863  Generator_loss: 6.6814374923706055\n",
            "epoch: 19/20,    batch: 282/2993    Discriminator_loss: 0.0015366894658654928  Generator_loss: 6.709589958190918\n",
            "epoch: 19/20,    batch: 283/2993    Discriminator_loss: 0.0015138371381908655  Generator_loss: 6.743571758270264\n",
            "epoch: 19/20,    batch: 284/2993    Discriminator_loss: 0.0014086401788517833  Generator_loss: 6.786158561706543\n",
            "epoch: 19/20,    batch: 285/2993    Discriminator_loss: 0.0013457051245495677  Generator_loss: 6.837469100952148\n",
            "epoch: 19/20,    batch: 286/2993    Discriminator_loss: 0.0013350999215617776  Generator_loss: 6.896493911743164\n",
            "epoch: 19/20,    batch: 287/2993    Discriminator_loss: 0.0011780796339735389  Generator_loss: 6.9594926834106445\n",
            "epoch: 19/20,    batch: 288/2993    Discriminator_loss: 0.0011295765871182084  Generator_loss: 7.024281024932861\n",
            "epoch: 19/20,    batch: 289/2993    Discriminator_loss: 0.0010337713174521923  Generator_loss: 7.094186305999756\n",
            "epoch: 19/20,    batch: 290/2993    Discriminator_loss: 0.0009435756364837289  Generator_loss: 7.1594953536987305\n",
            "epoch: 19/20,    batch: 291/2993    Discriminator_loss: 0.000898466445505619  Generator_loss: 7.219242095947266\n",
            "epoch: 19/20,    batch: 292/2993    Discriminator_loss: 0.0009170846315100789  Generator_loss: 7.264516353607178\n",
            "epoch: 19/20,    batch: 293/2993    Discriminator_loss: 0.0007755144033581018  Generator_loss: 7.307060241699219\n",
            "epoch: 19/20,    batch: 294/2993    Discriminator_loss: 0.00084565335419029  Generator_loss: 7.337565898895264\n",
            "epoch: 19/20,    batch: 295/2993    Discriminator_loss: 0.0007856731535866857  Generator_loss: 7.357354164123535\n",
            "epoch: 19/20,    batch: 296/2993    Discriminator_loss: 0.0007077647605910897  Generator_loss: 7.370764255523682\n",
            "epoch: 19/20,    batch: 297/2993    Discriminator_loss: 0.003625079058110714  Generator_loss: 7.3063883781433105\n",
            "epoch: 19/20,    batch: 298/2993    Discriminator_loss: 0.0008168488857336342  Generator_loss: 7.255772113800049\n",
            "epoch: 19/20,    batch: 299/2993    Discriminator_loss: 0.000845222850330174  Generator_loss: 7.216518878936768\n",
            "epoch: 19/20,    batch: 300/2993    Discriminator_loss: 0.0008238303125835955  Generator_loss: 7.185615539550781\n",
            "epoch: 19/20,    batch: 301/2993    Discriminator_loss: 0.0016954598249867558  Generator_loss: 7.136270999908447\n",
            "epoch: 19/20,    batch: 302/2993    Discriminator_loss: 0.000976080889813602  Generator_loss: 7.095752239227295\n",
            "epoch: 19/20,    batch: 303/2993    Discriminator_loss: 0.0009314080816693604  Generator_loss: 7.062378883361816\n",
            "epoch: 19/20,    batch: 304/2993    Discriminator_loss: 0.000990625936537981  Generator_loss: 7.03466796875\n",
            "epoch: 19/20,    batch: 305/2993    Discriminator_loss: 0.0010567564750090241  Generator_loss: 7.013332366943359\n",
            "epoch: 19/20,    batch: 306/2993    Discriminator_loss: 0.0010378900915384293  Generator_loss: 6.997575283050537\n",
            "epoch: 19/20,    batch: 307/2993    Discriminator_loss: 0.0010282016592100263  Generator_loss: 6.988278388977051\n",
            "epoch: 19/20,    batch: 308/2993    Discriminator_loss: 0.0010739455465227365  Generator_loss: 6.985410690307617\n",
            "epoch: 19/20,    batch: 309/2993    Discriminator_loss: 0.0011182894231751561  Generator_loss: 6.989206790924072\n",
            "epoch: 19/20,    batch: 310/2993    Discriminator_loss: 0.0010248643811792135  Generator_loss: 6.9994025230407715\n",
            "epoch: 19/20,    batch: 311/2993    Discriminator_loss: 0.0027256207540631294  Generator_loss: 7.0050859451293945\n",
            "epoch: 19/20,    batch: 312/2993    Discriminator_loss: 0.001053601037710905  Generator_loss: 7.015163421630859\n",
            "epoch: 19/20,    batch: 313/2993    Discriminator_loss: 0.0009934238623827696  Generator_loss: 7.025989532470703\n",
            "epoch: 19/20,    batch: 314/2993    Discriminator_loss: 0.0010916129685938358  Generator_loss: 7.036221504211426\n",
            "epoch: 19/20,    batch: 315/2993    Discriminator_loss: 0.0010972550371661782  Generator_loss: 7.043816089630127\n",
            "epoch: 19/20,    batch: 316/2993    Discriminator_loss: 0.0009644595556892455  Generator_loss: 7.048548221588135\n",
            "epoch: 19/20,    batch: 317/2993    Discriminator_loss: 0.0009979672031477094  Generator_loss: 7.050260543823242\n",
            "epoch: 19/20,    batch: 318/2993    Discriminator_loss: 0.0010322608286514878  Generator_loss: 7.0484538078308105\n",
            "epoch: 19/20,    batch: 319/2993    Discriminator_loss: 0.0009655173635110259  Generator_loss: 7.043092250823975\n",
            "epoch: 19/20,    batch: 320/2993    Discriminator_loss: 0.0010193821508437395  Generator_loss: 7.035852432250977\n",
            "epoch: 19/20,    batch: 321/2993    Discriminator_loss: 0.0009948491351678967  Generator_loss: 7.027403831481934\n",
            "epoch: 19/20,    batch: 322/2993    Discriminator_loss: 0.0010305998148396611  Generator_loss: 7.009888648986816\n",
            "epoch: 19/20,    batch: 323/2993    Discriminator_loss: 0.001044259057380259  Generator_loss: 6.993484020233154\n",
            "epoch: 19/20,    batch: 324/2993    Discriminator_loss: 0.001030607963912189  Generator_loss: 6.975874423980713\n",
            "epoch: 19/20,    batch: 325/2993    Discriminator_loss: 0.0010765709448605776  Generator_loss: 6.948919773101807\n",
            "epoch: 19/20,    batch: 326/2993    Discriminator_loss: 0.0013302897568792105  Generator_loss: 6.913783073425293\n",
            "epoch: 19/20,    batch: 327/2993    Discriminator_loss: 0.0011260171886533499  Generator_loss: 6.903067111968994\n",
            "epoch: 19/20,    batch: 328/2993    Discriminator_loss: 0.0011696720030158758  Generator_loss: 6.8525543212890625\n",
            "epoch: 19/20,    batch: 329/2993    Discriminator_loss: 0.0013576315250247717  Generator_loss: 6.826263427734375\n",
            "epoch: 19/20,    batch: 330/2993    Discriminator_loss: 0.0013043670915067196  Generator_loss: 6.770447254180908\n",
            "epoch: 19/20,    batch: 331/2993    Discriminator_loss: 0.0013248167233541608  Generator_loss: 6.7253313064575195\n",
            "epoch: 19/20,    batch: 332/2993    Discriminator_loss: 0.0019756625406444073  Generator_loss: 6.668268203735352\n",
            "epoch: 19/20,    batch: 333/2993    Discriminator_loss: 0.00166989432182163  Generator_loss: 6.616915702819824\n",
            "epoch: 19/20,    batch: 334/2993    Discriminator_loss: 0.0015518948202952743  Generator_loss: 6.55083703994751\n",
            "epoch: 19/20,    batch: 335/2993    Discriminator_loss: 0.0018370671896263957  Generator_loss: 6.446770668029785\n",
            "epoch: 19/20,    batch: 336/2993    Discriminator_loss: 0.0020251707173883915  Generator_loss: 6.341992378234863\n",
            "epoch: 19/20,    batch: 337/2993    Discriminator_loss: 0.002497718669474125  Generator_loss: 6.1056623458862305\n",
            "epoch: 19/20,    batch: 338/2993    Discriminator_loss: 0.003918944858014584  Generator_loss: 5.723295211791992\n",
            "epoch: 19/20,    batch: 339/2993    Discriminator_loss: 0.014116058126091957  Generator_loss: 5.398989677429199\n",
            "epoch: 19/20,    batch: 340/2993    Discriminator_loss: 0.10639938712120056  Generator_loss: 9.465075492858887\n",
            "epoch: 19/20,    batch: 341/2993    Discriminator_loss: 0.00826724711805582  Generator_loss: 13.119861602783203\n",
            "epoch: 19/20,    batch: 342/2993    Discriminator_loss: 0.00019686712766997516  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 343/2993    Discriminator_loss: 4.153738700551912e-06  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 344/2993    Discriminator_loss: 0.00406348193064332  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 345/2993    Discriminator_loss: 5.094982770970091e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 346/2993    Discriminator_loss: 3.073376319662202e-06  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 347/2993    Discriminator_loss: 0.03981740027666092  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 348/2993    Discriminator_loss: 5.425926792668179e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 349/2993    Discriminator_loss: 1.2042194612149615e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 350/2993    Discriminator_loss: 0.0003444963658694178  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 351/2993    Discriminator_loss: 2.8628801373997703e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 352/2993    Discriminator_loss: 0.00018425076268613338  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 353/2993    Discriminator_loss: 0.04653315618634224  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 354/2993    Discriminator_loss: 8.09715402283473e-06  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 355/2993    Discriminator_loss: 0.07861623913049698  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 356/2993    Discriminator_loss: 7.80784321250394e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 357/2993    Discriminator_loss: 2.6077200345753226e-06  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 358/2993    Discriminator_loss: 0.0003343953867442906  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 359/2993    Discriminator_loss: 0.000646604981739074  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 360/2993    Discriminator_loss: 7.580982810395653e-07  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 361/2993    Discriminator_loss: 1.163370966911316  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 362/2993    Discriminator_loss: 0.00019804740441031754  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 363/2993    Discriminator_loss: 2.1314486730261706e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 364/2993    Discriminator_loss: 5.9027730458183214e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 365/2993    Discriminator_loss: 6.689877045573667e-05  Generator_loss: 14.597209930419922\n",
            "epoch: 19/20,    batch: 366/2993    Discriminator_loss: 6.09041380812414e-05  Generator_loss: 13.891820907592773\n",
            "epoch: 19/20,    batch: 367/2993    Discriminator_loss: 1.647901262913365e-05  Generator_loss: 13.245135307312012\n",
            "epoch: 19/20,    batch: 368/2993    Discriminator_loss: 0.004942707717418671  Generator_loss: 12.615952491760254\n",
            "epoch: 19/20,    batch: 369/2993    Discriminator_loss: 0.00018175644800066948  Generator_loss: 11.994245529174805\n",
            "epoch: 19/20,    batch: 370/2993    Discriminator_loss: 2.6025192710221745e-05  Generator_loss: 11.433298110961914\n",
            "epoch: 19/20,    batch: 371/2993    Discriminator_loss: 0.0004191022308077663  Generator_loss: 10.965259552001953\n",
            "epoch: 19/20,    batch: 372/2993    Discriminator_loss: 0.0002536195679567754  Generator_loss: 10.585676193237305\n",
            "epoch: 19/20,    batch: 373/2993    Discriminator_loss: 7.043808000162244e-05  Generator_loss: 10.283355712890625\n",
            "epoch: 19/20,    batch: 374/2993    Discriminator_loss: 0.00022913055727258325  Generator_loss: 10.042673110961914\n",
            "epoch: 19/20,    batch: 375/2993    Discriminator_loss: 0.0003143216308671981  Generator_loss: 9.846290588378906\n",
            "epoch: 19/20,    batch: 376/2993    Discriminator_loss: 7.117203494999558e-05  Generator_loss: 9.680724143981934\n",
            "epoch: 19/20,    batch: 377/2993    Discriminator_loss: 0.00010458349424879998  Generator_loss: 9.53571891784668\n",
            "epoch: 19/20,    batch: 378/2993    Discriminator_loss: 0.00010923537047347054  Generator_loss: 9.40493106842041\n",
            "epoch: 19/20,    batch: 379/2993    Discriminator_loss: 0.00010075478348881006  Generator_loss: 9.284059524536133\n",
            "epoch: 19/20,    batch: 380/2993    Discriminator_loss: 0.00013105993275530636  Generator_loss: 9.169703483581543\n",
            "epoch: 19/20,    batch: 381/2993    Discriminator_loss: 0.0001508616260252893  Generator_loss: 9.061042785644531\n",
            "epoch: 19/20,    batch: 382/2993    Discriminator_loss: 0.00017076643416658044  Generator_loss: 8.956632614135742\n",
            "epoch: 19/20,    batch: 383/2993    Discriminator_loss: 0.00018440603162162006  Generator_loss: 8.856069564819336\n",
            "epoch: 19/20,    batch: 384/2993    Discriminator_loss: 0.0001652048813411966  Generator_loss: 8.759134292602539\n",
            "epoch: 19/20,    batch: 385/2993    Discriminator_loss: 0.00019322913431096822  Generator_loss: 8.66524887084961\n",
            "epoch: 19/20,    batch: 386/2993    Discriminator_loss: 0.00022937812900636345  Generator_loss: 8.574442863464355\n",
            "epoch: 19/20,    batch: 387/2993    Discriminator_loss: 0.0002113478840328753  Generator_loss: 8.485175132751465\n",
            "epoch: 19/20,    batch: 388/2993    Discriminator_loss: 0.0002611135132610798  Generator_loss: 8.39732837677002\n",
            "epoch: 19/20,    batch: 389/2993    Discriminator_loss: 0.00031163060339167714  Generator_loss: 8.31003189086914\n",
            "epoch: 19/20,    batch: 390/2993    Discriminator_loss: 0.00027593495906330645  Generator_loss: 8.223230361938477\n",
            "epoch: 19/20,    batch: 391/2993    Discriminator_loss: 0.0003171251155436039  Generator_loss: 8.136491775512695\n",
            "epoch: 19/20,    batch: 392/2993    Discriminator_loss: 0.0005654235137626529  Generator_loss: 8.049959182739258\n",
            "epoch: 19/20,    batch: 393/2993    Discriminator_loss: 0.00035061995731666684  Generator_loss: 7.963315963745117\n",
            "epoch: 19/20,    batch: 394/2993    Discriminator_loss: 0.0004577200161293149  Generator_loss: 7.877161026000977\n",
            "epoch: 19/20,    batch: 395/2993    Discriminator_loss: 0.0004805391654372215  Generator_loss: 7.792261600494385\n",
            "epoch: 19/20,    batch: 396/2993    Discriminator_loss: 0.00045414172927848995  Generator_loss: 7.708584785461426\n",
            "epoch: 19/20,    batch: 397/2993    Discriminator_loss: 0.0005279886536300182  Generator_loss: 7.626743793487549\n",
            "epoch: 19/20,    batch: 398/2993    Discriminator_loss: 0.0006112174596637487  Generator_loss: 7.5469512939453125\n",
            "epoch: 19/20,    batch: 399/2993    Discriminator_loss: 0.0006060983869247139  Generator_loss: 7.468883514404297\n",
            "epoch: 19/20,    batch: 400/2993    Discriminator_loss: 0.0006376656820066273  Generator_loss: 7.392810344696045\n",
            "epoch: 19/20,    batch: 401/2993    Discriminator_loss: 0.0007213568314909935  Generator_loss: 7.318605422973633\n",
            "epoch: 19/20,    batch: 402/2993    Discriminator_loss: 0.0007420402253046632  Generator_loss: 7.245975017547607\n",
            "epoch: 19/20,    batch: 403/2993    Discriminator_loss: 0.0007859712932258844  Generator_loss: 7.175811767578125\n",
            "epoch: 19/20,    batch: 404/2993    Discriminator_loss: 0.0008874025079421699  Generator_loss: 7.107448577880859\n",
            "epoch: 19/20,    batch: 405/2993    Discriminator_loss: 0.0009359512478113174  Generator_loss: 7.0416154861450195\n",
            "epoch: 19/20,    batch: 406/2993    Discriminator_loss: 0.0009472490637563169  Generator_loss: 6.9786696434021\n",
            "epoch: 19/20,    batch: 407/2993    Discriminator_loss: 0.0042795827612280846  Generator_loss: 6.91733455657959\n",
            "epoch: 19/20,    batch: 408/2993    Discriminator_loss: 0.0010922838700935245  Generator_loss: 6.860203742980957\n",
            "epoch: 19/20,    batch: 409/2993    Discriminator_loss: 0.0011227037757635117  Generator_loss: 6.80698299407959\n",
            "epoch: 19/20,    batch: 410/2993    Discriminator_loss: 0.0012003651354461908  Generator_loss: 6.757950305938721\n",
            "epoch: 19/20,    batch: 411/2993    Discriminator_loss: 0.0012557038571685553  Generator_loss: 6.713186740875244\n",
            "epoch: 19/20,    batch: 412/2993    Discriminator_loss: 0.0013147959252819419  Generator_loss: 6.672142028808594\n",
            "epoch: 19/20,    batch: 413/2993    Discriminator_loss: 0.001392401522025466  Generator_loss: 6.634641170501709\n",
            "epoch: 19/20,    batch: 414/2993    Discriminator_loss: 0.0013807963114231825  Generator_loss: 6.600257873535156\n",
            "epoch: 19/20,    batch: 415/2993    Discriminator_loss: 0.15363003313541412  Generator_loss: 6.482963562011719\n",
            "epoch: 19/20,    batch: 416/2993    Discriminator_loss: 0.0017270883545279503  Generator_loss: 6.385474681854248\n",
            "epoch: 19/20,    batch: 417/2993    Discriminator_loss: 0.0018084546318277717  Generator_loss: 6.304633140563965\n",
            "epoch: 19/20,    batch: 418/2993    Discriminator_loss: 0.0019690494518727064  Generator_loss: 6.237726211547852\n",
            "epoch: 19/20,    batch: 419/2993    Discriminator_loss: 0.0021108377259224653  Generator_loss: 6.182044982910156\n",
            "epoch: 19/20,    batch: 420/2993    Discriminator_loss: 0.002175520174205303  Generator_loss: 6.135956287384033\n",
            "epoch: 19/20,    batch: 421/2993    Discriminator_loss: 0.002317493548616767  Generator_loss: 6.098384380340576\n",
            "epoch: 19/20,    batch: 422/2993    Discriminator_loss: 0.0023761363700032234  Generator_loss: 6.0676116943359375\n",
            "epoch: 19/20,    batch: 423/2993    Discriminator_loss: 0.0024098230060189962  Generator_loss: 6.042749404907227\n",
            "epoch: 19/20,    batch: 424/2993    Discriminator_loss: 0.002476154128089547  Generator_loss: 6.022701740264893\n",
            "epoch: 19/20,    batch: 425/2993    Discriminator_loss: 0.002611336763948202  Generator_loss: 6.006146430969238\n",
            "epoch: 19/20,    batch: 426/2993    Discriminator_loss: 0.0025390710216015577  Generator_loss: 5.993142127990723\n",
            "epoch: 19/20,    batch: 427/2993    Discriminator_loss: 0.0027670918498188257  Generator_loss: 5.982269763946533\n",
            "epoch: 19/20,    batch: 428/2993    Discriminator_loss: 0.0027687738183885813  Generator_loss: 5.973330020904541\n",
            "epoch: 19/20,    batch: 429/2993    Discriminator_loss: 0.00265033938921988  Generator_loss: 5.965571403503418\n",
            "epoch: 19/20,    batch: 430/2993    Discriminator_loss: 0.002646057400852442  Generator_loss: 5.958813190460205\n",
            "epoch: 19/20,    batch: 431/2993    Discriminator_loss: 0.0027766854036599398  Generator_loss: 5.952189922332764\n",
            "epoch: 19/20,    batch: 432/2993    Discriminator_loss: 0.0027969167567789555  Generator_loss: 5.945634841918945\n",
            "epoch: 19/20,    batch: 433/2993    Discriminator_loss: 0.0027119775768369436  Generator_loss: 5.939973831176758\n",
            "epoch: 19/20,    batch: 434/2993    Discriminator_loss: 1.1558008193969727  Generator_loss: 5.520997524261475\n",
            "epoch: 19/20,    batch: 435/2993    Discriminator_loss: 0.004955839831382036  Generator_loss: 5.203726291656494\n",
            "epoch: 19/20,    batch: 436/2993    Discriminator_loss: 0.0064893849194049835  Generator_loss: 4.959572792053223\n",
            "epoch: 19/20,    batch: 437/2993    Discriminator_loss: 0.0081886425614357  Generator_loss: 4.774547576904297\n",
            "epoch: 19/20,    batch: 438/2993    Discriminator_loss: 0.009779508225619793  Generator_loss: 4.64141845703125\n",
            "epoch: 19/20,    batch: 439/2993    Discriminator_loss: 0.010601230897009373  Generator_loss: 4.553837776184082\n",
            "epoch: 19/20,    batch: 440/2993    Discriminator_loss: 0.011313052847981453  Generator_loss: 4.507747650146484\n",
            "epoch: 19/20,    batch: 441/2993    Discriminator_loss: 0.01154973916709423  Generator_loss: 4.506722450256348\n",
            "epoch: 19/20,    batch: 442/2993    Discriminator_loss: 0.01141869556158781  Generator_loss: 4.54166841506958\n",
            "epoch: 19/20,    batch: 443/2993    Discriminator_loss: 0.010831712745130062  Generator_loss: 4.595754623413086\n",
            "epoch: 19/20,    batch: 444/2993    Discriminator_loss: 0.010225852951407433  Generator_loss: 4.661807060241699\n",
            "epoch: 19/20,    batch: 445/2993    Discriminator_loss: 0.009580274112522602  Generator_loss: 4.734052658081055\n",
            "epoch: 19/20,    batch: 446/2993    Discriminator_loss: 0.008831538259983063  Generator_loss: 4.809161186218262\n",
            "epoch: 19/20,    batch: 447/2993    Discriminator_loss: 0.008236355148255825  Generator_loss: 4.884990692138672\n",
            "epoch: 19/20,    batch: 448/2993    Discriminator_loss: 0.007700610905885696  Generator_loss: 4.960247993469238\n",
            "epoch: 19/20,    batch: 449/2993    Discriminator_loss: 0.007000964600592852  Generator_loss: 5.032810211181641\n",
            "epoch: 19/20,    batch: 450/2993    Discriminator_loss: 0.006544815376400948  Generator_loss: 5.102128505706787\n",
            "epoch: 19/20,    batch: 451/2993    Discriminator_loss: 0.00620795926079154  Generator_loss: 5.167703628540039\n",
            "epoch: 19/20,    batch: 452/2993    Discriminator_loss: 0.005691433325409889  Generator_loss: 5.229162216186523\n",
            "epoch: 19/20,    batch: 453/2993    Discriminator_loss: 0.005410917103290558  Generator_loss: 5.286668300628662\n",
            "epoch: 19/20,    batch: 454/2993    Discriminator_loss: 0.005121402908116579  Generator_loss: 5.340343475341797\n",
            "epoch: 19/20,    batch: 455/2993    Discriminator_loss: 0.004803743213415146  Generator_loss: 5.390058517456055\n",
            "epoch: 19/20,    batch: 456/2993    Discriminator_loss: 0.004615542944520712  Generator_loss: 5.435629844665527\n",
            "epoch: 19/20,    batch: 457/2993    Discriminator_loss: 0.004435841925442219  Generator_loss: 5.477200508117676\n",
            "epoch: 19/20,    batch: 458/2993    Discriminator_loss: 0.004231832921504974  Generator_loss: 5.514575958251953\n",
            "epoch: 19/20,    batch: 459/2993    Discriminator_loss: 0.004309138283133507  Generator_loss: 5.547600746154785\n",
            "epoch: 19/20,    batch: 460/2993    Discriminator_loss: 0.004029539879411459  Generator_loss: 5.576530456542969\n",
            "epoch: 19/20,    batch: 461/2993    Discriminator_loss: 0.0038503590039908886  Generator_loss: 5.601418495178223\n",
            "epoch: 19/20,    batch: 462/2993    Discriminator_loss: 0.0037870421074330807  Generator_loss: 5.622516632080078\n",
            "epoch: 19/20,    batch: 463/2993    Discriminator_loss: 0.0038978622760623693  Generator_loss: 5.640419960021973\n",
            "epoch: 19/20,    batch: 464/2993    Discriminator_loss: 0.0036213009152561426  Generator_loss: 5.655842304229736\n",
            "epoch: 19/20,    batch: 465/2993    Discriminator_loss: 0.003600836033001542  Generator_loss: 5.669227600097656\n",
            "epoch: 19/20,    batch: 466/2993    Discriminator_loss: 0.003686264157295227  Generator_loss: 5.681441307067871\n",
            "epoch: 19/20,    batch: 467/2993    Discriminator_loss: 0.003505455097183585  Generator_loss: 5.69318962097168\n",
            "epoch: 19/20,    batch: 468/2993    Discriminator_loss: 0.0034411479718983173  Generator_loss: 5.705056190490723\n",
            "epoch: 19/20,    batch: 469/2993    Discriminator_loss: 0.0034030729439109564  Generator_loss: 5.717667102813721\n",
            "epoch: 19/20,    batch: 470/2993    Discriminator_loss: 0.003470960073173046  Generator_loss: 5.730835437774658\n",
            "epoch: 19/20,    batch: 471/2993    Discriminator_loss: 0.0032926397398114204  Generator_loss: 5.744904518127441\n",
            "epoch: 19/20,    batch: 472/2993    Discriminator_loss: 0.0032620460260659456  Generator_loss: 5.759398937225342\n",
            "epoch: 19/20,    batch: 473/2993    Discriminator_loss: 0.0032735804561525583  Generator_loss: 5.774198055267334\n",
            "epoch: 19/20,    batch: 474/2993    Discriminator_loss: 0.0031589719001203775  Generator_loss: 5.7887067794799805\n",
            "epoch: 19/20,    batch: 475/2993    Discriminator_loss: 0.00310395541600883  Generator_loss: 5.802525520324707\n",
            "epoch: 19/20,    batch: 476/2993    Discriminator_loss: 0.0031215306371450424  Generator_loss: 5.814682960510254\n",
            "epoch: 19/20,    batch: 477/2993    Discriminator_loss: 0.0031083454377949238  Generator_loss: 5.824934959411621\n",
            "epoch: 19/20,    batch: 478/2993    Discriminator_loss: 0.00301717990078032  Generator_loss: 5.832852363586426\n",
            "epoch: 19/20,    batch: 479/2993    Discriminator_loss: 0.0030832658521831036  Generator_loss: 5.837522983551025\n",
            "epoch: 19/20,    batch: 480/2993    Discriminator_loss: 0.0029893824830651283  Generator_loss: 5.839194297790527\n",
            "epoch: 19/20,    batch: 481/2993    Discriminator_loss: 0.003005414269864559  Generator_loss: 5.837230205535889\n",
            "epoch: 19/20,    batch: 482/2993    Discriminator_loss: 0.003084035823121667  Generator_loss: 5.832446098327637\n",
            "epoch: 19/20,    batch: 483/2993    Discriminator_loss: 0.0030246723908931017  Generator_loss: 5.825708389282227\n",
            "epoch: 19/20,    batch: 484/2993    Discriminator_loss: 0.003068365156650543  Generator_loss: 5.818061828613281\n",
            "epoch: 19/20,    batch: 485/2993    Discriminator_loss: 0.0031741359271109104  Generator_loss: 5.8105926513671875\n",
            "epoch: 19/20,    batch: 486/2993    Discriminator_loss: 0.0030894316732883453  Generator_loss: 5.803788661956787\n",
            "epoch: 19/20,    batch: 487/2993    Discriminator_loss: 0.0031451021786779165  Generator_loss: 5.798043727874756\n",
            "epoch: 19/20,    batch: 488/2993    Discriminator_loss: 0.0031889546662569046  Generator_loss: 5.793294429779053\n",
            "epoch: 19/20,    batch: 489/2993    Discriminator_loss: 0.003138285130262375  Generator_loss: 5.789198875427246\n",
            "epoch: 19/20,    batch: 490/2993    Discriminator_loss: 0.003213494783267379  Generator_loss: 5.785670280456543\n",
            "epoch: 19/20,    batch: 491/2993    Discriminator_loss: 0.0032384248916059732  Generator_loss: 5.782569885253906\n",
            "epoch: 19/20,    batch: 492/2993    Discriminator_loss: 0.003172997385263443  Generator_loss: 5.779843330383301\n",
            "epoch: 19/20,    batch: 493/2993    Discriminator_loss: 0.003232077695429325  Generator_loss: 5.777370929718018\n",
            "epoch: 19/20,    batch: 494/2993    Discriminator_loss: 0.003255536314100027  Generator_loss: 5.775108337402344\n",
            "epoch: 19/20,    batch: 495/2993    Discriminator_loss: 0.0031895574647933245  Generator_loss: 5.772968292236328\n",
            "epoch: 19/20,    batch: 496/2993    Discriminator_loss: 0.0032037398777902126  Generator_loss: 5.770475387573242\n",
            "epoch: 19/20,    batch: 497/2993    Discriminator_loss: 0.0032858476042747498  Generator_loss: 5.767862796783447\n",
            "epoch: 19/20,    batch: 498/2993    Discriminator_loss: 0.0032390484120696783  Generator_loss: 5.764735221862793\n",
            "epoch: 19/20,    batch: 499/2993    Discriminator_loss: 0.003235521260648966  Generator_loss: 5.761024475097656\n",
            "epoch: 19/20,    batch: 500/2993    Discriminator_loss: 0.0035130935721099377  Generator_loss: 5.756766319274902\n",
            "epoch: 19/20,    batch: 501/2993    Discriminator_loss: 0.0034156148321926594  Generator_loss: 5.75192928314209\n",
            "epoch: 19/20,    batch: 502/2993    Discriminator_loss: 0.003276803530752659  Generator_loss: 5.7467217445373535\n",
            "epoch: 19/20,    batch: 503/2993    Discriminator_loss: 0.0033236562740057707  Generator_loss: 5.741332530975342\n",
            "epoch: 19/20,    batch: 504/2993    Discriminator_loss: 0.00339355506002903  Generator_loss: 5.7359418869018555\n",
            "epoch: 19/20,    batch: 505/2993    Discriminator_loss: 0.003332707332447171  Generator_loss: 5.73087215423584\n",
            "epoch: 19/20,    batch: 506/2993    Discriminator_loss: 0.003360351314768195  Generator_loss: 5.7264509201049805\n",
            "epoch: 19/20,    batch: 507/2993    Discriminator_loss: 0.0033924472518265247  Generator_loss: 5.722806930541992\n",
            "epoch: 19/20,    batch: 508/2993    Discriminator_loss: 0.00339525961317122  Generator_loss: 5.720247745513916\n",
            "epoch: 19/20,    batch: 509/2993    Discriminator_loss: 0.0033730948343873024  Generator_loss: 5.718929290771484\n",
            "epoch: 19/20,    batch: 510/2993    Discriminator_loss: 0.0033860187977552414  Generator_loss: 5.718876838684082\n",
            "epoch: 19/20,    batch: 511/2993    Discriminator_loss: 0.0034987283870577812  Generator_loss: 5.71992301940918\n",
            "epoch: 19/20,    batch: 512/2993    Discriminator_loss: 0.00335685140453279  Generator_loss: 5.722562313079834\n",
            "epoch: 19/20,    batch: 513/2993    Discriminator_loss: 0.0033646535594016314  Generator_loss: 5.726405143737793\n",
            "epoch: 19/20,    batch: 514/2993    Discriminator_loss: 0.0034174707252532244  Generator_loss: 5.73169469833374\n",
            "epoch: 19/20,    batch: 515/2993    Discriminator_loss: 0.0033044174779206514  Generator_loss: 5.7383575439453125\n",
            "epoch: 19/20,    batch: 516/2993    Discriminator_loss: 0.0032979524694383144  Generator_loss: 5.746370315551758\n",
            "epoch: 19/20,    batch: 517/2993    Discriminator_loss: 0.003318324452266097  Generator_loss: 5.755626678466797\n",
            "epoch: 19/20,    batch: 518/2993    Discriminator_loss: 0.0032144926954060793  Generator_loss: 5.76624059677124\n",
            "epoch: 19/20,    batch: 519/2993    Discriminator_loss: 0.0032320525497198105  Generator_loss: 5.778073310852051\n",
            "epoch: 19/20,    batch: 520/2993    Discriminator_loss: 0.0032092465553432703  Generator_loss: 5.7911529541015625\n",
            "epoch: 19/20,    batch: 521/2993    Discriminator_loss: 0.0031586168333888054  Generator_loss: 5.805253028869629\n",
            "epoch: 19/20,    batch: 522/2993    Discriminator_loss: 0.003122851252555847  Generator_loss: 5.820102691650391\n",
            "epoch: 19/20,    batch: 523/2993    Discriminator_loss: 0.0030471780337393284  Generator_loss: 5.835601329803467\n",
            "epoch: 19/20,    batch: 524/2993    Discriminator_loss: 0.0029691453091800213  Generator_loss: 5.851263523101807\n",
            "epoch: 19/20,    batch: 525/2993    Discriminator_loss: 0.003013621550053358  Generator_loss: 5.867043495178223\n",
            "epoch: 19/20,    batch: 526/2993    Discriminator_loss: 0.0028598892968147993  Generator_loss: 5.882486343383789\n",
            "epoch: 19/20,    batch: 527/2993    Discriminator_loss: 0.002837209729477763  Generator_loss: 5.897397041320801\n",
            "epoch: 19/20,    batch: 528/2993    Discriminator_loss: 0.002965357154607773  Generator_loss: 5.91162109375\n",
            "epoch: 19/20,    batch: 529/2993    Discriminator_loss: 0.002767840400338173  Generator_loss: 5.925148010253906\n",
            "epoch: 19/20,    batch: 530/2993    Discriminator_loss: 0.0027067845221608877  Generator_loss: 5.937950134277344\n",
            "epoch: 19/20,    batch: 531/2993    Discriminator_loss: 0.0027637681923806667  Generator_loss: 5.949991703033447\n",
            "epoch: 19/20,    batch: 532/2993    Discriminator_loss: 0.0027997803408652544  Generator_loss: 5.961180686950684\n",
            "epoch: 19/20,    batch: 533/2993    Discriminator_loss: 0.0026061520911753178  Generator_loss: 5.971841335296631\n",
            "epoch: 19/20,    batch: 534/2993    Discriminator_loss: 0.0027584198396652937  Generator_loss: 5.981716156005859\n",
            "epoch: 19/20,    batch: 535/2993    Discriminator_loss: 0.003810519352555275  Generator_loss: 5.990689754486084\n",
            "epoch: 19/20,    batch: 536/2993    Discriminator_loss: 0.0025475143920630217  Generator_loss: 5.999301433563232\n",
            "epoch: 19/20,    batch: 537/2993    Discriminator_loss: 0.002528662793338299  Generator_loss: 6.007290363311768\n",
            "epoch: 19/20,    batch: 538/2993    Discriminator_loss: 0.0025576059706509113  Generator_loss: 6.014925003051758\n",
            "epoch: 19/20,    batch: 539/2993    Discriminator_loss: 0.0026631157379597425  Generator_loss: 6.021961212158203\n",
            "epoch: 19/20,    batch: 540/2993    Discriminator_loss: 0.002469604602083564  Generator_loss: 6.028532028198242\n",
            "epoch: 19/20,    batch: 541/2993    Discriminator_loss: 0.10884011536836624  Generator_loss: 5.9507927894592285\n",
            "epoch: 19/20,    batch: 542/2993    Discriminator_loss: 0.00305482791736722  Generator_loss: 5.887274265289307\n",
            "epoch: 19/20,    batch: 543/2993    Discriminator_loss: 0.0029171998612582684  Generator_loss: 5.836244583129883\n",
            "epoch: 19/20,    batch: 544/2993    Discriminator_loss: 0.003143679117783904  Generator_loss: 5.796173095703125\n",
            "epoch: 19/20,    batch: 545/2993    Discriminator_loss: 0.0033050670754164457  Generator_loss: 5.765384674072266\n",
            "epoch: 19/20,    batch: 546/2993    Discriminator_loss: 0.003329049563035369  Generator_loss: 5.742500305175781\n",
            "epoch: 19/20,    batch: 547/2993    Discriminator_loss: 0.0033085355535149574  Generator_loss: 5.726469993591309\n",
            "epoch: 19/20,    batch: 548/2993    Discriminator_loss: 0.003397503402084112  Generator_loss: 5.716215133666992\n",
            "epoch: 19/20,    batch: 549/2993    Discriminator_loss: 0.0035026560071855783  Generator_loss: 5.710554122924805\n",
            "epoch: 19/20,    batch: 550/2993    Discriminator_loss: 0.003401918802410364  Generator_loss: 5.709011077880859\n",
            "epoch: 19/20,    batch: 551/2993    Discriminator_loss: 0.0034730485640466213  Generator_loss: 5.710806846618652\n",
            "epoch: 19/20,    batch: 552/2993    Discriminator_loss: 0.003412103746086359  Generator_loss: 5.715373992919922\n",
            "epoch: 19/20,    batch: 553/2993    Discriminator_loss: 0.003386357333511114  Generator_loss: 5.722319602966309\n",
            "epoch: 19/20,    batch: 554/2993    Discriminator_loss: 0.0034574151504784822  Generator_loss: 5.731602668762207\n",
            "epoch: 19/20,    batch: 555/2993    Discriminator_loss: 0.0033857575617730618  Generator_loss: 5.7425713539123535\n",
            "epoch: 19/20,    batch: 556/2993    Discriminator_loss: 0.003320873947814107  Generator_loss: 5.755226135253906\n",
            "epoch: 19/20,    batch: 557/2993    Discriminator_loss: 0.0033654419239610434  Generator_loss: 5.769359588623047\n",
            "epoch: 19/20,    batch: 558/2993    Discriminator_loss: 0.0031589437276124954  Generator_loss: 5.7846479415893555\n",
            "epoch: 19/20,    batch: 559/2993    Discriminator_loss: 0.003144861664623022  Generator_loss: 5.800849437713623\n",
            "epoch: 19/20,    batch: 560/2993    Discriminator_loss: 0.0031764269806444645  Generator_loss: 5.817837715148926\n",
            "epoch: 19/20,    batch: 561/2993    Discriminator_loss: 0.00300589669495821  Generator_loss: 5.8352251052856445\n",
            "epoch: 19/20,    batch: 562/2993    Discriminator_loss: 0.003037072718143463  Generator_loss: 5.852816581726074\n",
            "epoch: 19/20,    batch: 563/2993    Discriminator_loss: 0.003263256046921015  Generator_loss: 5.870094299316406\n",
            "epoch: 19/20,    batch: 564/2993    Discriminator_loss: 0.00285258237272501  Generator_loss: 5.887188911437988\n",
            "epoch: 19/20,    batch: 565/2993    Discriminator_loss: 0.002909355331212282  Generator_loss: 5.9036760330200195\n",
            "epoch: 19/20,    batch: 566/2993    Discriminator_loss: 0.0028836424462497234  Generator_loss: 5.919382095336914\n",
            "epoch: 19/20,    batch: 567/2993    Discriminator_loss: 0.0028257949743419886  Generator_loss: 5.9342169761657715\n",
            "epoch: 19/20,    batch: 568/2993    Discriminator_loss: 0.0026941571850329638  Generator_loss: 5.947816848754883\n",
            "epoch: 19/20,    batch: 569/2993    Discriminator_loss: 0.002959159668534994  Generator_loss: 5.960078239440918\n",
            "epoch: 19/20,    batch: 570/2993    Discriminator_loss: 0.002778401365503669  Generator_loss: 5.970849514007568\n",
            "epoch: 19/20,    batch: 571/2993    Discriminator_loss: 0.0025988733395934105  Generator_loss: 5.980348110198975\n",
            "epoch: 19/20,    batch: 572/2993    Discriminator_loss: 0.0026334167923778296  Generator_loss: 5.988471984863281\n",
            "epoch: 19/20,    batch: 573/2993    Discriminator_loss: 0.0027538002468645573  Generator_loss: 5.995296478271484\n",
            "epoch: 19/20,    batch: 574/2993    Discriminator_loss: 0.0025443509221076965  Generator_loss: 6.001251220703125\n",
            "epoch: 19/20,    batch: 575/2993    Discriminator_loss: 0.0026423644740134478  Generator_loss: 6.006594181060791\n",
            "epoch: 19/20,    batch: 576/2993    Discriminator_loss: 0.002629328751936555  Generator_loss: 6.011490821838379\n",
            "epoch: 19/20,    batch: 577/2993    Discriminator_loss: 0.002502111718058586  Generator_loss: 6.016698837280273\n",
            "epoch: 19/20,    batch: 578/2993    Discriminator_loss: 0.0025309529155492783  Generator_loss: 6.022019386291504\n",
            "epoch: 19/20,    batch: 579/2993    Discriminator_loss: 0.0029394079465419054  Generator_loss: 6.027843475341797\n",
            "epoch: 19/20,    batch: 580/2993    Discriminator_loss: 0.00245853909291327  Generator_loss: 6.034112453460693\n",
            "epoch: 19/20,    batch: 581/2993    Discriminator_loss: 0.002511771861463785  Generator_loss: 6.040802955627441\n",
            "epoch: 19/20,    batch: 582/2993    Discriminator_loss: 0.002588861156255007  Generator_loss: 6.047661304473877\n",
            "epoch: 19/20,    batch: 583/2993    Discriminator_loss: 0.002410375978797674  Generator_loss: 6.054427146911621\n",
            "epoch: 19/20,    batch: 584/2993    Discriminator_loss: 0.0024309742730110884  Generator_loss: 6.060975074768066\n",
            "epoch: 19/20,    batch: 585/2993    Discriminator_loss: 0.0024420274421572685  Generator_loss: 6.066863059997559\n",
            "epoch: 19/20,    batch: 586/2993    Discriminator_loss: 0.0023707537911832333  Generator_loss: 6.071779251098633\n",
            "epoch: 19/20,    batch: 587/2993    Discriminator_loss: 0.002509953221306205  Generator_loss: 6.075455188751221\n",
            "epoch: 19/20,    batch: 588/2993    Discriminator_loss: 0.0024145147763192654  Generator_loss: 6.076781272888184\n",
            "epoch: 19/20,    batch: 589/2993    Discriminator_loss: 0.00237353821285069  Generator_loss: 6.074934959411621\n",
            "epoch: 19/20,    batch: 590/2993    Discriminator_loss: 0.0024295931216329336  Generator_loss: 6.086182594299316\n",
            "epoch: 19/20,    batch: 591/2993    Discriminator_loss: 0.0023861646186560392  Generator_loss: 6.077126502990723\n",
            "epoch: 19/20,    batch: 592/2993    Discriminator_loss: 0.0024073810782283545  Generator_loss: 6.081927299499512\n",
            "epoch: 19/20,    batch: 593/2993    Discriminator_loss: 0.002472856780514121  Generator_loss: 6.0826416015625\n",
            "epoch: 19/20,    batch: 594/2993    Discriminator_loss: 0.00234520947560668  Generator_loss: 6.081995964050293\n",
            "epoch: 19/20,    batch: 595/2993    Discriminator_loss: 0.00237993779592216  Generator_loss: 6.0807785987854\n",
            "epoch: 19/20,    batch: 596/2993    Discriminator_loss: 0.0025035450235009193  Generator_loss: 6.079677581787109\n",
            "epoch: 19/20,    batch: 597/2993    Discriminator_loss: 0.0023706781212240458  Generator_loss: 6.079376220703125\n",
            "epoch: 19/20,    batch: 598/2993    Discriminator_loss: 0.002353695686906576  Generator_loss: 6.079954147338867\n",
            "epoch: 19/20,    batch: 599/2993    Discriminator_loss: 0.0024321649689227343  Generator_loss: 6.081740379333496\n",
            "epoch: 19/20,    batch: 600/2993    Discriminator_loss: 0.002432987093925476  Generator_loss: 6.0848588943481445\n",
            "epoch: 19/20,    batch: 601/2993    Discriminator_loss: 0.0023310473188757896  Generator_loss: 6.0893659591674805\n",
            "epoch: 19/20,    batch: 602/2993    Discriminator_loss: 0.002350152935832739  Generator_loss: 6.095190525054932\n",
            "epoch: 19/20,    batch: 603/2993    Discriminator_loss: 0.0023751272819936275  Generator_loss: 6.101987838745117\n",
            "epoch: 19/20,    batch: 604/2993    Discriminator_loss: 0.002282765693962574  Generator_loss: 6.110110282897949\n",
            "epoch: 19/20,    batch: 605/2993    Discriminator_loss: 0.002264254493638873  Generator_loss: 6.119057655334473\n",
            "epoch: 19/20,    batch: 606/2993    Discriminator_loss: 0.002280239714309573  Generator_loss: 6.128981590270996\n",
            "epoch: 19/20,    batch: 607/2993    Discriminator_loss: 0.00226493738591671  Generator_loss: 6.139357566833496\n",
            "epoch: 19/20,    batch: 608/2993    Discriminator_loss: 0.0021939899306744337  Generator_loss: 6.150218963623047\n",
            "epoch: 19/20,    batch: 609/2993    Discriminator_loss: 0.0021978365257382393  Generator_loss: 6.160886764526367\n",
            "epoch: 19/20,    batch: 610/2993    Discriminator_loss: 0.0022280372213572264  Generator_loss: 6.1717329025268555\n",
            "epoch: 19/20,    batch: 611/2993    Discriminator_loss: 0.002121365163475275  Generator_loss: 6.1825480461120605\n",
            "epoch: 19/20,    batch: 612/2993    Discriminator_loss: 0.0021047478076070547  Generator_loss: 6.193387031555176\n",
            "epoch: 19/20,    batch: 613/2993    Discriminator_loss: 0.0023239620495587587  Generator_loss: 6.2044267654418945\n",
            "epoch: 19/20,    batch: 614/2993    Discriminator_loss: 0.0021016434766352177  Generator_loss: 6.215521335601807\n",
            "epoch: 19/20,    batch: 615/2993    Discriminator_loss: 0.0020352329593151808  Generator_loss: 6.226576328277588\n",
            "epoch: 19/20,    batch: 616/2993    Discriminator_loss: 0.002041631145402789  Generator_loss: 6.237276077270508\n",
            "epoch: 19/20,    batch: 617/2993    Discriminator_loss: 0.0020265690982341766  Generator_loss: 6.247459411621094\n",
            "epoch: 19/20,    batch: 618/2993    Discriminator_loss: 0.0019719647243618965  Generator_loss: 6.256564140319824\n",
            "epoch: 19/20,    batch: 619/2993    Discriminator_loss: 0.0019880090840160847  Generator_loss: 6.264143466949463\n",
            "epoch: 19/20,    batch: 620/2993    Discriminator_loss: 0.0019460726762190461  Generator_loss: 6.269620895385742\n",
            "epoch: 19/20,    batch: 621/2993    Discriminator_loss: 0.0019424717174842954  Generator_loss: 6.271977424621582\n",
            "epoch: 19/20,    batch: 622/2993    Discriminator_loss: 0.00198217760771513  Generator_loss: 6.270666599273682\n",
            "epoch: 19/20,    batch: 623/2993    Discriminator_loss: 0.001952439546585083  Generator_loss: 6.264795303344727\n",
            "epoch: 19/20,    batch: 624/2993    Discriminator_loss: 0.0019889953546226025  Generator_loss: 6.253591060638428\n",
            "epoch: 19/20,    batch: 625/2993    Discriminator_loss: 0.002435327274724841  Generator_loss: 6.2368927001953125\n",
            "epoch: 19/20,    batch: 626/2993    Discriminator_loss: 0.0020522023551166058  Generator_loss: 6.215731620788574\n",
            "epoch: 19/20,    batch: 627/2993    Discriminator_loss: 0.0021307237911969423  Generator_loss: 6.191156387329102\n",
            "epoch: 19/20,    batch: 628/2993    Discriminator_loss: 0.002203124575316906  Generator_loss: 6.164498329162598\n",
            "epoch: 19/20,    batch: 629/2993    Discriminator_loss: 0.00222878553904593  Generator_loss: 6.1368303298950195\n",
            "epoch: 19/20,    batch: 630/2993    Discriminator_loss: 0.002313693519681692  Generator_loss: 6.108944892883301\n",
            "epoch: 19/20,    batch: 631/2993    Discriminator_loss: 0.0023902985267341137  Generator_loss: 6.081619739532471\n",
            "epoch: 19/20,    batch: 632/2993    Discriminator_loss: 0.002423251513391733  Generator_loss: 6.055392265319824\n",
            "epoch: 19/20,    batch: 633/2993    Discriminator_loss: 0.0024969845544546843  Generator_loss: 6.030818462371826\n",
            "epoch: 19/20,    batch: 634/2993    Discriminator_loss: 0.0026090298779308796  Generator_loss: 6.008586406707764\n",
            "epoch: 19/20,    batch: 635/2993    Discriminator_loss: 0.002600886858999729  Generator_loss: 5.98879337310791\n",
            "epoch: 19/20,    batch: 636/2993    Discriminator_loss: 0.0026612593792378902  Generator_loss: 5.971776962280273\n",
            "epoch: 19/20,    batch: 637/2993    Discriminator_loss: 0.002741174539551139  Generator_loss: 5.957088470458984\n",
            "epoch: 19/20,    batch: 638/2993    Discriminator_loss: 0.0027354250196367502  Generator_loss: 5.945191383361816\n",
            "epoch: 19/20,    batch: 639/2993    Discriminator_loss: 0.0027757403440773487  Generator_loss: 5.935101509094238\n",
            "epoch: 19/20,    batch: 640/2993    Discriminator_loss: 0.0028451080434024334  Generator_loss: 5.926850318908691\n",
            "epoch: 19/20,    batch: 641/2993    Discriminator_loss: 0.0028390579391270876  Generator_loss: 5.92009162902832\n",
            "epoch: 19/20,    batch: 642/2993    Discriminator_loss: 0.0028702805284410715  Generator_loss: 5.9141693115234375\n",
            "epoch: 19/20,    batch: 643/2993    Discriminator_loss: 0.0028915712609887123  Generator_loss: 5.909212589263916\n",
            "epoch: 19/20,    batch: 644/2993    Discriminator_loss: 0.0028960888739675283  Generator_loss: 5.903852462768555\n",
            "epoch: 19/20,    batch: 645/2993    Discriminator_loss: 0.002911599352955818  Generator_loss: 5.898463726043701\n",
            "epoch: 19/20,    batch: 646/2993    Discriminator_loss: 0.002989252097904682  Generator_loss: 5.8920674324035645\n",
            "epoch: 19/20,    batch: 647/2993    Discriminator_loss: 0.0030268505215644836  Generator_loss: 5.884072780609131\n",
            "epoch: 19/20,    batch: 648/2993    Discriminator_loss: 0.0030151496175676584  Generator_loss: 5.874261856079102\n",
            "epoch: 19/20,    batch: 649/2993    Discriminator_loss: 0.0030930303037166595  Generator_loss: 5.862852096557617\n",
            "epoch: 19/20,    batch: 650/2993    Discriminator_loss: 0.003100268542766571  Generator_loss: 5.852588653564453\n",
            "epoch: 19/20,    batch: 651/2993    Discriminator_loss: 0.0031291961204260588  Generator_loss: 5.848776817321777\n",
            "epoch: 19/20,    batch: 652/2993    Discriminator_loss: 0.0031794703099876642  Generator_loss: 5.857135772705078\n",
            "epoch: 19/20,    batch: 653/2993    Discriminator_loss: 0.0030458043329417706  Generator_loss: 5.8774824142456055\n",
            "epoch: 19/20,    batch: 654/2993    Discriminator_loss: 0.0029920360539108515  Generator_loss: 5.904664993286133\n",
            "epoch: 19/20,    batch: 655/2993    Discriminator_loss: 0.002956001553684473  Generator_loss: 5.9370880126953125\n",
            "epoch: 19/20,    batch: 656/2993    Discriminator_loss: 0.002776586916297674  Generator_loss: 5.9726786613464355\n",
            "epoch: 19/20,    batch: 657/2993    Discriminator_loss: 0.00270859501324594  Generator_loss: 6.010456085205078\n",
            "epoch: 19/20,    batch: 658/2993    Discriminator_loss: 0.0026096708606928587  Generator_loss: 6.049306869506836\n",
            "epoch: 19/20,    batch: 659/2993    Discriminator_loss: 0.0024710025172680616  Generator_loss: 6.08778190612793\n",
            "epoch: 19/20,    batch: 660/2993    Discriminator_loss: 0.0024274068418890238  Generator_loss: 6.125163555145264\n",
            "epoch: 19/20,    batch: 661/2993    Discriminator_loss: 0.0023314894642680883  Generator_loss: 6.160414218902588\n",
            "epoch: 19/20,    batch: 662/2993    Discriminator_loss: 0.0022214199416339397  Generator_loss: 6.192811012268066\n",
            "epoch: 19/20,    batch: 663/2993    Discriminator_loss: 0.0022037967573851347  Generator_loss: 6.221848487854004\n",
            "epoch: 19/20,    batch: 664/2993    Discriminator_loss: 0.002158252289518714  Generator_loss: 6.246457099914551\n",
            "epoch: 19/20,    batch: 665/2993    Discriminator_loss: 0.0020579411648213863  Generator_loss: 6.265447616577148\n",
            "epoch: 19/20,    batch: 666/2993    Discriminator_loss: 0.002100373851135373  Generator_loss: 6.276766777038574\n",
            "epoch: 19/20,    batch: 667/2993    Discriminator_loss: 0.0023142893332988024  Generator_loss: 6.277368545532227\n",
            "epoch: 19/20,    batch: 668/2993    Discriminator_loss: 0.002066992921754718  Generator_loss: 6.262645721435547\n",
            "epoch: 19/20,    batch: 669/2993    Discriminator_loss: 0.002228301716968417  Generator_loss: 6.224086761474609\n",
            "epoch: 19/20,    batch: 670/2993    Discriminator_loss: 0.002538462169468403  Generator_loss: 6.150274276733398\n",
            "epoch: 19/20,    batch: 671/2993    Discriminator_loss: 0.0026470241136848927  Generator_loss: 6.045398712158203\n",
            "epoch: 19/20,    batch: 672/2993    Discriminator_loss: 0.0028507013339549303  Generator_loss: 6.010557174682617\n",
            "epoch: 19/20,    batch: 673/2993    Discriminator_loss: 0.003945327363908291  Generator_loss: 5.9054856300354\n",
            "epoch: 19/20,    batch: 674/2993    Discriminator_loss: 0.018597513437271118  Generator_loss: 6.470627784729004\n",
            "epoch: 19/20,    batch: 675/2993    Discriminator_loss: 0.0013772922102361917  Generator_loss: 7.094733715057373\n",
            "epoch: 19/20,    batch: 676/2993    Discriminator_loss: 0.0009956657886505127  Generator_loss: 7.502562522888184\n",
            "epoch: 19/20,    batch: 677/2993    Discriminator_loss: 0.0005265382933430374  Generator_loss: 7.832393646240234\n",
            "epoch: 19/20,    batch: 678/2993    Discriminator_loss: 0.00041544775012880564  Generator_loss: 8.057389259338379\n",
            "epoch: 19/20,    batch: 679/2993    Discriminator_loss: 0.0004864292568527162  Generator_loss: 8.201765060424805\n",
            "epoch: 19/20,    batch: 680/2993    Discriminator_loss: 0.0003513369301799685  Generator_loss: 8.278276443481445\n",
            "epoch: 19/20,    batch: 681/2993    Discriminator_loss: 0.0003133123100269586  Generator_loss: 8.303572654724121\n",
            "epoch: 19/20,    batch: 682/2993    Discriminator_loss: 0.006274973973631859  Generator_loss: 8.317692756652832\n",
            "epoch: 19/20,    batch: 683/2993    Discriminator_loss: 0.00026168132899329066  Generator_loss: 8.341110229492188\n",
            "epoch: 19/20,    batch: 684/2993    Discriminator_loss: 0.0002576493425294757  Generator_loss: 8.368375778198242\n",
            "epoch: 19/20,    batch: 685/2993    Discriminator_loss: 0.00029512448236346245  Generator_loss: 8.373799324035645\n",
            "epoch: 19/20,    batch: 686/2993    Discriminator_loss: 0.00024265005777124316  Generator_loss: 8.34588623046875\n",
            "epoch: 19/20,    batch: 687/2993    Discriminator_loss: 0.00031322584254667163  Generator_loss: 8.292561531066895\n",
            "epoch: 19/20,    batch: 688/2993    Discriminator_loss: 0.002072417177259922  Generator_loss: 8.230012893676758\n",
            "epoch: 19/20,    batch: 689/2993    Discriminator_loss: 0.0002883676206693053  Generator_loss: 8.172863006591797\n",
            "epoch: 19/20,    batch: 690/2993    Discriminator_loss: 0.00033191542024724185  Generator_loss: 8.12423324584961\n",
            "epoch: 19/20,    batch: 691/2993    Discriminator_loss: 0.00040321171400137246  Generator_loss: 8.077943801879883\n",
            "epoch: 19/20,    batch: 692/2993    Discriminator_loss: 0.00033820688258856535  Generator_loss: 8.028923034667969\n",
            "epoch: 19/20,    batch: 693/2993    Discriminator_loss: 0.0004605987633112818  Generator_loss: 7.975356101989746\n",
            "epoch: 19/20,    batch: 694/2993    Discriminator_loss: 0.00040631330921314657  Generator_loss: 7.919018745422363\n",
            "epoch: 19/20,    batch: 695/2993    Discriminator_loss: 0.0004096386255696416  Generator_loss: 7.861762523651123\n",
            "epoch: 19/20,    batch: 696/2993    Discriminator_loss: 0.00044717497075907886  Generator_loss: 7.805548191070557\n",
            "epoch: 19/20,    batch: 697/2993    Discriminator_loss: 0.0004700862627942115  Generator_loss: 7.750949382781982\n",
            "epoch: 19/20,    batch: 698/2993    Discriminator_loss: 0.00046283096889965236  Generator_loss: 7.698406219482422\n",
            "epoch: 19/20,    batch: 699/2993    Discriminator_loss: 0.0005431225872598588  Generator_loss: 7.6475324630737305\n",
            "epoch: 19/20,    batch: 700/2993    Discriminator_loss: 0.0005914185894653201  Generator_loss: 7.597190856933594\n",
            "epoch: 19/20,    batch: 701/2993    Discriminator_loss: 0.0005372660816647112  Generator_loss: 7.54763650894165\n",
            "epoch: 19/20,    batch: 702/2993    Discriminator_loss: 0.0005782035295851529  Generator_loss: 7.498079299926758\n",
            "epoch: 19/20,    batch: 703/2993    Discriminator_loss: 0.0006402741419151425  Generator_loss: 7.448570251464844\n",
            "epoch: 19/20,    batch: 704/2993    Discriminator_loss: 0.0006217446643859148  Generator_loss: 7.39809513092041\n",
            "epoch: 19/20,    batch: 705/2993    Discriminator_loss: 0.0006640088395215571  Generator_loss: 7.346977233886719\n",
            "epoch: 19/20,    batch: 706/2993    Discriminator_loss: 0.0007833234849385917  Generator_loss: 7.294312953948975\n",
            "epoch: 19/20,    batch: 707/2993    Discriminator_loss: 0.0007303543970920146  Generator_loss: 7.240151405334473\n",
            "epoch: 19/20,    batch: 708/2993    Discriminator_loss: 0.0008154744282364845  Generator_loss: 7.183438301086426\n",
            "epoch: 19/20,    batch: 709/2993    Discriminator_loss: 0.0009307407890446484  Generator_loss: 7.123802185058594\n",
            "epoch: 19/20,    batch: 710/2993    Discriminator_loss: 0.0008848733268678188  Generator_loss: 7.059850692749023\n",
            "epoch: 19/20,    batch: 711/2993    Discriminator_loss: 0.0009798344690352678  Generator_loss: 6.990650177001953\n",
            "epoch: 19/20,    batch: 712/2993    Discriminator_loss: 0.001145421527326107  Generator_loss: 6.913751125335693\n",
            "epoch: 19/20,    batch: 713/2993    Discriminator_loss: 0.0011344780214130878  Generator_loss: 6.827720642089844\n",
            "epoch: 19/20,    batch: 714/2993    Discriminator_loss: 0.0012904878240078688  Generator_loss: 6.729162216186523\n",
            "epoch: 19/20,    batch: 715/2993    Discriminator_loss: 0.0015692997258156538  Generator_loss: 6.612070560455322\n",
            "epoch: 19/20,    batch: 716/2993    Discriminator_loss: 0.0016911884304136038  Generator_loss: 6.465222358703613\n",
            "epoch: 19/20,    batch: 717/2993    Discriminator_loss: 0.002218738431110978  Generator_loss: 6.270645618438721\n",
            "epoch: 19/20,    batch: 718/2993    Discriminator_loss: 0.00322981970384717  Generator_loss: 6.0344696044921875\n",
            "epoch: 19/20,    batch: 719/2993    Discriminator_loss: 0.004388138651847839  Generator_loss: 5.8566436767578125\n",
            "epoch: 19/20,    batch: 720/2993    Discriminator_loss: 0.004580290988087654  Generator_loss: 5.874073028564453\n",
            "epoch: 19/20,    batch: 721/2993    Discriminator_loss: 0.003765008645132184  Generator_loss: 6.10484504699707\n",
            "epoch: 19/20,    batch: 722/2993    Discriminator_loss: 0.0026858325581997633  Generator_loss: 6.432657241821289\n",
            "epoch: 19/20,    batch: 723/2993    Discriminator_loss: 0.0020038834773004055  Generator_loss: 6.740246772766113\n",
            "epoch: 19/20,    batch: 724/2993    Discriminator_loss: 0.0015314184129238129  Generator_loss: 6.9714155197143555\n",
            "epoch: 19/20,    batch: 725/2993    Discriminator_loss: 0.0013167255092412233  Generator_loss: 7.080268859863281\n",
            "epoch: 19/20,    batch: 726/2993    Discriminator_loss: 0.0014164542080834508  Generator_loss: 6.999102592468262\n",
            "epoch: 19/20,    batch: 727/2993    Discriminator_loss: 0.0017364963423460722  Generator_loss: 6.738884449005127\n",
            "epoch: 19/20,    batch: 728/2993    Discriminator_loss: 0.0023204232566058636  Generator_loss: 6.422157287597656\n",
            "epoch: 19/20,    batch: 729/2993    Discriminator_loss: 0.003407166339457035  Generator_loss: 6.163479804992676\n",
            "epoch: 19/20,    batch: 730/2993    Discriminator_loss: 0.0034955046139657497  Generator_loss: 5.995105743408203\n",
            "epoch: 19/20,    batch: 731/2993    Discriminator_loss: 0.0037839002907276154  Generator_loss: 5.926877975463867\n",
            "epoch: 19/20,    batch: 732/2993    Discriminator_loss: 0.0039827520959079266  Generator_loss: 5.954436779022217\n",
            "epoch: 19/20,    batch: 733/2993    Discriminator_loss: 0.003469485556706786  Generator_loss: 6.068354606628418\n",
            "epoch: 19/20,    batch: 734/2993    Discriminator_loss: 0.0029719588346779346  Generator_loss: 6.243182182312012\n",
            "epoch: 19/20,    batch: 735/2993    Discriminator_loss: 0.002727813320234418  Generator_loss: 6.448640823364258\n",
            "epoch: 19/20,    batch: 736/2993    Discriminator_loss: 0.002167052123695612  Generator_loss: 6.657286643981934\n",
            "epoch: 19/20,    batch: 737/2993    Discriminator_loss: 0.0015663928352296352  Generator_loss: 6.848299026489258\n",
            "epoch: 19/20,    batch: 738/2993    Discriminator_loss: 0.0031724008731544018  Generator_loss: 6.99208927154541\n",
            "epoch: 19/20,    batch: 739/2993    Discriminator_loss: 0.0013301711296662688  Generator_loss: 7.095247268676758\n",
            "epoch: 19/20,    batch: 740/2993    Discriminator_loss: 0.0010846350342035294  Generator_loss: 7.1499223709106445\n",
            "epoch: 19/20,    batch: 741/2993    Discriminator_loss: 0.001474593416787684  Generator_loss: 7.154818534851074\n",
            "epoch: 19/20,    batch: 742/2993    Discriminator_loss: 0.001528585678897798  Generator_loss: 7.118095397949219\n",
            "epoch: 19/20,    batch: 743/2993    Discriminator_loss: 0.0011445708805695176  Generator_loss: 7.048325061798096\n",
            "epoch: 19/20,    batch: 744/2993    Discriminator_loss: 0.005621160380542278  Generator_loss: 6.937366485595703\n",
            "epoch: 19/20,    batch: 745/2993    Discriminator_loss: 0.0016824943013489246  Generator_loss: 6.831785202026367\n",
            "epoch: 19/20,    batch: 746/2993    Discriminator_loss: 0.0015355204232037067  Generator_loss: 6.745052337646484\n",
            "epoch: 19/20,    batch: 747/2993    Discriminator_loss: 0.0016716155223548412  Generator_loss: 6.688235282897949\n",
            "epoch: 19/20,    batch: 748/2993    Discriminator_loss: 0.0018026079051196575  Generator_loss: 6.664435386657715\n",
            "epoch: 19/20,    batch: 749/2993    Discriminator_loss: 0.0016962809022516012  Generator_loss: 6.671995162963867\n",
            "epoch: 19/20,    batch: 750/2993    Discriminator_loss: 0.001712543424218893  Generator_loss: 6.703094005584717\n",
            "epoch: 19/20,    batch: 751/2993    Discriminator_loss: 0.0017361424397677183  Generator_loss: 6.74987268447876\n",
            "epoch: 19/20,    batch: 752/2993    Discriminator_loss: 0.0015035044634714723  Generator_loss: 6.8053693771362305\n",
            "epoch: 19/20,    batch: 753/2993    Discriminator_loss: 0.00143863121047616  Generator_loss: 6.863668441772461\n",
            "epoch: 19/20,    batch: 754/2993    Discriminator_loss: 0.001382622285746038  Generator_loss: 6.921645164489746\n",
            "epoch: 19/20,    batch: 755/2993    Discriminator_loss: 0.0012626413954421878  Generator_loss: 6.9775071144104\n",
            "epoch: 19/20,    batch: 756/2993    Discriminator_loss: 0.0013252143980935216  Generator_loss: 7.02862548828125\n",
            "epoch: 19/20,    batch: 757/2993    Discriminator_loss: 0.0011192277306690812  Generator_loss: 7.072728633880615\n",
            "epoch: 19/20,    batch: 758/2993    Discriminator_loss: 0.0011464658891782165  Generator_loss: 7.106598377227783\n",
            "epoch: 19/20,    batch: 759/2993    Discriminator_loss: 0.001197346718981862  Generator_loss: 7.127577781677246\n",
            "epoch: 19/20,    batch: 760/2993    Discriminator_loss: 0.0010011547710746527  Generator_loss: 7.133423805236816\n",
            "epoch: 19/20,    batch: 761/2993    Discriminator_loss: 0.0010563593823462725  Generator_loss: 7.123261451721191\n",
            "epoch: 19/20,    batch: 762/2993    Discriminator_loss: 0.0021116728894412518  Generator_loss: 7.094914436340332\n",
            "epoch: 19/20,    batch: 763/2993    Discriminator_loss: 0.0010690310737118125  Generator_loss: 7.056294918060303\n",
            "epoch: 19/20,    batch: 764/2993    Discriminator_loss: 0.003974043298512697  Generator_loss: 6.971993923187256\n",
            "epoch: 19/20,    batch: 765/2993    Discriminator_loss: 0.0016385362250730395  Generator_loss: 6.899174690246582\n",
            "epoch: 19/20,    batch: 766/2993    Discriminator_loss: 0.0013364501064643264  Generator_loss: 6.843111038208008\n",
            "epoch: 19/20,    batch: 767/2993    Discriminator_loss: 0.0014023527037352324  Generator_loss: 6.800712585449219\n",
            "epoch: 19/20,    batch: 768/2993    Discriminator_loss: 0.04382537677884102  Generator_loss: 6.582300186157227\n",
            "epoch: 19/20,    batch: 769/2993    Discriminator_loss: 0.002267264761030674  Generator_loss: 6.4875688552856445\n",
            "epoch: 19/20,    batch: 770/2993    Discriminator_loss: 0.0019520665518939495  Generator_loss: 6.480257511138916\n",
            "epoch: 19/20,    batch: 771/2993    Discriminator_loss: 0.2864179015159607  Generator_loss: 5.171900749206543\n",
            "epoch: 19/20,    batch: 772/2993    Discriminator_loss: 0.012021888978779316  Generator_loss: 4.5648369789123535\n",
            "epoch: 19/20,    batch: 773/2993    Discriminator_loss: 0.014226983301341534  Generator_loss: 4.811672210693359\n",
            "epoch: 19/20,    batch: 774/2993    Discriminator_loss: 0.007467422168701887  Generator_loss: 5.639984130859375\n",
            "epoch: 19/20,    batch: 775/2993    Discriminator_loss: 0.0029424852691590786  Generator_loss: 6.603619575500488\n",
            "epoch: 19/20,    batch: 776/2993    Discriminator_loss: 0.0010934812016785145  Generator_loss: 7.449671745300293\n",
            "epoch: 19/20,    batch: 777/2993    Discriminator_loss: 0.000753384199924767  Generator_loss: 8.099102973937988\n",
            "epoch: 19/20,    batch: 778/2993    Discriminator_loss: 0.0005175903788767755  Generator_loss: 8.555492401123047\n",
            "epoch: 19/20,    batch: 779/2993    Discriminator_loss: 0.00020627722551580518  Generator_loss: 8.847091674804688\n",
            "epoch: 19/20,    batch: 780/2993    Discriminator_loss: 0.00020207995839882642  Generator_loss: 9.00857162475586\n",
            "epoch: 19/20,    batch: 781/2993    Discriminator_loss: 0.0002590355579741299  Generator_loss: 9.069194793701172\n",
            "epoch: 19/20,    batch: 782/2993    Discriminator_loss: 0.0001434282457921654  Generator_loss: 9.046392440795898\n",
            "epoch: 19/20,    batch: 783/2993    Discriminator_loss: 0.0002568519557826221  Generator_loss: 8.948631286621094\n",
            "epoch: 19/20,    batch: 784/2993    Discriminator_loss: 0.000247908232267946  Generator_loss: 8.785165786743164\n",
            "epoch: 19/20,    batch: 785/2993    Discriminator_loss: 0.00023517917725257576  Generator_loss: 8.56815242767334\n",
            "epoch: 19/20,    batch: 786/2993    Discriminator_loss: 0.00039159617153927684  Generator_loss: 8.312808990478516\n",
            "epoch: 19/20,    batch: 787/2993    Discriminator_loss: 0.000415968825109303  Generator_loss: 8.032934188842773\n",
            "epoch: 19/20,    batch: 788/2993    Discriminator_loss: 0.0004996610805392265  Generator_loss: 7.749806880950928\n",
            "epoch: 19/20,    batch: 789/2993    Discriminator_loss: 0.0007192649645730853  Generator_loss: 7.442218780517578\n",
            "epoch: 19/20,    batch: 790/2993    Discriminator_loss: 0.0009862021543085575  Generator_loss: 7.129571914672852\n",
            "epoch: 19/20,    batch: 791/2993    Discriminator_loss: 0.001323143718764186  Generator_loss: 6.85111141204834\n",
            "epoch: 19/20,    batch: 792/2993    Discriminator_loss: 0.0016500938218086958  Generator_loss: 6.618006706237793\n",
            "epoch: 19/20,    batch: 793/2993    Discriminator_loss: 0.0019333470845595002  Generator_loss: 6.452396392822266\n",
            "epoch: 19/20,    batch: 794/2993    Discriminator_loss: 0.0022208113223314285  Generator_loss: 6.366514205932617\n",
            "epoch: 19/20,    batch: 795/2993    Discriminator_loss: 0.002315097488462925  Generator_loss: 6.357089519500732\n",
            "epoch: 19/20,    batch: 796/2993    Discriminator_loss: 0.0022371988743543625  Generator_loss: 6.408024787902832\n",
            "epoch: 19/20,    batch: 797/2993    Discriminator_loss: 0.002258723136037588  Generator_loss: 6.495845794677734\n",
            "epoch: 19/20,    batch: 798/2993    Discriminator_loss: 0.0020295933354645967  Generator_loss: 6.603248596191406\n",
            "epoch: 19/20,    batch: 799/2993    Discriminator_loss: 0.0016911799320951104  Generator_loss: 6.7165446281433105\n",
            "epoch: 19/20,    batch: 800/2993    Discriminator_loss: 0.001502390019595623  Generator_loss: 6.827287673950195\n",
            "epoch: 19/20,    batch: 801/2993    Discriminator_loss: 0.0014245075872167945  Generator_loss: 6.929274559020996\n",
            "epoch: 19/20,    batch: 802/2993    Discriminator_loss: 0.0012498183641582727  Generator_loss: 7.020861625671387\n",
            "epoch: 19/20,    batch: 803/2993    Discriminator_loss: 0.0011815313482657075  Generator_loss: 7.100057601928711\n",
            "epoch: 19/20,    batch: 804/2993    Discriminator_loss: 0.5994447469711304  Generator_loss: 3.1686043739318848\n",
            "epoch: 19/20,    batch: 805/2993    Discriminator_loss: 0.1802251785993576  Generator_loss: 3.2367348670959473\n",
            "epoch: 19/20,    batch: 806/2993    Discriminator_loss: 0.01350240409374237  Generator_loss: 5.664161682128906\n",
            "epoch: 19/20,    batch: 807/2993    Discriminator_loss: 0.0015443498268723488  Generator_loss: 7.508867263793945\n",
            "epoch: 19/20,    batch: 808/2993    Discriminator_loss: 0.0003564282669685781  Generator_loss: 8.85145378112793\n",
            "epoch: 19/20,    batch: 809/2993    Discriminator_loss: 9.8674681794364e-05  Generator_loss: 9.81355094909668\n",
            "epoch: 19/20,    batch: 810/2993    Discriminator_loss: 0.00011330298002576455  Generator_loss: 10.435297966003418\n",
            "epoch: 19/20,    batch: 811/2993    Discriminator_loss: 0.00014730366820003837  Generator_loss: 10.790206909179688\n",
            "epoch: 19/20,    batch: 812/2993    Discriminator_loss: 2.1824846044182777e-05  Generator_loss: 10.960098266601562\n",
            "epoch: 19/20,    batch: 813/2993    Discriminator_loss: 6.907318311277777e-05  Generator_loss: 11.009071350097656\n",
            "epoch: 19/20,    batch: 814/2993    Discriminator_loss: 8.950013580033556e-05  Generator_loss: 10.981765747070312\n",
            "epoch: 19/20,    batch: 815/2993    Discriminator_loss: 2.1545423805946484e-05  Generator_loss: 10.906479835510254\n",
            "epoch: 19/20,    batch: 816/2993    Discriminator_loss: 0.0005337828770279884  Generator_loss: 10.795827865600586\n",
            "epoch: 19/20,    batch: 817/2993    Discriminator_loss: 0.00024245133681688458  Generator_loss: 10.665093421936035\n",
            "epoch: 19/20,    batch: 818/2993    Discriminator_loss: 4.0759223338682204e-05  Generator_loss: 10.514983177185059\n",
            "epoch: 19/20,    batch: 819/2993    Discriminator_loss: 7.879800978116691e-05  Generator_loss: 10.350601196289062\n",
            "epoch: 19/20,    batch: 820/2993    Discriminator_loss: 8.20955538074486e-05  Generator_loss: 10.168334007263184\n",
            "epoch: 19/20,    batch: 821/2993    Discriminator_loss: 0.00010174828639719635  Generator_loss: 9.969703674316406\n",
            "epoch: 19/20,    batch: 822/2993    Discriminator_loss: 0.0005105441669002175  Generator_loss: 9.752336502075195\n",
            "epoch: 19/20,    batch: 823/2993    Discriminator_loss: 0.00010013323480961844  Generator_loss: 9.516258239746094\n",
            "epoch: 19/20,    batch: 824/2993    Discriminator_loss: 0.000132110551930964  Generator_loss: 9.263773918151855\n",
            "epoch: 19/20,    batch: 825/2993    Discriminator_loss: 0.0002065729786409065  Generator_loss: 9.000051498413086\n",
            "epoch: 19/20,    batch: 826/2993    Discriminator_loss: 0.00016363186296075583  Generator_loss: 8.732585906982422\n",
            "epoch: 19/20,    batch: 827/2993    Discriminator_loss: 0.0002536378742661327  Generator_loss: 8.471416473388672\n",
            "epoch: 19/20,    batch: 828/2993    Discriminator_loss: 0.00030097010312601924  Generator_loss: 8.22514820098877\n",
            "epoch: 19/20,    batch: 829/2993    Discriminator_loss: 0.00034515553852543235  Generator_loss: 8.001603126525879\n",
            "epoch: 19/20,    batch: 830/2993    Discriminator_loss: 0.0004266166652087122  Generator_loss: 7.80394983291626\n",
            "epoch: 19/20,    batch: 831/2993    Discriminator_loss: 0.0005603827885352075  Generator_loss: 7.63303279876709\n",
            "epoch: 19/20,    batch: 832/2993    Discriminator_loss: 0.0006181971402838826  Generator_loss: 7.48629093170166\n",
            "epoch: 19/20,    batch: 833/2993    Discriminator_loss: 0.0006602422217838466  Generator_loss: 7.3611273765563965\n",
            "epoch: 19/20,    batch: 834/2993    Discriminator_loss: 0.00080357666593045  Generator_loss: 7.253453254699707\n",
            "epoch: 19/20,    batch: 835/2993    Discriminator_loss: 0.000802240043412894  Generator_loss: 7.160428047180176\n",
            "epoch: 19/20,    batch: 836/2993    Discriminator_loss: 0.0008604973554611206  Generator_loss: 7.078902721405029\n",
            "epoch: 19/20,    batch: 837/2993    Discriminator_loss: 0.0009559883619658649  Generator_loss: 7.007140636444092\n",
            "epoch: 19/20,    batch: 838/2993    Discriminator_loss: 0.001059451955370605  Generator_loss: 6.942739486694336\n",
            "epoch: 19/20,    batch: 839/2993    Discriminator_loss: 0.0010457468451932073  Generator_loss: 6.884461402893066\n",
            "epoch: 19/20,    batch: 840/2993    Discriminator_loss: 0.001565219135954976  Generator_loss: 6.829934120178223\n",
            "epoch: 19/20,    batch: 841/2993    Discriminator_loss: 0.0011956559028476477  Generator_loss: 6.7791829109191895\n",
            "epoch: 19/20,    batch: 842/2993    Discriminator_loss: 0.0012223009252920747  Generator_loss: 6.730820655822754\n",
            "epoch: 19/20,    batch: 843/2993    Discriminator_loss: 0.0016861900221556425  Generator_loss: 6.680179595947266\n",
            "epoch: 19/20,    batch: 844/2993    Discriminator_loss: 0.0013996721245348454  Generator_loss: 6.631557941436768\n",
            "epoch: 19/20,    batch: 845/2993    Discriminator_loss: 0.001459802850149572  Generator_loss: 6.584970474243164\n",
            "epoch: 19/20,    batch: 846/2993    Discriminator_loss: 0.0014936024090275168  Generator_loss: 6.541678428649902\n",
            "epoch: 19/20,    batch: 847/2993    Discriminator_loss: 0.0016167019493877888  Generator_loss: 6.502283573150635\n",
            "epoch: 19/20,    batch: 848/2993    Discriminator_loss: 0.001603909651748836  Generator_loss: 6.467257022857666\n",
            "epoch: 19/20,    batch: 849/2993    Discriminator_loss: 0.0016752788797020912  Generator_loss: 6.436290740966797\n",
            "epoch: 19/20,    batch: 850/2993    Discriminator_loss: 0.0017865800764411688  Generator_loss: 6.409214496612549\n",
            "epoch: 19/20,    batch: 851/2993    Discriminator_loss: 0.001735227880999446  Generator_loss: 6.38543701171875\n",
            "epoch: 19/20,    batch: 852/2993    Discriminator_loss: 0.0018285135738551617  Generator_loss: 6.3646955490112305\n",
            "epoch: 19/20,    batch: 853/2993    Discriminator_loss: 0.0018806335283443332  Generator_loss: 6.3461456298828125\n",
            "epoch: 19/20,    batch: 854/2993    Discriminator_loss: 0.0018388282041996717  Generator_loss: 6.330098628997803\n",
            "epoch: 19/20,    batch: 855/2993    Discriminator_loss: 0.004066994413733482  Generator_loss: 6.315986156463623\n",
            "epoch: 19/20,    batch: 856/2993    Discriminator_loss: 0.006520908325910568  Generator_loss: 6.3009185791015625\n",
            "epoch: 19/20,    batch: 857/2993    Discriminator_loss: 0.0023662124294787645  Generator_loss: 6.287607192993164\n",
            "epoch: 19/20,    batch: 858/2993    Discriminator_loss: 0.0022741714492440224  Generator_loss: 6.27619743347168\n",
            "epoch: 19/20,    batch: 859/2993    Discriminator_loss: 0.0023595979437232018  Generator_loss: 6.26645565032959\n",
            "epoch: 19/20,    batch: 860/2993    Discriminator_loss: 0.0023883769754320383  Generator_loss: 6.258469581604004\n",
            "epoch: 19/20,    batch: 861/2993    Discriminator_loss: 0.002432763110846281  Generator_loss: 6.252108573913574\n",
            "epoch: 19/20,    batch: 862/2993    Discriminator_loss: 0.0024622194468975067  Generator_loss: 6.247709274291992\n",
            "epoch: 19/20,    batch: 863/2993    Discriminator_loss: 0.002623922424390912  Generator_loss: 6.245192527770996\n",
            "epoch: 19/20,    batch: 864/2993    Discriminator_loss: 0.0026260241866111755  Generator_loss: 6.244589328765869\n",
            "epoch: 19/20,    batch: 865/2993    Discriminator_loss: 0.0025280958507210016  Generator_loss: 6.246087074279785\n",
            "epoch: 19/20,    batch: 866/2993    Discriminator_loss: 0.0024561795871704817  Generator_loss: 6.249874114990234\n",
            "epoch: 19/20,    batch: 867/2993    Discriminator_loss: 0.0023664170876145363  Generator_loss: 6.256059169769287\n",
            "epoch: 19/20,    batch: 868/2993    Discriminator_loss: 0.002339279744774103  Generator_loss: 6.264664173126221\n",
            "epoch: 19/20,    batch: 869/2993    Discriminator_loss: 0.0023033616598695517  Generator_loss: 6.275874137878418\n",
            "epoch: 19/20,    batch: 870/2993    Discriminator_loss: 0.0023143626749515533  Generator_loss: 6.289525032043457\n",
            "epoch: 19/20,    batch: 871/2993    Discriminator_loss: 0.002278472762554884  Generator_loss: 6.305487632751465\n",
            "epoch: 19/20,    batch: 872/2993    Discriminator_loss: 0.002284829970449209  Generator_loss: 6.323488712310791\n",
            "epoch: 19/20,    batch: 873/2993    Discriminator_loss: 0.0022966512478888035  Generator_loss: 6.342808723449707\n",
            "epoch: 19/20,    batch: 874/2993    Discriminator_loss: 0.002234748098999262  Generator_loss: 6.363349914550781\n",
            "epoch: 19/20,    batch: 875/2993    Discriminator_loss: 0.002206219593062997  Generator_loss: 6.383814334869385\n",
            "epoch: 19/20,    batch: 876/2993    Discriminator_loss: 0.002150321612134576  Generator_loss: 6.404386520385742\n",
            "epoch: 19/20,    batch: 877/2993    Discriminator_loss: 0.0020914627239108086  Generator_loss: 6.4231953620910645\n",
            "epoch: 19/20,    batch: 878/2993    Discriminator_loss: 0.00206747162155807  Generator_loss: 6.437796592712402\n",
            "epoch: 19/20,    batch: 879/2993    Discriminator_loss: 0.0020085079595446587  Generator_loss: 6.440314769744873\n",
            "epoch: 19/20,    batch: 880/2993    Discriminator_loss: 0.0019567091949284077  Generator_loss: 6.4551897048950195\n",
            "epoch: 19/20,    batch: 881/2993    Discriminator_loss: 0.0018813044298440218  Generator_loss: 6.473419189453125\n",
            "epoch: 19/20,    batch: 882/2993    Discriminator_loss: 0.0021204734221100807  Generator_loss: 6.4738054275512695\n",
            "epoch: 19/20,    batch: 883/2993    Discriminator_loss: 0.003100665519014001  Generator_loss: 6.495786190032959\n",
            "epoch: 19/20,    batch: 884/2993    Discriminator_loss: 0.0016077839536592364  Generator_loss: 6.499978065490723\n",
            "epoch: 19/20,    batch: 885/2993    Discriminator_loss: 0.0015516045968979597  Generator_loss: 6.503978729248047\n",
            "epoch: 19/20,    batch: 886/2993    Discriminator_loss: 0.04956641048192978  Generator_loss: 6.450984001159668\n",
            "epoch: 19/20,    batch: 887/2993    Discriminator_loss: 0.0017646047053858638  Generator_loss: 6.395297527313232\n",
            "epoch: 19/20,    batch: 888/2993    Discriminator_loss: 0.001788519904948771  Generator_loss: 6.355388164520264\n",
            "epoch: 19/20,    batch: 889/2993    Discriminator_loss: 0.0018298145150765777  Generator_loss: 6.331933498382568\n",
            "epoch: 19/20,    batch: 890/2993    Discriminator_loss: 0.0019474825821816921  Generator_loss: 6.30951452255249\n",
            "epoch: 19/20,    batch: 891/2993    Discriminator_loss: 0.001910687773488462  Generator_loss: 6.295568466186523\n",
            "epoch: 19/20,    batch: 892/2993    Discriminator_loss: 0.001919188187457621  Generator_loss: 6.291032791137695\n",
            "epoch: 19/20,    batch: 893/2993    Discriminator_loss: 0.00205412064678967  Generator_loss: 6.288392066955566\n",
            "epoch: 19/20,    batch: 894/2993    Discriminator_loss: 0.0020038823131471872  Generator_loss: 6.288434028625488\n",
            "epoch: 19/20,    batch: 895/2993    Discriminator_loss: 0.001943505252711475  Generator_loss: 6.290465354919434\n",
            "epoch: 19/20,    batch: 896/2993    Discriminator_loss: 0.007945191115140915  Generator_loss: 6.276204586029053\n",
            "epoch: 19/20,    batch: 897/2993    Discriminator_loss: 0.07470253854990005  Generator_loss: 6.177181720733643\n",
            "epoch: 19/20,    batch: 898/2993    Discriminator_loss: 0.0022650486789643764  Generator_loss: 6.099599838256836\n",
            "epoch: 19/20,    batch: 899/2993    Discriminator_loss: 0.0024250023998320103  Generator_loss: 6.0396223068237305\n",
            "epoch: 19/20,    batch: 900/2993    Discriminator_loss: 0.21278288960456848  Generator_loss: 5.889398574829102\n",
            "epoch: 19/20,    batch: 901/2993    Discriminator_loss: 0.003197973594069481  Generator_loss: 5.775049686431885\n",
            "epoch: 19/20,    batch: 902/2993    Discriminator_loss: 0.0034168092533946037  Generator_loss: 5.694497108459473\n",
            "epoch: 19/20,    batch: 903/2993    Discriminator_loss: 0.009540985338389874  Generator_loss: 5.634661674499512\n",
            "epoch: 19/20,    batch: 904/2993    Discriminator_loss: 0.003970594145357609  Generator_loss: 5.604918479919434\n",
            "epoch: 19/20,    batch: 905/2993    Discriminator_loss: 0.003910635132342577  Generator_loss: 5.60153865814209\n",
            "epoch: 19/20,    batch: 906/2993    Discriminator_loss: 0.003941195085644722  Generator_loss: 5.619848251342773\n",
            "epoch: 19/20,    batch: 907/2993    Discriminator_loss: 0.0038871141150593758  Generator_loss: 5.654628753662109\n",
            "epoch: 19/20,    batch: 908/2993    Discriminator_loss: 0.003634503111243248  Generator_loss: 5.701375484466553\n",
            "epoch: 19/20,    batch: 909/2993    Discriminator_loss: 0.0034826339688152075  Generator_loss: 5.759824275970459\n",
            "epoch: 19/20,    batch: 910/2993    Discriminator_loss: 0.0032722889445722103  Generator_loss: 5.836277484893799\n",
            "epoch: 19/20,    batch: 911/2993    Discriminator_loss: 0.002990842331200838  Generator_loss: 5.903717041015625\n",
            "epoch: 19/20,    batch: 912/2993    Discriminator_loss: 0.002878982573747635  Generator_loss: 5.968761444091797\n",
            "epoch: 19/20,    batch: 913/2993    Discriminator_loss: 0.002653303323313594  Generator_loss: 6.042116165161133\n",
            "epoch: 19/20,    batch: 914/2993    Discriminator_loss: 0.002433049725368619  Generator_loss: 6.1129326820373535\n",
            "epoch: 19/20,    batch: 915/2993    Discriminator_loss: 0.002300984226167202  Generator_loss: 6.1765241622924805\n",
            "epoch: 19/20,    batch: 916/2993    Discriminator_loss: 0.0022192848846316338  Generator_loss: 6.2335309982299805\n",
            "epoch: 19/20,    batch: 917/2993    Discriminator_loss: 0.0020600161515176296  Generator_loss: 6.286230087280273\n",
            "epoch: 19/20,    batch: 918/2993    Discriminator_loss: 0.002014265162870288  Generator_loss: 6.339037895202637\n",
            "epoch: 19/20,    batch: 919/2993    Discriminator_loss: 0.001816466567106545  Generator_loss: 6.385894775390625\n",
            "epoch: 19/20,    batch: 920/2993    Discriminator_loss: 0.0017395414179190993  Generator_loss: 6.423323154449463\n",
            "epoch: 19/20,    batch: 921/2993    Discriminator_loss: 0.002197986003011465  Generator_loss: 6.456058979034424\n",
            "epoch: 19/20,    batch: 922/2993    Discriminator_loss: 0.0017263724002987146  Generator_loss: 6.4863972663879395\n",
            "epoch: 19/20,    batch: 923/2993    Discriminator_loss: 0.0015760012902319431  Generator_loss: 6.511269569396973\n",
            "epoch: 19/20,    batch: 924/2993    Discriminator_loss: 0.0016530613647773862  Generator_loss: 6.528182029724121\n",
            "epoch: 19/20,    batch: 925/2993    Discriminator_loss: 0.0016209116438403726  Generator_loss: 6.53878927230835\n",
            "epoch: 19/20,    batch: 926/2993    Discriminator_loss: 0.0015304780099540949  Generator_loss: 6.54315710067749\n",
            "epoch: 19/20,    batch: 927/2993    Discriminator_loss: 0.0015252495650202036  Generator_loss: 6.54245662689209\n",
            "epoch: 19/20,    batch: 928/2993    Discriminator_loss: 0.0016091467114165425  Generator_loss: 6.532509803771973\n",
            "epoch: 19/20,    batch: 929/2993    Discriminator_loss: 0.0016350816003978252  Generator_loss: 6.5146331787109375\n",
            "epoch: 19/20,    batch: 930/2993    Discriminator_loss: 0.0016059722984209657  Generator_loss: 6.491360664367676\n",
            "epoch: 19/20,    batch: 931/2993    Discriminator_loss: 0.001759238075464964  Generator_loss: 6.463073253631592\n",
            "epoch: 19/20,    batch: 932/2993    Discriminator_loss: 0.001779870130121708  Generator_loss: 6.432147979736328\n",
            "epoch: 19/20,    batch: 933/2993    Discriminator_loss: 0.0017749648541212082  Generator_loss: 6.400635242462158\n",
            "epoch: 19/20,    batch: 934/2993    Discriminator_loss: 0.0018445157911628485  Generator_loss: 6.373510360717773\n",
            "epoch: 19/20,    batch: 935/2993    Discriminator_loss: 0.0019884209614247084  Generator_loss: 6.353150844573975\n",
            "epoch: 19/20,    batch: 936/2993    Discriminator_loss: 0.0020096658263355494  Generator_loss: 6.339746952056885\n",
            "epoch: 19/20,    batch: 937/2993    Discriminator_loss: 0.0019215329084545374  Generator_loss: 6.335247039794922\n",
            "epoch: 19/20,    batch: 938/2993    Discriminator_loss: 0.0020745275542140007  Generator_loss: 6.34039831161499\n",
            "epoch: 19/20,    batch: 939/2993    Discriminator_loss: 0.002241447800770402  Generator_loss: 6.3543477058410645\n",
            "epoch: 19/20,    batch: 940/2993    Discriminator_loss: 0.004890635143965483  Generator_loss: 6.376238822937012\n",
            "epoch: 19/20,    batch: 941/2993    Discriminator_loss: 0.0018166834488511086  Generator_loss: 6.403731346130371\n",
            "epoch: 19/20,    batch: 942/2993    Discriminator_loss: 0.0020198135171085596  Generator_loss: 6.436153411865234\n",
            "epoch: 19/20,    batch: 943/2993    Discriminator_loss: 0.0018080195877701044  Generator_loss: 6.472470760345459\n",
            "epoch: 19/20,    batch: 944/2993    Discriminator_loss: 0.0016400340246036649  Generator_loss: 6.511221885681152\n",
            "epoch: 19/20,    batch: 945/2993    Discriminator_loss: 0.0018258756026625633  Generator_loss: 6.550225257873535\n",
            "epoch: 19/20,    batch: 946/2993    Discriminator_loss: 0.0015983361518010497  Generator_loss: 6.587841510772705\n",
            "epoch: 19/20,    batch: 947/2993    Discriminator_loss: 0.0014792376896366477  Generator_loss: 6.62358283996582\n",
            "epoch: 19/20,    batch: 948/2993    Discriminator_loss: 0.0015929057262837887  Generator_loss: 6.650654315948486\n",
            "epoch: 19/20,    batch: 949/2993    Discriminator_loss: 0.0014806048711761832  Generator_loss: 6.649296760559082\n",
            "epoch: 19/20,    batch: 950/2993    Discriminator_loss: 0.00145098683424294  Generator_loss: 6.669774532318115\n",
            "epoch: 19/20,    batch: 951/2993    Discriminator_loss: 0.001412860699929297  Generator_loss: 6.739100456237793\n",
            "epoch: 19/20,    batch: 952/2993    Discriminator_loss: 0.0013031281996518373  Generator_loss: 6.75765323638916\n",
            "epoch: 19/20,    batch: 953/2993    Discriminator_loss: 0.0016519492492079735  Generator_loss: 6.756146430969238\n",
            "epoch: 19/20,    batch: 954/2993    Discriminator_loss: 0.0013452350394800305  Generator_loss: 6.748276710510254\n",
            "epoch: 19/20,    batch: 955/2993    Discriminator_loss: 0.0012846444733440876  Generator_loss: 6.744235038757324\n",
            "epoch: 19/20,    batch: 956/2993    Discriminator_loss: 0.0012739875819534063  Generator_loss: 6.7450642585754395\n",
            "epoch: 19/20,    batch: 957/2993    Discriminator_loss: 0.001359167043119669  Generator_loss: 6.748756408691406\n",
            "epoch: 19/20,    batch: 958/2993    Discriminator_loss: 0.0013330888468772173  Generator_loss: 6.752232551574707\n",
            "epoch: 19/20,    batch: 959/2993    Discriminator_loss: 0.0012451047077775002  Generator_loss: 6.7557172775268555\n",
            "epoch: 19/20,    batch: 960/2993    Discriminator_loss: 0.00363950920291245  Generator_loss: 6.749362945556641\n",
            "epoch: 19/20,    batch: 961/2993    Discriminator_loss: 0.0018095429986715317  Generator_loss: 6.744598865509033\n",
            "epoch: 19/20,    batch: 962/2993    Discriminator_loss: 0.0012801472330465913  Generator_loss: 6.739926815032959\n",
            "epoch: 19/20,    batch: 963/2993    Discriminator_loss: 0.001342435018159449  Generator_loss: 6.732655048370361\n",
            "epoch: 19/20,    batch: 964/2993    Discriminator_loss: 1.7451248168945312  Generator_loss: 5.2942047119140625\n",
            "epoch: 19/20,    batch: 965/2993    Discriminator_loss: 0.010768331587314606  Generator_loss: 4.070448875427246\n",
            "epoch: 19/20,    batch: 966/2993    Discriminator_loss: 0.03176725655794144  Generator_loss: 3.3344616889953613\n",
            "epoch: 19/20,    batch: 967/2993    Discriminator_loss: 0.04875015839934349  Generator_loss: 3.3762741088867188\n",
            "epoch: 19/20,    batch: 968/2993    Discriminator_loss: 0.03062455914914608  Generator_loss: 4.049323081970215\n",
            "epoch: 19/20,    batch: 969/2993    Discriminator_loss: 0.012657396495342255  Generator_loss: 4.9222092628479\n",
            "epoch: 19/20,    batch: 970/2993    Discriminator_loss: 0.005204558372497559  Generator_loss: 5.730784893035889\n",
            "epoch: 19/20,    batch: 971/2993    Discriminator_loss: 0.0024503441527485847  Generator_loss: 6.401963710784912\n",
            "epoch: 19/20,    batch: 972/2993    Discriminator_loss: 0.00141146220266819  Generator_loss: 6.934379577636719\n",
            "epoch: 19/20,    batch: 973/2993    Discriminator_loss: 0.0008264355710707605  Generator_loss: 7.346797943115234\n",
            "epoch: 19/20,    batch: 974/2993    Discriminator_loss: 0.0010843778727576137  Generator_loss: 7.656070232391357\n",
            "epoch: 19/20,    batch: 975/2993    Discriminator_loss: 0.0004969454603269696  Generator_loss: 7.882972717285156\n",
            "epoch: 19/20,    batch: 976/2993    Discriminator_loss: 0.00036848135641776025  Generator_loss: 8.043292045593262\n",
            "epoch: 19/20,    batch: 977/2993    Discriminator_loss: 0.0004003936192020774  Generator_loss: 8.149613380432129\n",
            "epoch: 19/20,    batch: 978/2993    Discriminator_loss: 0.00032252076198346913  Generator_loss: 8.213889122009277\n",
            "epoch: 19/20,    batch: 979/2993    Discriminator_loss: 0.00031561145442537963  Generator_loss: 8.246161460876465\n",
            "epoch: 19/20,    batch: 980/2993    Discriminator_loss: 0.00039819974335841835  Generator_loss: 8.25350284576416\n",
            "epoch: 19/20,    batch: 981/2993    Discriminator_loss: 0.0002890090981964022  Generator_loss: 8.243607521057129\n",
            "epoch: 19/20,    batch: 982/2993    Discriminator_loss: 0.00034517672611400485  Generator_loss: 8.220346450805664\n",
            "epoch: 19/20,    batch: 983/2993    Discriminator_loss: 0.0004230617778375745  Generator_loss: 8.188871383666992\n",
            "epoch: 19/20,    batch: 984/2993    Discriminator_loss: 0.0003006284823641181  Generator_loss: 8.151278495788574\n",
            "epoch: 19/20,    batch: 985/2993    Discriminator_loss: 0.0007224959554150701  Generator_loss: 8.109146118164062\n",
            "epoch: 19/20,    batch: 986/2993    Discriminator_loss: 0.0003900341398548335  Generator_loss: 8.063806533813477\n",
            "epoch: 19/20,    batch: 987/2993    Discriminator_loss: 0.00033690297277644277  Generator_loss: 8.016213417053223\n",
            "epoch: 19/20,    batch: 988/2993    Discriminator_loss: 0.0004789585364051163  Generator_loss: 7.966543197631836\n",
            "epoch: 19/20,    batch: 989/2993    Discriminator_loss: 0.00043353167711757123  Generator_loss: 7.914981842041016\n",
            "epoch: 19/20,    batch: 990/2993    Discriminator_loss: 0.0003937298897653818  Generator_loss: 7.861298084259033\n",
            "epoch: 19/20,    batch: 991/2993    Discriminator_loss: 0.0004210433689877391  Generator_loss: 7.805905342102051\n",
            "epoch: 19/20,    batch: 992/2993    Discriminator_loss: 0.0005320253549143672  Generator_loss: 7.747993469238281\n",
            "epoch: 19/20,    batch: 993/2993    Discriminator_loss: 0.0004897562321275473  Generator_loss: 7.687313079833984\n",
            "epoch: 19/20,    batch: 994/2993    Discriminator_loss: 0.0006215245230123401  Generator_loss: 7.624979019165039\n",
            "epoch: 19/20,    batch: 995/2993    Discriminator_loss: 0.000578539737034589  Generator_loss: 7.566721439361572\n",
            "epoch: 19/20,    batch: 996/2993    Discriminator_loss: 0.0005672667175531387  Generator_loss: 7.5049214363098145\n",
            "epoch: 19/20,    batch: 997/2993    Discriminator_loss: 0.0006033742101863027  Generator_loss: 7.438582420349121\n",
            "epoch: 19/20,    batch: 998/2993    Discriminator_loss: 0.0006693035247735679  Generator_loss: 7.375058174133301\n",
            "epoch: 19/20,    batch: 999/2993    Discriminator_loss: 0.0007503614760935307  Generator_loss: 7.311680793762207\n",
            "epoch: 19/20,    batch: 1000/2993    Discriminator_loss: 0.0007283485028892756  Generator_loss: 7.246036052703857\n",
            "epoch: 19/20,    batch: 1001/2993    Discriminator_loss: 0.0009650149731896818  Generator_loss: 7.177679061889648\n",
            "epoch: 19/20,    batch: 1002/2993    Discriminator_loss: 0.0008873848710209131  Generator_loss: 7.110190391540527\n",
            "epoch: 19/20,    batch: 1003/2993    Discriminator_loss: 0.0008954067016020417  Generator_loss: 7.045285224914551\n",
            "epoch: 19/20,    batch: 1004/2993    Discriminator_loss: 0.0009776640217751265  Generator_loss: 6.979000091552734\n",
            "epoch: 19/20,    batch: 1005/2993    Discriminator_loss: 0.0010503680678084493  Generator_loss: 6.913593292236328\n",
            "epoch: 19/20,    batch: 1006/2993    Discriminator_loss: 0.0011355130700394511  Generator_loss: 6.850072860717773\n",
            "epoch: 19/20,    batch: 1007/2993    Discriminator_loss: 0.0011734062572941184  Generator_loss: 6.789092063903809\n",
            "epoch: 19/20,    batch: 1008/2993    Discriminator_loss: 0.0015718520153313875  Generator_loss: 6.72941780090332\n",
            "epoch: 19/20,    batch: 1009/2993    Discriminator_loss: 0.0013588067376986146  Generator_loss: 6.671924114227295\n",
            "epoch: 19/20,    batch: 1010/2993    Discriminator_loss: 0.0014456551289185882  Generator_loss: 6.616550922393799\n",
            "epoch: 19/20,    batch: 1011/2993    Discriminator_loss: 0.0016187531873583794  Generator_loss: 6.565194129943848\n",
            "epoch: 19/20,    batch: 1012/2993    Discriminator_loss: 0.001573475543409586  Generator_loss: 6.518906593322754\n",
            "epoch: 19/20,    batch: 1013/2993    Discriminator_loss: 0.0016649330500513315  Generator_loss: 6.478200912475586\n",
            "epoch: 19/20,    batch: 1014/2993    Discriminator_loss: 0.0017702158074826002  Generator_loss: 6.443439960479736\n",
            "epoch: 19/20,    batch: 1015/2993    Discriminator_loss: 0.001770703005604446  Generator_loss: 6.415534019470215\n",
            "epoch: 19/20,    batch: 1016/2993    Discriminator_loss: 0.0018549555679783225  Generator_loss: 6.394361972808838\n",
            "epoch: 19/20,    batch: 1017/2993    Discriminator_loss: 0.0018908772617578506  Generator_loss: 6.379189491271973\n",
            "epoch: 19/20,    batch: 1018/2993    Discriminator_loss: 0.0018639096524566412  Generator_loss: 6.3694748878479\n",
            "epoch: 19/20,    batch: 1019/2993    Discriminator_loss: 0.0019407426007092  Generator_loss: 6.363715648651123\n",
            "epoch: 19/20,    batch: 1020/2993    Discriminator_loss: 0.0024120952002704144  Generator_loss: 6.359200477600098\n",
            "epoch: 19/20,    batch: 1021/2993    Discriminator_loss: 0.00191863055806607  Generator_loss: 6.35521125793457\n",
            "epoch: 19/20,    batch: 1022/2993    Discriminator_loss: 0.0020514638163149357  Generator_loss: 6.348984718322754\n",
            "epoch: 19/20,    batch: 1023/2993    Discriminator_loss: 0.002032921416684985  Generator_loss: 6.339915752410889\n",
            "epoch: 19/20,    batch: 1024/2993    Discriminator_loss: 0.002004076261073351  Generator_loss: 6.327378273010254\n",
            "epoch: 19/20,    batch: 1025/2993    Discriminator_loss: 0.0021107785869389772  Generator_loss: 6.310573577880859\n",
            "epoch: 19/20,    batch: 1026/2993    Discriminator_loss: 0.002152529312297702  Generator_loss: 6.292313575744629\n",
            "epoch: 19/20,    batch: 1027/2993    Discriminator_loss: 0.0022012293338775635  Generator_loss: 6.2747039794921875\n",
            "epoch: 19/20,    batch: 1028/2993    Discriminator_loss: 0.0022293790243566036  Generator_loss: 6.260486602783203\n",
            "epoch: 19/20,    batch: 1029/2993    Discriminator_loss: 0.0026593829970806837  Generator_loss: 6.252320289611816\n",
            "epoch: 19/20,    batch: 1030/2993    Discriminator_loss: 0.0022870011162012815  Generator_loss: 6.255971908569336\n",
            "epoch: 19/20,    batch: 1031/2993    Discriminator_loss: 0.0022509200498461723  Generator_loss: 6.273674488067627\n",
            "epoch: 19/20,    batch: 1032/2993    Discriminator_loss: 0.0022300786804407835  Generator_loss: 6.306118965148926\n",
            "epoch: 19/20,    batch: 1033/2993    Discriminator_loss: 0.00218215212225914  Generator_loss: 6.352354049682617\n",
            "epoch: 19/20,    batch: 1034/2993    Discriminator_loss: 0.002046174369752407  Generator_loss: 6.40626859664917\n",
            "epoch: 19/20,    batch: 1035/2993    Discriminator_loss: 0.003259213175624609  Generator_loss: 6.452264785766602\n",
            "epoch: 19/20,    batch: 1036/2993    Discriminator_loss: 0.07723882794380188  Generator_loss: 5.6072235107421875\n",
            "epoch: 19/20,    batch: 1037/2993    Discriminator_loss: 0.006328412797302008  Generator_loss: 5.036328315734863\n",
            "epoch: 19/20,    batch: 1038/2993    Discriminator_loss: 0.009704288095235825  Generator_loss: 4.814394950866699\n",
            "epoch: 19/20,    batch: 1039/2993    Discriminator_loss: 0.010330567136406898  Generator_loss: 4.952597618103027\n",
            "epoch: 19/20,    batch: 1040/2993    Discriminator_loss: 0.007649799343198538  Generator_loss: 5.3619818687438965\n",
            "epoch: 19/20,    batch: 1041/2993    Discriminator_loss: 0.004602896049618721  Generator_loss: 5.896441459655762\n",
            "epoch: 19/20,    batch: 1042/2993    Discriminator_loss: 0.0028042015619575977  Generator_loss: 6.434074401855469\n",
            "epoch: 19/20,    batch: 1043/2993    Discriminator_loss: 0.0019156544003635645  Generator_loss: 6.903543472290039\n",
            "epoch: 19/20,    batch: 1044/2993    Discriminator_loss: 0.0010388825321570039  Generator_loss: 7.275674819946289\n",
            "epoch: 19/20,    batch: 1045/2993    Discriminator_loss: 0.0007813549600541592  Generator_loss: 7.545555591583252\n",
            "epoch: 19/20,    batch: 1046/2993    Discriminator_loss: 0.0006498814327642322  Generator_loss: 7.7237772941589355\n",
            "epoch: 19/20,    batch: 1047/2993    Discriminator_loss: 0.0005217557772994041  Generator_loss: 7.8242082595825195\n",
            "epoch: 19/20,    batch: 1048/2993    Discriminator_loss: 0.0005316852475516498  Generator_loss: 7.863137722015381\n",
            "epoch: 19/20,    batch: 1049/2993    Discriminator_loss: 0.0005444223643280566  Generator_loss: 7.852551460266113\n",
            "epoch: 19/20,    batch: 1050/2993    Discriminator_loss: 0.0004885885864496231  Generator_loss: 7.802857398986816\n",
            "epoch: 19/20,    batch: 1051/2993    Discriminator_loss: 0.0005457607912831008  Generator_loss: 7.721044540405273\n",
            "epoch: 19/20,    batch: 1052/2993    Discriminator_loss: 0.0006129411631263793  Generator_loss: 7.6151018142700195\n",
            "epoch: 19/20,    batch: 1053/2993    Discriminator_loss: 0.0006562005146406591  Generator_loss: 7.49293851852417\n",
            "epoch: 19/20,    batch: 1054/2993    Discriminator_loss: 0.0007763542234897614  Generator_loss: 7.374405384063721\n",
            "epoch: 19/20,    batch: 1055/2993    Discriminator_loss: 0.0008404229301959276  Generator_loss: 7.255219459533691\n",
            "epoch: 19/20,    batch: 1056/2993    Discriminator_loss: 0.0009525744244456291  Generator_loss: 7.1185736656188965\n",
            "epoch: 19/20,    batch: 1057/2993    Discriminator_loss: 0.0011230811942368746  Generator_loss: 6.9752607345581055\n",
            "epoch: 19/20,    batch: 1058/2993    Discriminator_loss: 0.0012999665923416615  Generator_loss: 6.838125228881836\n",
            "epoch: 19/20,    batch: 1059/2993    Discriminator_loss: 0.0014652787940576673  Generator_loss: 6.7187180519104\n",
            "epoch: 19/20,    batch: 1060/2993    Discriminator_loss: 0.0016853868728503585  Generator_loss: 6.6200666427612305\n",
            "epoch: 19/20,    batch: 1061/2993    Discriminator_loss: 0.0018887787591665983  Generator_loss: 6.5449981689453125\n",
            "epoch: 19/20,    batch: 1062/2993    Discriminator_loss: 0.0020047433208674192  Generator_loss: 6.494021415710449\n",
            "epoch: 19/20,    batch: 1063/2993    Discriminator_loss: 0.0022236215882003307  Generator_loss: 6.468713760375977\n",
            "epoch: 19/20,    batch: 1064/2993    Discriminator_loss: 0.002326531335711479  Generator_loss: 6.4393157958984375\n",
            "epoch: 19/20,    batch: 1065/2993    Discriminator_loss: 0.0023591388016939163  Generator_loss: 6.48171329498291\n",
            "epoch: 19/20,    batch: 1066/2993    Discriminator_loss: 0.002078115241602063  Generator_loss: 6.727902889251709\n",
            "epoch: 19/20,    batch: 1067/2993    Discriminator_loss: 0.0023307285737246275  Generator_loss: 6.56364631652832\n",
            "epoch: 19/20,    batch: 1068/2993    Discriminator_loss: 0.0017806289251893759  Generator_loss: 6.8555684089660645\n",
            "epoch: 19/20,    batch: 1069/2993    Discriminator_loss: 0.0015535560669377446  Generator_loss: 6.965209007263184\n",
            "epoch: 19/20,    batch: 1070/2993    Discriminator_loss: 0.003170716343447566  Generator_loss: 7.004533767700195\n",
            "epoch: 19/20,    batch: 1071/2993    Discriminator_loss: 0.0015535899437963963  Generator_loss: 7.008953094482422\n",
            "epoch: 19/20,    batch: 1072/2993    Discriminator_loss: 0.0015408676117658615  Generator_loss: 6.986798286437988\n",
            "epoch: 19/20,    batch: 1073/2993    Discriminator_loss: 0.001647204509936273  Generator_loss: 6.945733547210693\n",
            "epoch: 19/20,    batch: 1074/2993    Discriminator_loss: 0.0018180798506364226  Generator_loss: 6.894333839416504\n",
            "epoch: 19/20,    batch: 1075/2993    Discriminator_loss: 0.0017681603785604239  Generator_loss: 6.981791973114014\n",
            "epoch: 19/20,    batch: 1076/2993    Discriminator_loss: 0.0018722859676927328  Generator_loss: 6.902146816253662\n",
            "epoch: 19/20,    batch: 1077/2993    Discriminator_loss: 0.009361352771520615  Generator_loss: 6.858449935913086\n",
            "epoch: 19/20,    batch: 1078/2993    Discriminator_loss: 0.002954240655526519  Generator_loss: 6.846332550048828\n",
            "epoch: 19/20,    batch: 1079/2993    Discriminator_loss: 0.0020860517397522926  Generator_loss: 6.853652000427246\n",
            "epoch: 19/20,    batch: 1080/2993    Discriminator_loss: 0.0021070961374789476  Generator_loss: 6.916924953460693\n",
            "epoch: 19/20,    batch: 1081/2993    Discriminator_loss: 0.0019248179160058498  Generator_loss: 7.051139831542969\n",
            "epoch: 19/20,    batch: 1082/2993    Discriminator_loss: 0.001653303625062108  Generator_loss: 7.2005157470703125\n",
            "epoch: 19/20,    batch: 1083/2993    Discriminator_loss: 0.0015736904460936785  Generator_loss: 7.30754280090332\n",
            "epoch: 19/20,    batch: 1084/2993    Discriminator_loss: 0.0014741055201739073  Generator_loss: 7.339573860168457\n",
            "epoch: 19/20,    batch: 1085/2993    Discriminator_loss: 0.0017077067168429494  Generator_loss: 7.153010845184326\n",
            "epoch: 19/20,    batch: 1086/2993    Discriminator_loss: 0.001808395842090249  Generator_loss: 7.138561248779297\n",
            "epoch: 19/20,    batch: 1087/2993    Discriminator_loss: 0.0019434134010225534  Generator_loss: 7.086050987243652\n",
            "epoch: 19/20,    batch: 1088/2993    Discriminator_loss: 0.0020611051004379988  Generator_loss: 7.101912498474121\n",
            "epoch: 19/20,    batch: 1089/2993    Discriminator_loss: 0.0020531676709651947  Generator_loss: 7.1496782302856445\n",
            "epoch: 19/20,    batch: 1090/2993    Discriminator_loss: 0.002017694991081953  Generator_loss: 7.164730072021484\n",
            "epoch: 19/20,    batch: 1091/2993    Discriminator_loss: 0.0019277571700513363  Generator_loss: 7.253503322601318\n",
            "epoch: 19/20,    batch: 1092/2993    Discriminator_loss: 0.0020592997316271067  Generator_loss: 7.335778713226318\n",
            "epoch: 19/20,    batch: 1093/2993    Discriminator_loss: 0.001744554378092289  Generator_loss: 7.378091812133789\n",
            "epoch: 19/20,    batch: 1094/2993    Discriminator_loss: 0.0019790646620094776  Generator_loss: 7.342830657958984\n",
            "epoch: 19/20,    batch: 1095/2993    Discriminator_loss: 0.0012677303748205304  Generator_loss: 7.788046836853027\n",
            "epoch: 19/20,    batch: 1096/2993    Discriminator_loss: 0.0012367375893518329  Generator_loss: 7.64199686050415\n",
            "epoch: 19/20,    batch: 1097/2993    Discriminator_loss: 0.0015893119852989912  Generator_loss: 7.381182670593262\n",
            "epoch: 19/20,    batch: 1098/2993    Discriminator_loss: 0.002333682030439377  Generator_loss: 7.127558708190918\n",
            "epoch: 19/20,    batch: 1099/2993    Discriminator_loss: 0.00197707861661911  Generator_loss: 7.367999076843262\n",
            "epoch: 19/20,    batch: 1100/2993    Discriminator_loss: 0.00226505845785141  Generator_loss: 7.280971527099609\n",
            "epoch: 19/20,    batch: 1101/2993    Discriminator_loss: 0.0015347088919952512  Generator_loss: 7.723590850830078\n",
            "epoch: 19/20,    batch: 1102/2993    Discriminator_loss: 0.00117435900028795  Generator_loss: 7.989591121673584\n",
            "epoch: 19/20,    batch: 1103/2993    Discriminator_loss: 0.0009399257833138108  Generator_loss: 8.118626594543457\n",
            "epoch: 19/20,    batch: 1104/2993    Discriminator_loss: 0.0009545162902213633  Generator_loss: 8.106050491333008\n",
            "epoch: 19/20,    batch: 1105/2993    Discriminator_loss: 0.0022057085298001766  Generator_loss: 7.986025810241699\n",
            "epoch: 19/20,    batch: 1106/2993    Discriminator_loss: 0.0011355073656886816  Generator_loss: 7.826199054718018\n",
            "epoch: 19/20,    batch: 1107/2993    Discriminator_loss: 0.002966890810057521  Generator_loss: 7.671965599060059\n",
            "epoch: 19/20,    batch: 1108/2993    Discriminator_loss: 0.0014622355811297894  Generator_loss: 7.659152030944824\n",
            "epoch: 19/20,    batch: 1109/2993    Discriminator_loss: 0.0014817051123827696  Generator_loss: 7.682389259338379\n",
            "epoch: 19/20,    batch: 1110/2993    Discriminator_loss: 0.0013999443035572767  Generator_loss: 7.842893600463867\n",
            "epoch: 19/20,    batch: 1111/2993    Discriminator_loss: 0.001116136321797967  Generator_loss: 8.04326057434082\n",
            "epoch: 19/20,    batch: 1112/2993    Discriminator_loss: 0.0008904067799448967  Generator_loss: 8.22573471069336\n",
            "epoch: 19/20,    batch: 1113/2993    Discriminator_loss: 0.0017363708466291428  Generator_loss: 8.333425521850586\n",
            "epoch: 19/20,    batch: 1114/2993    Discriminator_loss: 0.0006961320759728551  Generator_loss: 8.3812837600708\n",
            "epoch: 19/20,    batch: 1115/2993    Discriminator_loss: 0.0007322985329665244  Generator_loss: 8.37069034576416\n",
            "epoch: 19/20,    batch: 1116/2993    Discriminator_loss: 0.000693321751896292  Generator_loss: 8.316641807556152\n",
            "epoch: 19/20,    batch: 1117/2993    Discriminator_loss: 0.0006813482032157481  Generator_loss: 8.244914054870605\n",
            "epoch: 19/20,    batch: 1118/2993    Discriminator_loss: 0.0008757198811508715  Generator_loss: 8.164519309997559\n",
            "epoch: 19/20,    batch: 1119/2993    Discriminator_loss: 0.0007946969126351178  Generator_loss: 8.113221168518066\n",
            "epoch: 19/20,    batch: 1120/2993    Discriminator_loss: 0.0007476484752260149  Generator_loss: 8.113618850708008\n",
            "epoch: 19/20,    batch: 1121/2993    Discriminator_loss: 0.0038732592947781086  Generator_loss: 8.059843063354492\n",
            "epoch: 19/20,    batch: 1122/2993    Discriminator_loss: 0.0008421096717938781  Generator_loss: 8.060524940490723\n",
            "epoch: 19/20,    batch: 1123/2993    Discriminator_loss: 0.0007312387460842729  Generator_loss: 8.13194751739502\n",
            "epoch: 19/20,    batch: 1124/2993    Discriminator_loss: 0.0009038981515914202  Generator_loss: 8.222330093383789\n",
            "epoch: 19/20,    batch: 1125/2993    Discriminator_loss: 0.0007444022921845317  Generator_loss: 8.301155090332031\n",
            "epoch: 19/20,    batch: 1126/2993    Discriminator_loss: 0.0005555686657316983  Generator_loss: 8.352057456970215\n",
            "epoch: 19/20,    batch: 1127/2993    Discriminator_loss: 0.01275772973895073  Generator_loss: 8.190038681030273\n",
            "epoch: 19/20,    batch: 1128/2993    Discriminator_loss: 0.0007016781019046903  Generator_loss: 8.102668762207031\n",
            "epoch: 19/20,    batch: 1129/2993    Discriminator_loss: 0.0007320460863411427  Generator_loss: 8.100471496582031\n",
            "epoch: 19/20,    batch: 1130/2993    Discriminator_loss: 0.0007221215637400746  Generator_loss: 8.160025596618652\n",
            "epoch: 19/20,    batch: 1131/2993    Discriminator_loss: 0.0006763388519175351  Generator_loss: 8.252017974853516\n",
            "epoch: 19/20,    batch: 1132/2993    Discriminator_loss: 0.0005380635848268867  Generator_loss: 8.338615417480469\n",
            "epoch: 19/20,    batch: 1133/2993    Discriminator_loss: 0.0007062307558953762  Generator_loss: 8.390691757202148\n",
            "epoch: 19/20,    batch: 1134/2993    Discriminator_loss: 0.000663471408188343  Generator_loss: 8.397478103637695\n",
            "epoch: 19/20,    batch: 1135/2993    Discriminator_loss: 0.0005065532750450075  Generator_loss: 8.365076065063477\n",
            "epoch: 19/20,    batch: 1136/2993    Discriminator_loss: 0.0005297159077599645  Generator_loss: 8.295916557312012\n",
            "epoch: 19/20,    batch: 1137/2993    Discriminator_loss: 0.0006315193604677916  Generator_loss: 8.200706481933594\n",
            "epoch: 19/20,    batch: 1138/2993    Discriminator_loss: 0.0005485510337166488  Generator_loss: 8.09402847290039\n",
            "epoch: 19/20,    batch: 1139/2993    Discriminator_loss: 0.0006060669547878206  Generator_loss: 7.9908976554870605\n",
            "epoch: 19/20,    batch: 1140/2993    Discriminator_loss: 0.002017166931182146  Generator_loss: 7.884003639221191\n",
            "epoch: 19/20,    batch: 1141/2993    Discriminator_loss: 0.0007724160677753389  Generator_loss: 7.81917667388916\n",
            "epoch: 19/20,    batch: 1142/2993    Discriminator_loss: 0.0007590295863337815  Generator_loss: 7.7975287437438965\n",
            "epoch: 19/20,    batch: 1143/2993    Discriminator_loss: 0.0008991574868559837  Generator_loss: 7.815187931060791\n",
            "epoch: 19/20,    batch: 1144/2993    Discriminator_loss: 0.0007216934463940561  Generator_loss: 7.859832763671875\n",
            "epoch: 19/20,    batch: 1145/2993    Discriminator_loss: 0.015178331173956394  Generator_loss: 7.763028621673584\n",
            "epoch: 19/20,    batch: 1146/2993    Discriminator_loss: 0.0013162919785827398  Generator_loss: 7.717487812042236\n",
            "epoch: 19/20,    batch: 1147/2993    Discriminator_loss: 0.000739091366995126  Generator_loss: 7.724860191345215\n",
            "epoch: 19/20,    batch: 1148/2993    Discriminator_loss: 0.0008109899354167283  Generator_loss: 7.767422676086426\n",
            "epoch: 19/20,    batch: 1149/2993    Discriminator_loss: 0.0007102700183168054  Generator_loss: 7.828662395477295\n",
            "epoch: 19/20,    batch: 1150/2993    Discriminator_loss: 0.0005954241496510804  Generator_loss: 7.892951011657715\n",
            "epoch: 19/20,    batch: 1151/2993    Discriminator_loss: 0.0037975844461470842  Generator_loss: 7.931011199951172\n",
            "epoch: 19/20,    batch: 1152/2993    Discriminator_loss: 0.0006042011082172394  Generator_loss: 7.964548110961914\n",
            "epoch: 19/20,    batch: 1153/2993    Discriminator_loss: 0.0004931244184263051  Generator_loss: 7.991587162017822\n",
            "epoch: 19/20,    batch: 1154/2993    Discriminator_loss: 0.0006982223712839186  Generator_loss: 8.011137008666992\n",
            "epoch: 19/20,    batch: 1155/2993    Discriminator_loss: 0.0004940871149301529  Generator_loss: 8.023781776428223\n",
            "epoch: 19/20,    batch: 1156/2993    Discriminator_loss: 0.00045618898002430797  Generator_loss: 8.029014587402344\n",
            "epoch: 19/20,    batch: 1157/2993    Discriminator_loss: 0.13833969831466675  Generator_loss: 4.905210494995117\n",
            "epoch: 19/20,    batch: 1158/2993    Discriminator_loss: 0.041659001260995865  Generator_loss: 6.763233184814453\n",
            "epoch: 19/20,    batch: 1159/2993    Discriminator_loss: 9.946239151759073e-05  Generator_loss: 11.299545288085938\n",
            "epoch: 19/20,    batch: 1160/2993    Discriminator_loss: 0.13880684971809387  Generator_loss: 12.420775413513184\n",
            "epoch: 19/20,    batch: 1161/2993    Discriminator_loss: 6.139928882475942e-05  Generator_loss: 13.061005592346191\n",
            "epoch: 19/20,    batch: 1162/2993    Discriminator_loss: 3.4604003303684294e-05  Generator_loss: 13.389908790588379\n",
            "epoch: 19/20,    batch: 1163/2993    Discriminator_loss: 8.66344416863285e-05  Generator_loss: 13.656044960021973\n",
            "epoch: 19/20,    batch: 1164/2993    Discriminator_loss: 0.0024229635018855333  Generator_loss: 13.763227462768555\n",
            "epoch: 19/20,    batch: 1165/2993    Discriminator_loss: 4.048957271152176e-05  Generator_loss: 13.763227462768555\n",
            "epoch: 19/20,    batch: 1166/2993    Discriminator_loss: 1.1392130545573309e-05  Generator_loss: 13.726383209228516\n",
            "epoch: 19/20,    batch: 1167/2993    Discriminator_loss: 5.513509313459508e-05  Generator_loss: 13.656044960021973\n",
            "epoch: 19/20,    batch: 1168/2993    Discriminator_loss: 4.990312299923971e-05  Generator_loss: 13.559247016906738\n",
            "epoch: 19/20,    batch: 1169/2993    Discriminator_loss: 3.5200795537093654e-05  Generator_loss: 13.47099781036377\n",
            "epoch: 19/20,    batch: 1170/2993    Discriminator_loss: 3.243876562919468e-05  Generator_loss: 13.31490421295166\n",
            "epoch: 19/20,    batch: 1171/2993    Discriminator_loss: 3.317495793453418e-05  Generator_loss: 13.17991828918457\n",
            "epoch: 19/20,    batch: 1172/2993    Discriminator_loss: 3.941463364753872e-05  Generator_loss: 13.061005592346191\n",
            "epoch: 19/20,    batch: 1173/2993    Discriminator_loss: 1.6149449947988614e-05  Generator_loss: 12.90556526184082\n",
            "epoch: 19/20,    batch: 1174/2993    Discriminator_loss: 4.6783010475337505e-05  Generator_loss: 12.771068572998047\n",
            "epoch: 19/20,    batch: 1175/2993    Discriminator_loss: 0.0027132576797157526  Generator_loss: 12.58066177368164\n",
            "epoch: 19/20,    batch: 1176/2993    Discriminator_loss: 2.461435906297993e-05  Generator_loss: 12.420775413513184\n",
            "epoch: 19/20,    batch: 1177/2993    Discriminator_loss: 8.195034024538472e-05  Generator_loss: 12.257542610168457\n",
            "epoch: 19/20,    batch: 1178/2993    Discriminator_loss: 4.6260320232249796e-05  Generator_loss: 12.095671653747559\n",
            "epoch: 19/20,    batch: 1179/2993    Discriminator_loss: 2.6852983864955604e-05  Generator_loss: 11.937986373901367\n",
            "epoch: 19/20,    batch: 1180/2993    Discriminator_loss: 3.0156676075421274e-05  Generator_loss: 11.786023139953613\n",
            "epoch: 19/20,    batch: 1181/2993    Discriminator_loss: 5.548872286453843e-05  Generator_loss: 11.627047538757324\n",
            "epoch: 19/20,    batch: 1182/2993    Discriminator_loss: 1.390472607454285e-05  Generator_loss: 11.466880798339844\n",
            "epoch: 19/20,    batch: 1183/2993    Discriminator_loss: 4.260013156454079e-05  Generator_loss: 11.309222221374512\n",
            "epoch: 19/20,    batch: 1184/2993    Discriminator_loss: 6.108028173912317e-05  Generator_loss: 11.143548965454102\n",
            "epoch: 19/20,    batch: 1185/2993    Discriminator_loss: 2.4153168851626106e-05  Generator_loss: 10.972176551818848\n",
            "epoch: 19/20,    batch: 1186/2993    Discriminator_loss: 3.489700611680746e-05  Generator_loss: 10.749460220336914\n",
            "epoch: 19/20,    batch: 1187/2993    Discriminator_loss: 9.450665675103664e-05  Generator_loss: 10.5774564743042\n",
            "epoch: 19/20,    batch: 1188/2993    Discriminator_loss: 5.0799189921235666e-05  Generator_loss: 10.421568870544434\n",
            "epoch: 19/20,    batch: 1189/2993    Discriminator_loss: 7.534606265835464e-05  Generator_loss: 10.24930191040039\n",
            "epoch: 19/20,    batch: 1190/2993    Discriminator_loss: 9.466319170314819e-05  Generator_loss: 10.068170547485352\n",
            "epoch: 19/20,    batch: 1191/2993    Discriminator_loss: 7.688446203246713e-05  Generator_loss: 9.882762908935547\n",
            "epoch: 19/20,    batch: 1192/2993    Discriminator_loss: 0.00011319230543449521  Generator_loss: 9.692721366882324\n",
            "epoch: 19/20,    batch: 1193/2993    Discriminator_loss: 9.173093712888658e-05  Generator_loss: 9.500202178955078\n",
            "epoch: 19/20,    batch: 1194/2993    Discriminator_loss: 0.00013712942018173635  Generator_loss: 9.306363105773926\n",
            "epoch: 19/20,    batch: 1195/2993    Discriminator_loss: 0.0001389658427797258  Generator_loss: 9.111886978149414\n",
            "epoch: 19/20,    batch: 1196/2993    Discriminator_loss: 0.000223640920012258  Generator_loss: 8.917712211608887\n",
            "epoch: 19/20,    batch: 1197/2993    Discriminator_loss: 0.00020216635311953723  Generator_loss: 8.724967956542969\n",
            "epoch: 19/20,    batch: 1198/2993    Discriminator_loss: 0.0002143208694178611  Generator_loss: 8.535354614257812\n",
            "epoch: 19/20,    batch: 1199/2993    Discriminator_loss: 0.0003295095812063664  Generator_loss: 8.34998893737793\n",
            "epoch: 19/20,    batch: 1200/2993    Discriminator_loss: 0.00030102269374765456  Generator_loss: 8.1695556640625\n",
            "epoch: 19/20,    batch: 1201/2993    Discriminator_loss: 0.00037104255170561373  Generator_loss: 7.995615005493164\n",
            "epoch: 19/20,    batch: 1202/2993    Discriminator_loss: 0.0004845252842642367  Generator_loss: 7.829297065734863\n",
            "epoch: 19/20,    batch: 1203/2993    Discriminator_loss: 0.000482954055769369  Generator_loss: 7.67183780670166\n",
            "epoch: 19/20,    batch: 1204/2993    Discriminator_loss: 0.0005997103871777654  Generator_loss: 7.524813652038574\n",
            "epoch: 19/20,    batch: 1205/2993    Discriminator_loss: 0.0007065644604153931  Generator_loss: 7.3896026611328125\n",
            "epoch: 19/20,    batch: 1206/2993    Discriminator_loss: 0.000734930217731744  Generator_loss: 7.267922401428223\n",
            "epoch: 19/20,    batch: 1207/2993    Discriminator_loss: 0.0009242770029231906  Generator_loss: 7.161354064941406\n",
            "epoch: 19/20,    batch: 1208/2993    Discriminator_loss: 0.0010413762647658587  Generator_loss: 7.070578098297119\n",
            "epoch: 19/20,    batch: 1209/2993    Discriminator_loss: 0.0010035078739747405  Generator_loss: 6.996304035186768\n",
            "epoch: 19/20,    batch: 1210/2993    Discriminator_loss: 0.0011486744042485952  Generator_loss: 6.938439846038818\n",
            "epoch: 19/20,    batch: 1211/2993    Discriminator_loss: 0.0011553558288142085  Generator_loss: 6.895704746246338\n",
            "epoch: 19/20,    batch: 1212/2993    Discriminator_loss: 0.0011404628166928887  Generator_loss: 6.867550373077393\n",
            "epoch: 19/20,    batch: 1213/2993    Discriminator_loss: 0.0011724727228283882  Generator_loss: 6.852212905883789\n",
            "epoch: 19/20,    batch: 1214/2993    Discriminator_loss: 0.001232514507137239  Generator_loss: 6.8474531173706055\n",
            "epoch: 19/20,    batch: 1215/2993    Discriminator_loss: 0.0011644231854006648  Generator_loss: 6.851346492767334\n",
            "epoch: 19/20,    batch: 1216/2993    Discriminator_loss: 0.0011808887356892228  Generator_loss: 6.862015247344971\n",
            "epoch: 19/20,    batch: 1217/2993    Discriminator_loss: 0.001218658173456788  Generator_loss: 6.876706600189209\n",
            "epoch: 19/20,    batch: 1218/2993    Discriminator_loss: 0.001141311600804329  Generator_loss: 6.89365291595459\n",
            "epoch: 19/20,    batch: 1219/2993    Discriminator_loss: 0.0011226731585338712  Generator_loss: 6.911800384521484\n",
            "epoch: 19/20,    batch: 1220/2993    Discriminator_loss: 0.0011255457065999508  Generator_loss: 6.933737277984619\n",
            "epoch: 19/20,    batch: 1221/2993    Discriminator_loss: 0.0010799341835081577  Generator_loss: 6.953744888305664\n",
            "epoch: 19/20,    batch: 1222/2993    Discriminator_loss: 0.0010973085882142186  Generator_loss: 6.965433120727539\n",
            "epoch: 19/20,    batch: 1223/2993    Discriminator_loss: 0.0010673602810129523  Generator_loss: 6.976895809173584\n",
            "epoch: 19/20,    batch: 1224/2993    Discriminator_loss: 0.0010461973724886775  Generator_loss: 6.987369537353516\n",
            "epoch: 19/20,    batch: 1225/2993    Discriminator_loss: 0.0011177585693076253  Generator_loss: 6.991598129272461\n",
            "epoch: 19/20,    batch: 1226/2993    Discriminator_loss: 0.0010360566666349769  Generator_loss: 6.988713264465332\n",
            "epoch: 19/20,    batch: 1227/2993    Discriminator_loss: 0.0011079518590122461  Generator_loss: 6.985285758972168\n",
            "epoch: 19/20,    batch: 1228/2993    Discriminator_loss: 0.001222890568897128  Generator_loss: 6.979876518249512\n",
            "epoch: 19/20,    batch: 1229/2993    Discriminator_loss: 0.0011386387050151825  Generator_loss: 6.966708660125732\n",
            "epoch: 19/20,    batch: 1230/2993    Discriminator_loss: 0.0010826654033735394  Generator_loss: 6.953561782836914\n",
            "epoch: 19/20,    batch: 1231/2993    Discriminator_loss: 0.0011612919624894857  Generator_loss: 6.939985275268555\n",
            "epoch: 19/20,    batch: 1232/2993    Discriminator_loss: 0.0011413343017920852  Generator_loss: 6.923732757568359\n",
            "epoch: 19/20,    batch: 1233/2993    Discriminator_loss: 0.0011322193313390017  Generator_loss: 6.908533096313477\n",
            "epoch: 19/20,    batch: 1234/2993    Discriminator_loss: 0.0011952391359955072  Generator_loss: 6.898170471191406\n",
            "epoch: 19/20,    batch: 1235/2993    Discriminator_loss: 0.0012515508569777012  Generator_loss: 6.891968727111816\n",
            "epoch: 19/20,    batch: 1236/2993    Discriminator_loss: 0.0013607729924842715  Generator_loss: 6.889654159545898\n",
            "epoch: 19/20,    batch: 1237/2993    Discriminator_loss: 0.0011656183050945401  Generator_loss: 6.893836975097656\n",
            "epoch: 19/20,    batch: 1238/2993    Discriminator_loss: 0.001195891760289669  Generator_loss: 6.9052205085754395\n",
            "epoch: 19/20,    batch: 1239/2993    Discriminator_loss: 0.0011566507164388895  Generator_loss: 6.920452117919922\n",
            "epoch: 19/20,    batch: 1240/2993    Discriminator_loss: 0.001204481697641313  Generator_loss: 6.935650825500488\n",
            "epoch: 19/20,    batch: 1241/2993    Discriminator_loss: 0.0011816147016361356  Generator_loss: 6.9490790367126465\n",
            "epoch: 19/20,    batch: 1242/2993    Discriminator_loss: 0.0010682597057893872  Generator_loss: 6.958256244659424\n",
            "epoch: 19/20,    batch: 1243/2993    Discriminator_loss: 0.0010782016906887293  Generator_loss: 6.959362030029297\n",
            "epoch: 19/20,    batch: 1244/2993    Discriminator_loss: 0.0011581352446228266  Generator_loss: 6.948153495788574\n",
            "epoch: 19/20,    batch: 1245/2993    Discriminator_loss: 0.001138233346864581  Generator_loss: 6.92221212387085\n",
            "epoch: 19/20,    batch: 1246/2993    Discriminator_loss: 0.0012163405772298574  Generator_loss: 6.881010055541992\n",
            "epoch: 19/20,    batch: 1247/2993    Discriminator_loss: 0.0013128183782100677  Generator_loss: 6.82328462600708\n",
            "epoch: 19/20,    batch: 1248/2993    Discriminator_loss: 0.0013624868588522077  Generator_loss: 6.755033016204834\n",
            "epoch: 19/20,    batch: 1249/2993    Discriminator_loss: 0.0015233641024678946  Generator_loss: 6.683226108551025\n",
            "epoch: 19/20,    batch: 1250/2993    Discriminator_loss: 0.0016873307758942246  Generator_loss: 6.620479583740234\n",
            "epoch: 19/20,    batch: 1251/2993    Discriminator_loss: 0.0017988355830311775  Generator_loss: 6.579324722290039\n",
            "epoch: 19/20,    batch: 1252/2993    Discriminator_loss: 0.0018859327537938952  Generator_loss: 6.568499565124512\n",
            "epoch: 19/20,    batch: 1253/2993    Discriminator_loss: 0.0018905914621427655  Generator_loss: 6.589259624481201\n",
            "epoch: 19/20,    batch: 1254/2993    Discriminator_loss: 0.001827900530770421  Generator_loss: 6.635814666748047\n",
            "epoch: 19/20,    batch: 1255/2993    Discriminator_loss: 0.0018002507276833057  Generator_loss: 6.693042755126953\n",
            "epoch: 19/20,    batch: 1256/2993    Discriminator_loss: 0.0016648118617013097  Generator_loss: 6.741771697998047\n",
            "epoch: 19/20,    batch: 1257/2993    Discriminator_loss: 0.001722907880321145  Generator_loss: 6.727673530578613\n",
            "epoch: 19/20,    batch: 1258/2993    Discriminator_loss: 0.001607133774086833  Generator_loss: 6.810977458953857\n",
            "epoch: 19/20,    batch: 1259/2993    Discriminator_loss: 0.0018124158959835768  Generator_loss: 6.683560371398926\n",
            "epoch: 19/20,    batch: 1260/2993    Discriminator_loss: 0.001916948240250349  Generator_loss: 6.649284362792969\n",
            "epoch: 19/20,    batch: 1261/2993    Discriminator_loss: 0.0022604467812925577  Generator_loss: 6.51140022277832\n",
            "epoch: 19/20,    batch: 1262/2993    Discriminator_loss: 0.002940216101706028  Generator_loss: 6.31473445892334\n",
            "epoch: 19/20,    batch: 1263/2993    Discriminator_loss: 0.003729239571839571  Generator_loss: 6.170703887939453\n",
            "epoch: 19/20,    batch: 1264/2993    Discriminator_loss: 0.004514479544013739  Generator_loss: 6.077484130859375\n",
            "epoch: 19/20,    batch: 1265/2993    Discriminator_loss: 0.005089638754725456  Generator_loss: 6.053145408630371\n",
            "epoch: 19/20,    batch: 1266/2993    Discriminator_loss: 0.0051645552739501  Generator_loss: 6.137030601501465\n",
            "epoch: 19/20,    batch: 1267/2993    Discriminator_loss: 0.005318866111338139  Generator_loss: 6.145084381103516\n",
            "epoch: 19/20,    batch: 1268/2993    Discriminator_loss: 0.020574314519762993  Generator_loss: 5.249328136444092\n",
            "epoch: 19/20,    batch: 1269/2993    Discriminator_loss: 0.006549635902047157  Generator_loss: 7.502300262451172\n",
            "epoch: 19/20,    batch: 1270/2993    Discriminator_loss: 0.002037863014265895  Generator_loss: 8.91379165649414\n",
            "epoch: 19/20,    batch: 1271/2993    Discriminator_loss: 0.00025533887674100697  Generator_loss: 10.284205436706543\n",
            "epoch: 19/20,    batch: 1272/2993    Discriminator_loss: 0.0001969808799913153  Generator_loss: 9.835403442382812\n",
            "epoch: 19/20,    batch: 1273/2993    Discriminator_loss: 0.0003832050133496523  Generator_loss: 9.638274192810059\n",
            "epoch: 19/20,    batch: 1274/2993    Discriminator_loss: 0.0002735544112510979  Generator_loss: 9.143108367919922\n",
            "epoch: 19/20,    batch: 1275/2993    Discriminator_loss: 0.0005443122354336083  Generator_loss: 8.262535095214844\n",
            "epoch: 19/20,    batch: 1276/2993    Discriminator_loss: 0.0013966928236186504  Generator_loss: 7.135095596313477\n",
            "epoch: 19/20,    batch: 1277/2993    Discriminator_loss: 0.0030166120268404484  Generator_loss: 6.192083358764648\n",
            "epoch: 19/20,    batch: 1278/2993    Discriminator_loss: 0.005410891957581043  Generator_loss: 5.559417724609375\n",
            "epoch: 19/20,    batch: 1279/2993    Discriminator_loss: 0.008184811100363731  Generator_loss: 5.156537055969238\n",
            "epoch: 19/20,    batch: 1280/2993    Discriminator_loss: 0.010378170758485794  Generator_loss: 4.944733619689941\n",
            "epoch: 19/20,    batch: 1281/2993    Discriminator_loss: 0.01348303072154522  Generator_loss: 4.848252296447754\n",
            "epoch: 19/20,    batch: 1282/2993    Discriminator_loss: 0.011886476539075375  Generator_loss: 4.819405555725098\n",
            "epoch: 19/20,    batch: 1283/2993    Discriminator_loss: 0.011514040641486645  Generator_loss: 4.850091934204102\n",
            "epoch: 19/20,    batch: 1284/2993    Discriminator_loss: 0.011412719264626503  Generator_loss: 4.878032684326172\n",
            "epoch: 19/20,    batch: 1285/2993    Discriminator_loss: 0.010840978473424911  Generator_loss: 4.932944297790527\n",
            "epoch: 19/20,    batch: 1286/2993    Discriminator_loss: 0.01044230442494154  Generator_loss: 4.954401969909668\n",
            "epoch: 19/20,    batch: 1287/2993    Discriminator_loss: 0.010477542877197266  Generator_loss: 4.963226318359375\n",
            "epoch: 19/20,    batch: 1288/2993    Discriminator_loss: 0.010313458740711212  Generator_loss: 4.989323139190674\n",
            "epoch: 19/20,    batch: 1289/2993    Discriminator_loss: 0.010125384666025639  Generator_loss: 5.019732475280762\n",
            "epoch: 19/20,    batch: 1290/2993    Discriminator_loss: 0.010378449223935604  Generator_loss: 5.001125335693359\n",
            "epoch: 19/20,    batch: 1291/2993    Discriminator_loss: 0.012642251327633858  Generator_loss: 4.792031764984131\n",
            "epoch: 19/20,    batch: 1292/2993    Discriminator_loss: 0.012049932964146137  Generator_loss: 4.825783729553223\n",
            "epoch: 19/20,    batch: 1293/2993    Discriminator_loss: 0.010227004997432232  Generator_loss: 5.006509304046631\n",
            "epoch: 19/20,    batch: 1294/2993    Discriminator_loss: 0.008397658355534077  Generator_loss: 5.190576553344727\n",
            "epoch: 19/20,    batch: 1295/2993    Discriminator_loss: 0.006783994846045971  Generator_loss: 5.370701789855957\n",
            "epoch: 19/20,    batch: 1296/2993    Discriminator_loss: 0.004152198322117329  Generator_loss: 5.860613822937012\n",
            "epoch: 19/20,    batch: 1297/2993    Discriminator_loss: 0.004987726919353008  Generator_loss: 5.716666221618652\n",
            "epoch: 19/20,    batch: 1298/2993    Discriminator_loss: 0.004412309266626835  Generator_loss: 5.838895797729492\n",
            "epoch: 19/20,    batch: 1299/2993    Discriminator_loss: 0.0038821676280349493  Generator_loss: 5.917518138885498\n",
            "epoch: 19/20,    batch: 1300/2993    Discriminator_loss: 0.004040299449115992  Generator_loss: 5.953182220458984\n",
            "epoch: 19/20,    batch: 1301/2993    Discriminator_loss: 0.003604090539738536  Generator_loss: 5.951899528503418\n",
            "epoch: 19/20,    batch: 1302/2993    Discriminator_loss: 0.003646974451839924  Generator_loss: 5.924984931945801\n",
            "epoch: 19/20,    batch: 1303/2993    Discriminator_loss: 0.003910313360393047  Generator_loss: 5.882045269012451\n",
            "epoch: 19/20,    batch: 1304/2993    Discriminator_loss: 0.00398242799565196  Generator_loss: 5.8326921463012695\n",
            "epoch: 19/20,    batch: 1305/2993    Discriminator_loss: 0.004173405934125185  Generator_loss: 5.783225059509277\n",
            "epoch: 19/20,    batch: 1306/2993    Discriminator_loss: 0.004308693576604128  Generator_loss: 5.7359418869018555\n",
            "epoch: 19/20,    batch: 1307/2993    Discriminator_loss: 0.005059374962002039  Generator_loss: 5.696510314941406\n",
            "epoch: 19/20,    batch: 1308/2993    Discriminator_loss: 0.004536454100161791  Generator_loss: 5.667081832885742\n",
            "epoch: 19/20,    batch: 1309/2993    Discriminator_loss: 0.004578994121402502  Generator_loss: 5.651447772979736\n",
            "epoch: 19/20,    batch: 1310/2993    Discriminator_loss: 0.0064310794696211815  Generator_loss: 5.640835285186768\n",
            "epoch: 19/20,    batch: 1311/2993    Discriminator_loss: 0.004721212200820446  Generator_loss: 5.641819000244141\n",
            "epoch: 19/20,    batch: 1312/2993    Discriminator_loss: 0.004428743850439787  Generator_loss: 5.651864051818848\n",
            "epoch: 19/20,    batch: 1313/2993    Discriminator_loss: 0.004712820053100586  Generator_loss: 5.668473243713379\n",
            "epoch: 19/20,    batch: 1314/2993    Discriminator_loss: 0.0041607036255300045  Generator_loss: 5.691833019256592\n",
            "epoch: 19/20,    batch: 1315/2993    Discriminator_loss: 0.0040595256723463535  Generator_loss: 5.710140228271484\n",
            "epoch: 19/20,    batch: 1316/2993    Discriminator_loss: 0.004024182911962271  Generator_loss: 5.731049537658691\n",
            "epoch: 19/20,    batch: 1317/2993    Discriminator_loss: 0.004007391165941954  Generator_loss: 5.722020626068115\n",
            "epoch: 19/20,    batch: 1318/2993    Discriminator_loss: 0.004657315090298653  Generator_loss: 5.585971355438232\n",
            "epoch: 19/20,    batch: 1319/2993    Discriminator_loss: 0.005061906296759844  Generator_loss: 5.515613555908203\n",
            "epoch: 19/20,    batch: 1320/2993    Discriminator_loss: 0.0037006153725087643  Generator_loss: 5.900876045227051\n",
            "epoch: 19/20,    batch: 1321/2993    Discriminator_loss: 0.003873884677886963  Generator_loss: 5.86363410949707\n",
            "epoch: 19/20,    batch: 1322/2993    Discriminator_loss: 0.0040397075936198235  Generator_loss: 5.760514259338379\n",
            "epoch: 19/20,    batch: 1323/2993    Discriminator_loss: 0.0035300208255648613  Generator_loss: 5.83599853515625\n",
            "epoch: 19/20,    batch: 1324/2993    Discriminator_loss: 0.0030951134394854307  Generator_loss: 6.000119209289551\n",
            "epoch: 19/20,    batch: 1325/2993    Discriminator_loss: 0.002642315113916993  Generator_loss: 6.128528594970703\n",
            "epoch: 19/20,    batch: 1326/2993    Discriminator_loss: 0.0026014044415205717  Generator_loss: 6.152185440063477\n",
            "epoch: 19/20,    batch: 1327/2993    Discriminator_loss: 0.002795136533677578  Generator_loss: 6.1005964279174805\n",
            "epoch: 19/20,    batch: 1328/2993    Discriminator_loss: 0.6090134978294373  Generator_loss: 5.156489372253418\n",
            "epoch: 19/20,    batch: 1329/2993    Discriminator_loss: 0.009564235806465149  Generator_loss: 4.5445051193237305\n",
            "epoch: 19/20,    batch: 1330/2993    Discriminator_loss: 0.015882140025496483  Generator_loss: 4.128243446350098\n",
            "epoch: 19/20,    batch: 1331/2993    Discriminator_loss: 0.021749304607510567  Generator_loss: 3.913236141204834\n",
            "epoch: 19/20,    batch: 1332/2993    Discriminator_loss: 0.0239770095795393  Generator_loss: 3.9032230377197266\n",
            "epoch: 19/20,    batch: 1333/2993    Discriminator_loss: 0.02187994122505188  Generator_loss: 4.056026935577393\n",
            "epoch: 19/20,    batch: 1334/2993    Discriminator_loss: 0.017827056348323822  Generator_loss: 4.301882743835449\n",
            "epoch: 19/20,    batch: 1335/2993    Discriminator_loss: 0.013147410936653614  Generator_loss: 4.5909881591796875\n",
            "epoch: 19/20,    batch: 1336/2993    Discriminator_loss: 0.009409861639142036  Generator_loss: 4.918515682220459\n",
            "epoch: 19/20,    batch: 1337/2993    Discriminator_loss: 0.007448616437613964  Generator_loss: 5.257556915283203\n",
            "epoch: 19/20,    batch: 1338/2993    Discriminator_loss: 0.004806676413863897  Generator_loss: 5.537393093109131\n",
            "epoch: 19/20,    batch: 1339/2993    Discriminator_loss: 0.003776569152250886  Generator_loss: 5.741023063659668\n",
            "epoch: 19/20,    batch: 1340/2993    Discriminator_loss: 0.0035038848873227835  Generator_loss: 5.888607025146484\n",
            "epoch: 19/20,    batch: 1341/2993    Discriminator_loss: 0.002798795234411955  Generator_loss: 5.997575759887695\n",
            "epoch: 19/20,    batch: 1342/2993    Discriminator_loss: 0.0025649552699178457  Generator_loss: 6.077531814575195\n",
            "epoch: 19/20,    batch: 1343/2993    Discriminator_loss: 0.0028067799285054207  Generator_loss: 6.1340250968933105\n",
            "epoch: 19/20,    batch: 1344/2993    Discriminator_loss: 0.006790516898036003  Generator_loss: 6.1687822341918945\n",
            "epoch: 19/20,    batch: 1345/2993    Discriminator_loss: 0.0022161155939102173  Generator_loss: 6.189675331115723\n",
            "epoch: 19/20,    batch: 1346/2993    Discriminator_loss: 0.00897595752030611  Generator_loss: 6.1921586990356445\n",
            "epoch: 19/20,    batch: 1347/2993    Discriminator_loss: 0.007447441108524799  Generator_loss: 6.181540489196777\n",
            "epoch: 19/20,    batch: 1348/2993    Discriminator_loss: 0.0022244772408157587  Generator_loss: 6.167720794677734\n",
            "epoch: 19/20,    batch: 1349/2993    Discriminator_loss: 0.004426862578839064  Generator_loss: 6.150901794433594\n",
            "epoch: 19/20,    batch: 1350/2993    Discriminator_loss: 0.0023067169822752476  Generator_loss: 6.134200096130371\n",
            "epoch: 19/20,    batch: 1351/2993    Discriminator_loss: 0.002324150875210762  Generator_loss: 6.118895530700684\n",
            "epoch: 19/20,    batch: 1352/2993    Discriminator_loss: 0.010053257457911968  Generator_loss: 6.097116470336914\n",
            "epoch: 19/20,    batch: 1353/2993    Discriminator_loss: 0.002390913898125291  Generator_loss: 6.080174446105957\n",
            "epoch: 19/20,    batch: 1354/2993    Discriminator_loss: 0.0024336737114936113  Generator_loss: 6.068059921264648\n",
            "epoch: 19/20,    batch: 1355/2993    Discriminator_loss: 0.002598785562440753  Generator_loss: 6.0604777336120605\n",
            "epoch: 19/20,    batch: 1356/2993    Discriminator_loss: 0.0024679687339812517  Generator_loss: 6.055931091308594\n",
            "epoch: 19/20,    batch: 1357/2993    Discriminator_loss: 0.0024786461144685745  Generator_loss: 6.052428245544434\n",
            "epoch: 19/20,    batch: 1358/2993    Discriminator_loss: 0.005559842102229595  Generator_loss: 6.046287536621094\n",
            "epoch: 19/20,    batch: 1359/2993    Discriminator_loss: 0.002504528034478426  Generator_loss: 6.039642333984375\n",
            "epoch: 19/20,    batch: 1360/2993    Discriminator_loss: 0.002497255802154541  Generator_loss: 6.031929969787598\n",
            "epoch: 19/20,    batch: 1361/2993    Discriminator_loss: 0.12504680454730988  Generator_loss: 5.91762638092041\n",
            "epoch: 19/20,    batch: 1362/2993    Discriminator_loss: 0.16085058450698853  Generator_loss: 5.5089898109436035\n",
            "epoch: 19/20,    batch: 1363/2993    Discriminator_loss: 0.005171423312276602  Generator_loss: 5.155098915100098\n",
            "epoch: 19/20,    batch: 1364/2993    Discriminator_loss: 0.007292060647159815  Generator_loss: 4.853585720062256\n",
            "epoch: 19/20,    batch: 1365/2993    Discriminator_loss: 0.009752364829182625  Generator_loss: 4.64139461517334\n",
            "epoch: 19/20,    batch: 1366/2993    Discriminator_loss: 0.011424245312809944  Generator_loss: 4.560070991516113\n",
            "epoch: 19/20,    batch: 1367/2993    Discriminator_loss: 0.011531058698892593  Generator_loss: 4.605072021484375\n",
            "epoch: 19/20,    batch: 1368/2993    Discriminator_loss: 0.010843905620276928  Generator_loss: 4.731382369995117\n",
            "epoch: 19/20,    batch: 1369/2993    Discriminator_loss: 0.008777515962719917  Generator_loss: 4.902195453643799\n",
            "epoch: 19/20,    batch: 1370/2993    Discriminator_loss: 0.007255697622895241  Generator_loss: 5.102621555328369\n",
            "epoch: 19/20,    batch: 1371/2993    Discriminator_loss: 0.005873233545571566  Generator_loss: 5.313209533691406\n",
            "epoch: 19/20,    batch: 1372/2993    Discriminator_loss: 0.4647171199321747  Generator_loss: 5.071454048156738\n",
            "epoch: 19/20,    batch: 1373/2993    Discriminator_loss: 0.06657572090625763  Generator_loss: 4.858780860900879\n",
            "epoch: 19/20,    batch: 1374/2993    Discriminator_loss: 0.009215373545885086  Generator_loss: 4.742305278778076\n",
            "epoch: 19/20,    batch: 1375/2993    Discriminator_loss: 0.010071315802633762  Generator_loss: 4.724431037902832\n",
            "epoch: 19/20,    batch: 1376/2993    Discriminator_loss: 0.009814322926104069  Generator_loss: 4.799992561340332\n",
            "epoch: 19/20,    batch: 1377/2993    Discriminator_loss: 0.008712938986718655  Generator_loss: 4.9370903968811035\n",
            "epoch: 19/20,    batch: 1378/2993    Discriminator_loss: 0.007353341672569513  Generator_loss: 5.09747314453125\n",
            "epoch: 19/20,    batch: 1379/2993    Discriminator_loss: 0.0062837800942361355  Generator_loss: 5.259235382080078\n",
            "epoch: 19/20,    batch: 1380/2993    Discriminator_loss: 0.005179627798497677  Generator_loss: 5.416074752807617\n",
            "epoch: 19/20,    batch: 1381/2993    Discriminator_loss: 0.0043740347027778625  Generator_loss: 5.5679168701171875\n",
            "epoch: 19/20,    batch: 1382/2993    Discriminator_loss: 0.0037589194253087044  Generator_loss: 5.712989807128906\n",
            "epoch: 19/20,    batch: 1383/2993    Discriminator_loss: 0.0032791909761726856  Generator_loss: 5.827000141143799\n",
            "epoch: 19/20,    batch: 1384/2993    Discriminator_loss: 0.0029249743092805147  Generator_loss: 5.930901050567627\n",
            "epoch: 19/20,    batch: 1385/2993    Discriminator_loss: 0.002644523046910763  Generator_loss: 6.016358375549316\n",
            "epoch: 19/20,    batch: 1386/2993    Discriminator_loss: 0.002453806344419718  Generator_loss: 6.087613105773926\n",
            "epoch: 19/20,    batch: 1387/2993    Discriminator_loss: 0.002351887058466673  Generator_loss: 6.147139549255371\n",
            "epoch: 19/20,    batch: 1388/2993    Discriminator_loss: 0.0021867991890758276  Generator_loss: 6.19442892074585\n",
            "epoch: 19/20,    batch: 1389/2993    Discriminator_loss: 0.002081412822008133  Generator_loss: 6.232637405395508\n",
            "epoch: 19/20,    batch: 1390/2993    Discriminator_loss: 0.002019071951508522  Generator_loss: 6.283176422119141\n",
            "epoch: 19/20,    batch: 1391/2993    Discriminator_loss: 0.0019400158198550344  Generator_loss: 6.304051876068115\n",
            "epoch: 19/20,    batch: 1392/2993    Discriminator_loss: 0.0018640580819919705  Generator_loss: 6.334799766540527\n",
            "epoch: 19/20,    batch: 1393/2993    Discriminator_loss: 0.0019042380154132843  Generator_loss: 6.357768535614014\n",
            "epoch: 19/20,    batch: 1394/2993    Discriminator_loss: 0.0017886256100609899  Generator_loss: 6.376418113708496\n",
            "epoch: 19/20,    batch: 1395/2993    Discriminator_loss: 0.001743481494486332  Generator_loss: 6.3926286697387695\n",
            "epoch: 19/20,    batch: 1396/2993    Discriminator_loss: 0.00202817190438509  Generator_loss: 6.406182765960693\n",
            "epoch: 19/20,    batch: 1397/2993    Discriminator_loss: 0.001696121646091342  Generator_loss: 6.4181952476501465\n",
            "epoch: 19/20,    batch: 1398/2993    Discriminator_loss: 0.0017035340424627066  Generator_loss: 6.4285736083984375\n",
            "epoch: 19/20,    batch: 1399/2993    Discriminator_loss: 0.001679350039921701  Generator_loss: 6.4373674392700195\n",
            "epoch: 19/20,    batch: 1400/2993    Discriminator_loss: 0.0017316900193691254  Generator_loss: 6.444948196411133\n",
            "epoch: 19/20,    batch: 1401/2993    Discriminator_loss: 0.0016454460565000772  Generator_loss: 6.450901985168457\n",
            "epoch: 19/20,    batch: 1402/2993    Discriminator_loss: 0.0016262875869870186  Generator_loss: 6.455510139465332\n",
            "epoch: 19/20,    batch: 1403/2993    Discriminator_loss: 0.0017660941230133176  Generator_loss: 6.458852767944336\n",
            "epoch: 19/20,    batch: 1404/2993    Discriminator_loss: 0.0016175704076886177  Generator_loss: 6.461117267608643\n",
            "epoch: 19/20,    batch: 1405/2993    Discriminator_loss: 0.0016363387694582343  Generator_loss: 6.462464332580566\n",
            "epoch: 19/20,    batch: 1406/2993    Discriminator_loss: 0.0016404157504439354  Generator_loss: 6.46323299407959\n",
            "epoch: 19/20,    batch: 1407/2993    Discriminator_loss: 0.0016461838968098164  Generator_loss: 6.463321208953857\n",
            "epoch: 19/20,    batch: 1408/2993    Discriminator_loss: 0.0016176316421478987  Generator_loss: 6.463010787963867\n",
            "epoch: 19/20,    batch: 1409/2993    Discriminator_loss: 0.0016094616148620844  Generator_loss: 6.462764739990234\n",
            "epoch: 19/20,    batch: 1410/2993    Discriminator_loss: 0.0017947679152712226  Generator_loss: 6.462407112121582\n",
            "epoch: 19/20,    batch: 1411/2993    Discriminator_loss: 0.0016137970378622413  Generator_loss: 6.4626359939575195\n",
            "epoch: 19/20,    batch: 1412/2993    Discriminator_loss: 0.0016351616941392422  Generator_loss: 6.463756084442139\n",
            "epoch: 19/20,    batch: 1413/2993    Discriminator_loss: 0.0016633464256301522  Generator_loss: 6.465701103210449\n",
            "epoch: 19/20,    batch: 1414/2993    Discriminator_loss: 0.0016749788774177432  Generator_loss: 6.468568325042725\n",
            "epoch: 19/20,    batch: 1415/2993    Discriminator_loss: 0.0016064373776316643  Generator_loss: 6.472304821014404\n",
            "epoch: 19/20,    batch: 1416/2993    Discriminator_loss: 0.0016480499180033803  Generator_loss: 6.476971626281738\n",
            "epoch: 19/20,    batch: 1417/2993    Discriminator_loss: 0.0015901810256764293  Generator_loss: 6.482252597808838\n",
            "epoch: 19/20,    batch: 1418/2993    Discriminator_loss: 0.0015748084988445044  Generator_loss: 6.488278388977051\n",
            "epoch: 19/20,    batch: 1419/2993    Discriminator_loss: 0.001708712661638856  Generator_loss: 6.4945292472839355\n",
            "epoch: 19/20,    batch: 1420/2993    Discriminator_loss: 0.0015565593494102359  Generator_loss: 6.501333236694336\n",
            "epoch: 19/20,    batch: 1421/2993    Discriminator_loss: 0.0015414234949275851  Generator_loss: 6.508274078369141\n",
            "epoch: 19/20,    batch: 1422/2993    Discriminator_loss: 0.001617837930098176  Generator_loss: 6.515825271606445\n",
            "epoch: 19/20,    batch: 1423/2993    Discriminator_loss: 0.0015369760803878307  Generator_loss: 6.5235185623168945\n",
            "epoch: 19/20,    batch: 1424/2993    Discriminator_loss: 0.0015059091383591294  Generator_loss: 6.531147003173828\n",
            "epoch: 19/20,    batch: 1425/2993    Discriminator_loss: 0.0015446924371644855  Generator_loss: 6.53903865814209\n",
            "epoch: 19/20,    batch: 1426/2993    Discriminator_loss: 0.0015004256274551153  Generator_loss: 6.546560764312744\n",
            "epoch: 19/20,    batch: 1427/2993    Discriminator_loss: 0.0014796960167586803  Generator_loss: 6.554234027862549\n",
            "epoch: 19/20,    batch: 1428/2993    Discriminator_loss: 0.001466784393414855  Generator_loss: 6.561763286590576\n",
            "epoch: 19/20,    batch: 1429/2993    Discriminator_loss: 0.0014681849861517549  Generator_loss: 6.568917274475098\n",
            "epoch: 19/20,    batch: 1430/2993    Discriminator_loss: 0.0014372777659446  Generator_loss: 6.576113224029541\n",
            "epoch: 19/20,    batch: 1431/2993    Discriminator_loss: 0.0014464522246271372  Generator_loss: 6.58275842666626\n",
            "epoch: 19/20,    batch: 1432/2993    Discriminator_loss: 0.0014294201973825693  Generator_loss: 6.589583396911621\n",
            "epoch: 19/20,    batch: 1433/2993    Discriminator_loss: 0.0014513175701722503  Generator_loss: 6.595980167388916\n",
            "epoch: 19/20,    batch: 1434/2993    Discriminator_loss: 0.004021489527076483  Generator_loss: 6.598851203918457\n",
            "epoch: 19/20,    batch: 1435/2993    Discriminator_loss: 0.0014566164463758469  Generator_loss: 6.602097988128662\n",
            "epoch: 19/20,    batch: 1436/2993    Discriminator_loss: 0.00139316963031888  Generator_loss: 6.606029510498047\n",
            "epoch: 19/20,    batch: 1437/2993    Discriminator_loss: 0.0013995080953463912  Generator_loss: 6.610439300537109\n",
            "epoch: 19/20,    batch: 1438/2993    Discriminator_loss: 0.001395968603901565  Generator_loss: 6.6147847175598145\n",
            "epoch: 19/20,    batch: 1439/2993    Discriminator_loss: 0.001403048518113792  Generator_loss: 6.619565486907959\n",
            "epoch: 19/20,    batch: 1440/2993    Discriminator_loss: 0.0014428033027797937  Generator_loss: 6.6242146492004395\n",
            "epoch: 19/20,    batch: 1441/2993    Discriminator_loss: 0.001378511660732329  Generator_loss: 6.629133701324463\n",
            "epoch: 19/20,    batch: 1442/2993    Discriminator_loss: 0.0013616440119221807  Generator_loss: 6.633467674255371\n",
            "epoch: 19/20,    batch: 1443/2993    Discriminator_loss: 0.001358718960545957  Generator_loss: 6.637184143066406\n",
            "epoch: 19/20,    batch: 1444/2993    Discriminator_loss: 0.0013783513568341732  Generator_loss: 6.63987922668457\n",
            "epoch: 19/20,    batch: 1445/2993    Discriminator_loss: 0.0013822373002767563  Generator_loss: 6.641324996948242\n",
            "epoch: 19/20,    batch: 1446/2993    Discriminator_loss: 0.0013727443292737007  Generator_loss: 6.640315532684326\n",
            "epoch: 19/20,    batch: 1447/2993    Discriminator_loss: 0.001366803073324263  Generator_loss: 6.636826515197754\n",
            "epoch: 19/20,    batch: 1448/2993    Discriminator_loss: 0.0013863279018551111  Generator_loss: 6.630121231079102\n",
            "epoch: 19/20,    batch: 1449/2993    Discriminator_loss: 0.0016050823032855988  Generator_loss: 6.61912727355957\n",
            "epoch: 19/20,    batch: 1450/2993    Discriminator_loss: 0.0014496613293886185  Generator_loss: 6.604304313659668\n",
            "epoch: 19/20,    batch: 1451/2993    Discriminator_loss: 0.001461829524487257  Generator_loss: 6.587453365325928\n",
            "epoch: 19/20,    batch: 1452/2993    Discriminator_loss: 0.0015238067135214806  Generator_loss: 6.568936347961426\n",
            "epoch: 19/20,    batch: 1453/2993    Discriminator_loss: 0.0015418374678120017  Generator_loss: 6.550225734710693\n",
            "epoch: 19/20,    batch: 1454/2993    Discriminator_loss: 0.0015450433129444718  Generator_loss: 6.53304386138916\n",
            "epoch: 19/20,    batch: 1455/2993    Discriminator_loss: 0.0016513413283973932  Generator_loss: 6.517818450927734\n",
            "epoch: 19/20,    batch: 1456/2993    Discriminator_loss: 0.0016227266751229763  Generator_loss: 6.507027626037598\n",
            "epoch: 19/20,    batch: 1457/2993    Discriminator_loss: 0.0016111700097098947  Generator_loss: 6.499640464782715\n",
            "epoch: 19/20,    batch: 1458/2993    Discriminator_loss: 0.0016488399123772979  Generator_loss: 6.495776176452637\n",
            "epoch: 19/20,    batch: 1459/2993    Discriminator_loss: 0.0016359827714040875  Generator_loss: 6.494393825531006\n",
            "epoch: 19/20,    batch: 1460/2993    Discriminator_loss: 0.0016425453359261155  Generator_loss: 6.494299411773682\n",
            "epoch: 19/20,    batch: 1461/2993    Discriminator_loss: 0.0016243793070316315  Generator_loss: 6.493631362915039\n",
            "epoch: 19/20,    batch: 1462/2993    Discriminator_loss: 0.0016559171490371227  Generator_loss: 6.502360820770264\n",
            "epoch: 19/20,    batch: 1463/2993    Discriminator_loss: 0.001590333878993988  Generator_loss: 6.511152267456055\n",
            "epoch: 19/20,    batch: 1464/2993    Discriminator_loss: 0.0016194125637412071  Generator_loss: 6.515632629394531\n",
            "epoch: 19/20,    batch: 1465/2993    Discriminator_loss: 0.0015650519635528326  Generator_loss: 6.532214164733887\n",
            "epoch: 19/20,    batch: 1466/2993    Discriminator_loss: 0.0015646480023860931  Generator_loss: 6.5391035079956055\n",
            "epoch: 19/20,    batch: 1467/2993    Discriminator_loss: 0.0026659588329494  Generator_loss: 6.538483619689941\n",
            "epoch: 19/20,    batch: 1468/2993    Discriminator_loss: 0.0015530179953202605  Generator_loss: 6.552720069885254\n",
            "epoch: 19/20,    batch: 1469/2993    Discriminator_loss: 0.0015617894241586328  Generator_loss: 6.549374580383301\n",
            "epoch: 19/20,    batch: 1470/2993    Discriminator_loss: 0.0015220169443637133  Generator_loss: 6.561943054199219\n",
            "epoch: 19/20,    batch: 1471/2993    Discriminator_loss: 0.0015770200407132506  Generator_loss: 6.563590049743652\n",
            "epoch: 19/20,    batch: 1472/2993    Discriminator_loss: 0.0015090042725205421  Generator_loss: 6.5647735595703125\n",
            "epoch: 19/20,    batch: 1473/2993    Discriminator_loss: 0.0014908320736140013  Generator_loss: 6.578723430633545\n",
            "epoch: 19/20,    batch: 1474/2993    Discriminator_loss: 0.0021456535905599594  Generator_loss: 6.584118843078613\n",
            "epoch: 19/20,    batch: 1475/2993    Discriminator_loss: 0.0014988862676545978  Generator_loss: 6.592015266418457\n",
            "epoch: 19/20,    batch: 1476/2993    Discriminator_loss: 0.001466528745368123  Generator_loss: 6.591961860656738\n",
            "epoch: 19/20,    batch: 1477/2993    Discriminator_loss: 0.0016303318552672863  Generator_loss: 6.5972771644592285\n",
            "epoch: 19/20,    batch: 1478/2993    Discriminator_loss: 0.0017058103112503886  Generator_loss: 6.598915100097656\n",
            "epoch: 19/20,    batch: 1479/2993    Discriminator_loss: 0.0014606916811317205  Generator_loss: 6.605960845947266\n",
            "epoch: 19/20,    batch: 1480/2993    Discriminator_loss: 0.0014492998598143458  Generator_loss: 6.60965633392334\n",
            "epoch: 19/20,    batch: 1481/2993    Discriminator_loss: 0.002487064339220524  Generator_loss: 6.62083625793457\n",
            "epoch: 19/20,    batch: 1482/2993    Discriminator_loss: 0.0014343193033710122  Generator_loss: 6.625687599182129\n",
            "epoch: 19/20,    batch: 1483/2993    Discriminator_loss: 0.0014220712473616004  Generator_loss: 6.636415481567383\n",
            "epoch: 19/20,    batch: 1484/2993    Discriminator_loss: 0.0015002950094640255  Generator_loss: 6.647035598754883\n",
            "epoch: 19/20,    batch: 1485/2993    Discriminator_loss: 0.0014019866939634085  Generator_loss: 6.659893035888672\n",
            "epoch: 19/20,    batch: 1486/2993    Discriminator_loss: 0.0014233842957764864  Generator_loss: 6.672708988189697\n",
            "epoch: 19/20,    batch: 1487/2993    Discriminator_loss: 0.0016632474726065993  Generator_loss: 6.685604095458984\n",
            "epoch: 19/20,    batch: 1488/2993    Discriminator_loss: 0.0013525460381060839  Generator_loss: 6.7000017166137695\n",
            "epoch: 19/20,    batch: 1489/2993    Discriminator_loss: 0.0027945167385041714  Generator_loss: 6.710753917694092\n",
            "epoch: 19/20,    batch: 1490/2993    Discriminator_loss: 0.0013591254828497767  Generator_loss: 6.718592166900635\n",
            "epoch: 19/20,    batch: 1491/2993    Discriminator_loss: 0.001302827731706202  Generator_loss: 6.735673904418945\n",
            "epoch: 19/20,    batch: 1492/2993    Discriminator_loss: 0.0015442462172359228  Generator_loss: 6.744222164154053\n",
            "epoch: 19/20,    batch: 1493/2993    Discriminator_loss: 0.0012802433921024203  Generator_loss: 6.761103630065918\n",
            "epoch: 19/20,    batch: 1494/2993    Discriminator_loss: 0.001260999240912497  Generator_loss: 6.772441864013672\n",
            "epoch: 19/20,    batch: 1495/2993    Discriminator_loss: 0.001277630333788693  Generator_loss: 6.788749694824219\n",
            "epoch: 19/20,    batch: 1496/2993    Discriminator_loss: 0.5803205966949463  Generator_loss: 5.822420597076416\n",
            "epoch: 19/20,    batch: 1497/2993    Discriminator_loss: 0.006063842214643955  Generator_loss: 4.9621782302856445\n",
            "epoch: 19/20,    batch: 1498/2993    Discriminator_loss: 0.012627399526536465  Generator_loss: 4.978755950927734\n",
            "epoch: 19/20,    batch: 1499/2993    Discriminator_loss: 0.0065465327352285385  Generator_loss: 5.462917804718018\n",
            "epoch: 19/20,    batch: 1500/2993    Discriminator_loss: 0.004002654924988747  Generator_loss: 5.87147855758667\n",
            "epoch: 19/20,    batch: 1501/2993    Discriminator_loss: 0.002724136458709836  Generator_loss: 6.210528373718262\n",
            "epoch: 19/20,    batch: 1502/2993    Discriminator_loss: 0.0020120637491345406  Generator_loss: 6.496890068054199\n",
            "epoch: 19/20,    batch: 1503/2993    Discriminator_loss: 0.001568023581057787  Generator_loss: 6.759615898132324\n",
            "epoch: 19/20,    batch: 1504/2993    Discriminator_loss: 0.0012754170456901193  Generator_loss: 6.994141578674316\n",
            "epoch: 19/20,    batch: 1505/2993    Discriminator_loss: 0.001082167262211442  Generator_loss: 7.179520606994629\n",
            "epoch: 19/20,    batch: 1506/2993    Discriminator_loss: 0.0009739920496940613  Generator_loss: 7.298979759216309\n",
            "epoch: 19/20,    batch: 1507/2993    Discriminator_loss: 0.0009648893028497696  Generator_loss: 7.277900695800781\n",
            "epoch: 19/20,    batch: 1508/2993    Discriminator_loss: 0.0009112776606343687  Generator_loss: 7.32086706161499\n",
            "epoch: 19/20,    batch: 1509/2993    Discriminator_loss: 0.0009610974811948836  Generator_loss: 7.228826999664307\n",
            "epoch: 19/20,    batch: 1510/2993    Discriminator_loss: 0.0009739702218212187  Generator_loss: 7.193742752075195\n",
            "epoch: 19/20,    batch: 1511/2993    Discriminator_loss: 0.0010309997014701366  Generator_loss: 7.111597537994385\n",
            "epoch: 19/20,    batch: 1512/2993    Discriminator_loss: 0.0010768729262053967  Generator_loss: 7.041932582855225\n",
            "epoch: 19/20,    batch: 1513/2993    Discriminator_loss: 0.0011157981352880597  Generator_loss: 6.989910125732422\n",
            "epoch: 19/20,    batch: 1514/2993    Discriminator_loss: 0.001135077211074531  Generator_loss: 6.9477152824401855\n",
            "epoch: 19/20,    batch: 1515/2993    Discriminator_loss: 0.0011539753759279847  Generator_loss: 6.913162708282471\n",
            "epoch: 19/20,    batch: 1516/2993    Discriminator_loss: 0.0011778054758906364  Generator_loss: 6.884785175323486\n",
            "epoch: 19/20,    batch: 1517/2993    Discriminator_loss: 0.0011966896709054708  Generator_loss: 6.8621721267700195\n",
            "epoch: 19/20,    batch: 1518/2993    Discriminator_loss: 0.0012140142498537898  Generator_loss: 6.843731880187988\n",
            "epoch: 19/20,    batch: 1519/2993    Discriminator_loss: 0.0012319112429395318  Generator_loss: 6.828160762786865\n",
            "epoch: 19/20,    batch: 1520/2993    Discriminator_loss: 0.001242577563971281  Generator_loss: 6.8146562576293945\n",
            "epoch: 19/20,    batch: 1521/2993    Discriminator_loss: 0.0012559592723846436  Generator_loss: 6.8026123046875\n",
            "epoch: 19/20,    batch: 1522/2993    Discriminator_loss: 0.0012668813578784466  Generator_loss: 6.791145324707031\n",
            "epoch: 19/20,    batch: 1523/2993    Discriminator_loss: 0.001282680663280189  Generator_loss: 6.780323028564453\n",
            "epoch: 19/20,    batch: 1524/2993    Discriminator_loss: 0.0012958617880940437  Generator_loss: 6.770348072052002\n",
            "epoch: 19/20,    batch: 1525/2993    Discriminator_loss: 0.0013096010079607368  Generator_loss: 6.761449813842773\n",
            "epoch: 19/20,    batch: 1526/2993    Discriminator_loss: 0.0013180200476199389  Generator_loss: 6.753996849060059\n",
            "epoch: 19/20,    batch: 1527/2993    Discriminator_loss: 0.0013245317386463284  Generator_loss: 6.748282432556152\n",
            "epoch: 19/20,    batch: 1528/2993    Discriminator_loss: 0.0013276695972308517  Generator_loss: 6.744112014770508\n",
            "epoch: 19/20,    batch: 1529/2993    Discriminator_loss: 0.001377325621433556  Generator_loss: 6.7414774894714355\n",
            "epoch: 19/20,    batch: 1530/2993    Discriminator_loss: 0.0013124900870025158  Generator_loss: 6.7405500411987305\n",
            "epoch: 19/20,    batch: 1531/2993    Discriminator_loss: 0.0012613233411684632  Generator_loss: 6.741534233093262\n",
            "epoch: 19/20,    batch: 1532/2993    Discriminator_loss: 0.0012447225162759423  Generator_loss: 6.744256973266602\n",
            "epoch: 19/20,    batch: 1533/2993    Discriminator_loss: 0.001249495311640203  Generator_loss: 6.748415946960449\n",
            "epoch: 19/20,    batch: 1534/2993    Discriminator_loss: 0.001248141867108643  Generator_loss: 6.754361152648926\n",
            "epoch: 19/20,    batch: 1535/2993    Discriminator_loss: 0.0012303475523367524  Generator_loss: 6.761364936828613\n",
            "epoch: 19/20,    batch: 1536/2993    Discriminator_loss: 0.0013016380835324526  Generator_loss: 6.769714832305908\n",
            "epoch: 19/20,    batch: 1537/2993    Discriminator_loss: 0.0012292464962229133  Generator_loss: 6.779664516448975\n",
            "epoch: 19/20,    batch: 1538/2993    Discriminator_loss: 0.0011951860506087542  Generator_loss: 6.7908735275268555\n",
            "epoch: 19/20,    batch: 1539/2993    Discriminator_loss: 0.001785054337233305  Generator_loss: 6.802267074584961\n",
            "epoch: 19/20,    batch: 1540/2993    Discriminator_loss: 0.0011702588526532054  Generator_loss: 6.815630912780762\n",
            "epoch: 19/20,    batch: 1541/2993    Discriminator_loss: 0.0011813129531219602  Generator_loss: 6.831282138824463\n",
            "epoch: 19/20,    batch: 1542/2993    Discriminator_loss: 0.0012797784293070436  Generator_loss: 6.848565101623535\n",
            "epoch: 19/20,    batch: 1543/2993    Discriminator_loss: 0.0015451021026819944  Generator_loss: 6.867303848266602\n",
            "epoch: 19/20,    batch: 1544/2993    Discriminator_loss: 0.0011309906840324402  Generator_loss: 6.888039588928223\n",
            "epoch: 19/20,    batch: 1545/2993    Discriminator_loss: 0.0010711924405768514  Generator_loss: 6.910424709320068\n",
            "epoch: 19/20,    batch: 1546/2993    Discriminator_loss: 0.001299070194363594  Generator_loss: 6.933263301849365\n",
            "epoch: 19/20,    batch: 1547/2993    Discriminator_loss: 0.0010302619775757194  Generator_loss: 6.956885814666748\n",
            "epoch: 19/20,    batch: 1548/2993    Discriminator_loss: 0.001033276435919106  Generator_loss: 6.981180191040039\n",
            "epoch: 19/20,    batch: 1549/2993    Discriminator_loss: 0.0010748700005933642  Generator_loss: 7.005249500274658\n",
            "epoch: 19/20,    batch: 1550/2993    Discriminator_loss: 0.0010797645663842559  Generator_loss: 7.028861045837402\n",
            "epoch: 19/20,    batch: 1551/2993    Discriminator_loss: 0.0009580471669323742  Generator_loss: 7.051300048828125\n",
            "epoch: 19/20,    batch: 1552/2993    Discriminator_loss: 0.0009568860987201333  Generator_loss: 7.072628021240234\n",
            "epoch: 19/20,    batch: 1553/2993    Discriminator_loss: 0.0009083763579837978  Generator_loss: 7.092074394226074\n",
            "epoch: 19/20,    batch: 1554/2993    Discriminator_loss: 0.0008992887451313436  Generator_loss: 7.109201431274414\n",
            "epoch: 19/20,    batch: 1555/2993    Discriminator_loss: 0.0009430090431123972  Generator_loss: 7.124357223510742\n",
            "epoch: 19/20,    batch: 1556/2993    Discriminator_loss: 0.0013034736039116979  Generator_loss: 7.136631488800049\n",
            "epoch: 19/20,    batch: 1557/2993    Discriminator_loss: 0.0008721774793229997  Generator_loss: 7.145886421203613\n",
            "epoch: 19/20,    batch: 1558/2993    Discriminator_loss: 0.0009029339998960495  Generator_loss: 7.152202606201172\n",
            "epoch: 19/20,    batch: 1559/2993    Discriminator_loss: 0.000880414096172899  Generator_loss: 7.155346870422363\n",
            "epoch: 19/20,    batch: 1560/2993    Discriminator_loss: 0.0008511602063663304  Generator_loss: 7.156368732452393\n",
            "epoch: 19/20,    batch: 1561/2993    Discriminator_loss: 0.0008914163336157799  Generator_loss: 7.153755187988281\n",
            "epoch: 19/20,    batch: 1562/2993    Discriminator_loss: 0.0008965573506429791  Generator_loss: 7.149362564086914\n",
            "epoch: 19/20,    batch: 1563/2993    Discriminator_loss: 0.0008693201234564185  Generator_loss: 7.142738342285156\n",
            "epoch: 19/20,    batch: 1564/2993    Discriminator_loss: 0.0008950964547693729  Generator_loss: 7.13461971282959\n",
            "epoch: 19/20,    batch: 1565/2993    Discriminator_loss: 0.0009442834998480976  Generator_loss: 7.12500524520874\n",
            "epoch: 19/20,    batch: 1566/2993    Discriminator_loss: 0.0008974055526778102  Generator_loss: 7.114391326904297\n",
            "epoch: 19/20,    batch: 1567/2993    Discriminator_loss: 0.0010030086850747466  Generator_loss: 7.102231025695801\n",
            "epoch: 19/20,    batch: 1568/2993    Discriminator_loss: 0.0009291991009376943  Generator_loss: 7.090445518493652\n",
            "epoch: 19/20,    batch: 1569/2993    Discriminator_loss: 0.0009435954852961004  Generator_loss: 7.079438209533691\n",
            "epoch: 19/20,    batch: 1570/2993    Discriminator_loss: 0.00099960679654032  Generator_loss: 7.069088935852051\n",
            "epoch: 19/20,    batch: 1571/2993    Discriminator_loss: 0.0010049673728644848  Generator_loss: 7.061018943786621\n",
            "epoch: 19/20,    batch: 1572/2993    Discriminator_loss: 0.0009731023455969989  Generator_loss: 7.056394100189209\n",
            "epoch: 19/20,    batch: 1573/2993    Discriminator_loss: 0.0009827318135648966  Generator_loss: 7.056262493133545\n",
            "epoch: 19/20,    batch: 1574/2993    Discriminator_loss: 0.0010038554901257157  Generator_loss: 7.059127330780029\n",
            "epoch: 19/20,    batch: 1575/2993    Discriminator_loss: 0.0010234499350190163  Generator_loss: 7.06441593170166\n",
            "epoch: 19/20,    batch: 1576/2993    Discriminator_loss: 0.0010128322755917907  Generator_loss: 7.068528652191162\n",
            "epoch: 19/20,    batch: 1577/2993    Discriminator_loss: 0.0010061655193567276  Generator_loss: 7.07063102722168\n",
            "epoch: 19/20,    batch: 1578/2993    Discriminator_loss: 0.0009978767484426498  Generator_loss: 7.069605827331543\n",
            "epoch: 19/20,    batch: 1579/2993    Discriminator_loss: 0.0010582295944914222  Generator_loss: 7.065467357635498\n",
            "epoch: 19/20,    batch: 1580/2993    Discriminator_loss: 0.0010227110469713807  Generator_loss: 7.058480262756348\n",
            "epoch: 19/20,    batch: 1581/2993    Discriminator_loss: 0.0010415577562525868  Generator_loss: 7.050548553466797\n",
            "epoch: 19/20,    batch: 1582/2993    Discriminator_loss: 0.0011379406787455082  Generator_loss: 7.0409440994262695\n",
            "epoch: 19/20,    batch: 1583/2993    Discriminator_loss: 0.0011397693306207657  Generator_loss: 7.033257961273193\n",
            "epoch: 19/20,    batch: 1584/2993    Discriminator_loss: 0.0010730798821896315  Generator_loss: 7.042220115661621\n",
            "epoch: 19/20,    batch: 1585/2993    Discriminator_loss: 0.0022905198857188225  Generator_loss: 7.022375106811523\n",
            "epoch: 19/20,    batch: 1586/2993    Discriminator_loss: 0.0014080695109441876  Generator_loss: 7.0290985107421875\n",
            "epoch: 19/20,    batch: 1587/2993    Discriminator_loss: 0.0010534648317843676  Generator_loss: 7.037360668182373\n",
            "epoch: 19/20,    batch: 1588/2993    Discriminator_loss: 0.0010888377437368035  Generator_loss: 7.046300411224365\n",
            "epoch: 19/20,    batch: 1589/2993    Discriminator_loss: 0.001061237184330821  Generator_loss: 7.0551252365112305\n",
            "epoch: 19/20,    batch: 1590/2993    Discriminator_loss: 0.001036301371641457  Generator_loss: 7.064866542816162\n",
            "epoch: 19/20,    batch: 1591/2993    Discriminator_loss: 0.0014399198116734624  Generator_loss: 7.122487545013428\n",
            "epoch: 19/20,    batch: 1592/2993    Discriminator_loss: 0.0009953017579391599  Generator_loss: 7.117839813232422\n",
            "epoch: 19/20,    batch: 1593/2993    Discriminator_loss: 0.0009382518474012613  Generator_loss: 7.163025856018066\n",
            "epoch: 19/20,    batch: 1594/2993    Discriminator_loss: 0.0010267195757478476  Generator_loss: 7.200932502746582\n",
            "epoch: 19/20,    batch: 1595/2993    Discriminator_loss: 0.0008937554666772485  Generator_loss: 7.2291789054870605\n",
            "epoch: 19/20,    batch: 1596/2993    Discriminator_loss: 0.0020980259869247675  Generator_loss: 7.245803356170654\n",
            "epoch: 19/20,    batch: 1597/2993    Discriminator_loss: 0.0009441392030566931  Generator_loss: 7.282009124755859\n",
            "epoch: 19/20,    batch: 1598/2993    Discriminator_loss: 0.0008268036181107163  Generator_loss: 7.300900459289551\n",
            "epoch: 19/20,    batch: 1599/2993    Discriminator_loss: 0.0008061854168772697  Generator_loss: 7.311923503875732\n",
            "epoch: 19/20,    batch: 1600/2993    Discriminator_loss: 0.001250249333679676  Generator_loss: 7.328644752502441\n",
            "epoch: 19/20,    batch: 1601/2993    Discriminator_loss: 0.0007842705235816538  Generator_loss: 7.3308563232421875\n",
            "epoch: 19/20,    batch: 1602/2993    Discriminator_loss: 0.0007941574440337718  Generator_loss: 7.325695037841797\n",
            "epoch: 19/20,    batch: 1603/2993    Discriminator_loss: 0.003965421579778194  Generator_loss: 7.309852123260498\n",
            "epoch: 19/20,    batch: 1604/2993    Discriminator_loss: 0.04312765225768089  Generator_loss: 7.179373741149902\n",
            "epoch: 19/20,    batch: 1605/2993    Discriminator_loss: 0.0019812302198261023  Generator_loss: 7.084826946258545\n",
            "epoch: 19/20,    batch: 1606/2993    Discriminator_loss: 0.0012990706600248814  Generator_loss: 7.021274566650391\n",
            "epoch: 19/20,    batch: 1607/2993    Discriminator_loss: 0.0015814707148820162  Generator_loss: 6.986316680908203\n",
            "epoch: 19/20,    batch: 1608/2993    Discriminator_loss: 0.001513372641056776  Generator_loss: 6.977662563323975\n",
            "epoch: 19/20,    batch: 1609/2993    Discriminator_loss: 0.0013346073683351278  Generator_loss: 6.989234924316406\n",
            "epoch: 19/20,    batch: 1610/2993    Discriminator_loss: 0.0020452970638871193  Generator_loss: 7.032875061035156\n",
            "epoch: 19/20,    batch: 1611/2993    Discriminator_loss: 0.0010959269711747766  Generator_loss: 7.073836326599121\n",
            "epoch: 19/20,    batch: 1612/2993    Discriminator_loss: 0.000984588754363358  Generator_loss: 7.141870498657227\n",
            "epoch: 19/20,    batch: 1613/2993    Discriminator_loss: 0.0009492349927313626  Generator_loss: 7.209795951843262\n",
            "epoch: 19/20,    batch: 1614/2993    Discriminator_loss: 0.0010118780191987753  Generator_loss: 7.267634868621826\n",
            "epoch: 19/20,    batch: 1615/2993    Discriminator_loss: 0.000809523684438318  Generator_loss: 7.333855628967285\n",
            "epoch: 19/20,    batch: 1616/2993    Discriminator_loss: 0.0007728291675448418  Generator_loss: 7.376004219055176\n",
            "epoch: 19/20,    batch: 1617/2993    Discriminator_loss: 0.0015901501756161451  Generator_loss: 7.416894912719727\n",
            "epoch: 19/20,    batch: 1618/2993    Discriminator_loss: 0.0007319526630453765  Generator_loss: 7.43587064743042\n",
            "epoch: 19/20,    batch: 1619/2993    Discriminator_loss: 0.0007111268350854516  Generator_loss: 7.4510602951049805\n",
            "epoch: 19/20,    batch: 1620/2993    Discriminator_loss: 0.000858103740029037  Generator_loss: 7.437102317810059\n",
            "epoch: 19/20,    batch: 1621/2993    Discriminator_loss: 0.0007524068932980299  Generator_loss: 7.423098564147949\n",
            "epoch: 19/20,    batch: 1622/2993    Discriminator_loss: 0.0007553602918051183  Generator_loss: 7.401462554931641\n",
            "epoch: 19/20,    batch: 1623/2993    Discriminator_loss: 0.0010900809429585934  Generator_loss: 7.376466751098633\n",
            "epoch: 19/20,    batch: 1624/2993    Discriminator_loss: 0.0008368721464648843  Generator_loss: 7.320367813110352\n",
            "epoch: 19/20,    batch: 1625/2993    Discriminator_loss: 0.001045443583279848  Generator_loss: 7.2624311447143555\n",
            "epoch: 19/20,    batch: 1626/2993    Discriminator_loss: 0.0015337120275944471  Generator_loss: 7.2035112380981445\n",
            "epoch: 19/20,    batch: 1627/2993    Discriminator_loss: 0.0009946860373020172  Generator_loss: 7.135228633880615\n",
            "epoch: 19/20,    batch: 1628/2993    Discriminator_loss: 0.0012030964717268944  Generator_loss: 7.0746073722839355\n",
            "epoch: 19/20,    batch: 1629/2993    Discriminator_loss: 0.0011126312892884016  Generator_loss: 7.033441543579102\n",
            "epoch: 19/20,    batch: 1630/2993    Discriminator_loss: 0.0011606693733483553  Generator_loss: 7.012360572814941\n",
            "epoch: 19/20,    batch: 1631/2993    Discriminator_loss: 0.0012512075481936336  Generator_loss: 6.995682716369629\n",
            "epoch: 19/20,    batch: 1632/2993    Discriminator_loss: 0.0012018367415294051  Generator_loss: 7.009792327880859\n",
            "epoch: 19/20,    batch: 1633/2993    Discriminator_loss: 0.0011896751821041107  Generator_loss: 7.023763179779053\n",
            "epoch: 19/20,    batch: 1634/2993    Discriminator_loss: 0.0017793318256735802  Generator_loss: 7.0629377365112305\n",
            "epoch: 19/20,    batch: 1635/2993    Discriminator_loss: 0.003088424913585186  Generator_loss: 7.080522060394287\n",
            "epoch: 19/20,    batch: 1636/2993    Discriminator_loss: 0.001154741970822215  Generator_loss: 7.096310138702393\n",
            "epoch: 19/20,    batch: 1637/2993    Discriminator_loss: 0.0011602272279560566  Generator_loss: 7.142099380493164\n",
            "epoch: 19/20,    batch: 1638/2993    Discriminator_loss: 0.002173065207898617  Generator_loss: 7.16916036605835\n",
            "epoch: 19/20,    batch: 1639/2993    Discriminator_loss: 0.0011378481285646558  Generator_loss: 7.218010902404785\n",
            "epoch: 19/20,    batch: 1640/2993    Discriminator_loss: 0.0011158724082633853  Generator_loss: 7.265823841094971\n",
            "epoch: 19/20,    batch: 1641/2993    Discriminator_loss: 0.012262260541319847  Generator_loss: 7.1849775314331055\n",
            "epoch: 19/20,    batch: 1642/2993    Discriminator_loss: 0.001294852001592517  Generator_loss: 7.181364059448242\n",
            "epoch: 19/20,    batch: 1643/2993    Discriminator_loss: 0.001247683190740645  Generator_loss: 7.236944675445557\n",
            "epoch: 19/20,    batch: 1644/2993    Discriminator_loss: 0.0011895180214196444  Generator_loss: 7.341180801391602\n",
            "epoch: 19/20,    batch: 1645/2993    Discriminator_loss: 0.00223938818089664  Generator_loss: 7.490818500518799\n",
            "epoch: 19/20,    batch: 1646/2993    Discriminator_loss: 0.0009598737233318388  Generator_loss: 7.752862453460693\n",
            "epoch: 19/20,    batch: 1647/2993    Discriminator_loss: 0.0005810980219393969  Generator_loss: 8.315738677978516\n",
            "epoch: 19/20,    batch: 1648/2993    Discriminator_loss: 0.00841959472745657  Generator_loss: 8.203094482421875\n",
            "epoch: 19/20,    batch: 1649/2993    Discriminator_loss: 0.0006702576065436006  Generator_loss: 8.022754669189453\n",
            "epoch: 19/20,    batch: 1650/2993    Discriminator_loss: 0.001013200031593442  Generator_loss: 7.689670562744141\n",
            "epoch: 19/20,    batch: 1651/2993    Discriminator_loss: 0.0094728022813797  Generator_loss: 7.34404182434082\n",
            "epoch: 19/20,    batch: 1652/2993    Discriminator_loss: 0.1985902488231659  Generator_loss: 4.894274711608887\n",
            "epoch: 19/20,    batch: 1653/2993    Discriminator_loss: 0.019573217257857323  Generator_loss: 4.506793022155762\n",
            "epoch: 19/20,    batch: 1654/2993    Discriminator_loss: 0.014298875816166401  Generator_loss: 5.346745014190674\n",
            "epoch: 19/20,    batch: 1655/2993    Discriminator_loss: 0.0040733832865953445  Generator_loss: 7.06882905960083\n",
            "epoch: 19/20,    batch: 1656/2993    Discriminator_loss: 0.0008582691662013531  Generator_loss: 8.950976371765137\n",
            "epoch: 19/20,    batch: 1657/2993    Discriminator_loss: 0.001118353335186839  Generator_loss: 10.194731712341309\n",
            "epoch: 19/20,    batch: 1658/2993    Discriminator_loss: 0.00014239874144550413  Generator_loss: 10.563848495483398\n",
            "epoch: 19/20,    batch: 1659/2993    Discriminator_loss: 0.00011552815703907982  Generator_loss: 10.307750701904297\n",
            "epoch: 19/20,    batch: 1660/2993    Discriminator_loss: 0.00027315865736454725  Generator_loss: 9.739938735961914\n",
            "epoch: 19/20,    batch: 1661/2993    Discriminator_loss: 0.000262368906987831  Generator_loss: 9.011079788208008\n",
            "epoch: 19/20,    batch: 1662/2993    Discriminator_loss: 0.0004532292077783495  Generator_loss: 8.236750602722168\n",
            "epoch: 19/20,    batch: 1663/2993    Discriminator_loss: 0.0008935703663155437  Generator_loss: 7.632959842681885\n",
            "epoch: 19/20,    batch: 1664/2993    Discriminator_loss: 0.0010971951996907592  Generator_loss: 7.175863265991211\n",
            "epoch: 19/20,    batch: 1665/2993    Discriminator_loss: 0.0014866511337459087  Generator_loss: 6.83397102355957\n",
            "epoch: 19/20,    batch: 1666/2993    Discriminator_loss: 0.0019661812111735344  Generator_loss: 6.59775972366333\n",
            "epoch: 19/20,    batch: 1667/2993    Discriminator_loss: 0.0021951799280941486  Generator_loss: 6.449855804443359\n",
            "epoch: 19/20,    batch: 1668/2993    Discriminator_loss: 0.0023729195818305016  Generator_loss: 6.374927997589111\n",
            "epoch: 19/20,    batch: 1669/2993    Discriminator_loss: 0.007296751253306866  Generator_loss: 6.322714328765869\n",
            "epoch: 19/20,    batch: 1670/2993    Discriminator_loss: 0.0025684682186692953  Generator_loss: 6.324316501617432\n",
            "epoch: 19/20,    batch: 1671/2993    Discriminator_loss: 0.002523113042116165  Generator_loss: 6.366494178771973\n",
            "epoch: 19/20,    batch: 1672/2993    Discriminator_loss: 0.002389190485700965  Generator_loss: 6.437961578369141\n",
            "epoch: 19/20,    batch: 1673/2993    Discriminator_loss: 0.0023250917438417673  Generator_loss: 6.528472900390625\n",
            "epoch: 19/20,    batch: 1674/2993    Discriminator_loss: 0.002044307766482234  Generator_loss: 6.629985809326172\n",
            "epoch: 19/20,    batch: 1675/2993    Discriminator_loss: 0.0036889712791889906  Generator_loss: 6.721254348754883\n",
            "epoch: 19/20,    batch: 1676/2993    Discriminator_loss: 0.003562633879482746  Generator_loss: 6.796360969543457\n",
            "epoch: 19/20,    batch: 1677/2993    Discriminator_loss: 0.001545330393128097  Generator_loss: 6.874167442321777\n",
            "epoch: 19/20,    batch: 1678/2993    Discriminator_loss: 0.0014092146884649992  Generator_loss: 6.949766635894775\n",
            "epoch: 19/20,    batch: 1679/2993    Discriminator_loss: 0.0013461718335747719  Generator_loss: 7.016557693481445\n",
            "epoch: 19/20,    batch: 1680/2993    Discriminator_loss: 0.0012406943133100867  Generator_loss: 7.06866455078125\n",
            "epoch: 19/20,    batch: 1681/2993    Discriminator_loss: 0.0011600630823522806  Generator_loss: 7.102444171905518\n",
            "epoch: 19/20,    batch: 1682/2993    Discriminator_loss: 0.0016884636133909225  Generator_loss: 7.112140655517578\n",
            "epoch: 19/20,    batch: 1683/2993    Discriminator_loss: 0.001111229183152318  Generator_loss: 7.117060661315918\n",
            "epoch: 19/20,    batch: 1684/2993    Discriminator_loss: 0.001089409925043583  Generator_loss: 7.121530532836914\n",
            "epoch: 19/20,    batch: 1685/2993    Discriminator_loss: 0.001464354107156396  Generator_loss: 7.096602439880371\n",
            "epoch: 19/20,    batch: 1686/2993    Discriminator_loss: 0.0011280081234872341  Generator_loss: 7.0484747886657715\n",
            "epoch: 19/20,    batch: 1687/2993    Discriminator_loss: 0.0011485691647976637  Generator_loss: 7.001507759094238\n",
            "epoch: 19/20,    batch: 1688/2993    Discriminator_loss: 0.0037655713967978954  Generator_loss: 6.947051048278809\n",
            "epoch: 19/20,    batch: 1689/2993    Discriminator_loss: 0.001545197213999927  Generator_loss: 6.902926921844482\n",
            "epoch: 19/20,    batch: 1690/2993    Discriminator_loss: 0.0012607944663614035  Generator_loss: 6.866513252258301\n",
            "epoch: 19/20,    batch: 1691/2993    Discriminator_loss: 0.001715776277706027  Generator_loss: 6.836087703704834\n",
            "epoch: 19/20,    batch: 1692/2993    Discriminator_loss: 0.0013165747513994575  Generator_loss: 6.818151473999023\n",
            "epoch: 19/20,    batch: 1693/2993    Discriminator_loss: 0.002581319771707058  Generator_loss: 6.810199737548828\n",
            "epoch: 19/20,    batch: 1694/2993    Discriminator_loss: 0.04017862677574158  Generator_loss: 6.532989501953125\n",
            "epoch: 19/20,    batch: 1695/2993    Discriminator_loss: 0.001817823387682438  Generator_loss: 6.38754415512085\n",
            "epoch: 19/20,    batch: 1696/2993    Discriminator_loss: 0.0024846368469297886  Generator_loss: 6.318026542663574\n",
            "epoch: 19/20,    batch: 1697/2993    Discriminator_loss: 0.0021302374079823494  Generator_loss: 6.300734996795654\n",
            "epoch: 19/20,    batch: 1698/2993    Discriminator_loss: 0.002079410944133997  Generator_loss: 6.322833061218262\n",
            "epoch: 19/20,    batch: 1699/2993    Discriminator_loss: 0.003534720279276371  Generator_loss: 6.371644973754883\n",
            "epoch: 19/20,    batch: 1700/2993    Discriminator_loss: 0.001876497408375144  Generator_loss: 6.443210124969482\n",
            "epoch: 19/20,    batch: 1701/2993    Discriminator_loss: 0.0017255505081266165  Generator_loss: 6.529379844665527\n",
            "epoch: 19/20,    batch: 1702/2993    Discriminator_loss: 0.0015924960607662797  Generator_loss: 6.6233062744140625\n",
            "epoch: 19/20,    batch: 1703/2993    Discriminator_loss: 0.0019108017440885305  Generator_loss: 6.720542907714844\n",
            "epoch: 19/20,    batch: 1704/2993    Discriminator_loss: 0.0012825796147808433  Generator_loss: 6.817501068115234\n",
            "epoch: 19/20,    batch: 1705/2993    Discriminator_loss: 0.0011545594315975904  Generator_loss: 6.912444114685059\n",
            "epoch: 19/20,    batch: 1706/2993    Discriminator_loss: 0.00814455933868885  Generator_loss: 6.980921745300293\n",
            "epoch: 19/20,    batch: 1707/2993    Discriminator_loss: 0.0010123774409294128  Generator_loss: 7.04787015914917\n",
            "epoch: 19/20,    batch: 1708/2993    Discriminator_loss: 0.0009441529400646687  Generator_loss: 7.113740921020508\n",
            "epoch: 19/20,    batch: 1709/2993    Discriminator_loss: 0.0010428543901070952  Generator_loss: 7.176912784576416\n",
            "epoch: 19/20,    batch: 1710/2993    Discriminator_loss: 0.0013516625622287393  Generator_loss: 7.234334945678711\n",
            "epoch: 19/20,    batch: 1711/2993    Discriminator_loss: 0.0007697294349782169  Generator_loss: 7.286382675170898\n",
            "epoch: 19/20,    batch: 1712/2993    Discriminator_loss: 0.0007257703691720963  Generator_loss: 7.331446647644043\n",
            "epoch: 19/20,    batch: 1713/2993    Discriminator_loss: 0.00990656390786171  Generator_loss: 7.316259860992432\n",
            "epoch: 19/20,    batch: 1714/2993    Discriminator_loss: 0.0007694024825468659  Generator_loss: 7.30734920501709\n",
            "epoch: 19/20,    batch: 1715/2993    Discriminator_loss: 0.000733138236682862  Generator_loss: 7.305001258850098\n",
            "epoch: 19/20,    batch: 1716/2993    Discriminator_loss: 0.005579332821071148  Generator_loss: 7.274835586547852\n",
            "epoch: 19/20,    batch: 1717/2993    Discriminator_loss: 0.0009566271910443902  Generator_loss: 7.255308151245117\n",
            "epoch: 19/20,    batch: 1718/2993    Discriminator_loss: 0.00078401347855106  Generator_loss: 7.245395660400391\n",
            "epoch: 19/20,    batch: 1719/2993    Discriminator_loss: 0.0007670369232073426  Generator_loss: 7.244299411773682\n",
            "epoch: 19/20,    batch: 1720/2993    Discriminator_loss: 0.0013473981525748968  Generator_loss: 7.249466419219971\n",
            "epoch: 19/20,    batch: 1721/2993    Discriminator_loss: 0.0007751986850053072  Generator_loss: 7.2625322341918945\n",
            "epoch: 19/20,    batch: 1722/2993    Discriminator_loss: 0.0007372788386419415  Generator_loss: 7.281980514526367\n",
            "epoch: 19/20,    batch: 1723/2993    Discriminator_loss: 0.0008668580558151007  Generator_loss: 7.305539131164551\n",
            "epoch: 19/20,    batch: 1724/2993    Discriminator_loss: 0.0007112495368346572  Generator_loss: 7.331645965576172\n",
            "epoch: 19/20,    batch: 1725/2993    Discriminator_loss: 0.0008071632473729551  Generator_loss: 7.358200550079346\n",
            "epoch: 19/20,    batch: 1726/2993    Discriminator_loss: 0.0018345046555623412  Generator_loss: 7.382256507873535\n",
            "epoch: 19/20,    batch: 1727/2993    Discriminator_loss: 0.000664170365780592  Generator_loss: 7.406432628631592\n",
            "epoch: 19/20,    batch: 1728/2993    Discriminator_loss: 0.0048400964587926865  Generator_loss: 7.416183948516846\n",
            "epoch: 19/20,    batch: 1729/2993    Discriminator_loss: 0.0006794888759031892  Generator_loss: 7.428905963897705\n",
            "epoch: 19/20,    batch: 1730/2993    Discriminator_loss: 0.0006278989021666348  Generator_loss: 7.444458961486816\n",
            "epoch: 19/20,    batch: 1731/2993    Discriminator_loss: 0.00069727300433442  Generator_loss: 7.46139669418335\n",
            "epoch: 19/20,    batch: 1732/2993    Discriminator_loss: 0.0006090264650993049  Generator_loss: 7.4795637130737305\n",
            "epoch: 19/20,    batch: 1733/2993    Discriminator_loss: 0.0005916560767218471  Generator_loss: 7.498220443725586\n",
            "epoch: 19/20,    batch: 1734/2993    Discriminator_loss: 0.0006000493303872645  Generator_loss: 7.51715087890625\n",
            "epoch: 19/20,    batch: 1735/2993    Discriminator_loss: 0.000713235349394381  Generator_loss: 7.535489082336426\n",
            "epoch: 19/20,    batch: 1736/2993    Discriminator_loss: 0.0005615093978121877  Generator_loss: 7.553345680236816\n",
            "epoch: 19/20,    batch: 1737/2993    Discriminator_loss: 0.0006557279848493636  Generator_loss: 7.569663047790527\n",
            "epoch: 19/20,    batch: 1738/2993    Discriminator_loss: 0.0005495172808878124  Generator_loss: 7.584958076477051\n",
            "epoch: 19/20,    batch: 1739/2993    Discriminator_loss: 0.0005360814975574613  Generator_loss: 7.5990705490112305\n",
            "epoch: 19/20,    batch: 1740/2993    Discriminator_loss: 0.0008685470093041658  Generator_loss: 7.610793113708496\n",
            "epoch: 19/20,    batch: 1741/2993    Discriminator_loss: 0.0005302579957060516  Generator_loss: 7.621321678161621\n",
            "epoch: 19/20,    batch: 1742/2993    Discriminator_loss: 0.000524097413290292  Generator_loss: 7.630965232849121\n",
            "epoch: 19/20,    batch: 1743/2993    Discriminator_loss: 0.0008288513636216521  Generator_loss: 7.638997554779053\n",
            "epoch: 19/20,    batch: 1744/2993    Discriminator_loss: 0.0005184139590710402  Generator_loss: 7.646853446960449\n",
            "epoch: 19/20,    batch: 1745/2993    Discriminator_loss: 0.0005220443126745522  Generator_loss: 7.654520034790039\n",
            "epoch: 19/20,    batch: 1746/2993    Discriminator_loss: 0.0005297288880683482  Generator_loss: 7.66298246383667\n",
            "epoch: 19/20,    batch: 1747/2993    Discriminator_loss: 0.000621251470874995  Generator_loss: 7.671989440917969\n",
            "epoch: 19/20,    batch: 1748/2993    Discriminator_loss: 0.000524213828612119  Generator_loss: 7.681764125823975\n",
            "epoch: 19/20,    batch: 1749/2993    Discriminator_loss: 0.0004931901930831373  Generator_loss: 7.691811561584473\n",
            "epoch: 19/20,    batch: 1750/2993    Discriminator_loss: 0.0005560759454965591  Generator_loss: 7.702455043792725\n",
            "epoch: 19/20,    batch: 1751/2993    Discriminator_loss: 0.0004822493647225201  Generator_loss: 7.712717056274414\n",
            "epoch: 19/20,    batch: 1752/2993    Discriminator_loss: 0.000489779922645539  Generator_loss: 7.722580909729004\n",
            "epoch: 19/20,    batch: 1753/2993    Discriminator_loss: 0.0023688727524131536  Generator_loss: 7.723649978637695\n",
            "epoch: 19/20,    batch: 1754/2993    Discriminator_loss: 0.0004735993570648134  Generator_loss: 7.725193023681641\n",
            "epoch: 19/20,    batch: 1755/2993    Discriminator_loss: 0.0011311504058539867  Generator_loss: 7.723624229431152\n",
            "epoch: 19/20,    batch: 1756/2993    Discriminator_loss: 0.003696335945278406  Generator_loss: 7.708833694458008\n",
            "epoch: 19/20,    batch: 1757/2993    Discriminator_loss: 0.0004914526944048703  Generator_loss: 7.696271896362305\n",
            "epoch: 19/20,    batch: 1758/2993    Discriminator_loss: 0.002933561336249113  Generator_loss: 7.670462608337402\n",
            "epoch: 19/20,    batch: 1759/2993    Discriminator_loss: 0.005009165033698082  Generator_loss: 7.630873203277588\n",
            "epoch: 19/20,    batch: 1760/2993    Discriminator_loss: 0.0005297760362736881  Generator_loss: 7.599264144897461\n",
            "epoch: 19/20,    batch: 1761/2993    Discriminator_loss: 0.0010154815390706062  Generator_loss: 7.573831081390381\n",
            "epoch: 19/20,    batch: 1762/2993    Discriminator_loss: 0.0005546822212636471  Generator_loss: 7.55560827255249\n",
            "epoch: 19/20,    batch: 1763/2993    Discriminator_loss: 0.0005584226455539465  Generator_loss: 7.544821739196777\n",
            "epoch: 19/20,    batch: 1764/2993    Discriminator_loss: 0.0014726383378729224  Generator_loss: 7.537117004394531\n",
            "epoch: 19/20,    batch: 1765/2993    Discriminator_loss: 0.0005696282023563981  Generator_loss: 7.536816120147705\n",
            "epoch: 19/20,    batch: 1766/2993    Discriminator_loss: 0.0005653874250128865  Generator_loss: 7.543216705322266\n",
            "epoch: 19/20,    batch: 1767/2993    Discriminator_loss: 0.0008403090760111809  Generator_loss: 7.554803848266602\n",
            "epoch: 19/20,    batch: 1768/2993    Discriminator_loss: 0.000568066316191107  Generator_loss: 7.570948600769043\n",
            "epoch: 19/20,    batch: 1769/2993    Discriminator_loss: 0.0005334484740160406  Generator_loss: 7.591203689575195\n",
            "epoch: 19/20,    batch: 1770/2993    Discriminator_loss: 0.0008227038779295981  Generator_loss: 7.613105297088623\n",
            "epoch: 19/20,    batch: 1771/2993    Discriminator_loss: 0.0005259938188828528  Generator_loss: 7.636601448059082\n",
            "epoch: 19/20,    batch: 1772/2993    Discriminator_loss: 0.0005114405648782849  Generator_loss: 7.660480499267578\n",
            "epoch: 19/20,    batch: 1773/2993    Discriminator_loss: 0.000542833935469389  Generator_loss: 7.684198379516602\n",
            "epoch: 19/20,    batch: 1774/2993    Discriminator_loss: 0.0004881465865764767  Generator_loss: 7.706851959228516\n",
            "epoch: 19/20,    batch: 1775/2993    Discriminator_loss: 0.0004715510585810989  Generator_loss: 7.728293418884277\n",
            "epoch: 19/20,    batch: 1776/2993    Discriminator_loss: 0.000743634533137083  Generator_loss: 7.747061729431152\n",
            "epoch: 19/20,    batch: 1777/2993    Discriminator_loss: 0.0005120679852552712  Generator_loss: 7.764283180236816\n",
            "epoch: 19/20,    batch: 1778/2993    Discriminator_loss: 0.000454966735560447  Generator_loss: 7.780021667480469\n",
            "epoch: 19/20,    batch: 1779/2993    Discriminator_loss: 0.001524507300928235  Generator_loss: 7.789846420288086\n",
            "epoch: 19/20,    batch: 1780/2993    Discriminator_loss: 0.00045068515464663506  Generator_loss: 7.799214839935303\n",
            "epoch: 19/20,    batch: 1781/2993    Discriminator_loss: 0.00043784116860479116  Generator_loss: 7.808322429656982\n",
            "epoch: 19/20,    batch: 1782/2993    Discriminator_loss: 0.00047329909284599125  Generator_loss: 7.816903591156006\n",
            "epoch: 19/20,    batch: 1783/2993    Discriminator_loss: 0.00046813907101750374  Generator_loss: 7.825017929077148\n",
            "epoch: 19/20,    batch: 1784/2993    Discriminator_loss: 0.0004396198783069849  Generator_loss: 7.833227634429932\n",
            "epoch: 19/20,    batch: 1785/2993    Discriminator_loss: 0.0004511396982707083  Generator_loss: 7.841135025024414\n",
            "epoch: 19/20,    batch: 1786/2993    Discriminator_loss: 0.0005623043398372829  Generator_loss: 7.848915100097656\n",
            "epoch: 19/20,    batch: 1787/2993    Discriminator_loss: 0.00042157561983913183  Generator_loss: 7.857178688049316\n",
            "epoch: 19/20,    batch: 1788/2993    Discriminator_loss: 0.0019382510799914598  Generator_loss: 7.858614444732666\n",
            "epoch: 19/20,    batch: 1789/2993    Discriminator_loss: 0.0014440433587878942  Generator_loss: 7.858807563781738\n",
            "epoch: 19/20,    batch: 1790/2993    Discriminator_loss: 0.0004087125707883388  Generator_loss: 7.861124038696289\n",
            "epoch: 19/20,    batch: 1791/2993    Discriminator_loss: 0.0007346050115302205  Generator_loss: 7.864745140075684\n",
            "epoch: 19/20,    batch: 1792/2993    Discriminator_loss: 0.00041559591772966087  Generator_loss: 7.870075225830078\n",
            "epoch: 19/20,    batch: 1793/2993    Discriminator_loss: 0.00040394204552285373  Generator_loss: 7.8765716552734375\n",
            "epoch: 19/20,    batch: 1794/2993    Discriminator_loss: 0.0010993753094226122  Generator_loss: 7.88104772567749\n",
            "epoch: 19/20,    batch: 1795/2993    Discriminator_loss: 0.00040980271296575665  Generator_loss: 7.885712623596191\n",
            "epoch: 19/20,    batch: 1796/2993    Discriminator_loss: 0.0003937046567443758  Generator_loss: 7.890140056610107\n",
            "epoch: 19/20,    batch: 1797/2993    Discriminator_loss: 0.0006134815630502999  Generator_loss: 7.893199443817139\n",
            "epoch: 19/20,    batch: 1798/2993    Discriminator_loss: 0.0004072867159266025  Generator_loss: 7.895087242126465\n",
            "epoch: 19/20,    batch: 1799/2993    Discriminator_loss: 0.000442999298684299  Generator_loss: 7.895057201385498\n",
            "epoch: 19/20,    batch: 1800/2993    Discriminator_loss: 0.0017392635345458984  Generator_loss: 7.887259006500244\n",
            "epoch: 19/20,    batch: 1801/2993    Discriminator_loss: 0.00040382443694397807  Generator_loss: 7.878330230712891\n",
            "epoch: 19/20,    batch: 1802/2993    Discriminator_loss: 0.0004015295417048037  Generator_loss: 7.867708206176758\n",
            "epoch: 19/20,    batch: 1803/2993    Discriminator_loss: 0.001538401236757636  Generator_loss: 7.847531318664551\n",
            "epoch: 19/20,    batch: 1804/2993    Discriminator_loss: 0.0007855869480408728  Generator_loss: 7.823825836181641\n",
            "epoch: 19/20,    batch: 1805/2993    Discriminator_loss: 0.00044382945634424686  Generator_loss: 7.7980523109436035\n",
            "epoch: 19/20,    batch: 1806/2993    Discriminator_loss: 0.0013937365729361773  Generator_loss: 7.765046119689941\n",
            "epoch: 19/20,    batch: 1807/2993    Discriminator_loss: 0.0013411690015345812  Generator_loss: 7.7213616371154785\n",
            "epoch: 19/20,    batch: 1808/2993    Discriminator_loss: 0.0004959088983014226  Generator_loss: 7.675234794616699\n",
            "epoch: 19/20,    batch: 1809/2993    Discriminator_loss: 0.0005210866802372038  Generator_loss: 7.625528335571289\n",
            "epoch: 19/20,    batch: 1810/2993    Discriminator_loss: 0.024120235815644264  Generator_loss: 7.3009419441223145\n",
            "epoch: 19/20,    batch: 1811/2993    Discriminator_loss: 0.0009000534191727638  Generator_loss: 7.031707286834717\n",
            "epoch: 19/20,    batch: 1812/2993    Discriminator_loss: 0.0011039180681109428  Generator_loss: 6.8197431564331055\n",
            "epoch: 19/20,    batch: 1813/2993    Discriminator_loss: 0.004465330392122269  Generator_loss: 6.642982006072998\n",
            "epoch: 19/20,    batch: 1814/2993    Discriminator_loss: 0.002151964232325554  Generator_loss: 6.524479866027832\n",
            "epoch: 19/20,    batch: 1815/2993    Discriminator_loss: 0.0016902410425245762  Generator_loss: 6.464280128479004\n",
            "epoch: 19/20,    batch: 1816/2993    Discriminator_loss: 0.0017313538119196892  Generator_loss: 6.455099105834961\n",
            "epoch: 19/20,    batch: 1817/2993    Discriminator_loss: 0.0017903349362313747  Generator_loss: 6.4885478019714355\n",
            "epoch: 19/20,    batch: 1818/2993    Discriminator_loss: 0.001629664096981287  Generator_loss: 6.55560827255249\n",
            "epoch: 19/20,    batch: 1819/2993    Discriminator_loss: 0.0015068785287439823  Generator_loss: 6.646352767944336\n",
            "epoch: 19/20,    batch: 1820/2993    Discriminator_loss: 0.0017713849665597081  Generator_loss: 6.750514984130859\n",
            "epoch: 19/20,    batch: 1821/2993    Discriminator_loss: 0.0012707628775388002  Generator_loss: 6.863037109375\n",
            "epoch: 19/20,    batch: 1822/2993    Discriminator_loss: 0.0010904032969847322  Generator_loss: 6.979037284851074\n",
            "epoch: 19/20,    batch: 1823/2993    Discriminator_loss: 0.000984460930339992  Generator_loss: 7.093840599060059\n",
            "epoch: 19/20,    batch: 1824/2993    Discriminator_loss: 0.0008765858365222812  Generator_loss: 7.203680515289307\n",
            "epoch: 19/20,    batch: 1825/2993    Discriminator_loss: 0.0007682114373892546  Generator_loss: 7.307010173797607\n",
            "epoch: 19/20,    batch: 1826/2993    Discriminator_loss: 0.0007867494132369757  Generator_loss: 7.401396751403809\n",
            "epoch: 19/20,    batch: 1827/2993    Discriminator_loss: 0.000672356691211462  Generator_loss: 7.486729621887207\n",
            "epoch: 19/20,    batch: 1828/2993    Discriminator_loss: 0.0005832368624396622  Generator_loss: 7.562166213989258\n",
            "epoch: 19/20,    batch: 1829/2993    Discriminator_loss: 0.0007947005215100944  Generator_loss: 7.626590728759766\n",
            "epoch: 19/20,    batch: 1830/2993    Discriminator_loss: 0.0005400750087574124  Generator_loss: 7.6813764572143555\n",
            "epoch: 19/20,    batch: 1831/2993    Discriminator_loss: 0.0004888020339421928  Generator_loss: 7.726027965545654\n",
            "epoch: 19/20,    batch: 1832/2993    Discriminator_loss: 0.0004822181072086096  Generator_loss: 7.7615580558776855\n",
            "epoch: 19/20,    batch: 1833/2993    Discriminator_loss: 0.0004728874482680112  Generator_loss: 7.788722038269043\n",
            "epoch: 19/20,    batch: 1834/2993    Discriminator_loss: 0.00045906950253993273  Generator_loss: 7.808763027191162\n",
            "epoch: 19/20,    batch: 1835/2993    Discriminator_loss: 0.0004889428382739425  Generator_loss: 7.82291316986084\n",
            "epoch: 19/20,    batch: 1836/2993    Discriminator_loss: 0.000453623419161886  Generator_loss: 7.832513809204102\n",
            "epoch: 19/20,    batch: 1837/2993    Discriminator_loss: 0.0004450313572306186  Generator_loss: 7.839261054992676\n",
            "epoch: 19/20,    batch: 1838/2993    Discriminator_loss: 0.0005122370203025639  Generator_loss: 7.843012809753418\n",
            "epoch: 19/20,    batch: 1839/2993    Discriminator_loss: 0.00045137573033571243  Generator_loss: 7.842918395996094\n",
            "epoch: 19/20,    batch: 1840/2993    Discriminator_loss: 0.00042271052370779216  Generator_loss: 7.84451150894165\n",
            "epoch: 19/20,    batch: 1841/2993    Discriminator_loss: 0.0005481918924488127  Generator_loss: 7.845142364501953\n",
            "epoch: 19/20,    batch: 1842/2993    Discriminator_loss: 0.0004260928544681519  Generator_loss: 7.853163719177246\n",
            "epoch: 19/20,    batch: 1843/2993    Discriminator_loss: 0.00041713041719049215  Generator_loss: 7.858774185180664\n",
            "epoch: 19/20,    batch: 1844/2993    Discriminator_loss: 0.0004482253280002624  Generator_loss: 7.863960266113281\n",
            "epoch: 19/20,    batch: 1845/2993    Discriminator_loss: 0.000421662291046232  Generator_loss: 7.86927604675293\n",
            "epoch: 19/20,    batch: 1846/2993    Discriminator_loss: 0.0004126371059101075  Generator_loss: 7.871374130249023\n",
            "epoch: 19/20,    batch: 1847/2993    Discriminator_loss: 0.0005149359931237996  Generator_loss: 7.8696465492248535\n",
            "epoch: 19/20,    batch: 1848/2993    Discriminator_loss: 0.00041868758853524923  Generator_loss: 7.905148506164551\n",
            "epoch: 19/20,    batch: 1849/2993    Discriminator_loss: 0.0004077344201505184  Generator_loss: 7.884455680847168\n",
            "epoch: 19/20,    batch: 1850/2993    Discriminator_loss: 0.0005136365070939064  Generator_loss: 7.904190540313721\n",
            "epoch: 19/20,    batch: 1851/2993    Discriminator_loss: 0.0004787998623214662  Generator_loss: 7.916383743286133\n",
            "epoch: 19/20,    batch: 1852/2993    Discriminator_loss: 0.0004130275046918541  Generator_loss: 7.917283058166504\n",
            "epoch: 19/20,    batch: 1853/2993    Discriminator_loss: 0.0005213536787778139  Generator_loss: 7.902617454528809\n",
            "epoch: 19/20,    batch: 1854/2993    Discriminator_loss: 0.00044351935503073037  Generator_loss: 7.889235496520996\n",
            "epoch: 19/20,    batch: 1855/2993    Discriminator_loss: 0.00040440683369524777  Generator_loss: 7.891139030456543\n",
            "epoch: 19/20,    batch: 1856/2993    Discriminator_loss: 0.000622317660599947  Generator_loss: 7.875210762023926\n",
            "epoch: 19/20,    batch: 1857/2993    Discriminator_loss: 0.0004632031195797026  Generator_loss: 7.847140789031982\n",
            "epoch: 19/20,    batch: 1858/2993    Discriminator_loss: 0.00042853443301282823  Generator_loss: 7.822383403778076\n",
            "epoch: 19/20,    batch: 1859/2993    Discriminator_loss: 0.0006849215133115649  Generator_loss: 7.799205303192139\n",
            "epoch: 19/20,    batch: 1860/2993    Discriminator_loss: 0.0004957221099175513  Generator_loss: 7.773643970489502\n",
            "epoch: 19/20,    batch: 1861/2993    Discriminator_loss: 0.00047874529263935983  Generator_loss: 7.745992660522461\n",
            "epoch: 19/20,    batch: 1862/2993    Discriminator_loss: 0.000536926556378603  Generator_loss: 7.7170257568359375\n",
            "epoch: 19/20,    batch: 1863/2993    Discriminator_loss: 0.0005243828636594117  Generator_loss: 7.691102027893066\n",
            "epoch: 19/20,    batch: 1864/2993    Discriminator_loss: 0.0005617570714093745  Generator_loss: 7.669480323791504\n",
            "epoch: 19/20,    batch: 1865/2993    Discriminator_loss: 0.0006147194071672857  Generator_loss: 7.653011798858643\n",
            "epoch: 19/20,    batch: 1866/2993    Discriminator_loss: 0.0005527824396267533  Generator_loss: 7.642424583435059\n",
            "epoch: 19/20,    batch: 1867/2993    Discriminator_loss: 0.0005709605757147074  Generator_loss: 7.637296199798584\n",
            "epoch: 19/20,    batch: 1868/2993    Discriminator_loss: 0.0005770533462055027  Generator_loss: 7.636300563812256\n",
            "epoch: 19/20,    batch: 1869/2993    Discriminator_loss: 0.0006417836411856115  Generator_loss: 7.638278007507324\n",
            "epoch: 19/20,    batch: 1870/2993    Discriminator_loss: 0.0007359046721830964  Generator_loss: 7.639020919799805\n",
            "epoch: 19/20,    batch: 1871/2993    Discriminator_loss: 0.0006026081391610205  Generator_loss: 7.640190601348877\n",
            "epoch: 19/20,    batch: 1872/2993    Discriminator_loss: 0.0005866803112439811  Generator_loss: 7.640438556671143\n",
            "epoch: 19/20,    batch: 1873/2993    Discriminator_loss: 0.0005832027527503669  Generator_loss: 7.638216972351074\n",
            "epoch: 19/20,    batch: 1874/2993    Discriminator_loss: 0.000644627318251878  Generator_loss: 7.630551338195801\n",
            "epoch: 19/20,    batch: 1875/2993    Discriminator_loss: 0.0005995286046527326  Generator_loss: 7.6195068359375\n",
            "epoch: 19/20,    batch: 1876/2993    Discriminator_loss: 0.0005585899925790727  Generator_loss: 7.6103715896606445\n",
            "epoch: 19/20,    batch: 1877/2993    Discriminator_loss: 0.0010383196640759706  Generator_loss: 7.6135053634643555\n",
            "epoch: 19/20,    batch: 1878/2993    Discriminator_loss: 0.0012093326076865196  Generator_loss: 7.623142242431641\n",
            "epoch: 19/20,    batch: 1879/2993    Discriminator_loss: 0.0005447492585517466  Generator_loss: 7.6279144287109375\n",
            "epoch: 19/20,    batch: 1880/2993    Discriminator_loss: 0.0006485771737061441  Generator_loss: 7.630972862243652\n",
            "epoch: 19/20,    batch: 1881/2993    Discriminator_loss: 0.0005653028492815793  Generator_loss: 7.640872478485107\n",
            "epoch: 19/20,    batch: 1882/2993    Discriminator_loss: 0.0005259589524939656  Generator_loss: 7.660717964172363\n",
            "epoch: 19/20,    batch: 1883/2993    Discriminator_loss: 0.000620890234131366  Generator_loss: 7.685788154602051\n",
            "epoch: 19/20,    batch: 1884/2993    Discriminator_loss: 0.0005500533152371645  Generator_loss: 7.711010932922363\n",
            "epoch: 19/20,    batch: 1885/2993    Discriminator_loss: 0.0004849748220294714  Generator_loss: 7.735095977783203\n",
            "epoch: 19/20,    batch: 1886/2993    Discriminator_loss: 0.0005088630132377148  Generator_loss: 7.758884906768799\n",
            "epoch: 19/20,    batch: 1887/2993    Discriminator_loss: 0.00047093594912439585  Generator_loss: 7.784756660461426\n",
            "epoch: 19/20,    batch: 1888/2993    Discriminator_loss: 0.0004401773039717227  Generator_loss: 7.813976287841797\n",
            "epoch: 19/20,    batch: 1889/2993    Discriminator_loss: 0.0005643945187330246  Generator_loss: 7.844646453857422\n",
            "epoch: 19/20,    batch: 1890/2993    Discriminator_loss: 0.0004247484903316945  Generator_loss: 7.8760223388671875\n",
            "epoch: 19/20,    batch: 1891/2993    Discriminator_loss: 0.0017702883342280984  Generator_loss: 7.90311861038208\n",
            "epoch: 19/20,    batch: 1892/2993    Discriminator_loss: 0.0022268735338002443  Generator_loss: 7.907522678375244\n",
            "epoch: 19/20,    batch: 1893/2993    Discriminator_loss: 0.00040146237006410956  Generator_loss: 7.914920330047607\n",
            "epoch: 19/20,    batch: 1894/2993    Discriminator_loss: 0.0005679859314113855  Generator_loss: 7.923473358154297\n",
            "epoch: 19/20,    batch: 1895/2993    Discriminator_loss: 0.0005049603641964495  Generator_loss: 7.933574676513672\n",
            "epoch: 19/20,    batch: 1896/2993    Discriminator_loss: 0.00038682122249156237  Generator_loss: 7.945806503295898\n",
            "epoch: 19/20,    batch: 1897/2993    Discriminator_loss: 0.0006884903414174914  Generator_loss: 7.959629535675049\n",
            "epoch: 19/20,    batch: 1898/2993    Discriminator_loss: 0.00042970720096491277  Generator_loss: 7.974403381347656\n",
            "epoch: 19/20,    batch: 1899/2993    Discriminator_loss: 0.0003727635194081813  Generator_loss: 7.990068435668945\n",
            "epoch: 19/20,    batch: 1900/2993    Discriminator_loss: 0.0005779532948508859  Generator_loss: 8.006452560424805\n",
            "epoch: 19/20,    batch: 1901/2993    Discriminator_loss: 0.0003781520645134151  Generator_loss: 8.025089263916016\n",
            "epoch: 19/20,    batch: 1902/2993    Discriminator_loss: 0.0003563931386452168  Generator_loss: 8.045648574829102\n",
            "epoch: 19/20,    batch: 1903/2993    Discriminator_loss: 0.00038583079003728926  Generator_loss: 8.067909240722656\n",
            "epoch: 19/20,    batch: 1904/2993    Discriminator_loss: 0.0003529908717609942  Generator_loss: 8.091675758361816\n",
            "epoch: 19/20,    batch: 1905/2993    Discriminator_loss: 0.00033286947291344404  Generator_loss: 8.116019248962402\n",
            "epoch: 19/20,    batch: 1906/2993    Discriminator_loss: 0.0004764499026350677  Generator_loss: 8.139795303344727\n",
            "epoch: 19/20,    batch: 1907/2993    Discriminator_loss: 0.00032213455415330827  Generator_loss: 8.163116455078125\n",
            "epoch: 19/20,    batch: 1908/2993    Discriminator_loss: 0.0003184274537488818  Generator_loss: 8.185924530029297\n",
            "epoch: 19/20,    batch: 1909/2993    Discriminator_loss: 0.0002998286799993366  Generator_loss: 8.207377433776855\n",
            "epoch: 19/20,    batch: 1910/2993    Discriminator_loss: 0.00033537240233272314  Generator_loss: 8.227333068847656\n",
            "epoch: 19/20,    batch: 1911/2993    Discriminator_loss: 0.00029731838731095195  Generator_loss: 8.245336532592773\n",
            "epoch: 19/20,    batch: 1912/2993    Discriminator_loss: 0.0003366874880157411  Generator_loss: 8.260496139526367\n",
            "epoch: 19/20,    batch: 1913/2993    Discriminator_loss: 0.0004934896132908762  Generator_loss: 8.27076530456543\n",
            "epoch: 19/20,    batch: 1914/2993    Discriminator_loss: 0.0003089956589974463  Generator_loss: 8.278421401977539\n",
            "epoch: 19/20,    batch: 1915/2993    Discriminator_loss: 0.0002721564087551087  Generator_loss: 8.283599853515625\n",
            "epoch: 19/20,    batch: 1916/2993    Discriminator_loss: 0.0003729793825186789  Generator_loss: 8.285415649414062\n",
            "epoch: 19/20,    batch: 1917/2993    Discriminator_loss: 0.0002835316408891231  Generator_loss: 8.284425735473633\n",
            "epoch: 19/20,    batch: 1918/2993    Discriminator_loss: 0.0002729426487348974  Generator_loss: 8.280698776245117\n",
            "epoch: 19/20,    batch: 1919/2993    Discriminator_loss: 0.00042654492426663637  Generator_loss: 8.273855209350586\n",
            "epoch: 19/20,    batch: 1920/2993    Discriminator_loss: 0.00028536212630569935  Generator_loss: 8.265276908874512\n",
            "epoch: 19/20,    batch: 1921/2993    Discriminator_loss: 0.0004310016520321369  Generator_loss: 8.25350284576416\n",
            "epoch: 19/20,    batch: 1922/2993    Discriminator_loss: 0.0016748941270634532  Generator_loss: 8.225077629089355\n",
            "epoch: 19/20,    batch: 1923/2993    Discriminator_loss: 0.0003037214046344161  Generator_loss: 8.199605941772461\n",
            "epoch: 19/20,    batch: 1924/2993    Discriminator_loss: 0.0008057319209910929  Generator_loss: 8.170476913452148\n",
            "epoch: 19/20,    batch: 1925/2993    Discriminator_loss: 0.0017986041493713856  Generator_loss: 8.12850570678711\n",
            "epoch: 19/20,    batch: 1926/2993    Discriminator_loss: 0.0003266431449446827  Generator_loss: 8.094123840332031\n",
            "epoch: 19/20,    batch: 1927/2993    Discriminator_loss: 0.00040877109859138727  Generator_loss: 8.065713882446289\n",
            "epoch: 19/20,    batch: 1928/2993    Discriminator_loss: 0.0003538683522492647  Generator_loss: 8.043628692626953\n",
            "epoch: 19/20,    batch: 1929/2993    Discriminator_loss: 0.0003528163069859147  Generator_loss: 8.026958465576172\n",
            "epoch: 19/20,    batch: 1930/2993    Discriminator_loss: 0.0006775872898288071  Generator_loss: 8.012214660644531\n",
            "epoch: 19/20,    batch: 1931/2993    Discriminator_loss: 0.0003695150080602616  Generator_loss: 8.00229263305664\n",
            "epoch: 19/20,    batch: 1932/2993    Discriminator_loss: 0.0003729751624632627  Generator_loss: 7.996997356414795\n",
            "epoch: 19/20,    batch: 1933/2993    Discriminator_loss: 0.0032093985937535763  Generator_loss: 7.952402591705322\n",
            "epoch: 19/20,    batch: 1934/2993    Discriminator_loss: 0.0004045148380100727  Generator_loss: 7.920720100402832\n",
            "epoch: 19/20,    batch: 1935/2993    Discriminator_loss: 0.00039728180854581296  Generator_loss: 7.90158748626709\n",
            "epoch: 19/20,    batch: 1936/2993    Discriminator_loss: 0.002177390968427062  Generator_loss: 7.865346908569336\n",
            "epoch: 19/20,    batch: 1937/2993    Discriminator_loss: 0.0007006868254393339  Generator_loss: 7.843183517456055\n",
            "epoch: 19/20,    batch: 1938/2993    Discriminator_loss: 0.0004427315725479275  Generator_loss: 7.836004257202148\n",
            "epoch: 19/20,    batch: 1939/2993    Discriminator_loss: 0.00042209646198898554  Generator_loss: 7.842045307159424\n",
            "epoch: 19/20,    batch: 1940/2993    Discriminator_loss: 0.0009614741429686546  Generator_loss: 7.853517532348633\n",
            "epoch: 19/20,    batch: 1941/2993    Discriminator_loss: 0.00042935111559927464  Generator_loss: 7.875443458557129\n",
            "epoch: 19/20,    batch: 1942/2993    Discriminator_loss: 0.0004027866816613823  Generator_loss: 7.905823707580566\n",
            "epoch: 19/20,    batch: 1943/2993    Discriminator_loss: 0.000934250361751765  Generator_loss: 7.936488151550293\n",
            "epoch: 19/20,    batch: 1944/2993    Discriminator_loss: 0.0004097953496966511  Generator_loss: 7.972532272338867\n",
            "epoch: 19/20,    batch: 1945/2993    Discriminator_loss: 0.00037093940773047507  Generator_loss: 8.012203216552734\n",
            "epoch: 19/20,    batch: 1946/2993    Discriminator_loss: 0.0003526002692524344  Generator_loss: 8.053994178771973\n",
            "epoch: 19/20,    batch: 1947/2993    Discriminator_loss: 0.0004451015265658498  Generator_loss: 8.095125198364258\n",
            "epoch: 19/20,    batch: 1948/2993    Discriminator_loss: 0.0003378692490514368  Generator_loss: 8.136590003967285\n",
            "epoch: 19/20,    batch: 1949/2993    Discriminator_loss: 0.00030608236556872725  Generator_loss: 8.175085067749023\n",
            "epoch: 19/20,    batch: 1950/2993    Discriminator_loss: 0.0012145184446126223  Generator_loss: 8.196237564086914\n",
            "epoch: 19/20,    batch: 1951/2993    Discriminator_loss: 0.00040135305607691407  Generator_loss: 8.219173431396484\n",
            "epoch: 19/20,    batch: 1952/2993    Discriminator_loss: 0.00029857587651349604  Generator_loss: 8.2369384765625\n",
            "epoch: 19/20,    batch: 1953/2993    Discriminator_loss: 0.0011631289962679148  Generator_loss: 8.230762481689453\n",
            "epoch: 19/20,    batch: 1954/2993    Discriminator_loss: 0.01749584451317787  Generator_loss: 7.790329933166504\n",
            "epoch: 19/20,    batch: 1955/2993    Discriminator_loss: 0.0005474816425703466  Generator_loss: 7.441581726074219\n",
            "epoch: 19/20,    batch: 1956/2993    Discriminator_loss: 0.0008001716923899949  Generator_loss: 7.18889045715332\n",
            "epoch: 19/20,    batch: 1957/2993    Discriminator_loss: 0.0009218966588377953  Generator_loss: 7.033069610595703\n",
            "epoch: 19/20,    batch: 1958/2993    Discriminator_loss: 0.0010030940175056458  Generator_loss: 7.001090049743652\n",
            "epoch: 19/20,    batch: 1959/2993    Discriminator_loss: 0.0009541266481392086  Generator_loss: 7.161901473999023\n",
            "epoch: 19/20,    batch: 1960/2993    Discriminator_loss: 0.0008910036995075643  Generator_loss: 7.19174861907959\n",
            "epoch: 19/20,    batch: 1961/2993    Discriminator_loss: 0.000823376583866775  Generator_loss: 7.264840602874756\n",
            "epoch: 19/20,    batch: 1962/2993    Discriminator_loss: 0.0009409941267222166  Generator_loss: 7.444022178649902\n",
            "epoch: 19/20,    batch: 1963/2993    Discriminator_loss: 0.0005949745536781847  Generator_loss: 7.6283745765686035\n",
            "epoch: 19/20,    batch: 1964/2993    Discriminator_loss: 0.00048435170901939273  Generator_loss: 7.790234565734863\n",
            "epoch: 19/20,    batch: 1965/2993    Discriminator_loss: 0.000461462012026459  Generator_loss: 7.930856704711914\n",
            "epoch: 19/20,    batch: 1966/2993    Discriminator_loss: 0.0003860665310639888  Generator_loss: 8.053549766540527\n",
            "epoch: 19/20,    batch: 1967/2993    Discriminator_loss: 0.0003313873603474349  Generator_loss: 8.162986755371094\n",
            "epoch: 19/20,    batch: 1968/2993    Discriminator_loss: 0.0003439458378124982  Generator_loss: 8.26563835144043\n",
            "epoch: 19/20,    batch: 1969/2993    Discriminator_loss: 0.00028967217076569796  Generator_loss: 8.36465835571289\n",
            "epoch: 19/20,    batch: 1970/2993    Discriminator_loss: 0.00024107852368615568  Generator_loss: 8.452905654907227\n",
            "epoch: 19/20,    batch: 1971/2993    Discriminator_loss: 0.00032979995012283325  Generator_loss: 8.518895149230957\n",
            "epoch: 19/20,    batch: 1972/2993    Discriminator_loss: 0.0002196651475969702  Generator_loss: 8.560867309570312\n",
            "epoch: 19/20,    batch: 1973/2993    Discriminator_loss: 0.00021373714844230562  Generator_loss: 8.582263946533203\n",
            "epoch: 19/20,    batch: 1974/2993    Discriminator_loss: 0.0004083600942976773  Generator_loss: 8.590468406677246\n",
            "epoch: 19/20,    batch: 1975/2993    Discriminator_loss: 0.0002423575788270682  Generator_loss: 8.590989112854004\n",
            "epoch: 19/20,    batch: 1976/2993    Discriminator_loss: 0.0002047455491265282  Generator_loss: 8.582801818847656\n",
            "epoch: 19/20,    batch: 1977/2993    Discriminator_loss: 0.0002954970404971391  Generator_loss: 8.559234619140625\n",
            "epoch: 19/20,    batch: 1978/2993    Discriminator_loss: 0.0002215062122559175  Generator_loss: 8.52437686920166\n",
            "epoch: 19/20,    batch: 1979/2993    Discriminator_loss: 0.00023857568157836795  Generator_loss: 8.486349105834961\n",
            "epoch: 19/20,    batch: 1980/2993    Discriminator_loss: 0.0002451117616146803  Generator_loss: 8.447732925415039\n",
            "epoch: 19/20,    batch: 1981/2993    Discriminator_loss: 0.0002562618174124509  Generator_loss: 8.410249710083008\n",
            "epoch: 19/20,    batch: 1982/2993    Discriminator_loss: 0.0002552822988945991  Generator_loss: 8.373766899108887\n",
            "epoch: 19/20,    batch: 1983/2993    Discriminator_loss: 0.000287815259071067  Generator_loss: 8.341658592224121\n",
            "epoch: 19/20,    batch: 1984/2993    Discriminator_loss: 0.0003247059357818216  Generator_loss: 8.319692611694336\n",
            "epoch: 19/20,    batch: 1985/2993    Discriminator_loss: 0.0002870997413992882  Generator_loss: 8.311410903930664\n",
            "epoch: 19/20,    batch: 1986/2993    Discriminator_loss: 0.0002916634548455477  Generator_loss: 8.315620422363281\n",
            "epoch: 19/20,    batch: 1987/2993    Discriminator_loss: 0.0002878194791264832  Generator_loss: 8.330421447753906\n",
            "epoch: 19/20,    batch: 1988/2993    Discriminator_loss: 0.00028148156707175076  Generator_loss: 8.354254722595215\n",
            "epoch: 19/20,    batch: 1989/2993    Discriminator_loss: 0.0003371087950654328  Generator_loss: 8.38467025756836\n",
            "epoch: 19/20,    batch: 1990/2993    Discriminator_loss: 0.00026689068181440234  Generator_loss: 8.421424865722656\n",
            "epoch: 19/20,    batch: 1991/2993    Discriminator_loss: 0.00024388625752180815  Generator_loss: 8.462082862854004\n",
            "epoch: 19/20,    batch: 1992/2993    Discriminator_loss: 0.00025377192650921643  Generator_loss: 8.504537582397461\n",
            "epoch: 19/20,    batch: 1993/2993    Discriminator_loss: 0.0002494670625310391  Generator_loss: 8.546743392944336\n",
            "epoch: 19/20,    batch: 1994/2993    Discriminator_loss: 0.00020718770974781364  Generator_loss: 8.587346076965332\n",
            "epoch: 19/20,    batch: 1995/2993    Discriminator_loss: 0.000588574621360749  Generator_loss: 8.619940757751465\n",
            "epoch: 19/20,    batch: 1996/2993    Discriminator_loss: 0.00037841955781914294  Generator_loss: 8.650732040405273\n",
            "epoch: 19/20,    batch: 1997/2993    Discriminator_loss: 0.00018869539781007916  Generator_loss: 8.679585456848145\n",
            "epoch: 19/20,    batch: 1998/2993    Discriminator_loss: 0.00021561466564889997  Generator_loss: 8.704947471618652\n",
            "epoch: 19/20,    batch: 1999/2993    Discriminator_loss: 0.00020580666023306549  Generator_loss: 8.726964950561523\n",
            "epoch: 19/20,    batch: 2000/2993    Discriminator_loss: 0.00025449797976762056  Generator_loss: 8.74376106262207\n",
            "epoch: 19/20,    batch: 2001/2993    Discriminator_loss: 0.0003776014782488346  Generator_loss: 8.751760482788086\n",
            "epoch: 19/20,    batch: 2002/2993    Discriminator_loss: 0.00018547993386164308  Generator_loss: 8.755322456359863\n",
            "epoch: 19/20,    batch: 2003/2993    Discriminator_loss: 0.0001739966101013124  Generator_loss: 8.753905296325684\n",
            "epoch: 19/20,    batch: 2004/2993    Discriminator_loss: 0.00036462448770180345  Generator_loss: 8.744555473327637\n",
            "epoch: 19/20,    batch: 2005/2993    Discriminator_loss: 0.00018046806508209556  Generator_loss: 8.731778144836426\n",
            "epoch: 19/20,    batch: 2006/2993    Discriminator_loss: 0.0002039427199633792  Generator_loss: 8.717658996582031\n",
            "epoch: 19/20,    batch: 2007/2993    Discriminator_loss: 0.005601287819445133  Generator_loss: 8.572257041931152\n",
            "epoch: 19/20,    batch: 2008/2993    Discriminator_loss: 0.006383043713867664  Generator_loss: 8.190078735351562\n",
            "epoch: 19/20,    batch: 2009/2993    Discriminator_loss: 0.00038335268618538976  Generator_loss: 7.901960372924805\n",
            "epoch: 19/20,    batch: 2010/2993    Discriminator_loss: 0.0004913967568427324  Generator_loss: 7.707639217376709\n",
            "epoch: 19/20,    batch: 2011/2993    Discriminator_loss: 0.0018174707656726241  Generator_loss: 7.567383289337158\n",
            "epoch: 19/20,    batch: 2012/2993    Discriminator_loss: 0.0006970622343942523  Generator_loss: 7.520603179931641\n",
            "epoch: 19/20,    batch: 2013/2993    Discriminator_loss: 0.0006085322820581496  Generator_loss: 7.553374290466309\n",
            "epoch: 19/20,    batch: 2014/2993    Discriminator_loss: 0.013232801109552383  Generator_loss: 7.378810882568359\n",
            "epoch: 19/20,    batch: 2015/2993    Discriminator_loss: 0.0016421570908278227  Generator_loss: 7.3137969970703125\n",
            "epoch: 19/20,    batch: 2016/2993    Discriminator_loss: 0.0008395532495342195  Generator_loss: 7.355672836303711\n",
            "epoch: 19/20,    batch: 2017/2993    Discriminator_loss: 0.0006653992459177971  Generator_loss: 7.478330612182617\n",
            "epoch: 19/20,    batch: 2018/2993    Discriminator_loss: 0.0006658027414232492  Generator_loss: 7.652376174926758\n",
            "epoch: 19/20,    batch: 2019/2993    Discriminator_loss: 0.00048497971147298813  Generator_loss: 7.853210926055908\n",
            "epoch: 19/20,    batch: 2020/2993    Discriminator_loss: 0.0003882023156620562  Generator_loss: 8.06039047241211\n",
            "epoch: 19/20,    batch: 2021/2993    Discriminator_loss: 0.8548212051391602  Generator_loss: 1.7300639152526855\n",
            "epoch: 19/20,    batch: 2022/2993    Discriminator_loss: 0.8443442583084106  Generator_loss: 7.936269760131836\n",
            "epoch: 19/20,    batch: 2023/2993    Discriminator_loss: 3.1255367503035814e-06  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2024/2993    Discriminator_loss: 2.0485957065830007e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2025/2993    Discriminator_loss: 0.00021581281907856464  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2026/2993    Discriminator_loss: 8.977967809187248e-07  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2027/2993    Discriminator_loss: 8.636951679363847e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2028/2993    Discriminator_loss: 3.73268048861064e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2029/2993    Discriminator_loss: 5.506054549186956e-06  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2030/2993    Discriminator_loss: 3.244091203669086e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2031/2993    Discriminator_loss: 4.358975274953991e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2032/2993    Discriminator_loss: 0.00011099661787739024  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2033/2993    Discriminator_loss: 5.6622033298481256e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2034/2993    Discriminator_loss: 2.0191757357679307e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2035/2993    Discriminator_loss: 4.120035009691492e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2036/2993    Discriminator_loss: 2.8765614842996e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2037/2993    Discriminator_loss: 1.1483309208415449e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2038/2993    Discriminator_loss: 0.005497124046087265  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2039/2993    Discriminator_loss: 0.21194438636302948  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2040/2993    Discriminator_loss: 1.7980364646064118e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2041/2993    Discriminator_loss: 2.2645721401204355e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2042/2993    Discriminator_loss: 0.0009076280985027552  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2043/2993    Discriminator_loss: 5.5307376896962523e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2044/2993    Discriminator_loss: 1.1596939657465555e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2045/2993    Discriminator_loss: 3.484382250462659e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2046/2993    Discriminator_loss: 0.000263385649304837  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2047/2993    Discriminator_loss: 0.00039469278999604285  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2048/2993    Discriminator_loss: 2.9616671781695914e-06  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2049/2993    Discriminator_loss: 3.72953072655946e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2050/2993    Discriminator_loss: 3.5490778827806935e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2051/2993    Discriminator_loss: 9.700747796159703e-06  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2052/2993    Discriminator_loss: 3.390899655641988e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2053/2993    Discriminator_loss: 2.346972542000003e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2054/2993    Discriminator_loss: 4.349466325948015e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2055/2993    Discriminator_loss: 1.2852283362008166e-06  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2056/2993    Discriminator_loss: 2.7675763703882694e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2057/2993    Discriminator_loss: 1.7589223716640845e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2058/2993    Discriminator_loss: 1.1865089390994399e-06  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2059/2993    Discriminator_loss: 3.0997380235930905e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2060/2993    Discriminator_loss: 3.832756920019165e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2061/2993    Discriminator_loss: 6.031304110365454e-06  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2062/2993    Discriminator_loss: 1.6661721019772813e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2063/2993    Discriminator_loss: 2.3438613425241783e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2064/2993    Discriminator_loss: 1.0721542821556795e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2065/2993    Discriminator_loss: 4.87281649839133e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2066/2993    Discriminator_loss: 2.6162562789977528e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2067/2993    Discriminator_loss: 2.5312234356533736e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2068/2993    Discriminator_loss: 4.428461397765204e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2069/2993    Discriminator_loss: 1.0984356777044013e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2070/2993    Discriminator_loss: 2.0090803445782512e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2071/2993    Discriminator_loss: 4.031820935779251e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2072/2993    Discriminator_loss: 1.1434931366238743e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2073/2993    Discriminator_loss: 0.00010487460531294346  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2074/2993    Discriminator_loss: 6.664566899416968e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2075/2993    Discriminator_loss: 0.0003551978152245283  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2076/2993    Discriminator_loss: 2.963496399388532e-06  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2077/2993    Discriminator_loss: 1.0486817700439133e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2078/2993    Discriminator_loss: 2.8627611754927784e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2079/2993    Discriminator_loss: 4.915566478302935e-06  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2080/2993    Discriminator_loss: 4.023975634481758e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2081/2993    Discriminator_loss: 1.610277104191482e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2082/2993    Discriminator_loss: 1.4720912076882087e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2083/2993    Discriminator_loss: 4.6273744374047965e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2084/2993    Discriminator_loss: 4.308071220293641e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2085/2993    Discriminator_loss: 5.178205356060062e-06  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2086/2993    Discriminator_loss: 5.665457501891069e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2087/2993    Discriminator_loss: 3.1073584978003055e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2088/2993    Discriminator_loss: 1.73866210388951e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2089/2993    Discriminator_loss: 1.6045378288254142e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2090/2993    Discriminator_loss: 5.036993388785049e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2091/2993    Discriminator_loss: 1.3094467021801393e-06  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2092/2993    Discriminator_loss: 4.1910883737728e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2093/2993    Discriminator_loss: 2.8201040549902245e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2094/2993    Discriminator_loss: 1.2405243978719227e-06  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2095/2993    Discriminator_loss: 1.2466798580135219e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2096/2993    Discriminator_loss: 4.19748030253686e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2097/2993    Discriminator_loss: 1.2556438377941959e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2098/2993    Discriminator_loss: 2.0960675101378e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2099/2993    Discriminator_loss: 2.135209615516942e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2100/2993    Discriminator_loss: 8.676308425492607e-06  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2101/2993    Discriminator_loss: 2.9982145861140452e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2102/2993    Discriminator_loss: 2.1872132492717355e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2103/2993    Discriminator_loss: 2.908848546212539e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2104/2993    Discriminator_loss: 2.9067454306641594e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2105/2993    Discriminator_loss: 0.00022029437241144478  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2106/2993    Discriminator_loss: 3.2354408176615834e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2107/2993    Discriminator_loss: 6.473721441579983e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2108/2993    Discriminator_loss: 4.071147850481793e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2109/2993    Discriminator_loss: 1.974425686057657e-06  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2110/2993    Discriminator_loss: 0.00023904572299215943  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2111/2993    Discriminator_loss: 0.0002033772034337744  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2112/2993    Discriminator_loss: 5.272877388051711e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2113/2993    Discriminator_loss: 0.658343493938446  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2114/2993    Discriminator_loss: 0.0003525024512782693  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2115/2993    Discriminator_loss: 0.0001076587795978412  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2116/2993    Discriminator_loss: 6.901695451233536e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2117/2993    Discriminator_loss: 0.00029759755125269294  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2118/2993    Discriminator_loss: 5.9506248362595215e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2119/2993    Discriminator_loss: 7.981517228472512e-06  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2120/2993    Discriminator_loss: 1.4487879525404423e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2121/2993    Discriminator_loss: 1.9183833501301706e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2122/2993    Discriminator_loss: 5.668943776981905e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2123/2993    Discriminator_loss: 2.3711570520390524e-06  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2124/2993    Discriminator_loss: 0.0001249667548108846  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2125/2993    Discriminator_loss: 2.6271860406268388e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2126/2993    Discriminator_loss: 1.102688202081481e-06  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2127/2993    Discriminator_loss: 1.651255661272444e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2128/2993    Discriminator_loss: 2.7631544071482494e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2129/2993    Discriminator_loss: 2.602123913675314e-06  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2130/2993    Discriminator_loss: 1.6754795069573447e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2131/2993    Discriminator_loss: 1.2522890756372362e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2132/2993    Discriminator_loss: 5.3663075050280895e-06  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2133/2993    Discriminator_loss: 2.2033633285900578e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2134/2993    Discriminator_loss: 5.8190084928355645e-06  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2135/2993    Discriminator_loss: 0.00014014077896717936  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2136/2993    Discriminator_loss: 0.00018370656471233815  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2137/2993    Discriminator_loss: 1.166020410892088e-06  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2138/2993    Discriminator_loss: 1.969790901057422e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2139/2993    Discriminator_loss: 1.222464743477758e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2140/2993    Discriminator_loss: 4.921157142234733e-06  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2141/2993    Discriminator_loss: 1.0755034963949583e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2142/2993    Discriminator_loss: 1.6393463738495484e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2143/2993    Discriminator_loss: 1.0976821613439824e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2144/2993    Discriminator_loss: 1.0872400707739871e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2145/2993    Discriminator_loss: 1.4625649782828987e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2146/2993    Discriminator_loss: 7.221545729407808e-06  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2147/2993    Discriminator_loss: 7.361221832979936e-06  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2148/2993    Discriminator_loss: 2.0105913790757768e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2149/2993    Discriminator_loss: 1.782213985279668e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2150/2993    Discriminator_loss: 4.971477210347075e-06  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2151/2993    Discriminator_loss: 1.2628870535991155e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2152/2993    Discriminator_loss: 7.0371143010561354e-06  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2153/2993    Discriminator_loss: 4.252446160535328e-06  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2154/2993    Discriminator_loss: 1.2064502698194701e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2155/2993    Discriminator_loss: 3.642719821073115e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2156/2993    Discriminator_loss: 1.1939583828279865e-06  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2157/2993    Discriminator_loss: 1.662987779127434e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2158/2993    Discriminator_loss: 1.088367025658954e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2159/2993    Discriminator_loss: 4.018860636278987e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2160/2993    Discriminator_loss: 1.3085210412100423e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2161/2993    Discriminator_loss: 1.3070462955511175e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2162/2993    Discriminator_loss: 1.1479689419502392e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2163/2993    Discriminator_loss: 3.108143573626876e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2164/2993    Discriminator_loss: 4.675292984757107e-06  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2165/2993    Discriminator_loss: 7.867865861044265e-06  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2166/2993    Discriminator_loss: 2.810442674672231e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2167/2993    Discriminator_loss: 8.847580375004327e-07  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2168/2993    Discriminator_loss: 3.409149212529883e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2169/2993    Discriminator_loss: 1.5201236237771809e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2170/2993    Discriminator_loss: 1.2628772765310714e-06  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2171/2993    Discriminator_loss: 1.3949501408205833e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2172/2993    Discriminator_loss: 2.5285860829171725e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2173/2993    Discriminator_loss: 9.257371402782155e-07  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2174/2993    Discriminator_loss: 3.0308425266412087e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2175/2993    Discriminator_loss: 3.9057798858266324e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2176/2993    Discriminator_loss: 7.875410119595472e-06  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2177/2993    Discriminator_loss: 9.777098966878839e-06  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2178/2993    Discriminator_loss: 1.2247002814547159e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2179/2993    Discriminator_loss: 6.018267413310241e-06  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2180/2993    Discriminator_loss: 3.080220631090924e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2181/2993    Discriminator_loss: 3.026916783710476e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2182/2993    Discriminator_loss: 1.8055121472571045e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2183/2993    Discriminator_loss: 7.292330792552093e-06  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2184/2993    Discriminator_loss: 1.3893612958781887e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2185/2993    Discriminator_loss: 7.82875758886803e-06  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2186/2993    Discriminator_loss: 4.110877853236161e-06  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2187/2993    Discriminator_loss: 4.812172119272873e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2188/2993    Discriminator_loss: 1.8462846128386445e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2189/2993    Discriminator_loss: 5.860023520654067e-06  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2190/2993    Discriminator_loss: 1.8790662579704076e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2191/2993    Discriminator_loss: 1.9973605958512053e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2192/2993    Discriminator_loss: 1.3938534721091855e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2193/2993    Discriminator_loss: 2.1035302779637277e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2194/2993    Discriminator_loss: 1.0216826922260225e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2195/2993    Discriminator_loss: 5.2620007409132086e-06  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2196/2993    Discriminator_loss: 3.7434867408592254e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2197/2993    Discriminator_loss: 6.035103979229461e-06  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2198/2993    Discriminator_loss: 1.039365724864183e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2199/2993    Discriminator_loss: 2.899299215641804e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2200/2993    Discriminator_loss: 9.834782304096734e-07  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2201/2993    Discriminator_loss: 0.0001617650850676  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2202/2993    Discriminator_loss: 3.671030935947783e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2203/2993    Discriminator_loss: 3.2522034416615497e-06  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2204/2993    Discriminator_loss: 3.106798976659775e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2205/2993    Discriminator_loss: 3.971662590629421e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2206/2993    Discriminator_loss: 4.787004854733823e-07  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2207/2993    Discriminator_loss: 4.7977184294722974e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2208/2993    Discriminator_loss: 3.505812128423713e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2209/2993    Discriminator_loss: 2.224811578344088e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2210/2993    Discriminator_loss: 6.737245257681934e-06  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2211/2993    Discriminator_loss: 5.372704254114069e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2212/2993    Discriminator_loss: 1.589042949490249e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2213/2993    Discriminator_loss: 9.238734151040262e-07  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2214/2993    Discriminator_loss: 4.4571545004146174e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2215/2993    Discriminator_loss: 4.8782414523884654e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2216/2993    Discriminator_loss: 5.569314680542448e-07  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2217/2993    Discriminator_loss: 1.416751001670491e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2218/2993    Discriminator_loss: 3.163243309245445e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2219/2993    Discriminator_loss: 1.983728679988417e-06  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2220/2993    Discriminator_loss: 2.858908919733949e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2221/2993    Discriminator_loss: 2.4708497221581638e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2222/2993    Discriminator_loss: 2.7095480618299916e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2223/2993    Discriminator_loss: 7.348192411882337e-06  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2224/2993    Discriminator_loss: 5.5485492339357734e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2225/2993    Discriminator_loss: 1.125451672123745e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2226/2993    Discriminator_loss: 9.302119906351436e-06  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2227/2993    Discriminator_loss: 6.505943019874394e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2228/2993    Discriminator_loss: 1.0505352747713914e-06  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2229/2993    Discriminator_loss: 2.7667203539749607e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2230/2993    Discriminator_loss: 4.475167952477932e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2231/2993    Discriminator_loss: 8.158399396052118e-07  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2232/2993    Discriminator_loss: 1.2187391803308856e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2233/2993    Discriminator_loss: 4.855263978242874e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2234/2993    Discriminator_loss: 3.0938651889300672e-06  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2235/2993    Discriminator_loss: 7.543007850646973  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2236/2993    Discriminator_loss: 12.43956470489502  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2237/2993    Discriminator_loss: 1.1861048936843872  Generator_loss: 14.898982048034668\n",
            "epoch: 19/20,    batch: 2238/2993    Discriminator_loss: 0.0107497563585639  Generator_loss: 13.763227462768555\n",
            "epoch: 19/20,    batch: 2239/2993    Discriminator_loss: 0.0010215850779786706  Generator_loss: 12.858694076538086\n",
            "epoch: 19/20,    batch: 2240/2993    Discriminator_loss: 0.00031439794111065567  Generator_loss: 11.667959213256836\n",
            "epoch: 19/20,    batch: 2241/2993    Discriminator_loss: 0.00019311386859044433  Generator_loss: 9.864540100097656\n",
            "epoch: 19/20,    batch: 2242/2993    Discriminator_loss: 0.00031637464417144656  Generator_loss: 7.2624125480651855\n",
            "epoch: 19/20,    batch: 2243/2993    Discriminator_loss: 0.004523728042840958  Generator_loss: 3.996980667114258\n",
            "epoch: 19/20,    batch: 2244/2993    Discriminator_loss: 0.26748618483543396  Generator_loss: 5.891749858856201\n",
            "epoch: 19/20,    batch: 2245/2993    Discriminator_loss: 0.0004372589464765042  Generator_loss: 9.566145896911621\n",
            "epoch: 19/20,    batch: 2246/2993    Discriminator_loss: 0.00010252271022181958  Generator_loss: 10.577162742614746\n",
            "epoch: 19/20,    batch: 2247/2993    Discriminator_loss: 8.112953219097108e-05  Generator_loss: 11.001226425170898\n",
            "epoch: 19/20,    batch: 2248/2993    Discriminator_loss: 7.922046643216163e-05  Generator_loss: 11.234307289123535\n",
            "epoch: 19/20,    batch: 2249/2993    Discriminator_loss: 7.195954822236672e-05  Generator_loss: 11.374202728271484\n",
            "epoch: 19/20,    batch: 2250/2993    Discriminator_loss: 7.111950981197879e-05  Generator_loss: 11.455560684204102\n",
            "epoch: 19/20,    batch: 2251/2993    Discriminator_loss: 0.00018672745500225574  Generator_loss: 11.496504783630371\n",
            "epoch: 19/20,    batch: 2252/2993    Discriminator_loss: 3.726660361280665e-05  Generator_loss: 11.51348876953125\n",
            "epoch: 19/20,    batch: 2253/2993    Discriminator_loss: 1.6616762877674773e-05  Generator_loss: 11.51348876953125\n",
            "epoch: 19/20,    batch: 2254/2993    Discriminator_loss: 1.1080929652962368e-05  Generator_loss: 11.501631736755371\n",
            "epoch: 19/20,    batch: 2255/2993    Discriminator_loss: 3.097636727034114e-05  Generator_loss: 11.478330612182617\n",
            "epoch: 19/20,    batch: 2256/2993    Discriminator_loss: 4.426506347954273e-05  Generator_loss: 11.455560684204102\n",
            "epoch: 19/20,    batch: 2257/2993    Discriminator_loss: 1.125416201830376e-05  Generator_loss: 11.42234992980957\n",
            "epoch: 19/20,    batch: 2258/2993    Discriminator_loss: 2.3579410481033847e-05  Generator_loss: 11.390206336975098\n",
            "epoch: 19/20,    batch: 2259/2993    Discriminator_loss: 3.190382631146349e-05  Generator_loss: 11.359063148498535\n",
            "epoch: 19/20,    batch: 2260/2993    Discriminator_loss: 1.4040702808415517e-05  Generator_loss: 11.31899356842041\n",
            "epoch: 19/20,    batch: 2261/2993    Discriminator_loss: 1.3705423043575138e-05  Generator_loss: 11.28046703338623\n",
            "epoch: 19/20,    batch: 2262/2993    Discriminator_loss: 2.956052776426077e-05  Generator_loss: 11.235723495483398\n",
            "epoch: 19/20,    batch: 2263/2993    Discriminator_loss: 5.6081094953697175e-05  Generator_loss: 11.19885540008545\n",
            "epoch: 19/20,    batch: 2264/2993    Discriminator_loss: 1.4325704796647187e-05  Generator_loss: 11.156237602233887\n",
            "epoch: 19/20,    batch: 2265/2993    Discriminator_loss: 2.6509387680562213e-05  Generator_loss: 11.111621856689453\n",
            "epoch: 19/20,    batch: 2266/2993    Discriminator_loss: 3.344975266372785e-05  Generator_loss: 11.068418502807617\n",
            "epoch: 19/20,    batch: 2267/2993    Discriminator_loss: 1.6894322470761836e-05  Generator_loss: 11.023581504821777\n",
            "epoch: 19/20,    batch: 2268/2993    Discriminator_loss: 2.172802123823203e-05  Generator_loss: 10.987693786621094\n",
            "epoch: 19/20,    batch: 2269/2993    Discriminator_loss: 4.282481677364558e-05  Generator_loss: 10.94626235961914\n",
            "epoch: 19/20,    batch: 2270/2993    Discriminator_loss: 3.9194470446091145e-05  Generator_loss: 10.906479835510254\n",
            "epoch: 19/20,    batch: 2271/2993    Discriminator_loss: 1.91910130524775e-05  Generator_loss: 10.866660118103027\n",
            "epoch: 19/20,    batch: 2272/2993    Discriminator_loss: 5.629437873722054e-05  Generator_loss: 10.825356483459473\n",
            "epoch: 19/20,    batch: 2273/2993    Discriminator_loss: 5.4411928431363776e-05  Generator_loss: 10.79002571105957\n",
            "epoch: 19/20,    batch: 2274/2993    Discriminator_loss: 2.27710679610027e-05  Generator_loss: 10.755203247070312\n",
            "epoch: 19/20,    batch: 2275/2993    Discriminator_loss: 5.557388794841245e-05  Generator_loss: 10.71750545501709\n",
            "epoch: 19/20,    batch: 2276/2993    Discriminator_loss: 2.933142241090536e-05  Generator_loss: 10.683292388916016\n",
            "epoch: 19/20,    batch: 2277/2993    Discriminator_loss: 2.72638353635557e-05  Generator_loss: 10.649889945983887\n",
            "epoch: 19/20,    batch: 2278/2993    Discriminator_loss: 5.5675489420536906e-05  Generator_loss: 10.615291595458984\n",
            "epoch: 19/20,    batch: 2279/2993    Discriminator_loss: 2.617979953356553e-05  Generator_loss: 10.581703186035156\n",
            "epoch: 19/20,    batch: 2280/2993    Discriminator_loss: 3.2796000596135855e-05  Generator_loss: 10.544527053833008\n",
            "epoch: 19/20,    batch: 2281/2993    Discriminator_loss: 7.881860074121505e-05  Generator_loss: 10.500395774841309\n",
            "epoch: 19/20,    batch: 2282/2993    Discriminator_loss: 2.794937972794287e-05  Generator_loss: 10.478711128234863\n",
            "epoch: 19/20,    batch: 2283/2993    Discriminator_loss: 3.880127042066306e-05  Generator_loss: 10.455020904541016\n",
            "epoch: 19/20,    batch: 2284/2993    Discriminator_loss: 7.612015178892761e-05  Generator_loss: 10.416208267211914\n",
            "epoch: 19/20,    batch: 2285/2993    Discriminator_loss: 3.208455382264219e-05  Generator_loss: 10.375253677368164\n",
            "epoch: 19/20,    batch: 2286/2993    Discriminator_loss: 5.1901748520322144e-05  Generator_loss: 10.349437713623047\n",
            "epoch: 19/20,    batch: 2287/2993    Discriminator_loss: 6.185979873407632e-05  Generator_loss: 10.320646286010742\n",
            "epoch: 19/20,    batch: 2288/2993    Discriminator_loss: 3.4105607483070344e-05  Generator_loss: 10.286520004272461\n",
            "epoch: 19/20,    batch: 2289/2993    Discriminator_loss: 3.909197403118014e-05  Generator_loss: 10.24656867980957\n",
            "epoch: 19/20,    batch: 2290/2993    Discriminator_loss: 4.8520825657760724e-05  Generator_loss: 10.20633316040039\n",
            "epoch: 19/20,    batch: 2291/2993    Discriminator_loss: 9.465175389777869e-05  Generator_loss: 10.170570373535156\n",
            "epoch: 19/20,    batch: 2292/2993    Discriminator_loss: 4.059713683091104e-05  Generator_loss: 10.131728172302246\n",
            "epoch: 19/20,    batch: 2293/2993    Discriminator_loss: 5.9162412071600556e-05  Generator_loss: 10.087238311767578\n",
            "epoch: 19/20,    batch: 2294/2993    Discriminator_loss: 6.819120608270168e-05  Generator_loss: 10.03891372680664\n",
            "epoch: 19/20,    batch: 2295/2993    Discriminator_loss: 4.5842607505619526e-05  Generator_loss: 9.9893159866333\n",
            "epoch: 19/20,    batch: 2296/2993    Discriminator_loss: 5.479090032167733e-05  Generator_loss: 9.939205169677734\n",
            "epoch: 19/20,    batch: 2297/2993    Discriminator_loss: 7.406453369185328e-05  Generator_loss: 9.887810707092285\n",
            "epoch: 19/20,    batch: 2298/2993    Discriminator_loss: 6.792508065700531e-05  Generator_loss: 9.834468841552734\n",
            "epoch: 19/20,    batch: 2299/2993    Discriminator_loss: 5.846444400958717e-05  Generator_loss: 9.778751373291016\n",
            "epoch: 19/20,    batch: 2300/2993    Discriminator_loss: 8.069571777014062e-05  Generator_loss: 9.723732948303223\n",
            "epoch: 19/20,    batch: 2301/2993    Discriminator_loss: 7.344615005422384e-05  Generator_loss: 9.67057991027832\n",
            "epoch: 19/20,    batch: 2302/2993    Discriminator_loss: 6.64110848447308e-05  Generator_loss: 9.618875503540039\n",
            "epoch: 19/20,    batch: 2303/2993    Discriminator_loss: 9.525904170004651e-05  Generator_loss: 9.569074630737305\n",
            "epoch: 19/20,    batch: 2304/2993    Discriminator_loss: 9.260250953957438e-05  Generator_loss: 9.519450187683105\n",
            "epoch: 19/20,    batch: 2305/2993    Discriminator_loss: 8.826301927911118e-05  Generator_loss: 9.470723152160645\n",
            "epoch: 19/20,    batch: 2306/2993    Discriminator_loss: 8.54707759572193e-05  Generator_loss: 9.422231674194336\n",
            "epoch: 19/20,    batch: 2307/2993    Discriminator_loss: 0.00012348566087894142  Generator_loss: 9.373350143432617\n",
            "epoch: 19/20,    batch: 2308/2993    Discriminator_loss: 0.00010590203601168469  Generator_loss: 9.324238777160645\n",
            "epoch: 19/20,    batch: 2309/2993    Discriminator_loss: 9.786592272575945e-05  Generator_loss: 9.273290634155273\n",
            "epoch: 19/20,    batch: 2310/2993    Discriminator_loss: 0.0001228506152983755  Generator_loss: 9.21878719329834\n",
            "epoch: 19/20,    batch: 2311/2993    Discriminator_loss: 0.00010977690544677898  Generator_loss: 9.158079147338867\n",
            "epoch: 19/20,    batch: 2312/2993    Discriminator_loss: 0.0001132770994445309  Generator_loss: 9.126623153686523\n",
            "epoch: 19/20,    batch: 2313/2993    Discriminator_loss: 0.00015053221432026476  Generator_loss: 9.048042297363281\n",
            "epoch: 19/20,    batch: 2314/2993    Discriminator_loss: 0.00013471471902448684  Generator_loss: 8.992574691772461\n",
            "epoch: 19/20,    batch: 2315/2993    Discriminator_loss: 0.00014302111230790615  Generator_loss: 8.917976379394531\n",
            "epoch: 19/20,    batch: 2316/2993    Discriminator_loss: 0.00017372937873005867  Generator_loss: 8.812776565551758\n",
            "epoch: 19/20,    batch: 2317/2993    Discriminator_loss: 0.00016312673687934875  Generator_loss: 8.733672142028809\n",
            "epoch: 19/20,    batch: 2318/2993    Discriminator_loss: 0.0001850356493378058  Generator_loss: 8.650235176086426\n",
            "epoch: 19/20,    batch: 2319/2993    Discriminator_loss: 0.00023005862021818757  Generator_loss: 8.558691024780273\n",
            "epoch: 19/20,    batch: 2320/2993    Discriminator_loss: 0.0002105122257489711  Generator_loss: 8.466129302978516\n",
            "epoch: 19/20,    batch: 2321/2993    Discriminator_loss: 0.00025649313465692103  Generator_loss: 8.375334739685059\n",
            "epoch: 19/20,    batch: 2322/2993    Discriminator_loss: 0.0002964662853628397  Generator_loss: 8.284708023071289\n",
            "epoch: 19/20,    batch: 2323/2993    Discriminator_loss: 0.00027851114282384515  Generator_loss: 8.193929672241211\n",
            "epoch: 19/20,    batch: 2324/2993    Discriminator_loss: 0.00032014670432545245  Generator_loss: 8.100563049316406\n",
            "epoch: 19/20,    batch: 2325/2993    Discriminator_loss: 0.00037374484236352146  Generator_loss: 8.006341934204102\n",
            "epoch: 19/20,    batch: 2326/2993    Discriminator_loss: 0.0003999115724582225  Generator_loss: 7.909450054168701\n",
            "epoch: 19/20,    batch: 2327/2993    Discriminator_loss: 0.00040649992297403514  Generator_loss: 7.812784671783447\n",
            "epoch: 19/20,    batch: 2328/2993    Discriminator_loss: 0.0004710936627816409  Generator_loss: 7.718696117401123\n",
            "epoch: 19/20,    batch: 2329/2993    Discriminator_loss: 0.0005304815131239593  Generator_loss: 7.625080108642578\n",
            "epoch: 19/20,    batch: 2330/2993    Discriminator_loss: 0.000539382454007864  Generator_loss: 7.527033805847168\n",
            "epoch: 19/20,    batch: 2331/2993    Discriminator_loss: 0.0006098606390878558  Generator_loss: 7.42830753326416\n",
            "epoch: 19/20,    batch: 2332/2993    Discriminator_loss: 0.0007097183261066675  Generator_loss: 7.317234516143799\n",
            "epoch: 19/20,    batch: 2333/2993    Discriminator_loss: 0.0008012899779714644  Generator_loss: 7.19564151763916\n",
            "epoch: 19/20,    batch: 2334/2993    Discriminator_loss: 0.0008519061375409365  Generator_loss: 7.071351051330566\n",
            "epoch: 19/20,    batch: 2335/2993    Discriminator_loss: 0.001077225897461176  Generator_loss: 6.886775970458984\n",
            "epoch: 19/20,    batch: 2336/2993    Discriminator_loss: 0.0013412355910986662  Generator_loss: 6.6722307205200195\n",
            "epoch: 19/20,    batch: 2337/2993    Discriminator_loss: 0.0016920308116823435  Generator_loss: 6.398370265960693\n",
            "epoch: 19/20,    batch: 2338/2993    Discriminator_loss: 0.002551994752138853  Generator_loss: 6.098138809204102\n",
            "epoch: 19/20,    batch: 2339/2993    Discriminator_loss: 0.003640941809862852  Generator_loss: 5.685418128967285\n",
            "epoch: 19/20,    batch: 2340/2993    Discriminator_loss: 0.0058625368401408195  Generator_loss: 5.262587547302246\n",
            "epoch: 19/20,    batch: 2341/2993    Discriminator_loss: 0.008669430390000343  Generator_loss: 4.971449851989746\n",
            "epoch: 19/20,    batch: 2342/2993    Discriminator_loss: 0.016871357336640358  Generator_loss: 4.444350719451904\n",
            "epoch: 19/20,    batch: 2343/2993    Discriminator_loss: 0.01845592074096203  Generator_loss: 4.485669136047363\n",
            "epoch: 19/20,    batch: 2344/2993    Discriminator_loss: 0.015687111765146255  Generator_loss: 4.72635555267334\n",
            "epoch: 19/20,    batch: 2345/2993    Discriminator_loss: 0.013694113120436668  Generator_loss: 4.986391067504883\n",
            "epoch: 19/20,    batch: 2346/2993    Discriminator_loss: 0.009657954797148705  Generator_loss: 5.319089412689209\n",
            "epoch: 19/20,    batch: 2347/2993    Discriminator_loss: 0.007511274889111519  Generator_loss: 5.567173480987549\n",
            "epoch: 19/20,    batch: 2348/2993    Discriminator_loss: 0.007813990116119385  Generator_loss: 5.496916770935059\n",
            "epoch: 19/20,    batch: 2349/2993    Discriminator_loss: 0.007315111346542835  Generator_loss: 5.52890682220459\n",
            "epoch: 19/20,    batch: 2350/2993    Discriminator_loss: 0.007369923405349255  Generator_loss: 5.490787506103516\n",
            "epoch: 19/20,    batch: 2351/2993    Discriminator_loss: 0.006868061143904924  Generator_loss: 5.556283473968506\n",
            "epoch: 19/20,    batch: 2352/2993    Discriminator_loss: 0.006514689885079861  Generator_loss: 5.5818095207214355\n",
            "epoch: 19/20,    batch: 2353/2993    Discriminator_loss: 0.0053558978252112865  Generator_loss: 5.716548919677734\n",
            "epoch: 19/20,    batch: 2354/2993    Discriminator_loss: 0.0048443833366036415  Generator_loss: 5.769740104675293\n",
            "epoch: 19/20,    batch: 2355/2993    Discriminator_loss: 0.004438025876879692  Generator_loss: 5.83439826965332\n",
            "epoch: 19/20,    batch: 2356/2993    Discriminator_loss: 0.004536474123597145  Generator_loss: 5.8061723709106445\n",
            "epoch: 19/20,    batch: 2357/2993    Discriminator_loss: 0.004335864447057247  Generator_loss: 5.810140609741211\n",
            "epoch: 19/20,    batch: 2358/2993    Discriminator_loss: 0.003982107155025005  Generator_loss: 5.856803894042969\n",
            "epoch: 19/20,    batch: 2359/2993    Discriminator_loss: 0.003803262719884515  Generator_loss: 5.8807783126831055\n",
            "epoch: 19/20,    batch: 2360/2993    Discriminator_loss: 0.0037365909665822983  Generator_loss: 5.876468658447266\n",
            "epoch: 19/20,    batch: 2361/2993    Discriminator_loss: 0.0037116792518645525  Generator_loss: 5.859138488769531\n",
            "epoch: 19/20,    batch: 2362/2993    Discriminator_loss: 0.003686973825097084  Generator_loss: 5.84682559967041\n",
            "epoch: 19/20,    batch: 2363/2993    Discriminator_loss: 0.0036729692947119474  Generator_loss: 5.842061996459961\n",
            "epoch: 19/20,    batch: 2364/2993    Discriminator_loss: 0.003624963341280818  Generator_loss: 5.8376874923706055\n",
            "epoch: 19/20,    batch: 2365/2993    Discriminator_loss: 0.003597618080675602  Generator_loss: 5.834364891052246\n",
            "epoch: 19/20,    batch: 2366/2993    Discriminator_loss: 0.003627689788118005  Generator_loss: 5.821316719055176\n",
            "epoch: 19/20,    batch: 2367/2993    Discriminator_loss: 0.003672678954899311  Generator_loss: 5.798372745513916\n",
            "epoch: 19/20,    batch: 2368/2993    Discriminator_loss: 0.00372648099437356  Generator_loss: 5.767261505126953\n",
            "epoch: 19/20,    batch: 2369/2993    Discriminator_loss: 0.0038239259738475084  Generator_loss: 5.734865188598633\n",
            "epoch: 19/20,    batch: 2370/2993    Discriminator_loss: 0.003950622398406267  Generator_loss: 5.69954776763916\n",
            "epoch: 19/20,    batch: 2371/2993    Discriminator_loss: 0.004063381813466549  Generator_loss: 5.657689094543457\n",
            "epoch: 19/20,    batch: 2372/2993    Discriminator_loss: 0.004220812581479549  Generator_loss: 5.610624313354492\n",
            "epoch: 19/20,    batch: 2373/2993    Discriminator_loss: 0.004357168450951576  Generator_loss: 5.573907852172852\n",
            "epoch: 19/20,    batch: 2374/2993    Discriminator_loss: 0.0044455379247665405  Generator_loss: 5.550314426422119\n",
            "epoch: 19/20,    batch: 2375/2993    Discriminator_loss: 0.004455852322280407  Generator_loss: 5.536640644073486\n",
            "epoch: 19/20,    batch: 2376/2993    Discriminator_loss: 0.004486200865358114  Generator_loss: 5.528934955596924\n",
            "epoch: 19/20,    batch: 2377/2993    Discriminator_loss: 0.004477397538721561  Generator_loss: 5.527749538421631\n",
            "epoch: 19/20,    batch: 2378/2993    Discriminator_loss: 0.004415290895849466  Generator_loss: 5.532271385192871\n",
            "epoch: 19/20,    batch: 2379/2993    Discriminator_loss: 0.004367365501821041  Generator_loss: 5.5404052734375\n",
            "epoch: 19/20,    batch: 2380/2993    Discriminator_loss: 0.004344996064901352  Generator_loss: 5.552075386047363\n",
            "epoch: 19/20,    batch: 2381/2993    Discriminator_loss: 0.004221002571284771  Generator_loss: 5.5666046142578125\n",
            "epoch: 19/20,    batch: 2382/2993    Discriminator_loss: 0.0041526369750499725  Generator_loss: 5.584372043609619\n",
            "epoch: 19/20,    batch: 2383/2993    Discriminator_loss: 0.004083023872226477  Generator_loss: 5.604428291320801\n",
            "epoch: 19/20,    batch: 2384/2993    Discriminator_loss: 0.003954807762056589  Generator_loss: 5.627458572387695\n",
            "epoch: 19/20,    batch: 2385/2993    Discriminator_loss: 0.0038691535592079163  Generator_loss: 5.653873443603516\n",
            "epoch: 19/20,    batch: 2386/2993    Discriminator_loss: 0.003746046917513013  Generator_loss: 5.682400226593018\n",
            "epoch: 19/20,    batch: 2387/2993    Discriminator_loss: 0.0036120526492595673  Generator_loss: 5.713237285614014\n",
            "epoch: 19/20,    batch: 2388/2993    Discriminator_loss: 0.00352659379132092  Generator_loss: 5.745909690856934\n",
            "epoch: 19/20,    batch: 2389/2993    Discriminator_loss: 0.003378738183528185  Generator_loss: 5.779218673706055\n",
            "epoch: 19/20,    batch: 2390/2993    Discriminator_loss: 0.003270647255703807  Generator_loss: 5.812290191650391\n",
            "epoch: 19/20,    batch: 2391/2993    Discriminator_loss: 0.003173047909513116  Generator_loss: 5.844733238220215\n",
            "epoch: 19/20,    batch: 2392/2993    Discriminator_loss: 0.0030665406957268715  Generator_loss: 5.876105785369873\n",
            "epoch: 19/20,    batch: 2393/2993    Discriminator_loss: 0.0029756962321698666  Generator_loss: 5.90683650970459\n",
            "epoch: 19/20,    batch: 2394/2993    Discriminator_loss: 0.0029027035925537348  Generator_loss: 5.936877250671387\n",
            "epoch: 19/20,    batch: 2395/2993    Discriminator_loss: 0.002841770648956299  Generator_loss: 5.966386318206787\n",
            "epoch: 19/20,    batch: 2396/2993    Discriminator_loss: 0.0027333972975611687  Generator_loss: 5.995295524597168\n",
            "epoch: 19/20,    batch: 2397/2993    Discriminator_loss: 0.0026684103067964315  Generator_loss: 6.023013114929199\n",
            "epoch: 19/20,    batch: 2398/2993    Discriminator_loss: 0.002605342073366046  Generator_loss: 6.0502166748046875\n",
            "epoch: 19/20,    batch: 2399/2993    Discriminator_loss: 0.0025263254065066576  Generator_loss: 6.076671123504639\n",
            "epoch: 19/20,    batch: 2400/2993    Discriminator_loss: 0.0024799152743071318  Generator_loss: 6.101581573486328\n",
            "epoch: 19/20,    batch: 2401/2993    Discriminator_loss: 0.0024398930836468935  Generator_loss: 6.124978542327881\n",
            "epoch: 19/20,    batch: 2402/2993    Discriminator_loss: 0.002365772146731615  Generator_loss: 6.145884990692139\n",
            "epoch: 19/20,    batch: 2403/2993    Discriminator_loss: 0.002333573065698147  Generator_loss: 6.163190841674805\n",
            "epoch: 19/20,    batch: 2404/2993    Discriminator_loss: 0.002308489056304097  Generator_loss: 6.177591800689697\n",
            "epoch: 19/20,    batch: 2405/2993    Discriminator_loss: 0.002279768232256174  Generator_loss: 6.189070701599121\n",
            "epoch: 19/20,    batch: 2406/2993    Discriminator_loss: 0.0022730783093720675  Generator_loss: 6.198702812194824\n",
            "epoch: 19/20,    batch: 2407/2993    Discriminator_loss: 0.002264181151986122  Generator_loss: 6.207429885864258\n",
            "epoch: 19/20,    batch: 2408/2993    Discriminator_loss: 0.00225689890794456  Generator_loss: 6.216792106628418\n",
            "epoch: 19/20,    batch: 2409/2993    Discriminator_loss: 0.0022260688710957766  Generator_loss: 6.228602409362793\n",
            "epoch: 19/20,    batch: 2410/2993    Discriminator_loss: 0.002235677093267441  Generator_loss: 6.244256973266602\n",
            "epoch: 19/20,    batch: 2411/2993    Discriminator_loss: 0.0021673550363630056  Generator_loss: 6.2647247314453125\n",
            "epoch: 19/20,    batch: 2412/2993    Discriminator_loss: 0.002130920300260186  Generator_loss: 6.290051460266113\n",
            "epoch: 19/20,    batch: 2413/2993    Discriminator_loss: 0.002098080702126026  Generator_loss: 6.3195414543151855\n",
            "epoch: 19/20,    batch: 2414/2993    Discriminator_loss: 0.0020060245878994465  Generator_loss: 6.352714538574219\n",
            "epoch: 19/20,    batch: 2415/2993    Discriminator_loss: 0.001953963888809085  Generator_loss: 6.387871742248535\n",
            "epoch: 19/20,    batch: 2416/2993    Discriminator_loss: 0.0019160315860062838  Generator_loss: 6.424310207366943\n",
            "epoch: 19/20,    batch: 2417/2993    Discriminator_loss: 0.0018131798133254051  Generator_loss: 6.460821628570557\n",
            "epoch: 19/20,    batch: 2418/2993    Discriminator_loss: 0.0017678893636912107  Generator_loss: 6.496578216552734\n",
            "epoch: 19/20,    batch: 2419/2993    Discriminator_loss: 0.001715052523650229  Generator_loss: 6.531464576721191\n",
            "epoch: 19/20,    batch: 2420/2993    Discriminator_loss: 0.0016366051277145743  Generator_loss: 6.565265655517578\n",
            "epoch: 19/20,    batch: 2421/2993    Discriminator_loss: 0.0016032442217692733  Generator_loss: 6.597399711608887\n",
            "epoch: 19/20,    batch: 2422/2993    Discriminator_loss: 0.0015554542187601328  Generator_loss: 6.628028869628906\n",
            "epoch: 19/20,    batch: 2423/2993    Discriminator_loss: 0.0014889708254486322  Generator_loss: 6.656946659088135\n",
            "epoch: 19/20,    batch: 2424/2993    Discriminator_loss: 0.001466639805585146  Generator_loss: 6.6844282150268555\n",
            "epoch: 19/20,    batch: 2425/2993    Discriminator_loss: 0.0014101507840678096  Generator_loss: 6.710326671600342\n",
            "epoch: 19/20,    batch: 2426/2993    Discriminator_loss: 0.0013683331198990345  Generator_loss: 6.734686851501465\n",
            "epoch: 19/20,    batch: 2427/2993    Discriminator_loss: 0.001348674762994051  Generator_loss: 6.757568359375\n",
            "epoch: 19/20,    batch: 2428/2993    Discriminator_loss: 0.0013617010554298759  Generator_loss: 6.779605388641357\n",
            "epoch: 19/20,    batch: 2429/2993    Discriminator_loss: 0.0012817112728953362  Generator_loss: 6.800705909729004\n",
            "epoch: 19/20,    batch: 2430/2993    Discriminator_loss: 0.0012676987098529935  Generator_loss: 6.821682929992676\n",
            "epoch: 19/20,    batch: 2431/2993    Discriminator_loss: 0.0012430362403392792  Generator_loss: 6.840579032897949\n",
            "epoch: 19/20,    batch: 2432/2993    Discriminator_loss: 0.0012143786298111081  Generator_loss: 6.8572211265563965\n",
            "epoch: 19/20,    batch: 2433/2993    Discriminator_loss: 0.0012102031614631414  Generator_loss: 6.864190578460693\n",
            "epoch: 19/20,    batch: 2434/2993    Discriminator_loss: 0.0010728734778240323  Generator_loss: 7.008007049560547\n",
            "epoch: 19/20,    batch: 2435/2993    Discriminator_loss: 0.0011569367488846183  Generator_loss: 6.9360880851745605\n",
            "epoch: 19/20,    batch: 2436/2993    Discriminator_loss: 0.0010733939707279205  Generator_loss: 6.973427772521973\n",
            "epoch: 19/20,    batch: 2437/2993    Discriminator_loss: 0.0010703972075134516  Generator_loss: 7.00631856918335\n",
            "epoch: 19/20,    batch: 2438/2993    Discriminator_loss: 0.0010262054856866598  Generator_loss: 7.031766891479492\n",
            "epoch: 19/20,    batch: 2439/2993    Discriminator_loss: 0.0010022372007369995  Generator_loss: 7.038455009460449\n",
            "epoch: 19/20,    batch: 2440/2993    Discriminator_loss: 0.0009956782450899482  Generator_loss: 7.045540809631348\n",
            "epoch: 19/20,    batch: 2441/2993    Discriminator_loss: 0.0009935785783454776  Generator_loss: 7.064067840576172\n",
            "epoch: 19/20,    batch: 2442/2993    Discriminator_loss: 0.0010215615620836616  Generator_loss: 7.089404106140137\n",
            "epoch: 19/20,    batch: 2443/2993    Discriminator_loss: 0.0009279904188588262  Generator_loss: 7.1162614822387695\n",
            "epoch: 19/20,    batch: 2444/2993    Discriminator_loss: 0.0009227689006365836  Generator_loss: 7.141231536865234\n",
            "epoch: 19/20,    batch: 2445/2993    Discriminator_loss: 0.000907641020603478  Generator_loss: 7.162616729736328\n",
            "epoch: 19/20,    batch: 2446/2993    Discriminator_loss: 0.0008667102083563805  Generator_loss: 7.1808061599731445\n",
            "epoch: 19/20,    batch: 2447/2993    Discriminator_loss: 0.0008635176345705986  Generator_loss: 7.1965742111206055\n",
            "epoch: 19/20,    batch: 2448/2993    Discriminator_loss: 0.0008652054239064455  Generator_loss: 7.210757255554199\n",
            "epoch: 19/20,    batch: 2449/2993    Discriminator_loss: 0.000825210299808532  Generator_loss: 7.223952293395996\n",
            "epoch: 19/20,    batch: 2450/2993    Discriminator_loss: 0.000843674992211163  Generator_loss: 7.236289024353027\n",
            "epoch: 19/20,    batch: 2451/2993    Discriminator_loss: 0.0008269358077086508  Generator_loss: 7.247745513916016\n",
            "epoch: 19/20,    batch: 2452/2993    Discriminator_loss: 0.0007934286259114742  Generator_loss: 7.259011268615723\n",
            "epoch: 19/20,    batch: 2453/2993    Discriminator_loss: 0.0008183231693692505  Generator_loss: 7.271179676055908\n",
            "epoch: 19/20,    batch: 2454/2993    Discriminator_loss: 0.00079683109652251  Generator_loss: 7.285278797149658\n",
            "epoch: 19/20,    batch: 2455/2993    Discriminator_loss: 0.0007569958688691258  Generator_loss: 7.302681922912598\n",
            "epoch: 19/20,    batch: 2456/2993    Discriminator_loss: 0.0008137976983562112  Generator_loss: 7.323686122894287\n",
            "epoch: 19/20,    batch: 2457/2993    Discriminator_loss: 0.0007178424275480211  Generator_loss: 7.3487701416015625\n",
            "epoch: 19/20,    batch: 2458/2993    Discriminator_loss: 0.0007092221057973802  Generator_loss: 7.377480506896973\n",
            "epoch: 19/20,    batch: 2459/2993    Discriminator_loss: 0.0006853198283351958  Generator_loss: 7.4083356857299805\n",
            "epoch: 19/20,    batch: 2460/2993    Discriminator_loss: 0.0006524622440338135  Generator_loss: 7.441068649291992\n",
            "epoch: 19/20,    batch: 2461/2993    Discriminator_loss: 0.0006310496246442199  Generator_loss: 7.47421932220459\n",
            "epoch: 19/20,    batch: 2462/2993    Discriminator_loss: 0.0006338850362226367  Generator_loss: 7.507420539855957\n",
            "epoch: 19/20,    batch: 2463/2993    Discriminator_loss: 0.0006025113398209214  Generator_loss: 7.539896011352539\n",
            "epoch: 19/20,    batch: 2464/2993    Discriminator_loss: 0.0005664714844897389  Generator_loss: 7.5717010498046875\n",
            "epoch: 19/20,    batch: 2465/2993    Discriminator_loss: 0.000565487309359014  Generator_loss: 7.602512359619141\n",
            "epoch: 19/20,    batch: 2466/2993    Discriminator_loss: 0.0005324864177964628  Generator_loss: 7.63226318359375\n",
            "epoch: 19/20,    batch: 2467/2993    Discriminator_loss: 0.0005123818991705775  Generator_loss: 7.660899639129639\n",
            "epoch: 19/20,    batch: 2468/2993    Discriminator_loss: 0.0005375011824071407  Generator_loss: 7.68840217590332\n",
            "epoch: 19/20,    batch: 2469/2993    Discriminator_loss: 0.0005155146936886013  Generator_loss: 7.714869022369385\n",
            "epoch: 19/20,    batch: 2470/2993    Discriminator_loss: 0.00047044039820320904  Generator_loss: 7.740118026733398\n",
            "epoch: 19/20,    batch: 2471/2993    Discriminator_loss: 0.00047134587657637894  Generator_loss: 7.764089584350586\n",
            "epoch: 19/20,    batch: 2472/2993    Discriminator_loss: 0.0004559012595564127  Generator_loss: 7.786863327026367\n",
            "epoch: 19/20,    batch: 2473/2993    Discriminator_loss: 0.00043453581747598946  Generator_loss: 7.80818510055542\n",
            "epoch: 19/20,    batch: 2474/2993    Discriminator_loss: 0.0004387993540149182  Generator_loss: 7.828005790710449\n",
            "epoch: 19/20,    batch: 2475/2993    Discriminator_loss: 0.00045131906517781317  Generator_loss: 7.84648323059082\n",
            "epoch: 19/20,    batch: 2476/2993    Discriminator_loss: 0.00040900491876527667  Generator_loss: 7.863340377807617\n",
            "epoch: 19/20,    batch: 2477/2993    Discriminator_loss: 0.0004293014935683459  Generator_loss: 7.879037857055664\n",
            "epoch: 19/20,    batch: 2478/2993    Discriminator_loss: 0.0004298962012398988  Generator_loss: 7.89332914352417\n",
            "epoch: 19/20,    batch: 2479/2993    Discriminator_loss: 0.00038993690395727754  Generator_loss: 7.906288146972656\n",
            "epoch: 19/20,    batch: 2480/2993    Discriminator_loss: 0.00039376839413307607  Generator_loss: 7.917954444885254\n",
            "epoch: 19/20,    batch: 2481/2993    Discriminator_loss: 0.00042202879558317363  Generator_loss: 7.928215980529785\n",
            "epoch: 19/20,    batch: 2482/2993    Discriminator_loss: 0.0003771225456148386  Generator_loss: 7.936967849731445\n",
            "epoch: 19/20,    batch: 2483/2993    Discriminator_loss: 0.0003906445053871721  Generator_loss: 7.944093704223633\n",
            "epoch: 19/20,    batch: 2484/2993    Discriminator_loss: 0.0003918434085790068  Generator_loss: 7.949716567993164\n",
            "epoch: 19/20,    batch: 2485/2993    Discriminator_loss: 0.0003728115407284349  Generator_loss: 7.9536638259887695\n",
            "epoch: 19/20,    batch: 2486/2993    Discriminator_loss: 0.0005144492606632411  Generator_loss: 7.956222057342529\n",
            "epoch: 19/20,    batch: 2487/2993    Discriminator_loss: 0.00038319171289913356  Generator_loss: 7.957679271697998\n",
            "epoch: 19/20,    batch: 2488/2993    Discriminator_loss: 0.00037116213934496045  Generator_loss: 7.958052158355713\n",
            "epoch: 19/20,    batch: 2489/2993    Discriminator_loss: 0.00039215837023220956  Generator_loss: 7.957306861877441\n",
            "epoch: 19/20,    batch: 2490/2993    Discriminator_loss: 0.00037851842353120446  Generator_loss: 7.9558820724487305\n",
            "epoch: 19/20,    batch: 2491/2993    Discriminator_loss: 0.00038386433152481914  Generator_loss: 7.9536848068237305\n",
            "epoch: 19/20,    batch: 2492/2993    Discriminator_loss: 0.00037782362778671086  Generator_loss: 7.9510698318481445\n",
            "epoch: 19/20,    batch: 2493/2993    Discriminator_loss: 0.00037097869790159166  Generator_loss: 7.946901321411133\n",
            "epoch: 19/20,    batch: 2494/2993    Discriminator_loss: 0.0003790355985984206  Generator_loss: 7.940445899963379\n",
            "epoch: 19/20,    batch: 2495/2993    Discriminator_loss: 0.00040206321864388883  Generator_loss: 7.932068824768066\n",
            "epoch: 19/20,    batch: 2496/2993    Discriminator_loss: 0.0004009470867458731  Generator_loss: 7.9233503341674805\n",
            "epoch: 19/20,    batch: 2497/2993    Discriminator_loss: 0.0003846422187052667  Generator_loss: 7.913208961486816\n",
            "epoch: 19/20,    batch: 2498/2993    Discriminator_loss: 0.0003978762251790613  Generator_loss: 7.901406764984131\n",
            "epoch: 19/20,    batch: 2499/2993    Discriminator_loss: 0.00039599681622348726  Generator_loss: 7.888708114624023\n",
            "epoch: 19/20,    batch: 2500/2993    Discriminator_loss: 0.0003987517557106912  Generator_loss: 7.875953674316406\n",
            "epoch: 19/20,    batch: 2501/2993    Discriminator_loss: 0.0004103021929040551  Generator_loss: 7.863369941711426\n",
            "epoch: 19/20,    batch: 2502/2993    Discriminator_loss: 0.0004270368372090161  Generator_loss: 7.851161479949951\n",
            "epoch: 19/20,    batch: 2503/2993    Discriminator_loss: 0.0004122583195567131  Generator_loss: 7.83931827545166\n",
            "epoch: 19/20,    batch: 2504/2993    Discriminator_loss: 0.0004264478338882327  Generator_loss: 7.829765796661377\n",
            "epoch: 19/20,    batch: 2505/2993    Discriminator_loss: 0.0004293421807233244  Generator_loss: 7.820971488952637\n",
            "epoch: 19/20,    batch: 2506/2993    Discriminator_loss: 0.00042306797695346177  Generator_loss: 7.8141984939575195\n",
            "epoch: 19/20,    batch: 2507/2993    Discriminator_loss: 0.00044098019134253263  Generator_loss: 7.810102462768555\n",
            "epoch: 19/20,    batch: 2508/2993    Discriminator_loss: 0.0004406955267768353  Generator_loss: 7.807919025421143\n",
            "epoch: 19/20,    batch: 2509/2993    Discriminator_loss: 0.0004253098741173744  Generator_loss: 7.808038711547852\n",
            "epoch: 19/20,    batch: 2510/2993    Discriminator_loss: 0.0004338480648584664  Generator_loss: 7.809267520904541\n",
            "epoch: 19/20,    batch: 2511/2993    Discriminator_loss: 0.000521675159689039  Generator_loss: 7.811840057373047\n",
            "epoch: 19/20,    batch: 2512/2993    Discriminator_loss: 0.0004238334367983043  Generator_loss: 7.814493179321289\n",
            "epoch: 19/20,    batch: 2513/2993    Discriminator_loss: 0.00042993301758542657  Generator_loss: 7.818106651306152\n",
            "epoch: 19/20,    batch: 2514/2993    Discriminator_loss: 0.0005537478718906641  Generator_loss: 7.8218536376953125\n",
            "epoch: 19/20,    batch: 2515/2993    Discriminator_loss: 0.00042028684401884675  Generator_loss: 7.825475692749023\n",
            "epoch: 19/20,    batch: 2516/2993    Discriminator_loss: 0.0004310338117647916  Generator_loss: 7.829241752624512\n",
            "epoch: 19/20,    batch: 2517/2993    Discriminator_loss: 0.00042549570207484066  Generator_loss: 7.832429885864258\n",
            "epoch: 19/20,    batch: 2518/2993    Discriminator_loss: 0.0004178542585577816  Generator_loss: 7.8363542556762695\n",
            "epoch: 19/20,    batch: 2519/2993    Discriminator_loss: 0.000532539386767894  Generator_loss: 7.839469909667969\n",
            "epoch: 19/20,    batch: 2520/2993    Discriminator_loss: 0.0004209209291730076  Generator_loss: 7.844820022583008\n",
            "epoch: 19/20,    batch: 2521/2993    Discriminator_loss: 0.0004174384812358767  Generator_loss: 7.849230766296387\n",
            "epoch: 19/20,    batch: 2522/2993    Discriminator_loss: 0.0004359497397672385  Generator_loss: 7.855829238891602\n",
            "epoch: 19/20,    batch: 2523/2993    Discriminator_loss: 0.00040231336606666446  Generator_loss: 7.862382411956787\n",
            "epoch: 19/20,    batch: 2524/2993    Discriminator_loss: 0.0006137007731013  Generator_loss: 7.869998931884766\n",
            "epoch: 19/20,    batch: 2525/2993    Discriminator_loss: 0.0004110581649001688  Generator_loss: 7.87699556350708\n",
            "epoch: 19/20,    batch: 2526/2993    Discriminator_loss: 0.0003944177587982267  Generator_loss: 7.883903503417969\n",
            "epoch: 19/20,    batch: 2527/2993    Discriminator_loss: 0.00039971998194232583  Generator_loss: 7.889902114868164\n",
            "epoch: 19/20,    batch: 2528/2993    Discriminator_loss: 0.0004066334804520011  Generator_loss: 7.894448757171631\n",
            "epoch: 19/20,    batch: 2529/2993    Discriminator_loss: 0.00039399645174853504  Generator_loss: 7.9039716720581055\n",
            "epoch: 19/20,    batch: 2530/2993    Discriminator_loss: 0.00039419493987224996  Generator_loss: 7.903135299682617\n",
            "epoch: 19/20,    batch: 2531/2993    Discriminator_loss: 0.00039634425775147974  Generator_loss: 7.905401706695557\n",
            "epoch: 19/20,    batch: 2532/2993    Discriminator_loss: 0.00038795286673121154  Generator_loss: 7.9057769775390625\n",
            "epoch: 19/20,    batch: 2533/2993    Discriminator_loss: 0.0003885925398208201  Generator_loss: 7.900273323059082\n",
            "epoch: 19/20,    batch: 2534/2993    Discriminator_loss: 0.00039948217454366386  Generator_loss: 7.8977251052856445\n",
            "epoch: 19/20,    batch: 2535/2993    Discriminator_loss: 0.0004042449872940779  Generator_loss: 7.903826713562012\n",
            "epoch: 19/20,    batch: 2536/2993    Discriminator_loss: 0.0003939908347092569  Generator_loss: 7.884844779968262\n",
            "epoch: 19/20,    batch: 2537/2993    Discriminator_loss: 0.00040902747423388064  Generator_loss: 7.87516450881958\n",
            "epoch: 19/20,    batch: 2538/2993    Discriminator_loss: 0.00039908403414301574  Generator_loss: 7.883913993835449\n",
            "epoch: 19/20,    batch: 2539/2993    Discriminator_loss: 0.0004005189402960241  Generator_loss: 7.8636369705200195\n",
            "epoch: 19/20,    batch: 2540/2993    Discriminator_loss: 0.0004006917297374457  Generator_loss: 7.876255035400391\n",
            "epoch: 19/20,    batch: 2541/2993    Discriminator_loss: 0.00042889706674031913  Generator_loss: 7.852357864379883\n",
            "epoch: 19/20,    batch: 2542/2993    Discriminator_loss: 0.0004127557622268796  Generator_loss: 7.835308074951172\n",
            "epoch: 19/20,    batch: 2543/2993    Discriminator_loss: 0.0005202072206884623  Generator_loss: 7.823800086975098\n",
            "epoch: 19/20,    batch: 2544/2993    Discriminator_loss: 0.00044397899182513356  Generator_loss: 7.8079304695129395\n",
            "epoch: 19/20,    batch: 2545/2993    Discriminator_loss: 0.0004351813404355198  Generator_loss: 7.787195682525635\n",
            "epoch: 19/20,    batch: 2546/2993    Discriminator_loss: 0.0005843190592713654  Generator_loss: 7.766645908355713\n",
            "epoch: 19/20,    batch: 2547/2993    Discriminator_loss: 0.0004760762385558337  Generator_loss: 7.748425006866455\n",
            "epoch: 19/20,    batch: 2548/2993    Discriminator_loss: 0.0004616070073097944  Generator_loss: 7.730624198913574\n",
            "epoch: 19/20,    batch: 2549/2993    Discriminator_loss: 0.0004905129317194223  Generator_loss: 7.709366321563721\n",
            "epoch: 19/20,    batch: 2550/2993    Discriminator_loss: 0.000495301210321486  Generator_loss: 7.680086612701416\n",
            "epoch: 19/20,    batch: 2551/2993    Discriminator_loss: 0.0005062249256297946  Generator_loss: 7.6432719230651855\n",
            "epoch: 19/20,    batch: 2552/2993    Discriminator_loss: 0.0005654246197082102  Generator_loss: 7.595974445343018\n",
            "epoch: 19/20,    batch: 2553/2993    Discriminator_loss: 0.0005601366283372045  Generator_loss: 7.536215782165527\n",
            "epoch: 19/20,    batch: 2554/2993    Discriminator_loss: 0.0006240999791771173  Generator_loss: 7.4618964195251465\n",
            "epoch: 19/20,    batch: 2555/2993    Discriminator_loss: 0.0006779258255846798  Generator_loss: 7.371476173400879\n",
            "epoch: 19/20,    batch: 2556/2993    Discriminator_loss: 0.0007481666980311275  Generator_loss: 7.24914026260376\n",
            "epoch: 19/20,    batch: 2557/2993    Discriminator_loss: 0.0007743597961962223  Generator_loss: 7.225760459899902\n",
            "epoch: 19/20,    batch: 2558/2993    Discriminator_loss: 0.0008840522496029735  Generator_loss: 7.094826698303223\n",
            "epoch: 19/20,    batch: 2559/2993    Discriminator_loss: 0.000949908047914505  Generator_loss: 7.010497093200684\n",
            "epoch: 19/20,    batch: 2560/2993    Discriminator_loss: 0.0010062222136184573  Generator_loss: 6.968751907348633\n",
            "epoch: 19/20,    batch: 2561/2993    Discriminator_loss: 0.0010758352000266314  Generator_loss: 6.919310569763184\n",
            "epoch: 19/20,    batch: 2562/2993    Discriminator_loss: 0.001090067788027227  Generator_loss: 6.873858451843262\n",
            "epoch: 19/20,    batch: 2563/2993    Discriminator_loss: 0.0011427021818235517  Generator_loss: 6.834552764892578\n",
            "epoch: 19/20,    batch: 2564/2993    Discriminator_loss: 0.0011857886565849185  Generator_loss: 6.8008832931518555\n",
            "epoch: 19/20,    batch: 2565/2993    Discriminator_loss: 0.0012105987407267094  Generator_loss: 6.774346351623535\n",
            "epoch: 19/20,    batch: 2566/2993    Discriminator_loss: 0.0012515109265223145  Generator_loss: 6.758172035217285\n",
            "epoch: 19/20,    batch: 2567/2993    Discriminator_loss: 0.001285721082240343  Generator_loss: 6.73723840713501\n",
            "epoch: 19/20,    batch: 2568/2993    Discriminator_loss: 0.0013115741312503815  Generator_loss: 6.705219268798828\n",
            "epoch: 19/20,    batch: 2569/2993    Discriminator_loss: 0.001348707708530128  Generator_loss: 6.6724066734313965\n",
            "epoch: 19/20,    batch: 2570/2993    Discriminator_loss: 0.001408696873113513  Generator_loss: 6.634989261627197\n",
            "epoch: 19/20,    batch: 2571/2993    Discriminator_loss: 0.0014578185509890318  Generator_loss: 6.593910217285156\n",
            "epoch: 19/20,    batch: 2572/2993    Discriminator_loss: 0.0015206292737275362  Generator_loss: 6.553290367126465\n",
            "epoch: 19/20,    batch: 2573/2993    Discriminator_loss: 0.0018392633646726608  Generator_loss: 6.510922431945801\n",
            "epoch: 19/20,    batch: 2574/2993    Discriminator_loss: 0.00170617934782058  Generator_loss: 6.461956024169922\n",
            "epoch: 19/20,    batch: 2575/2993    Discriminator_loss: 0.0017865346744656563  Generator_loss: 6.398646354675293\n",
            "epoch: 19/20,    batch: 2576/2993    Discriminator_loss: 0.002223995514214039  Generator_loss: 6.2891435623168945\n",
            "epoch: 19/20,    batch: 2577/2993    Discriminator_loss: 0.0023604617454111576  Generator_loss: 6.210157871246338\n",
            "epoch: 19/20,    batch: 2578/2993    Discriminator_loss: 0.0037136345636099577  Generator_loss: 6.063229560852051\n",
            "epoch: 19/20,    batch: 2579/2993    Discriminator_loss: 0.0057852850295603275  Generator_loss: 6.33572244644165\n",
            "epoch: 19/20,    batch: 2580/2993    Discriminator_loss: 0.002200911520048976  Generator_loss: 6.770557403564453\n",
            "epoch: 19/20,    batch: 2581/2993    Discriminator_loss: 0.0014676294522359967  Generator_loss: 7.046153545379639\n",
            "epoch: 19/20,    batch: 2582/2993    Discriminator_loss: 0.001459213555790484  Generator_loss: 7.133823394775391\n",
            "epoch: 19/20,    batch: 2583/2993    Discriminator_loss: 0.004866376519203186  Generator_loss: 7.192275524139404\n",
            "epoch: 19/20,    batch: 2584/2993    Discriminator_loss: 0.16239774227142334  Generator_loss: 13.602621078491211\n",
            "epoch: 19/20,    batch: 2585/2993    Discriminator_loss: 2.0903074982925318e-05  Generator_loss: 14.898982048034668\n",
            "epoch: 19/20,    batch: 2586/2993    Discriminator_loss: 7.63685875426745e-07  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2587/2993    Discriminator_loss: 2.085267442453187e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2588/2993    Discriminator_loss: 2.4252338334918022e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2589/2993    Discriminator_loss: 9.611364475858863e-06  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2590/2993    Discriminator_loss: 3.797163662966341e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2591/2993    Discriminator_loss: 0.0001246085303137079  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2592/2993    Discriminator_loss: 8.65290641784668  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2593/2993    Discriminator_loss: 0.7972077131271362  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2594/2993    Discriminator_loss: 3.8738544390071183e-05  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2595/2993    Discriminator_loss: 2.0954823867214145e-06  Generator_loss: 15.33323860168457\n",
            "epoch: 19/20,    batch: 2596/2993    Discriminator_loss: 2.0562461941153742e-05  Generator_loss: 14.898982048034668\n",
            "epoch: 19/20,    batch: 2597/2993    Discriminator_loss: 1.166399488283787e-05  Generator_loss: 14.597209930419922\n",
            "epoch: 19/20,    batch: 2598/2993    Discriminator_loss: 1.320617229794152e-06  Generator_loss: 14.365705490112305\n",
            "epoch: 19/20,    batch: 2599/2993    Discriminator_loss: 4.1999315726570785e-05  Generator_loss: 14.365705490112305\n",
            "epoch: 19/20,    batch: 2600/2993    Discriminator_loss: 3.0287279514595866e-05  Generator_loss: 14.177849769592285\n",
            "epoch: 19/20,    batch: 2601/2993    Discriminator_loss: 1.7453031659897533e-06  Generator_loss: 14.019763946533203\n",
            "epoch: 19/20,    batch: 2602/2993    Discriminator_loss: 2.2243229977902956e-05  Generator_loss: 14.019763946533203\n",
            "epoch: 19/20,    batch: 2603/2993    Discriminator_loss: 8.314906153827906e-06  Generator_loss: 14.019763946533203\n",
            "epoch: 19/20,    batch: 2604/2993    Discriminator_loss: 4.032653123431373e-06  Generator_loss: 13.883291244506836\n",
            "epoch: 19/20,    batch: 2605/2993    Discriminator_loss: 1.6902067727642134e-05  Generator_loss: 13.883291244506836\n",
            "epoch: 19/20,    batch: 2606/2993    Discriminator_loss: 1.8220638594357297e-05  Generator_loss: 13.883291244506836\n",
            "epoch: 19/20,    batch: 2607/2993    Discriminator_loss: 1.0179563105339184e-05  Generator_loss: 13.763227462768555\n",
            "epoch: 19/20,    batch: 2608/2993    Discriminator_loss: 8.393130883632693e-06  Generator_loss: 13.763227462768555\n",
            "epoch: 19/20,    batch: 2609/2993    Discriminator_loss: 1.922272531373892e-05  Generator_loss: 13.656044960021973\n",
            "epoch: 19/20,    batch: 2610/2993    Discriminator_loss: 1.0224264769931324e-05  Generator_loss: 13.656044960021973\n",
            "epoch: 19/20,    batch: 2611/2993    Discriminator_loss: 1.8030701539828442e-05  Generator_loss: 13.656044960021973\n",
            "epoch: 19/20,    batch: 2612/2993    Discriminator_loss: 2.246950134576764e-05  Generator_loss: 13.586471557617188\n",
            "epoch: 19/20,    batch: 2613/2993    Discriminator_loss: 1.7676521792964195e-06  Generator_loss: 13.559247016906738\n",
            "epoch: 19/20,    batch: 2614/2993    Discriminator_loss: 1.439838160877116e-05  Generator_loss: 13.559247016906738\n",
            "epoch: 19/20,    batch: 2615/2993    Discriminator_loss: 3.0257975595304742e-05  Generator_loss: 13.559247016906738\n",
            "epoch: 19/20,    batch: 2616/2993    Discriminator_loss: 1.9073499970545527e-06  Generator_loss: 13.47099781036377\n",
            "epoch: 19/20,    batch: 2617/2993    Discriminator_loss: 2.7508160201250575e-05  Generator_loss: 13.47099781036377\n",
            "epoch: 19/20,    batch: 2618/2993    Discriminator_loss: 2.7527032216312364e-05  Generator_loss: 13.47099781036377\n",
            "epoch: 19/20,    batch: 2619/2993    Discriminator_loss: 5.28810232935939e-06  Generator_loss: 13.389908790588379\n",
            "epoch: 19/20,    batch: 2620/2993    Discriminator_loss: 2.1724335965700448e-05  Generator_loss: 13.389908790588379\n",
            "epoch: 19/20,    batch: 2621/2993    Discriminator_loss: 5.596765913651325e-05  Generator_loss: 13.389908790588379\n",
            "epoch: 19/20,    batch: 2622/2993    Discriminator_loss: 2.4676926841493696e-05  Generator_loss: 13.389908790588379\n",
            "epoch: 19/20,    batch: 2623/2993    Discriminator_loss: 5.6422501074848697e-05  Generator_loss: 13.31490421295166\n",
            "epoch: 19/20,    batch: 2624/2993    Discriminator_loss: 5.338356459105853e-06  Generator_loss: 13.31490421295166\n",
            "epoch: 19/20,    batch: 2625/2993    Discriminator_loss: 2.9671978154510725e-06  Generator_loss: 13.31490421295166\n",
            "epoch: 19/20,    batch: 2626/2993    Discriminator_loss: 2.0031273379572667e-05  Generator_loss: 13.245135307312012\n",
            "epoch: 19/20,    batch: 2627/2993    Discriminator_loss: 3.0505294489557855e-05  Generator_loss: 13.245135307312012\n",
            "epoch: 19/20,    batch: 2628/2993    Discriminator_loss: 5.718379725294653e-06  Generator_loss: 13.245135307312012\n",
            "epoch: 19/20,    batch: 2629/2993    Discriminator_loss: 3.14366006932687e-05  Generator_loss: 13.245135307312012\n",
            "epoch: 19/20,    batch: 2630/2993    Discriminator_loss: 1.1086545782745816e-05  Generator_loss: 13.17991828918457\n",
            "epoch: 19/20,    batch: 2631/2993    Discriminator_loss: 2.257527967230999e-06  Generator_loss: 13.17991828918457\n",
            "epoch: 19/20,    batch: 2632/2993    Discriminator_loss: 1.6359897927031852e-05  Generator_loss: 13.17991828918457\n",
            "epoch: 19/20,    batch: 2633/2993    Discriminator_loss: 4.139844895689748e-05  Generator_loss: 13.118696212768555\n",
            "epoch: 19/20,    batch: 2634/2993    Discriminator_loss: 2.5201613880199147e-06  Generator_loss: 13.118696212768555\n",
            "epoch: 19/20,    batch: 2635/2993    Discriminator_loss: 1.8963770344271325e-05  Generator_loss: 13.061005592346191\n",
            "epoch: 19/20,    batch: 2636/2993    Discriminator_loss: 1.452314609196037e-05  Generator_loss: 13.061005592346191\n",
            "epoch: 19/20,    batch: 2637/2993    Discriminator_loss: 4.706927029474173e-06  Generator_loss: 13.061005592346191\n",
            "epoch: 19/20,    batch: 2638/2993    Discriminator_loss: 1.6771507944213226e-05  Generator_loss: 13.006463050842285\n",
            "epoch: 19/20,    batch: 2639/2993    Discriminator_loss: 1.983371657843236e-05  Generator_loss: 13.006463050842285\n",
            "epoch: 19/20,    batch: 2640/2993    Discriminator_loss: 2.199721711804159e-05  Generator_loss: 13.006463050842285\n",
            "epoch: 19/20,    batch: 2641/2993    Discriminator_loss: 1.9256312953075394e-05  Generator_loss: 12.954742431640625\n",
            "epoch: 19/20,    batch: 2642/2993    Discriminator_loss: 3.052049578400329e-05  Generator_loss: 12.954742431640625\n",
            "epoch: 19/20,    batch: 2643/2993    Discriminator_loss: 3.965586529375287e-06  Generator_loss: 12.954742431640625\n",
            "epoch: 19/20,    batch: 2644/2993    Discriminator_loss: 3.108261080342345e-05  Generator_loss: 12.90556526184082\n",
            "epoch: 19/20,    batch: 2645/2993    Discriminator_loss: 2.238951128674671e-05  Generator_loss: 12.90556526184082\n",
            "epoch: 19/20,    batch: 2646/2993    Discriminator_loss: 3.522267206790275e-06  Generator_loss: 12.90556526184082\n",
            "epoch: 19/20,    batch: 2647/2993    Discriminator_loss: 2.419444172119256e-05  Generator_loss: 12.858694076538086\n",
            "epoch: 19/20,    batch: 2648/2993    Discriminator_loss: 2.2685710064251907e-05  Generator_loss: 12.858694076538086\n",
            "epoch: 19/20,    batch: 2649/2993    Discriminator_loss: 7.456223102053627e-06  Generator_loss: 12.858694076538086\n",
            "epoch: 19/20,    batch: 2650/2993    Discriminator_loss: 2.2441494365921244e-05  Generator_loss: 12.858694076538086\n",
            "epoch: 19/20,    batch: 2651/2993    Discriminator_loss: 1.98228626686614e-05  Generator_loss: 12.813921928405762\n",
            "epoch: 19/20,    batch: 2652/2993    Discriminator_loss: 2.2842355974717066e-05  Generator_loss: 12.813921928405762\n",
            "epoch: 19/20,    batch: 2653/2993    Discriminator_loss: 4.7651399654569104e-05  Generator_loss: 12.813921928405762\n",
            "epoch: 19/20,    batch: 2654/2993    Discriminator_loss: 1.5242401786963455e-05  Generator_loss: 12.813921928405762\n",
            "epoch: 19/20,    batch: 2655/2993    Discriminator_loss: 9.413852239958942e-06  Generator_loss: 12.813921928405762\n",
            "epoch: 19/20,    batch: 2656/2993    Discriminator_loss: 2.843954280251637e-05  Generator_loss: 12.771068572998047\n",
            "epoch: 19/20,    batch: 2657/2993    Discriminator_loss: 4.67897280032048e-06  Generator_loss: 12.771068572998047\n",
            "epoch: 19/20,    batch: 2658/2993    Discriminator_loss: 4.9490613491798285e-06  Generator_loss: 12.771068572998047\n",
            "epoch: 19/20,    batch: 2659/2993    Discriminator_loss: 9.518184015178122e-06  Generator_loss: 12.771068572998047\n",
            "epoch: 19/20,    batch: 2660/2993    Discriminator_loss: 2.3605760361533612e-05  Generator_loss: 12.771068572998047\n",
            "epoch: 19/20,    batch: 2661/2993    Discriminator_loss: 6.174701411509886e-06  Generator_loss: 12.729975700378418\n",
            "epoch: 19/20,    batch: 2662/2993    Discriminator_loss: 2.929990296252072e-05  Generator_loss: 12.729975700378418\n",
            "epoch: 19/20,    batch: 2663/2993    Discriminator_loss: 1.4631303201895207e-05  Generator_loss: 12.729975700378418\n",
            "epoch: 19/20,    batch: 2664/2993    Discriminator_loss: 3.6153996916254982e-06  Generator_loss: 12.729975700378418\n",
            "epoch: 19/20,    batch: 2665/2993    Discriminator_loss: 1.1017629731213674e-05  Generator_loss: 12.729975700378418\n",
            "epoch: 19/20,    batch: 2666/2993    Discriminator_loss: 2.3708482331130654e-05  Generator_loss: 12.690505981445312\n",
            "epoch: 19/20,    batch: 2667/2993    Discriminator_loss: 2.5957600882975385e-05  Generator_loss: 12.690505981445312\n",
            "epoch: 19/20,    batch: 2668/2993    Discriminator_loss: 5.20129942742642e-05  Generator_loss: 12.690505981445312\n",
            "epoch: 19/20,    batch: 2669/2993    Discriminator_loss: 2.382925413257908e-05  Generator_loss: 12.690505981445312\n",
            "epoch: 19/20,    batch: 2670/2993    Discriminator_loss: 5.496676294569625e-06  Generator_loss: 12.690505981445312\n",
            "epoch: 19/20,    batch: 2671/2993    Discriminator_loss: 3.717845174833201e-06  Generator_loss: 12.652534484863281\n",
            "epoch: 19/20,    batch: 2672/2993    Discriminator_loss: 1.1621114936133381e-05  Generator_loss: 12.652534484863281\n",
            "epoch: 19/20,    batch: 2673/2993    Discriminator_loss: 2.5036209990503266e-05  Generator_loss: 12.652534484863281\n",
            "epoch: 19/20,    batch: 2674/2993    Discriminator_loss: 3.79421362595167e-06  Generator_loss: 12.652534484863281\n",
            "epoch: 19/20,    batch: 2675/2993    Discriminator_loss: 9.956496796803549e-05  Generator_loss: 12.615952491760254\n",
            "epoch: 19/20,    batch: 2676/2993    Discriminator_loss: 3.7304223951650783e-05  Generator_loss: 12.615952491760254\n",
            "epoch: 19/20,    batch: 2677/2993    Discriminator_loss: 5.176301783649251e-06  Generator_loss: 12.615952491760254\n",
            "epoch: 19/20,    batch: 2678/2993    Discriminator_loss: 4.096289194421843e-05  Generator_loss: 12.609334945678711\n",
            "epoch: 19/20,    batch: 2679/2993    Discriminator_loss: 4.847768650506623e-05  Generator_loss: 12.58066177368164\n",
            "epoch: 19/20,    batch: 2680/2993    Discriminator_loss: 1.8096037820214406e-05  Generator_loss: 12.58066177368164\n",
            "epoch: 19/20,    batch: 2681/2993    Discriminator_loss: 7.424329669447616e-05  Generator_loss: 12.58066177368164\n",
            "epoch: 19/20,    batch: 2682/2993    Discriminator_loss: 2.3458871510229073e-05  Generator_loss: 12.546573638916016\n",
            "epoch: 19/20,    batch: 2683/2993    Discriminator_loss: 1.97017452592263e-05  Generator_loss: 12.546573638916016\n",
            "epoch: 19/20,    batch: 2684/2993    Discriminator_loss: 4.9516391300130635e-05  Generator_loss: 12.546573638916016\n",
            "epoch: 19/20,    batch: 2685/2993    Discriminator_loss: 1.859555959526915e-05  Generator_loss: 12.513609886169434\n",
            "epoch: 19/20,    batch: 2686/2993    Discriminator_loss: 2.4168255549739115e-05  Generator_loss: 12.513609886169434\n",
            "epoch: 19/20,    batch: 2687/2993    Discriminator_loss: 6.158216274343431e-05  Generator_loss: 12.513609886169434\n",
            "epoch: 19/20,    batch: 2688/2993    Discriminator_loss: 5.308556865202263e-06  Generator_loss: 12.513609886169434\n",
            "epoch: 19/20,    batch: 2689/2993    Discriminator_loss: 2.08731071325019e-05  Generator_loss: 12.481698036193848\n",
            "epoch: 19/20,    batch: 2690/2993    Discriminator_loss: 1.535017872811295e-05  Generator_loss: 12.481698036193848\n",
            "epoch: 19/20,    batch: 2691/2993    Discriminator_loss: 6.14674536336679e-06  Generator_loss: 12.481698036193848\n",
            "epoch: 19/20,    batch: 2692/2993    Discriminator_loss: 9.65229901339626e-06  Generator_loss: 12.481698036193848\n",
            "epoch: 19/20,    batch: 2693/2993    Discriminator_loss: 1.1004567568306811e-05  Generator_loss: 12.481698036193848\n",
            "epoch: 19/20,    batch: 2694/2993    Discriminator_loss: 1.4145136447041295e-05  Generator_loss: 12.450772285461426\n",
            "epoch: 19/20,    batch: 2695/2993    Discriminator_loss: 1.2137088560848497e-05  Generator_loss: 12.450772285461426\n",
            "epoch: 19/20,    batch: 2696/2993    Discriminator_loss: 2.4898559786379337e-05  Generator_loss: 12.450772285461426\n",
            "epoch: 19/20,    batch: 2697/2993    Discriminator_loss: 1.3034901712671854e-05  Generator_loss: 12.450772285461426\n",
            "epoch: 19/20,    batch: 2698/2993    Discriminator_loss: 4.883865585725289e-06  Generator_loss: 12.450772285461426\n",
            "epoch: 19/20,    batch: 2699/2993    Discriminator_loss: 4.091078517376445e-05  Generator_loss: 12.450772285461426\n",
            "epoch: 19/20,    batch: 2700/2993    Discriminator_loss: 1.0900254892476369e-05  Generator_loss: 12.421712875366211\n",
            "epoch: 19/20,    batch: 2701/2993    Discriminator_loss: 1.3610554560727905e-05  Generator_loss: 12.420775413513184\n",
            "epoch: 19/20,    batch: 2702/2993    Discriminator_loss: 0.00022636019275523722  Generator_loss: 12.420775413513184\n",
            "epoch: 19/20,    batch: 2703/2993    Discriminator_loss: 2.9620336135849357e-05  Generator_loss: 12.420775413513184\n",
            "epoch: 19/20,    batch: 2704/2993    Discriminator_loss: 9.113952728512231e-06  Generator_loss: 12.420775413513184\n",
            "epoch: 19/20,    batch: 2705/2993    Discriminator_loss: 5.2880595831084065e-06  Generator_loss: 12.420775413513184\n",
            "epoch: 19/20,    batch: 2706/2993    Discriminator_loss: 5.700302426703274e-05  Generator_loss: 12.418045043945312\n",
            "epoch: 19/20,    batch: 2707/2993    Discriminator_loss: 9.514424164080992e-06  Generator_loss: 12.39165210723877\n",
            "epoch: 19/20,    batch: 2708/2993    Discriminator_loss: 9.08419860934373e-06  Generator_loss: 12.39165210723877\n",
            "epoch: 19/20,    batch: 2709/2993    Discriminator_loss: 2.6925203201244585e-05  Generator_loss: 12.39165210723877\n",
            "epoch: 19/20,    batch: 2710/2993    Discriminator_loss: 6.048344948794693e-05  Generator_loss: 12.39165210723877\n",
            "epoch: 19/20,    batch: 2711/2993    Discriminator_loss: 7.489734343835153e-06  Generator_loss: 12.39165210723877\n",
            "epoch: 19/20,    batch: 2712/2993    Discriminator_loss: 1.1706788427545689e-05  Generator_loss: 12.39165210723877\n",
            "epoch: 19/20,    batch: 2713/2993    Discriminator_loss: 1.537064599688165e-05  Generator_loss: 12.36335277557373\n",
            "epoch: 19/20,    batch: 2714/2993    Discriminator_loss: 4.762792741530575e-06  Generator_loss: 12.36335277557373\n",
            "epoch: 19/20,    batch: 2715/2993    Discriminator_loss: 1.6085905372165143e-05  Generator_loss: 12.36335277557373\n",
            "epoch: 19/20,    batch: 2716/2993    Discriminator_loss: 2.3639157006982714e-05  Generator_loss: 12.36335277557373\n",
            "epoch: 19/20,    batch: 2717/2993    Discriminator_loss: 5.4817769523651805e-06  Generator_loss: 12.36335277557373\n",
            "epoch: 19/20,    batch: 2718/2993    Discriminator_loss: 1.9174243789166212e-05  Generator_loss: 12.36335277557373\n",
            "epoch: 19/20,    batch: 2719/2993    Discriminator_loss: 1.7089962057070807e-05  Generator_loss: 12.335831642150879\n",
            "epoch: 19/20,    batch: 2720/2993    Discriminator_loss: 1.2813366993214004e-05  Generator_loss: 12.335831642150879\n",
            "epoch: 19/20,    batch: 2721/2993    Discriminator_loss: 2.4885277525754645e-05  Generator_loss: 12.335831642150879\n",
            "epoch: 19/20,    batch: 2722/2993    Discriminator_loss: 1.6955902538029477e-05  Generator_loss: 12.335831642150879\n",
            "epoch: 19/20,    batch: 2723/2993    Discriminator_loss: 5.897270966670476e-05  Generator_loss: 12.335831642150879\n",
            "epoch: 19/20,    batch: 2724/2993    Discriminator_loss: 5.440728273242712e-05  Generator_loss: 12.335831642150879\n",
            "epoch: 19/20,    batch: 2725/2993    Discriminator_loss: 9.456681254960131e-06  Generator_loss: 12.309048652648926\n",
            "epoch: 19/20,    batch: 2726/2993    Discriminator_loss: 5.684804818884004e-06  Generator_loss: 12.309048652648926\n",
            "epoch: 19/20,    batch: 2727/2993    Discriminator_loss: 2.1042524167569354e-05  Generator_loss: 12.309048652648926\n",
            "epoch: 19/20,    batch: 2728/2993    Discriminator_loss: 1.6192130715353414e-05  Generator_loss: 12.309048652648926\n",
            "epoch: 19/20,    batch: 2729/2993    Discriminator_loss: 1.3647864761878736e-05  Generator_loss: 12.309048652648926\n",
            "epoch: 19/20,    batch: 2730/2993    Discriminator_loss: 3.196197212673724e-05  Generator_loss: 12.309048652648926\n",
            "epoch: 19/20,    batch: 2731/2993    Discriminator_loss: 4.0757196984486654e-05  Generator_loss: 12.282963752746582\n",
            "epoch: 19/20,    batch: 2732/2993    Discriminator_loss: 7.465500857506413e-06  Generator_loss: 12.282963752746582\n",
            "epoch: 19/20,    batch: 2733/2993    Discriminator_loss: 9.82366327662021e-06  Generator_loss: 12.282963752746582\n",
            "epoch: 19/20,    batch: 2734/2993    Discriminator_loss: 2.3972799681359902e-05  Generator_loss: 12.282963752746582\n",
            "epoch: 19/20,    batch: 2735/2993    Discriminator_loss: 2.828485048667062e-05  Generator_loss: 12.282963752746582\n",
            "epoch: 19/20,    batch: 2736/2993    Discriminator_loss: 8.456479918095283e-06  Generator_loss: 12.282963752746582\n",
            "epoch: 19/20,    batch: 2737/2993    Discriminator_loss: 4.9205817049369216e-05  Generator_loss: 12.282963752746582\n",
            "epoch: 19/20,    batch: 2738/2993    Discriminator_loss: 3.6705041566165164e-05  Generator_loss: 12.257542610168457\n",
            "epoch: 19/20,    batch: 2739/2993    Discriminator_loss: 7.65176628192421e-06  Generator_loss: 12.257542610168457\n",
            "epoch: 19/20,    batch: 2740/2993    Discriminator_loss: 8.396838893531822e-06  Generator_loss: 12.257542610168457\n",
            "epoch: 19/20,    batch: 2741/2993    Discriminator_loss: 2.8355629183351994e-05  Generator_loss: 12.257542610168457\n",
            "epoch: 19/20,    batch: 2742/2993    Discriminator_loss: 2.857757681340445e-05  Generator_loss: 12.257542610168457\n",
            "epoch: 19/20,    batch: 2743/2993    Discriminator_loss: 5.321589014783967e-06  Generator_loss: 12.257542610168457\n",
            "epoch: 19/20,    batch: 2744/2993    Discriminator_loss: 4.34124558523763e-05  Generator_loss: 12.23275089263916\n",
            "epoch: 19/20,    batch: 2745/2993    Discriminator_loss: 2.0023649994982406e-05  Generator_loss: 12.233526229858398\n",
            "epoch: 19/20,    batch: 2746/2993    Discriminator_loss: 5.722058631363325e-06  Generator_loss: 12.23275089263916\n",
            "epoch: 19/20,    batch: 2747/2993    Discriminator_loss: 2.5365841793245636e-05  Generator_loss: 12.23275089263916\n",
            "epoch: 19/20,    batch: 2748/2993    Discriminator_loss: 2.7156098440173082e-05  Generator_loss: 12.23275089263916\n",
            "epoch: 19/20,    batch: 2749/2993    Discriminator_loss: 4.477923721424304e-05  Generator_loss: 12.216875076293945\n",
            "epoch: 19/20,    batch: 2750/2993    Discriminator_loss: 5.111253267386928e-05  Generator_loss: 12.2085599899292\n",
            "epoch: 19/20,    batch: 2751/2993    Discriminator_loss: 1.8257840565638617e-05  Generator_loss: 12.2085599899292\n",
            "epoch: 19/20,    batch: 2752/2993    Discriminator_loss: 9.81059747573454e-06  Generator_loss: 12.2085599899292\n",
            "epoch: 19/20,    batch: 2753/2993    Discriminator_loss: 2.089348345180042e-05  Generator_loss: 12.2085599899292\n",
            "epoch: 19/20,    batch: 2754/2993    Discriminator_loss: 1.4800784811086487e-05  Generator_loss: 12.18493938446045\n",
            "epoch: 19/20,    batch: 2755/2993    Discriminator_loss: 6.115220458013937e-05  Generator_loss: 12.18493938446045\n",
            "epoch: 19/20,    batch: 2756/2993    Discriminator_loss: 2.8674192435573786e-05  Generator_loss: 12.18493938446045\n",
            "epoch: 19/20,    batch: 2757/2993    Discriminator_loss: 9.056234375748318e-06  Generator_loss: 12.161864280700684\n",
            "epoch: 19/20,    batch: 2758/2993    Discriminator_loss: 1.162109947472345e-05  Generator_loss: 12.161864280700684\n",
            "epoch: 19/20,    batch: 2759/2993    Discriminator_loss: 1.282437915506307e-05  Generator_loss: 12.15904426574707\n",
            "epoch: 19/20,    batch: 2760/2993    Discriminator_loss: 7.625690159329679e-06  Generator_loss: 12.139309883117676\n",
            "epoch: 19/20,    batch: 2761/2993    Discriminator_loss: 1.869391417130828e-05  Generator_loss: 12.131038665771484\n",
            "epoch: 19/20,    batch: 2762/2993    Discriminator_loss: 3.055078559555113e-05  Generator_loss: 12.117253303527832\n",
            "epoch: 19/20,    batch: 2763/2993    Discriminator_loss: 2.1169391402509063e-05  Generator_loss: 12.097695350646973\n",
            "epoch: 19/20,    batch: 2764/2993    Discriminator_loss: 1.277595765714068e-05  Generator_loss: 12.095671653747559\n",
            "epoch: 19/20,    batch: 2765/2993    Discriminator_loss: 1.8514867406338453e-05  Generator_loss: 12.075206756591797\n",
            "epoch: 19/20,    batch: 2766/2993    Discriminator_loss: 9.797544407774694e-06  Generator_loss: 12.060983657836914\n",
            "epoch: 19/20,    batch: 2767/2993    Discriminator_loss: 7.730000106676016e-06  Generator_loss: 12.053858757019043\n",
            "epoch: 19/20,    batch: 2768/2993    Discriminator_loss: 1.7255686543649063e-05  Generator_loss: 12.033590316772461\n",
            "epoch: 19/20,    batch: 2769/2993    Discriminator_loss: 2.9491904570022598e-05  Generator_loss: 12.013724327087402\n",
            "epoch: 19/20,    batch: 2770/2993    Discriminator_loss: 7.616378752572928e-06  Generator_loss: 11.994245529174805\n",
            "epoch: 19/20,    batch: 2771/2993    Discriminator_loss: 1.8276403352501802e-05  Generator_loss: 11.937986373901367\n",
            "epoch: 19/20,    batch: 2772/2993    Discriminator_loss: 1.21426301120664e-05  Generator_loss: 11.922174453735352\n",
            "epoch: 19/20,    batch: 2773/2993    Discriminator_loss: 8.858773981046397e-06  Generator_loss: 11.902165412902832\n",
            "epoch: 19/20,    batch: 2774/2993    Discriminator_loss: 1.465349669160787e-05  Generator_loss: 11.884724617004395\n",
            "epoch: 19/20,    batch: 2775/2993    Discriminator_loss: 2.4818320525810122e-05  Generator_loss: 11.852310180664062\n",
            "epoch: 19/20,    batch: 2776/2993    Discriminator_loss: 8.314879778481554e-06  Generator_loss: 11.834156036376953\n",
            "epoch: 19/20,    batch: 2777/2993    Discriminator_loss: 1.7184855096274987e-05  Generator_loss: 11.803815841674805\n",
            "epoch: 19/20,    batch: 2778/2993    Discriminator_loss: 2.7593741833698004e-05  Generator_loss: 11.786023139953613\n",
            "epoch: 19/20,    batch: 2779/2993    Discriminator_loss: 1.2161292033852078e-05  Generator_loss: 11.75517463684082\n",
            "epoch: 19/20,    batch: 2780/2993    Discriminator_loss: 3.674711479106918e-05  Generator_loss: 11.725713729858398\n",
            "epoch: 19/20,    batch: 2781/2993    Discriminator_loss: 3.1380717700812966e-05  Generator_loss: 11.696194648742676\n",
            "epoch: 19/20,    batch: 2782/2993    Discriminator_loss: 1.3966197002446279e-05  Generator_loss: 11.667959213256836\n",
            "epoch: 19/20,    batch: 2783/2993    Discriminator_loss: 2.7340191081748344e-05  Generator_loss: 11.640926361083984\n",
            "epoch: 19/20,    batch: 2784/2993    Discriminator_loss: 1.565565435157623e-05  Generator_loss: 11.614189147949219\n",
            "epoch: 19/20,    batch: 2785/2993    Discriminator_loss: 2.7407466404838488e-05  Generator_loss: 11.58774471282959\n",
            "epoch: 19/20,    batch: 2786/2993    Discriminator_loss: 2.935374686785508e-05  Generator_loss: 11.562768936157227\n",
            "epoch: 19/20,    batch: 2787/2993    Discriminator_loss: 1.5016782526799943e-05  Generator_loss: 11.537632942199707\n",
            "epoch: 19/20,    batch: 2788/2993    Discriminator_loss: 2.482198760844767e-05  Generator_loss: 11.512006759643555\n",
            "epoch: 19/20,    batch: 2789/2993    Discriminator_loss: 4.2737385228974745e-05  Generator_loss: 11.479415893554688\n",
            "epoch: 19/20,    batch: 2790/2993    Discriminator_loss: 1.1403169992263429e-05  Generator_loss: 11.455560684204102\n",
            "epoch: 19/20,    batch: 2791/2993    Discriminator_loss: 3.3336240448988974e-05  Generator_loss: 11.42234992980957\n",
            "epoch: 19/20,    batch: 2792/2993    Discriminator_loss: 2.6483307010494173e-05  Generator_loss: 11.400806427001953\n",
            "epoch: 19/20,    batch: 2793/2993    Discriminator_loss: 1.3448370737023652e-05  Generator_loss: 11.36933708190918\n",
            "epoch: 19/20,    batch: 2794/2993    Discriminator_loss: 2.9281336537678726e-05  Generator_loss: 11.348894119262695\n",
            "epoch: 19/20,    batch: 2795/2993    Discriminator_loss: 3.2915660995058715e-05  Generator_loss: 11.326394081115723\n",
            "epoch: 19/20,    batch: 2796/2993    Discriminator_loss: 2.7651407435769215e-05  Generator_loss: 11.299545288085938\n",
            "epoch: 19/20,    batch: 2797/2993    Discriminator_loss: 3.144468064419925e-05  Generator_loss: 11.278409957885742\n",
            "epoch: 19/20,    batch: 2798/2993    Discriminator_loss: 0.00023960761609487236  Generator_loss: 11.252516746520996\n",
            "epoch: 19/20,    batch: 2799/2993    Discriminator_loss: 2.4261174985440448e-05  Generator_loss: 11.227009773254395\n",
            "epoch: 19/20,    batch: 2800/2993    Discriminator_loss: 1.4221386663848534e-05  Generator_loss: 11.208428382873535\n",
            "epoch: 19/20,    batch: 2801/2993    Discriminator_loss: 0.00011102739517809823  Generator_loss: 11.192081451416016\n",
            "epoch: 19/20,    batch: 2802/2993    Discriminator_loss: 2.1882500732317567e-05  Generator_loss: 11.168049812316895\n",
            "epoch: 19/20,    batch: 2803/2993    Discriminator_loss: 3.311645195935853e-05  Generator_loss: 11.150524139404297\n",
            "epoch: 19/20,    batch: 2804/2993    Discriminator_loss: 3.0229444746510126e-05  Generator_loss: 11.136110305786133\n",
            "epoch: 19/20,    batch: 2805/2993    Discriminator_loss: 5.1586557674454525e-05  Generator_loss: 11.122650146484375\n",
            "epoch: 19/20,    batch: 2806/2993    Discriminator_loss: 2.6801830244949088e-05  Generator_loss: 11.107382774353027\n",
            "epoch: 19/20,    batch: 2807/2993    Discriminator_loss: 1.555133712827228e-05  Generator_loss: 11.091614723205566\n",
            "epoch: 19/20,    batch: 2808/2993    Discriminator_loss: 4.7397828893736005e-05  Generator_loss: 11.076815605163574\n",
            "epoch: 19/20,    batch: 2809/2993    Discriminator_loss: 2.5598532374715433e-05  Generator_loss: 11.06842041015625\n",
            "epoch: 19/20,    batch: 2810/2993    Discriminator_loss: 3.498850128380582e-05  Generator_loss: 11.054193496704102\n",
            "epoch: 19/20,    batch: 2811/2993    Discriminator_loss: 4.767146674566902e-05  Generator_loss: 11.03969955444336\n",
            "epoch: 19/20,    batch: 2812/2993    Discriminator_loss: 7.322989404201508e-05  Generator_loss: 11.030916213989258\n",
            "epoch: 19/20,    batch: 2813/2993    Discriminator_loss: 4.360774619271979e-05  Generator_loss: 11.016300201416016\n",
            "epoch: 19/20,    batch: 2814/2993    Discriminator_loss: 3.787966852542013e-05  Generator_loss: 11.009071350097656\n",
            "epoch: 19/20,    batch: 2815/2993    Discriminator_loss: 4.8208225052803755e-05  Generator_loss: 10.995436668395996\n",
            "epoch: 19/20,    batch: 2816/2993    Discriminator_loss: 2.6822466679732315e-05  Generator_loss: 10.987693786621094\n",
            "epoch: 19/20,    batch: 2817/2993    Discriminator_loss: 2.4087907149805687e-05  Generator_loss: 10.975654602050781\n",
            "epoch: 19/20,    batch: 2818/2993    Discriminator_loss: 6.766473961761221e-05  Generator_loss: 10.966763496398926\n",
            "epoch: 19/20,    batch: 2819/2993    Discriminator_loss: 2.1275354811223224e-05  Generator_loss: 10.959882736206055\n",
            "epoch: 19/20,    batch: 2820/2993    Discriminator_loss: 5.197507925913669e-05  Generator_loss: 10.9468994140625\n",
            "epoch: 19/20,    batch: 2821/2993    Discriminator_loss: 6.313820631476119e-05  Generator_loss: 10.939520835876465\n",
            "epoch: 19/20,    batch: 2822/2993    Discriminator_loss: 1.8311820895178244e-05  Generator_loss: 10.926173210144043\n",
            "epoch: 19/20,    batch: 2823/2993    Discriminator_loss: 4.187468584859744e-05  Generator_loss: 10.919565200805664\n",
            "epoch: 19/20,    batch: 2824/2993    Discriminator_loss: 5.582316589425318e-05  Generator_loss: 10.906479835510254\n",
            "epoch: 19/20,    batch: 2825/2993    Discriminator_loss: 2.8098515031160787e-05  Generator_loss: 10.895574569702148\n",
            "epoch: 19/20,    batch: 2826/2993    Discriminator_loss: 6.971362745389342e-05  Generator_loss: 10.887166023254395\n",
            "epoch: 19/20,    batch: 2827/2993    Discriminator_loss: 3.071900937356986e-05  Generator_loss: 10.874494552612305\n",
            "epoch: 19/20,    batch: 2828/2993    Discriminator_loss: 1.9792649254668504e-05  Generator_loss: 10.861982345581055\n",
            "epoch: 19/20,    batch: 2829/2993    Discriminator_loss: 7.378995360340923e-05  Generator_loss: 10.84579849243164\n",
            "epoch: 19/20,    batch: 2830/2993    Discriminator_loss: 4.4851447455585e-05  Generator_loss: 10.831368446350098\n",
            "epoch: 19/20,    batch: 2831/2993    Discriminator_loss: 4.862965579377487e-05  Generator_loss: 10.819380760192871\n",
            "epoch: 19/20,    batch: 2832/2993    Discriminator_loss: 0.00010890312842093408  Generator_loss: 10.801664352416992\n",
            "epoch: 19/20,    batch: 2833/2993    Discriminator_loss: 0.00012337580847088248  Generator_loss: 10.79002571105957\n",
            "epoch: 19/20,    batch: 2834/2993    Discriminator_loss: 3.613382432376966e-05  Generator_loss: 10.772995948791504\n",
            "epoch: 19/20,    batch: 2835/2993    Discriminator_loss: 2.2674208594253287e-05  Generator_loss: 10.761507034301758\n",
            "epoch: 19/20,    batch: 2836/2993    Discriminator_loss: 6.84335536789149e-05  Generator_loss: 10.745818138122559\n",
            "epoch: 19/20,    batch: 2837/2993    Discriminator_loss: 4.464827725314535e-05  Generator_loss: 10.733951568603516\n",
            "epoch: 19/20,    batch: 2838/2993    Discriminator_loss: 4.579249070957303e-05  Generator_loss: 10.722900390625\n",
            "epoch: 19/20,    batch: 2839/2993    Discriminator_loss: 0.00014215425471775234  Generator_loss: 10.712138175964355\n",
            "epoch: 19/20,    batch: 2840/2993    Discriminator_loss: 0.0001262050645891577  Generator_loss: 10.701988220214844\n",
            "epoch: 19/20,    batch: 2841/2993    Discriminator_loss: 3.4429489460308105e-05  Generator_loss: 10.695060729980469\n",
            "epoch: 19/20,    batch: 2842/2993    Discriminator_loss: 2.688946551643312e-05  Generator_loss: 10.685729026794434\n",
            "epoch: 19/20,    batch: 2843/2993    Discriminator_loss: 0.00010628141171764582  Generator_loss: 10.675357818603516\n",
            "epoch: 19/20,    batch: 2844/2993    Discriminator_loss: 4.6462504542432725e-05  Generator_loss: 10.66861343383789\n",
            "epoch: 19/20,    batch: 2845/2993    Discriminator_loss: 3.58584220521152e-05  Generator_loss: 10.65999984741211\n",
            "epoch: 19/20,    batch: 2846/2993    Discriminator_loss: 8.158581476891413e-05  Generator_loss: 10.650047302246094\n",
            "epoch: 19/20,    batch: 2847/2993    Discriminator_loss: 8.675660501467064e-05  Generator_loss: 10.64487361907959\n",
            "epoch: 19/20,    batch: 2848/2993    Discriminator_loss: 3.0463979783235118e-05  Generator_loss: 10.634915351867676\n",
            "epoch: 19/20,    batch: 2849/2993    Discriminator_loss: 3.941971226595342e-05  Generator_loss: 10.629973411560059\n",
            "epoch: 19/20,    batch: 2850/2993    Discriminator_loss: 4.3981457565678284e-05  Generator_loss: 10.620161056518555\n",
            "epoch: 19/20,    batch: 2851/2993    Discriminator_loss: 2.547942494857125e-05  Generator_loss: 10.611202239990234\n",
            "epoch: 19/20,    batch: 2852/2993    Discriminator_loss: 5.941988274571486e-05  Generator_loss: 10.605622291564941\n",
            "epoch: 19/20,    batch: 2853/2993    Discriminator_loss: 3.771342380787246e-05  Generator_loss: 10.597986221313477\n",
            "epoch: 19/20,    batch: 2854/2993    Discriminator_loss: 2.6703197363531217e-05  Generator_loss: 10.591291427612305\n",
            "epoch: 19/20,    batch: 2855/2993    Discriminator_loss: 6.807567842770368e-05  Generator_loss: 10.586559295654297\n",
            "epoch: 19/20,    batch: 2856/2993    Discriminator_loss: 4.242810973664746e-05  Generator_loss: 10.581850051879883\n",
            "epoch: 19/20,    batch: 2857/2993    Discriminator_loss: 3.5920202208217233e-05  Generator_loss: 10.577162742614746\n",
            "epoch: 19/20,    batch: 2858/2993    Discriminator_loss: 5.721256457036361e-05  Generator_loss: 10.570610046386719\n",
            "epoch: 19/20,    batch: 2859/2993    Discriminator_loss: 4.211140185361728e-05  Generator_loss: 10.567852973937988\n",
            "epoch: 19/20,    batch: 2860/2993    Discriminator_loss: 3.3699365303618833e-05  Generator_loss: 10.563230514526367\n",
            "epoch: 19/20,    batch: 2861/2993    Discriminator_loss: 3.839886994683184e-05  Generator_loss: 10.558629989624023\n",
            "epoch: 19/20,    batch: 2862/2993    Discriminator_loss: 3.257803837186657e-05  Generator_loss: 10.554049491882324\n",
            "epoch: 19/20,    batch: 2863/2993    Discriminator_loss: 2.762709482340142e-05  Generator_loss: 10.549489974975586\n",
            "epoch: 19/20,    batch: 2864/2993    Discriminator_loss: 4.127300780965015e-05  Generator_loss: 10.544951438903809\n",
            "epoch: 19/20,    batch: 2865/2993    Discriminator_loss: 6.35625037830323e-05  Generator_loss: 10.540433883666992\n",
            "epoch: 19/20,    batch: 2866/2993    Discriminator_loss: 3.443156310822815e-05  Generator_loss: 10.53593635559082\n",
            "epoch: 19/20,    batch: 2867/2993    Discriminator_loss: 5.8296442148275673e-05  Generator_loss: 10.531458854675293\n",
            "epoch: 19/20,    batch: 2868/2993    Discriminator_loss: 3.6560424632625654e-05  Generator_loss: 10.52700138092041\n",
            "epoch: 19/20,    batch: 2869/2993    Discriminator_loss: 2.7371928808861412e-05  Generator_loss: 10.522562980651855\n",
            "epoch: 19/20,    batch: 2870/2993    Discriminator_loss: 4.527057899395004e-05  Generator_loss: 10.518145561218262\n",
            "epoch: 19/20,    batch: 2871/2993    Discriminator_loss: 6.109604146331549e-05  Generator_loss: 10.51374626159668\n",
            "epoch: 19/20,    batch: 2872/2993    Discriminator_loss: 2.8368458515615202e-05  Generator_loss: 10.509366989135742\n",
            "epoch: 19/20,    batch: 2873/2993    Discriminator_loss: 5.593324749497697e-05  Generator_loss: 10.505143165588379\n",
            "epoch: 19/20,    batch: 2874/2993    Discriminator_loss: 3.6158096918370575e-05  Generator_loss: 10.500665664672852\n",
            "epoch: 19/20,    batch: 2875/2993    Discriminator_loss: 2.8595708499778993e-05  Generator_loss: 10.496342658996582\n",
            "epoch: 19/20,    batch: 2876/2993    Discriminator_loss: 4.7049241402419284e-05  Generator_loss: 10.49203872680664\n",
            "epoch: 19/20,    batch: 2877/2993    Discriminator_loss: 4.915592217002995e-05  Generator_loss: 10.487752914428711\n",
            "epoch: 19/20,    batch: 2878/2993    Discriminator_loss: 4.044444358441979e-05  Generator_loss: 10.483485221862793\n",
            "epoch: 19/20,    batch: 2879/2993    Discriminator_loss: 4.199764589429833e-05  Generator_loss: 10.479236602783203\n",
            "epoch: 19/20,    batch: 2880/2993    Discriminator_loss: 4.238875408191234e-05  Generator_loss: 10.475005149841309\n",
            "epoch: 19/20,    batch: 2881/2993    Discriminator_loss: 2.8925416700076312e-05  Generator_loss: 10.471319198608398\n",
            "epoch: 19/20,    batch: 2882/2993    Discriminator_loss: 7.541577360825613e-05  Generator_loss: 10.470791816711426\n",
            "epoch: 19/20,    batch: 2883/2993    Discriminator_loss: 4.6158900659065694e-05  Generator_loss: 10.466595649719238\n",
            "epoch: 19/20,    batch: 2884/2993    Discriminator_loss: 3.68344881280791e-05  Generator_loss: 10.462417602539062\n",
            "epoch: 19/20,    batch: 2885/2993    Discriminator_loss: 9.33907795115374e-05  Generator_loss: 10.458256721496582\n",
            "epoch: 19/20,    batch: 2886/2993    Discriminator_loss: 4.0185244870372117e-05  Generator_loss: 10.454113960266113\n",
            "epoch: 19/20,    batch: 2887/2993    Discriminator_loss: 6.735139322699979e-05  Generator_loss: 10.449987411499023\n",
            "epoch: 19/20,    batch: 2888/2993    Discriminator_loss: 4.924732638755813e-05  Generator_loss: 10.445878028869629\n",
            "epoch: 19/20,    batch: 2889/2993    Discriminator_loss: 3.4433327527949587e-05  Generator_loss: 10.441784858703613\n",
            "epoch: 19/20,    batch: 2890/2993    Discriminator_loss: 4.613106284523383e-05  Generator_loss: 10.437708854675293\n",
            "epoch: 19/20,    batch: 2891/2993    Discriminator_loss: 3.937872315873392e-05  Generator_loss: 10.433649063110352\n",
            "epoch: 19/20,    batch: 2892/2993    Discriminator_loss: 3.264516999479383e-05  Generator_loss: 10.429606437683105\n",
            "epoch: 19/20,    batch: 2893/2993    Discriminator_loss: 5.304533988237381e-05  Generator_loss: 10.425580024719238\n",
            "epoch: 19/20,    batch: 2894/2993    Discriminator_loss: 4.3288469896651804e-05  Generator_loss: 10.422821998596191\n",
            "epoch: 19/20,    batch: 2895/2993    Discriminator_loss: 3.6055724194739014e-05  Generator_loss: 10.421568870544434\n",
            "epoch: 19/20,    batch: 2896/2993    Discriminator_loss: 3.4034717828035355e-05  Generator_loss: 10.417574882507324\n",
            "epoch: 19/20,    batch: 2897/2993    Discriminator_loss: 4.7021283535286784e-05  Generator_loss: 10.413596153259277\n",
            "epoch: 19/20,    batch: 2898/2993    Discriminator_loss: 4.213927604723722e-05  Generator_loss: 10.409632682800293\n",
            "epoch: 19/20,    batch: 2899/2993    Discriminator_loss: 3.693678445415571e-05  Generator_loss: 10.405685424804688\n",
            "epoch: 19/20,    batch: 2900/2993    Discriminator_loss: 4.369457747088745e-05  Generator_loss: 10.401753425598145\n",
            "epoch: 19/20,    batch: 2901/2993    Discriminator_loss: 4.272780643077567e-05  Generator_loss: 10.39783763885498\n",
            "epoch: 19/20,    batch: 2902/2993    Discriminator_loss: 3.2769992685643956e-05  Generator_loss: 10.394546508789062\n",
            "epoch: 19/20,    batch: 2903/2993    Discriminator_loss: 4.154127964284271e-05  Generator_loss: 10.393936157226562\n",
            "epoch: 19/20,    batch: 2904/2993    Discriminator_loss: 4.3843567254953086e-05  Generator_loss: 10.390049934387207\n",
            "epoch: 19/20,    batch: 2905/2993    Discriminator_loss: 3.3269192499574274e-05  Generator_loss: 10.38617992401123\n",
            "epoch: 19/20,    batch: 2906/2993    Discriminator_loss: 3.962461050832644e-05  Generator_loss: 10.382323265075684\n",
            "epoch: 19/20,    batch: 2907/2993    Discriminator_loss: 4.129911758354865e-05  Generator_loss: 10.37860107421875\n",
            "epoch: 19/20,    batch: 2908/2993    Discriminator_loss: 3.259677396272309e-05  Generator_loss: 10.3784818649292\n",
            "epoch: 19/20,    batch: 2909/2993    Discriminator_loss: 4.8194800911005586e-05  Generator_loss: 10.374655723571777\n",
            "epoch: 19/20,    batch: 2910/2993    Discriminator_loss: 4.82507239212282e-05  Generator_loss: 10.370843887329102\n",
            "epoch: 19/20,    batch: 2911/2993    Discriminator_loss: 3.458053834037855e-05  Generator_loss: 10.367046356201172\n",
            "epoch: 19/20,    batch: 2912/2993    Discriminator_loss: 4.739015275845304e-05  Generator_loss: 10.366336822509766\n",
            "epoch: 19/20,    batch: 2913/2993    Discriminator_loss: 5.1311559218447655e-05  Generator_loss: 10.363263130187988\n",
            "epoch: 19/20,    batch: 2914/2993    Discriminator_loss: 3.904350160155445e-05  Generator_loss: 10.359495162963867\n",
            "epoch: 19/20,    batch: 2915/2993    Discriminator_loss: 4.8953050281852484e-05  Generator_loss: 10.355740547180176\n",
            "epoch: 19/20,    batch: 2916/2993    Discriminator_loss: 5.215935379965231e-05  Generator_loss: 10.351999282836914\n",
            "epoch: 19/20,    batch: 2917/2993    Discriminator_loss: 0.004156202077865601  Generator_loss: 10.348273277282715\n",
            "epoch: 19/20,    batch: 2918/2993    Discriminator_loss: 0.0001869503757916391  Generator_loss: 10.344792366027832\n",
            "epoch: 19/20,    batch: 2919/2993    Discriminator_loss: 4.700841964222491e-05  Generator_loss: 10.341439247131348\n",
            "epoch: 19/20,    batch: 2920/2993    Discriminator_loss: 4.976509808329865e-05  Generator_loss: 10.337751388549805\n",
            "epoch: 19/20,    batch: 2921/2993    Discriminator_loss: 4.972968599759042e-05  Generator_loss: 10.33499526977539\n",
            "epoch: 19/20,    batch: 2922/2993    Discriminator_loss: 4.210021143080667e-05  Generator_loss: 10.330303192138672\n",
            "epoch: 19/20,    batch: 2923/2993    Discriminator_loss: 8.529267506673932e-05  Generator_loss: 10.326200485229492\n",
            "epoch: 19/20,    batch: 2924/2993    Discriminator_loss: 5.5958495067898184e-05  Generator_loss: 10.3225679397583\n",
            "epoch: 19/20,    batch: 2925/2993    Discriminator_loss: 3.563109930837527e-05  Generator_loss: 10.318949699401855\n",
            "epoch: 19/20,    batch: 2926/2993    Discriminator_loss: 7.34979985281825e-05  Generator_loss: 10.315343856811523\n",
            "epoch: 19/20,    batch: 2927/2993    Discriminator_loss: 4.693937808042392e-05  Generator_loss: 10.308171272277832\n",
            "epoch: 19/20,    batch: 2928/2993    Discriminator_loss: 4.425721272127703e-05  Generator_loss: 10.304160118103027\n",
            "epoch: 19/20,    batch: 2929/2993    Discriminator_loss: 0.00010430706606712192  Generator_loss: 10.297508239746094\n",
            "epoch: 19/20,    batch: 2930/2993    Discriminator_loss: 5.6062868679873645e-05  Generator_loss: 10.290461540222168\n",
            "epoch: 19/20,    batch: 2931/2993    Discriminator_loss: 6.423483864637092e-05  Generator_loss: 10.280963897705078\n",
            "epoch: 19/20,    batch: 2932/2993    Discriminator_loss: 3.659226422314532e-05  Generator_loss: 10.273059844970703\n",
            "epoch: 19/20,    batch: 2933/2993    Discriminator_loss: 0.0003329009923618287  Generator_loss: 10.261272430419922\n",
            "epoch: 19/20,    batch: 2934/2993    Discriminator_loss: 4.717591218650341e-05  Generator_loss: 10.24919605255127\n",
            "epoch: 19/20,    batch: 2935/2993    Discriminator_loss: 4.134955815970898e-05  Generator_loss: 10.232802391052246\n",
            "epoch: 19/20,    batch: 2936/2993    Discriminator_loss: 0.00037180137587711215  Generator_loss: 10.216164588928223\n",
            "epoch: 19/20,    batch: 2937/2993    Discriminator_loss: 5.8031750086229295e-05  Generator_loss: 10.196697235107422\n",
            "epoch: 19/20,    batch: 2938/2993    Discriminator_loss: 6.851163925603032e-05  Generator_loss: 10.174665451049805\n",
            "epoch: 19/20,    batch: 2939/2993    Discriminator_loss: 6.541612674482167e-05  Generator_loss: 10.152441024780273\n",
            "epoch: 19/20,    batch: 2940/2993    Discriminator_loss: 0.000254040933214128  Generator_loss: 10.129297256469727\n",
            "epoch: 19/20,    batch: 2941/2993    Discriminator_loss: 5.163529931451194e-05  Generator_loss: 10.10822868347168\n",
            "epoch: 19/20,    batch: 2942/2993    Discriminator_loss: 4.372646799311042e-05  Generator_loss: 10.091094970703125\n",
            "epoch: 19/20,    batch: 2943/2993    Discriminator_loss: 0.00023957673693075776  Generator_loss: 10.079389572143555\n",
            "epoch: 19/20,    batch: 2944/2993    Discriminator_loss: 6.407073669834062e-05  Generator_loss: 10.06913948059082\n",
            "epoch: 19/20,    batch: 2945/2993    Discriminator_loss: 6.122088962001726e-05  Generator_loss: 10.061779975891113\n",
            "epoch: 19/20,    batch: 2946/2993    Discriminator_loss: 5.7122957514366135e-05  Generator_loss: 10.053954124450684\n",
            "epoch: 19/20,    batch: 2947/2993    Discriminator_loss: 0.00010069294512504712  Generator_loss: 10.04808235168457\n",
            "epoch: 19/20,    batch: 2948/2993    Discriminator_loss: 5.4090422054287046e-05  Generator_loss: 10.040363311767578\n",
            "epoch: 19/20,    batch: 2949/2993    Discriminator_loss: 0.00022330062347464263  Generator_loss: 10.034655570983887\n",
            "epoch: 19/20,    batch: 2950/2993    Discriminator_loss: 9.415049862582237e-05  Generator_loss: 10.027292251586914\n",
            "epoch: 19/20,    batch: 2951/2993    Discriminator_loss: 5.376265835366212e-05  Generator_loss: 10.021239280700684\n",
            "epoch: 19/20,    batch: 2952/2993    Discriminator_loss: 6.843697337899357e-05  Generator_loss: 10.015889167785645\n",
            "epoch: 19/20,    batch: 2953/2993    Discriminator_loss: 7.074320456013083e-05  Generator_loss: 10.010236740112305\n",
            "epoch: 19/20,    batch: 2954/2993    Discriminator_loss: 5.107669858261943e-05  Generator_loss: 10.005191802978516\n",
            "epoch: 19/20,    batch: 2955/2993    Discriminator_loss: 9.940721793100238e-05  Generator_loss: 10.000008583068848\n",
            "epoch: 19/20,    batch: 2956/2993    Discriminator_loss: 7.47310696169734e-05  Generator_loss: 9.994771003723145\n",
            "epoch: 19/20,    batch: 2957/2993    Discriminator_loss: 4.6736677177250385e-05  Generator_loss: 9.991350173950195\n",
            "epoch: 19/20,    batch: 2958/2993    Discriminator_loss: 0.0002058424288406968  Generator_loss: 9.98696517944336\n",
            "epoch: 19/20,    batch: 2959/2993    Discriminator_loss: 6.014047539792955e-05  Generator_loss: 9.981795310974121\n",
            "epoch: 19/20,    batch: 2960/2993    Discriminator_loss: 4.967039785697125e-05  Generator_loss: 9.976652145385742\n",
            "epoch: 19/20,    batch: 2961/2993    Discriminator_loss: 7.867444946896285e-05  Generator_loss: 9.973371505737305\n",
            "epoch: 19/20,    batch: 2962/2993    Discriminator_loss: 6.229749124031514e-05  Generator_loss: 9.968985557556152\n",
            "epoch: 19/20,    batch: 2963/2993    Discriminator_loss: 4.817096851184033e-05  Generator_loss: 9.96517562866211\n",
            "epoch: 19/20,    batch: 2964/2993    Discriminator_loss: 6.647546251770109e-05  Generator_loss: 9.96137809753418\n",
            "epoch: 19/20,    batch: 2965/2993    Discriminator_loss: 0.00010248267790302634  Generator_loss: 9.95704460144043\n",
            "epoch: 19/20,    batch: 2966/2993    Discriminator_loss: 6.0198846767889336e-05  Generator_loss: 9.953827857971191\n",
            "epoch: 19/20,    batch: 2967/2993    Discriminator_loss: 0.00010843774362001568  Generator_loss: 9.951168060302734\n",
            "epoch: 19/20,    batch: 2968/2993    Discriminator_loss: 6.466126069426537e-05  Generator_loss: 9.9464111328125\n",
            "epoch: 19/20,    batch: 2969/2993    Discriminator_loss: 5.519703699974343e-05  Generator_loss: 9.943848609924316\n",
            "epoch: 19/20,    batch: 2970/2993    Discriminator_loss: 7.364694465650246e-05  Generator_loss: 9.938896179199219\n",
            "epoch: 19/20,    batch: 2971/2993    Discriminator_loss: 0.00018829274631571025  Generator_loss: 9.936429023742676\n",
            "epoch: 19/20,    batch: 2972/2993    Discriminator_loss: 7.849707617424428e-05  Generator_loss: 9.931512832641602\n",
            "epoch: 19/20,    batch: 2973/2993    Discriminator_loss: 6.689648580504581e-05  Generator_loss: 9.92906379699707\n",
            "epoch: 19/20,    batch: 2974/2993    Discriminator_loss: 8.309136319439858e-05  Generator_loss: 9.92418384552002\n",
            "epoch: 19/20,    batch: 2975/2993    Discriminator_loss: 6.235173350432888e-05  Generator_loss: 9.920160293579102\n",
            "epoch: 19/20,    batch: 2976/2993    Discriminator_loss: 5.949234764557332e-05  Generator_loss: 9.916908264160156\n",
            "epoch: 19/20,    batch: 2977/2993    Discriminator_loss: 9.985936048906296e-05  Generator_loss: 9.912087440490723\n",
            "epoch: 19/20,    batch: 2978/2993    Discriminator_loss: 8.034217171370983e-05  Generator_loss: 9.909685134887695\n",
            "epoch: 19/20,    batch: 2979/2993    Discriminator_loss: 0.00020578195108100772  Generator_loss: 9.904898643493652\n",
            "epoch: 19/20,    batch: 2980/2993    Discriminator_loss: 0.00010120206570718437  Generator_loss: 9.900581359863281\n",
            "epoch: 19/20,    batch: 2981/2993    Discriminator_loss: 6.001027213642374e-05  Generator_loss: 9.897761344909668\n",
            "epoch: 19/20,    batch: 2982/2993    Discriminator_loss: 6.940227467566729e-05  Generator_loss: 9.894804000854492\n",
            "epoch: 19/20,    batch: 2983/2993    Discriminator_loss: 7.335084956139326e-05  Generator_loss: 9.89067554473877\n",
            "epoch: 19/20,    batch: 2984/2993    Discriminator_loss: 5.47947856830433e-05  Generator_loss: 9.888323783874512\n",
            "epoch: 19/20,    batch: 2985/2993    Discriminator_loss: 6.924734043423086e-05  Generator_loss: 9.885978698730469\n",
            "epoch: 19/20,    batch: 2986/2993    Discriminator_loss: 7.294299575733021e-05  Generator_loss: 9.881376266479492\n",
            "epoch: 19/20,    batch: 2987/2993    Discriminator_loss: 5.163196328794584e-05  Generator_loss: 9.878974914550781\n",
            "epoch: 19/20,    batch: 2988/2993    Discriminator_loss: 7.148073927965015e-05  Generator_loss: 9.8766508102417\n",
            "epoch: 19/20,    batch: 2989/2993    Discriminator_loss: 6.383057188941166e-05  Generator_loss: 9.874332427978516\n",
            "epoch: 19/20,    batch: 2990/2993    Discriminator_loss: 5.525301457964815e-05  Generator_loss: 9.87201976776123\n",
            "epoch: 19/20,    batch: 2991/2993    Discriminator_loss: 0.0001223715371452272  Generator_loss: 9.869711875915527\n",
            "epoch: 19/20,    batch: 2992/2993    Discriminator_loss: 6.187101098475978e-05  Generator_loss: 9.86952018737793\n",
            "  adding: checkpoints/ (stored 0%)\n",
            "  adding: checkpoints/generator/ (stored 0%)\n",
            "  adding: checkpoints/generator/gen_epoch0.h5 (deflated 8%)\n",
            "  adding: checkpoints/generator/gen_epoch7.h5 (deflated 8%)\n",
            "  adding: checkpoints/generator/gen_epoch4.h5 (deflated 8%)\n",
            "  adding: checkpoints/generator/gen_epoch2.h5 (deflated 8%)\n",
            "  adding: checkpoints/generator/gen_epoch12.h5 (deflated 8%)\n",
            "  adding: checkpoints/generator/gen_epoch16.h5 (deflated 8%)\n",
            "  adding: checkpoints/generator/gen_epoch13.h5 (deflated 8%)\n",
            "  adding: checkpoints/generator/gen_epoch10.h5 (deflated 8%)\n",
            "  adding: checkpoints/generator/gen_epoch15.h5 (deflated 8%)\n",
            "  adding: checkpoints/generator/gen_epoch19.h5 (deflated 8%)\n",
            "  adding: checkpoints/generator/gen_epoch8.h5 (deflated 8%)\n",
            "  adding: checkpoints/generator/gen_epoch11.h5 (deflated 8%)\n",
            "  adding: checkpoints/generator/gen_epoch18.h5 (deflated 8%)\n",
            "  adding: checkpoints/generator/gen_epoch14.h5 (deflated 8%)\n",
            "  adding: checkpoints/generator/gen_epoch1.h5 (deflated 8%)\n",
            "  adding: checkpoints/generator/gen_epoch6.h5 (deflated 8%)\n",
            "  adding: checkpoints/generator/gen_epoch9.h5 (deflated 8%)\n",
            "  adding: checkpoints/generator/gen_epoch3.h5 (deflated 8%)\n",
            "  adding: checkpoints/generator/gen_epoch5.h5 (deflated 8%)\n",
            "  adding: checkpoints/generator/gen_epoch17.h5 (deflated 8%)\n",
            "  adding: checkpoints/discriminator/ (stored 0%)\n",
            "  adding: checkpoints/discriminator/discr_epoch16.h5 (deflated 12%)\n",
            "  adding: checkpoints/discriminator/discr_epoch9.h5 (deflated 12%)\n",
            "  adding: checkpoints/discriminator/discr_epoch6.h5 (deflated 12%)\n",
            "  adding: checkpoints/discriminator/discr_epoch18.h5 (deflated 11%)\n",
            "  adding: checkpoints/discriminator/discr_epoch12.h5 (deflated 12%)\n",
            "  adding: checkpoints/discriminator/discr_epoch5.h5 (deflated 12%)\n",
            "  adding: checkpoints/discriminator/discr_epoch17.h5 (deflated 12%)\n",
            "  adding: checkpoints/discriminator/discr_epoch11.h5 (deflated 12%)\n",
            "  adding: checkpoints/discriminator/discr_epoch15.h5 (deflated 12%)\n",
            "  adding: checkpoints/discriminator/discr_epoch3.h5 (deflated 12%)\n",
            "  adding: checkpoints/discriminator/discr_epoch8.h5 (deflated 12%)\n",
            "  adding: checkpoints/discriminator/discr_epoch1.h5 (deflated 12%)\n",
            "  adding: checkpoints/discriminator/discr_epoch4.h5 (deflated 12%)\n",
            "  adding: checkpoints/discriminator/discr_epoch2.h5 (deflated 12%)\n",
            "  adding: checkpoints/discriminator/discr_epoch10.h5 (deflated 12%)\n",
            "  adding: checkpoints/discriminator/discr_epoch19.h5 (deflated 12%)\n",
            "  adding: checkpoints/discriminator/discr_epoch0.h5 (deflated 12%)\n",
            "  adding: checkpoints/discriminator/discr_epoch13.h5 (deflated 12%)\n",
            "  adding: checkpoints/discriminator/discr_epoch7.h5 (deflated 12%)\n",
            "  adding: checkpoints/discriminator/discr_epoch14.h5 (deflated 12%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encoder Training"
      ],
      "metadata": {
        "id": "sSWerpRs_of-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def encoder_training(encoder, generator, data, latent_size, checkpoints_backup_path, num_epochs=1):\n",
        "  '''\n",
        "  Encoder must be trained on regular data only.\n",
        "\n",
        "  The purpose of the encoder is to learn the inverse mapping of the generator,\n",
        "  i.e. how to map a time sequence to the latent space.\n",
        "  '''\n",
        "\n",
        "  # setup checkpoint saving\n",
        "  directory_path = \"./encoder_checkpoints\"\n",
        "\n",
        "  if not os.path.isdir('encoder_checkpoints'):\n",
        "    ! mkdir encoder_checkpoints\n",
        "\n",
        "  loss_fn = tf.keras.losses.MeanAbsoluteError()\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
        "\n",
        "  print(\"epoch: 0/%d\")\n",
        "  for epoch in range(num_epochs):\n",
        "    sum_loss = 0\n",
        "    for i, (time_sequences, labels) in enumerate(data):\n",
        "      with tf.GradientTape() as tape:\n",
        "        latent_output = encoder(time_sequences)\n",
        "        generated_seq = generator(latent_output)\n",
        "\n",
        "        enc_loss = loss_fn(time_sequences, generated_seq)\n",
        "\n",
        "      gradients = tape.gradient(enc_loss, encoder.trainable_weights)\n",
        "      optimizer.apply_gradients(zip(gradients, encoder.trainable_weights))\n",
        "\n",
        "      sum_loss += enc_loss\n",
        "\n",
        "      print(\n",
        "        f\"  epoch: {epoch}/{num_epochs},    batch: {i}/{len(data)}    Encoder_loss: {enc_loss}\"\n",
        "      )\n",
        "\n",
        "    print(\n",
        "      f\"epoch: {epoch}/{num_epochs},  Tot_epoch_loss: {sum_loss}\"\n",
        "    )\n",
        "\n",
        "    encoder.save_weights(directory_path + f\"/encoder_epoch{epoch}.h5\")\n",
        "\n",
        "    now = datetime.datetime.now()\n",
        "    zip_name = f\"encoder_checkpoints_{str(now.date())+'_'+str(now.time())}.zip\"\n",
        "\n",
        "    !zip -r {zip_name} ./encoder_checkpoints\n",
        "    !cp {zip_name} {checkpoints_backup_path}"
      ],
      "metadata": {
        "id": "fPPJfItp_vl3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Start Encoder Training"
      ],
      "metadata": {
        "id": "kWLk-Ux2zqNZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# init encoder\n",
        "encoder = init_encoder(in_dim=(WINDOW_SIZE, SAMPLE_SIZE), out_dim=(WINDOW_SIZE, LATENT_VAR_SIZE))\n",
        "encoder_training(encoder, generator, train_dataset, LATENT_VAR_SIZE, \"./drive/MyDrive/ml-applications/TimeSeriesAnomalyDetection_project/saved_encoder_checkpoints\", num_epochs=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMYNvwsBzm4u",
        "outputId": "c17ae3fa-d7e3-4cb8-fb56-d764a5345641"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "  epoch: 18/20,    batch: 1031/2993    Encoder_loss: 0.6423014402389526\n",
            "  epoch: 18/20,    batch: 1032/2993    Encoder_loss: 0.6078391671180725\n",
            "  epoch: 18/20,    batch: 1033/2993    Encoder_loss: 0.6946399807929993\n",
            "  epoch: 18/20,    batch: 1034/2993    Encoder_loss: 0.696884274482727\n",
            "  epoch: 18/20,    batch: 1035/2993    Encoder_loss: 0.5799621343612671\n",
            "  epoch: 18/20,    batch: 1036/2993    Encoder_loss: 0.6190717220306396\n",
            "  epoch: 18/20,    batch: 1037/2993    Encoder_loss: 0.6757188439369202\n",
            "  epoch: 18/20,    batch: 1038/2993    Encoder_loss: 0.6182004809379578\n",
            "  epoch: 18/20,    batch: 1039/2993    Encoder_loss: 0.5950061082839966\n",
            "  epoch: 18/20,    batch: 1040/2993    Encoder_loss: 0.6730180382728577\n",
            "  epoch: 18/20,    batch: 1041/2993    Encoder_loss: 0.6806582808494568\n",
            "  epoch: 18/20,    batch: 1042/2993    Encoder_loss: 0.610826849937439\n",
            "  epoch: 18/20,    batch: 1043/2993    Encoder_loss: 0.6898585557937622\n",
            "  epoch: 18/20,    batch: 1044/2993    Encoder_loss: 0.7382424473762512\n",
            "  epoch: 18/20,    batch: 1045/2993    Encoder_loss: 0.6298564672470093\n",
            "  epoch: 18/20,    batch: 1046/2993    Encoder_loss: 0.6660919189453125\n",
            "  epoch: 18/20,    batch: 1047/2993    Encoder_loss: 0.6799821257591248\n",
            "  epoch: 18/20,    batch: 1048/2993    Encoder_loss: 0.6096903681755066\n",
            "  epoch: 18/20,    batch: 1049/2993    Encoder_loss: 0.6773919463157654\n",
            "  epoch: 18/20,    batch: 1050/2993    Encoder_loss: 0.6774523854255676\n",
            "  epoch: 18/20,    batch: 1051/2993    Encoder_loss: 0.6529784798622131\n",
            "  epoch: 18/20,    batch: 1052/2993    Encoder_loss: 0.7044326663017273\n",
            "  epoch: 18/20,    batch: 1053/2993    Encoder_loss: 0.6442884206771851\n",
            "  epoch: 18/20,    batch: 1054/2993    Encoder_loss: 0.6382684111595154\n",
            "  epoch: 18/20,    batch: 1055/2993    Encoder_loss: 0.7064302563667297\n",
            "  epoch: 18/20,    batch: 1056/2993    Encoder_loss: 0.6193282008171082\n",
            "  epoch: 18/20,    batch: 1057/2993    Encoder_loss: 0.641056478023529\n",
            "  epoch: 18/20,    batch: 1058/2993    Encoder_loss: 0.7137166857719421\n",
            "  epoch: 18/20,    batch: 1059/2993    Encoder_loss: 0.6348324418067932\n",
            "  epoch: 18/20,    batch: 1060/2993    Encoder_loss: 0.58687824010849\n",
            "  epoch: 18/20,    batch: 1061/2993    Encoder_loss: 0.670569658279419\n",
            "  epoch: 18/20,    batch: 1062/2993    Encoder_loss: 0.7186655402183533\n",
            "  epoch: 18/20,    batch: 1063/2993    Encoder_loss: 0.6137762665748596\n",
            "  epoch: 18/20,    batch: 1064/2993    Encoder_loss: 0.6628344058990479\n",
            "  epoch: 18/20,    batch: 1065/2993    Encoder_loss: 0.7192131280899048\n",
            "  epoch: 18/20,    batch: 1066/2993    Encoder_loss: 0.6288411617279053\n",
            "  epoch: 18/20,    batch: 1067/2993    Encoder_loss: 0.6233506798744202\n",
            "  epoch: 18/20,    batch: 1068/2993    Encoder_loss: 0.7048673033714294\n",
            "  epoch: 18/20,    batch: 1069/2993    Encoder_loss: 0.6997177600860596\n",
            "  epoch: 18/20,    batch: 1070/2993    Encoder_loss: 0.6089457273483276\n",
            "  epoch: 18/20,    batch: 1071/2993    Encoder_loss: 0.6969485878944397\n",
            "  epoch: 18/20,    batch: 1072/2993    Encoder_loss: 0.6941558718681335\n",
            "  epoch: 18/20,    batch: 1073/2993    Encoder_loss: 0.5970166325569153\n",
            "  epoch: 18/20,    batch: 1074/2993    Encoder_loss: 0.6199888586997986\n",
            "  epoch: 18/20,    batch: 1075/2993    Encoder_loss: 0.709979236125946\n",
            "  epoch: 18/20,    batch: 1076/2993    Encoder_loss: 0.6704710125923157\n",
            "  epoch: 18/20,    batch: 1077/2993    Encoder_loss: 0.5661057829856873\n",
            "  epoch: 18/20,    batch: 1078/2993    Encoder_loss: 0.6765970587730408\n",
            "  epoch: 18/20,    batch: 1079/2993    Encoder_loss: 0.7205623984336853\n",
            "  epoch: 18/20,    batch: 1080/2993    Encoder_loss: 0.6515993475914001\n",
            "  epoch: 18/20,    batch: 1081/2993    Encoder_loss: 0.6835225820541382\n",
            "  epoch: 18/20,    batch: 1082/2993    Encoder_loss: 0.6500701904296875\n",
            "  epoch: 18/20,    batch: 1083/2993    Encoder_loss: 0.6386650800704956\n",
            "  epoch: 18/20,    batch: 1084/2993    Encoder_loss: 0.6964397430419922\n",
            "  epoch: 18/20,    batch: 1085/2993    Encoder_loss: 0.6447048783302307\n",
            "  epoch: 18/20,    batch: 1086/2993    Encoder_loss: 0.6376180648803711\n",
            "  epoch: 18/20,    batch: 1087/2993    Encoder_loss: 0.6865227222442627\n",
            "  epoch: 18/20,    batch: 1088/2993    Encoder_loss: 0.6187020540237427\n",
            "  epoch: 18/20,    batch: 1089/2993    Encoder_loss: 0.6517583131790161\n",
            "  epoch: 18/20,    batch: 1090/2993    Encoder_loss: 0.6913650631904602\n",
            "  epoch: 18/20,    batch: 1091/2993    Encoder_loss: 0.6011607050895691\n",
            "  epoch: 18/20,    batch: 1092/2993    Encoder_loss: 0.620407223701477\n",
            "  epoch: 18/20,    batch: 1093/2993    Encoder_loss: 0.6142977476119995\n",
            "  epoch: 18/20,    batch: 1094/2993    Encoder_loss: 0.557264506816864\n",
            "  epoch: 18/20,    batch: 1095/2993    Encoder_loss: 0.5983202457427979\n",
            "  epoch: 18/20,    batch: 1096/2993    Encoder_loss: 0.6472880244255066\n",
            "  epoch: 18/20,    batch: 1097/2993    Encoder_loss: 0.5969675183296204\n",
            "  epoch: 18/20,    batch: 1098/2993    Encoder_loss: 0.6237421035766602\n",
            "  epoch: 18/20,    batch: 1099/2993    Encoder_loss: 0.6730333566665649\n",
            "  epoch: 18/20,    batch: 1100/2993    Encoder_loss: 0.5744174122810364\n",
            "  epoch: 18/20,    batch: 1101/2993    Encoder_loss: 0.5897805690765381\n",
            "  epoch: 18/20,    batch: 1102/2993    Encoder_loss: 0.6795935034751892\n",
            "  epoch: 18/20,    batch: 1103/2993    Encoder_loss: 0.6114980578422546\n",
            "  epoch: 18/20,    batch: 1104/2993    Encoder_loss: 0.5782485604286194\n",
            "  epoch: 18/20,    batch: 1105/2993    Encoder_loss: 0.656096875667572\n",
            "  epoch: 18/20,    batch: 1106/2993    Encoder_loss: 0.6081036925315857\n",
            "  epoch: 18/20,    batch: 1107/2993    Encoder_loss: 0.5474720597267151\n",
            "  epoch: 18/20,    batch: 1108/2993    Encoder_loss: 0.6104610562324524\n",
            "  epoch: 18/20,    batch: 1109/2993    Encoder_loss: 0.6417264342308044\n",
            "  epoch: 18/20,    batch: 1110/2993    Encoder_loss: 0.5974123477935791\n",
            "  epoch: 18/20,    batch: 1111/2993    Encoder_loss: 0.6255657076835632\n",
            "  epoch: 18/20,    batch: 1112/2993    Encoder_loss: 0.575344979763031\n",
            "  epoch: 18/20,    batch: 1113/2993    Encoder_loss: 0.5667884945869446\n",
            "  epoch: 18/20,    batch: 1114/2993    Encoder_loss: 0.6293992400169373\n",
            "  epoch: 18/20,    batch: 1115/2993    Encoder_loss: 0.5798531174659729\n",
            "  epoch: 18/20,    batch: 1116/2993    Encoder_loss: 0.5897922515869141\n",
            "  epoch: 18/20,    batch: 1117/2993    Encoder_loss: 0.642784059047699\n",
            "  epoch: 18/20,    batch: 1118/2993    Encoder_loss: 0.555776834487915\n",
            "  epoch: 18/20,    batch: 1119/2993    Encoder_loss: 0.5842166543006897\n",
            "  epoch: 18/20,    batch: 1120/2993    Encoder_loss: 0.6498383283615112\n",
            "  epoch: 18/20,    batch: 1121/2993    Encoder_loss: 0.5648812651634216\n",
            "  epoch: 18/20,    batch: 1122/2993    Encoder_loss: 0.5926005244255066\n",
            "  epoch: 18/20,    batch: 1123/2993    Encoder_loss: 0.6334973573684692\n",
            "  epoch: 18/20,    batch: 1124/2993    Encoder_loss: 0.5730588436126709\n",
            "  epoch: 18/20,    batch: 1125/2993    Encoder_loss: 0.6010999083518982\n",
            "  epoch: 18/20,    batch: 1126/2993    Encoder_loss: 0.591069221496582\n",
            "  epoch: 18/20,    batch: 1127/2993    Encoder_loss: 0.5234337449073792\n",
            "  epoch: 18/20,    batch: 1128/2993    Encoder_loss: 0.5734401941299438\n",
            "  epoch: 18/20,    batch: 1129/2993    Encoder_loss: 0.6085616946220398\n",
            "  epoch: 18/20,    batch: 1130/2993    Encoder_loss: 0.5578440427780151\n",
            "  epoch: 18/20,    batch: 1131/2993    Encoder_loss: 0.6244580745697021\n",
            "  epoch: 18/20,    batch: 1132/2993    Encoder_loss: 0.6362091898918152\n",
            "  epoch: 18/20,    batch: 1133/2993    Encoder_loss: 0.5385305285453796\n",
            "  epoch: 18/20,    batch: 1134/2993    Encoder_loss: 0.5891916155815125\n",
            "  epoch: 18/20,    batch: 1135/2993    Encoder_loss: 0.641150712966919\n",
            "  epoch: 18/20,    batch: 1136/2993    Encoder_loss: 0.5596545934677124\n",
            "  epoch: 18/20,    batch: 1137/2993    Encoder_loss: 0.5705060958862305\n",
            "  epoch: 18/20,    batch: 1138/2993    Encoder_loss: 0.6304794549942017\n",
            "  epoch: 18/20,    batch: 1139/2993    Encoder_loss: 0.5528544783592224\n",
            "  epoch: 18/20,    batch: 1140/2993    Encoder_loss: 0.5395660996437073\n",
            "  epoch: 18/20,    batch: 1141/2993    Encoder_loss: 0.627191424369812\n",
            "  epoch: 18/20,    batch: 1142/2993    Encoder_loss: 0.6268995404243469\n",
            "  epoch: 18/20,    batch: 1143/2993    Encoder_loss: 0.6068616509437561\n",
            "  epoch: 18/20,    batch: 1144/2993    Encoder_loss: 0.6558540463447571\n",
            "  epoch: 18/20,    batch: 1145/2993    Encoder_loss: 0.6096157431602478\n",
            "  epoch: 18/20,    batch: 1146/2993    Encoder_loss: 0.6152941584587097\n",
            "  epoch: 18/20,    batch: 1147/2993    Encoder_loss: 0.6634333729743958\n",
            "  epoch: 18/20,    batch: 1148/2993    Encoder_loss: 0.5612232089042664\n",
            "  epoch: 18/20,    batch: 1149/2993    Encoder_loss: 0.5828834176063538\n",
            "  epoch: 18/20,    batch: 1150/2993    Encoder_loss: 0.659669816493988\n",
            "  epoch: 18/20,    batch: 1151/2993    Encoder_loss: 0.5950857400894165\n",
            "  epoch: 18/20,    batch: 1152/2993    Encoder_loss: 0.654629647731781\n",
            "  epoch: 18/20,    batch: 1153/2993    Encoder_loss: 0.6638118028640747\n",
            "  epoch: 18/20,    batch: 1154/2993    Encoder_loss: 0.5946618914604187\n",
            "  epoch: 18/20,    batch: 1155/2993    Encoder_loss: 0.6677931547164917\n",
            "  epoch: 18/20,    batch: 1156/2993    Encoder_loss: 0.6346083283424377\n",
            "  epoch: 18/20,    batch: 1157/2993    Encoder_loss: 0.5681814551353455\n",
            "  epoch: 18/20,    batch: 1158/2993    Encoder_loss: 0.634982168674469\n",
            "  epoch: 18/20,    batch: 1159/2993    Encoder_loss: 0.6258150935173035\n",
            "  epoch: 18/20,    batch: 1160/2993    Encoder_loss: 0.5222331285476685\n",
            "  epoch: 18/20,    batch: 1161/2993    Encoder_loss: 0.5775012969970703\n",
            "  epoch: 18/20,    batch: 1162/2993    Encoder_loss: 0.6443744897842407\n",
            "  epoch: 18/20,    batch: 1163/2993    Encoder_loss: 0.5600721836090088\n",
            "  epoch: 18/20,    batch: 1164/2993    Encoder_loss: 0.5710867643356323\n",
            "  epoch: 18/20,    batch: 1165/2993    Encoder_loss: 0.6452330350875854\n",
            "  epoch: 18/20,    batch: 1166/2993    Encoder_loss: 0.6085805296897888\n",
            "  epoch: 18/20,    batch: 1167/2993    Encoder_loss: 0.5460479855537415\n",
            "  epoch: 18/20,    batch: 1168/2993    Encoder_loss: 0.6326298117637634\n",
            "  epoch: 18/20,    batch: 1169/2993    Encoder_loss: 0.6762716770172119\n",
            "  epoch: 18/20,    batch: 1170/2993    Encoder_loss: 0.5852513909339905\n",
            "  epoch: 18/20,    batch: 1171/2993    Encoder_loss: 0.6087701320648193\n",
            "  epoch: 18/20,    batch: 1172/2993    Encoder_loss: 0.685590386390686\n",
            "  epoch: 18/20,    batch: 1173/2993    Encoder_loss: 0.614186704158783\n",
            "  epoch: 18/20,    batch: 1174/2993    Encoder_loss: 0.5536847710609436\n",
            "  epoch: 18/20,    batch: 1175/2993    Encoder_loss: 0.652470052242279\n",
            "  epoch: 18/20,    batch: 1176/2993    Encoder_loss: 0.6958729028701782\n",
            "  epoch: 18/20,    batch: 1177/2993    Encoder_loss: 0.5926320552825928\n",
            "  epoch: 18/20,    batch: 1178/2993    Encoder_loss: 0.6349818110466003\n",
            "  epoch: 18/20,    batch: 1179/2993    Encoder_loss: 0.6809130311012268\n",
            "  epoch: 18/20,    batch: 1180/2993    Encoder_loss: 0.5747917890548706\n",
            "  epoch: 18/20,    batch: 1181/2993    Encoder_loss: 0.6414121985435486\n",
            "  epoch: 18/20,    batch: 1182/2993    Encoder_loss: 0.6733158230781555\n",
            "  epoch: 18/20,    batch: 1183/2993    Encoder_loss: 0.5781744718551636\n",
            "  epoch: 18/20,    batch: 1184/2993    Encoder_loss: 0.6442741751670837\n",
            "  epoch: 18/20,    batch: 1185/2993    Encoder_loss: 0.6492851972579956\n",
            "  epoch: 18/20,    batch: 1186/2993    Encoder_loss: 0.5985328555107117\n",
            "  epoch: 18/20,    batch: 1187/2993    Encoder_loss: 0.6622903347015381\n",
            "  epoch: 18/20,    batch: 1188/2993    Encoder_loss: 0.6368423104286194\n",
            "  epoch: 18/20,    batch: 1189/2993    Encoder_loss: 0.6073840856552124\n",
            "  epoch: 18/20,    batch: 1190/2993    Encoder_loss: 0.667763352394104\n",
            "  epoch: 18/20,    batch: 1191/2993    Encoder_loss: 0.6235039830207825\n",
            "  epoch: 18/20,    batch: 1192/2993    Encoder_loss: 0.6058204174041748\n",
            "  epoch: 18/20,    batch: 1193/2993    Encoder_loss: 0.6392219662666321\n",
            "  epoch: 18/20,    batch: 1194/2993    Encoder_loss: 0.5697426199913025\n",
            "  epoch: 18/20,    batch: 1195/2993    Encoder_loss: 0.5849012136459351\n",
            "  epoch: 18/20,    batch: 1196/2993    Encoder_loss: 0.6517330408096313\n",
            "  epoch: 18/20,    batch: 1197/2993    Encoder_loss: 0.6083865761756897\n",
            "  epoch: 18/20,    batch: 1198/2993    Encoder_loss: 0.5977509617805481\n",
            "  epoch: 18/20,    batch: 1199/2993    Encoder_loss: 0.6831249594688416\n",
            "  epoch: 18/20,    batch: 1200/2993    Encoder_loss: 0.6258125901222229\n",
            "  epoch: 18/20,    batch: 1201/2993    Encoder_loss: 0.5412112474441528\n",
            "  epoch: 18/20,    batch: 1202/2993    Encoder_loss: 0.6385724544525146\n",
            "  epoch: 18/20,    batch: 1203/2993    Encoder_loss: 0.6666405200958252\n",
            "  epoch: 18/20,    batch: 1204/2993    Encoder_loss: 0.5918279886245728\n",
            "  epoch: 18/20,    batch: 1205/2993    Encoder_loss: 0.6579775214195251\n",
            "  epoch: 18/20,    batch: 1206/2993    Encoder_loss: 0.6441649198532104\n",
            "  epoch: 18/20,    batch: 1207/2993    Encoder_loss: 0.5693138837814331\n",
            "  epoch: 18/20,    batch: 1208/2993    Encoder_loss: 0.6513283848762512\n",
            "  epoch: 18/20,    batch: 1209/2993    Encoder_loss: 0.6856568455696106\n",
            "  epoch: 18/20,    batch: 1210/2993    Encoder_loss: 0.6113332509994507\n",
            "  epoch: 18/20,    batch: 1211/2993    Encoder_loss: 0.6565024256706238\n",
            "  epoch: 18/20,    batch: 1212/2993    Encoder_loss: 0.6861846446990967\n",
            "  epoch: 18/20,    batch: 1213/2993    Encoder_loss: 0.5923832654953003\n",
            "  epoch: 18/20,    batch: 1214/2993    Encoder_loss: 0.6403180956840515\n",
            "  epoch: 18/20,    batch: 1215/2993    Encoder_loss: 0.652660608291626\n",
            "  epoch: 18/20,    batch: 1216/2993    Encoder_loss: 0.5914450287818909\n",
            "  epoch: 18/20,    batch: 1217/2993    Encoder_loss: 0.6440742611885071\n",
            "  epoch: 18/20,    batch: 1218/2993    Encoder_loss: 0.6535158753395081\n",
            "  epoch: 18/20,    batch: 1219/2993    Encoder_loss: 0.6285170316696167\n",
            "  epoch: 18/20,    batch: 1220/2993    Encoder_loss: 0.6687394976615906\n",
            "  epoch: 18/20,    batch: 1221/2993    Encoder_loss: 0.6302441358566284\n",
            "  epoch: 18/20,    batch: 1222/2993    Encoder_loss: 0.6062394976615906\n",
            "  epoch: 18/20,    batch: 1223/2993    Encoder_loss: 0.6698570251464844\n",
            "  epoch: 18/20,    batch: 1224/2993    Encoder_loss: 0.6130683422088623\n",
            "  epoch: 18/20,    batch: 1225/2993    Encoder_loss: 0.6092950701713562\n",
            "  epoch: 18/20,    batch: 1226/2993    Encoder_loss: 0.6303189396858215\n",
            "  epoch: 18/20,    batch: 1227/2993    Encoder_loss: 0.5688276290893555\n",
            "  epoch: 18/20,    batch: 1228/2993    Encoder_loss: 0.6057755351066589\n",
            "  epoch: 18/20,    batch: 1229/2993    Encoder_loss: 0.6504854559898376\n",
            "  epoch: 18/20,    batch: 1230/2993    Encoder_loss: 0.5819381475448608\n",
            "  epoch: 18/20,    batch: 1231/2993    Encoder_loss: 0.6015530824661255\n",
            "  epoch: 18/20,    batch: 1232/2993    Encoder_loss: 0.6710187196731567\n",
            "  epoch: 18/20,    batch: 1233/2993    Encoder_loss: 0.5924174785614014\n",
            "  epoch: 18/20,    batch: 1234/2993    Encoder_loss: 0.561562716960907\n",
            "  epoch: 18/20,    batch: 1235/2993    Encoder_loss: 0.6391667723655701\n",
            "  epoch: 18/20,    batch: 1236/2993    Encoder_loss: 0.6503002047538757\n",
            "  epoch: 18/20,    batch: 1237/2993    Encoder_loss: 0.5991323590278625\n",
            "  epoch: 18/20,    batch: 1238/2993    Encoder_loss: 0.6355857253074646\n",
            "  epoch: 18/20,    batch: 1239/2993    Encoder_loss: 0.6270638704299927\n",
            "  epoch: 18/20,    batch: 1240/2993    Encoder_loss: 0.5885695815086365\n",
            "  epoch: 18/20,    batch: 1241/2993    Encoder_loss: 0.6371369957923889\n",
            "  epoch: 18/20,    batch: 1242/2993    Encoder_loss: 0.6380279064178467\n",
            "  epoch: 18/20,    batch: 1243/2993    Encoder_loss: 0.5709792971611023\n",
            "  epoch: 18/20,    batch: 1244/2993    Encoder_loss: 0.6333252191543579\n",
            "  epoch: 18/20,    batch: 1245/2993    Encoder_loss: 0.6864092350006104\n",
            "  epoch: 18/20,    batch: 1246/2993    Encoder_loss: 0.6255412697792053\n",
            "  epoch: 18/20,    batch: 1247/2993    Encoder_loss: 0.6730760931968689\n",
            "  epoch: 18/20,    batch: 1248/2993    Encoder_loss: 0.6486726999282837\n",
            "  epoch: 18/20,    batch: 1249/2993    Encoder_loss: 0.591936469078064\n",
            "  epoch: 18/20,    batch: 1250/2993    Encoder_loss: 0.6652726531028748\n",
            "  epoch: 18/20,    batch: 1251/2993    Encoder_loss: 0.6375710368156433\n",
            "  epoch: 18/20,    batch: 1252/2993    Encoder_loss: 0.637693464756012\n",
            "  epoch: 18/20,    batch: 1253/2993    Encoder_loss: 0.6950191855430603\n",
            "  epoch: 18/20,    batch: 1254/2993    Encoder_loss: 0.5873828530311584\n",
            "  epoch: 18/20,    batch: 1255/2993    Encoder_loss: 0.6042039394378662\n",
            "  epoch: 18/20,    batch: 1256/2993    Encoder_loss: 0.689365804195404\n",
            "  epoch: 18/20,    batch: 1257/2993    Encoder_loss: 0.6056248545646667\n",
            "  epoch: 18/20,    batch: 1258/2993    Encoder_loss: 0.652546226978302\n",
            "  epoch: 18/20,    batch: 1259/2993    Encoder_loss: 0.6752793192863464\n",
            "  epoch: 18/20,    batch: 1260/2993    Encoder_loss: 0.5940124988555908\n",
            "  epoch: 18/20,    batch: 1261/2993    Encoder_loss: 0.6171291470527649\n",
            "  epoch: 18/20,    batch: 1262/2993    Encoder_loss: 0.669101357460022\n",
            "  epoch: 18/20,    batch: 1263/2993    Encoder_loss: 0.6324360370635986\n",
            "  epoch: 18/20,    batch: 1264/2993    Encoder_loss: 0.6383970379829407\n",
            "  epoch: 18/20,    batch: 1265/2993    Encoder_loss: 0.6580753922462463\n",
            "  epoch: 18/20,    batch: 1266/2993    Encoder_loss: 0.5784468054771423\n",
            "  epoch: 18/20,    batch: 1267/2993    Encoder_loss: 0.6140516400337219\n",
            "  epoch: 18/20,    batch: 1268/2993    Encoder_loss: 0.684738039970398\n",
            "  epoch: 18/20,    batch: 1269/2993    Encoder_loss: 0.6254768967628479\n",
            "  epoch: 18/20,    batch: 1270/2993    Encoder_loss: 0.6187889575958252\n",
            "  epoch: 18/20,    batch: 1271/2993    Encoder_loss: 0.6739766597747803\n",
            "  epoch: 18/20,    batch: 1272/2993    Encoder_loss: 0.618148684501648\n",
            "  epoch: 18/20,    batch: 1273/2993    Encoder_loss: 0.5822153687477112\n",
            "  epoch: 18/20,    batch: 1274/2993    Encoder_loss: 0.646096408367157\n",
            "  epoch: 18/20,    batch: 1275/2993    Encoder_loss: 0.6616274118423462\n",
            "  epoch: 18/20,    batch: 1276/2993    Encoder_loss: 0.6106873154640198\n",
            "  epoch: 18/20,    batch: 1277/2993    Encoder_loss: 0.6712788343429565\n",
            "  epoch: 18/20,    batch: 1278/2993    Encoder_loss: 0.6499296426773071\n",
            "  epoch: 18/20,    batch: 1279/2993    Encoder_loss: 0.5939877033233643\n",
            "  epoch: 18/20,    batch: 1280/2993    Encoder_loss: 0.6676458716392517\n",
            "  epoch: 18/20,    batch: 1281/2993    Encoder_loss: 0.6442253589630127\n",
            "  epoch: 18/20,    batch: 1282/2993    Encoder_loss: 0.6408455967903137\n",
            "  epoch: 18/20,    batch: 1283/2993    Encoder_loss: 0.6961373090744019\n",
            "  epoch: 18/20,    batch: 1284/2993    Encoder_loss: 0.5949287414550781\n",
            "  epoch: 18/20,    batch: 1285/2993    Encoder_loss: 0.6026939749717712\n",
            "  epoch: 18/20,    batch: 1286/2993    Encoder_loss: 0.6757846474647522\n",
            "  epoch: 18/20,    batch: 1287/2993    Encoder_loss: 0.57297283411026\n",
            "  epoch: 18/20,    batch: 1288/2993    Encoder_loss: 0.6226816177368164\n",
            "  epoch: 18/20,    batch: 1289/2993    Encoder_loss: 0.6720076203346252\n",
            "  epoch: 18/20,    batch: 1290/2993    Encoder_loss: 0.5695430636405945\n",
            "  epoch: 18/20,    batch: 1291/2993    Encoder_loss: 0.6405277252197266\n",
            "  epoch: 18/20,    batch: 1292/2993    Encoder_loss: 0.6608694791793823\n",
            "  epoch: 18/20,    batch: 1293/2993    Encoder_loss: 0.5635813474655151\n",
            "  epoch: 18/20,    batch: 1294/2993    Encoder_loss: 0.589834988117218\n",
            "  epoch: 18/20,    batch: 1295/2993    Encoder_loss: 0.6686562299728394\n",
            "  epoch: 18/20,    batch: 1296/2993    Encoder_loss: 0.654937744140625\n",
            "  epoch: 18/20,    batch: 1297/2993    Encoder_loss: 0.6060163974761963\n",
            "  epoch: 18/20,    batch: 1298/2993    Encoder_loss: 0.6677255630493164\n",
            "  epoch: 18/20,    batch: 1299/2993    Encoder_loss: 0.6712890863418579\n",
            "  epoch: 18/20,    batch: 1300/2993    Encoder_loss: 0.5936418175697327\n",
            "  epoch: 18/20,    batch: 1301/2993    Encoder_loss: 0.6309449672698975\n",
            "  epoch: 18/20,    batch: 1302/2993    Encoder_loss: 0.6978460550308228\n",
            "  epoch: 18/20,    batch: 1303/2993    Encoder_loss: 0.613034188747406\n",
            "  epoch: 18/20,    batch: 1304/2993    Encoder_loss: 0.575282633304596\n",
            "  epoch: 18/20,    batch: 1305/2993    Encoder_loss: 0.6788499355316162\n",
            "  epoch: 18/20,    batch: 1306/2993    Encoder_loss: 0.6640681624412537\n",
            "  epoch: 18/20,    batch: 1307/2993    Encoder_loss: 0.5774945616722107\n",
            "  epoch: 18/20,    batch: 1308/2993    Encoder_loss: 0.6668712496757507\n",
            "  epoch: 18/20,    batch: 1309/2993    Encoder_loss: 0.6951401233673096\n",
            "  epoch: 18/20,    batch: 1310/2993    Encoder_loss: 0.5872910618782043\n",
            "  epoch: 18/20,    batch: 1311/2993    Encoder_loss: 0.6183589696884155\n",
            "  epoch: 18/20,    batch: 1312/2993    Encoder_loss: 0.7094582319259644\n",
            "  epoch: 18/20,    batch: 1313/2993    Encoder_loss: 0.6540457606315613\n",
            "  epoch: 18/20,    batch: 1314/2993    Encoder_loss: 0.6644466519355774\n",
            "  epoch: 18/20,    batch: 1315/2993    Encoder_loss: 0.7038094997406006\n",
            "  epoch: 18/20,    batch: 1316/2993    Encoder_loss: 0.5978745818138123\n",
            "  epoch: 18/20,    batch: 1317/2993    Encoder_loss: 0.6407396793365479\n",
            "  epoch: 18/20,    batch: 1318/2993    Encoder_loss: 0.6819143891334534\n",
            "  epoch: 18/20,    batch: 1319/2993    Encoder_loss: 0.6010415554046631\n",
            "  epoch: 18/20,    batch: 1320/2993    Encoder_loss: 0.6502802968025208\n",
            "  epoch: 18/20,    batch: 1321/2993    Encoder_loss: 0.6640957593917847\n",
            "  epoch: 18/20,    batch: 1322/2993    Encoder_loss: 0.6141661405563354\n",
            "  epoch: 18/20,    batch: 1323/2993    Encoder_loss: 0.6548253297805786\n",
            "  epoch: 18/20,    batch: 1324/2993    Encoder_loss: 0.6457671523094177\n",
            "  epoch: 18/20,    batch: 1325/2993    Encoder_loss: 0.6373226642608643\n",
            "  epoch: 18/20,    batch: 1326/2993    Encoder_loss: 0.6642584204673767\n",
            "  epoch: 18/20,    batch: 1327/2993    Encoder_loss: 0.6403972506523132\n",
            "  epoch: 18/20,    batch: 1328/2993    Encoder_loss: 0.5837287306785583\n",
            "  epoch: 18/20,    batch: 1329/2993    Encoder_loss: 0.6514065265655518\n",
            "  epoch: 18/20,    batch: 1330/2993    Encoder_loss: 0.6660817861557007\n",
            "  epoch: 18/20,    batch: 1331/2993    Encoder_loss: 0.6085456013679504\n",
            "  epoch: 18/20,    batch: 1332/2993    Encoder_loss: 0.649039089679718\n",
            "  epoch: 18/20,    batch: 1333/2993    Encoder_loss: 0.6791215538978577\n",
            "  epoch: 18/20,    batch: 1334/2993    Encoder_loss: 0.599716067314148\n",
            "  epoch: 18/20,    batch: 1335/2993    Encoder_loss: 0.609645664691925\n",
            "  epoch: 18/20,    batch: 1336/2993    Encoder_loss: 0.6830825805664062\n",
            "  epoch: 18/20,    batch: 1337/2993    Encoder_loss: 0.6310626864433289\n",
            "  epoch: 18/20,    batch: 1338/2993    Encoder_loss: 0.6057484149932861\n",
            "  epoch: 18/20,    batch: 1339/2993    Encoder_loss: 0.6460619568824768\n",
            "  epoch: 18/20,    batch: 1340/2993    Encoder_loss: 0.6057589650154114\n",
            "  epoch: 18/20,    batch: 1341/2993    Encoder_loss: 0.5904864072799683\n",
            "  epoch: 18/20,    batch: 1342/2993    Encoder_loss: 0.642835795879364\n",
            "  epoch: 18/20,    batch: 1343/2993    Encoder_loss: 0.6763127446174622\n",
            "  epoch: 18/20,    batch: 1344/2993    Encoder_loss: 0.605131208896637\n",
            "  epoch: 18/20,    batch: 1345/2993    Encoder_loss: 0.6586610674858093\n",
            "  epoch: 18/20,    batch: 1346/2993    Encoder_loss: 0.6725584864616394\n",
            "  epoch: 18/20,    batch: 1347/2993    Encoder_loss: 0.6198247671127319\n",
            "  epoch: 18/20,    batch: 1348/2993    Encoder_loss: 0.7067669034004211\n",
            "  epoch: 18/20,    batch: 1349/2993    Encoder_loss: 0.6719863414764404\n",
            "  epoch: 18/20,    batch: 1350/2993    Encoder_loss: 0.6240142583847046\n",
            "  epoch: 18/20,    batch: 1351/2993    Encoder_loss: 0.6973392963409424\n",
            "  epoch: 18/20,    batch: 1352/2993    Encoder_loss: 0.6513088941574097\n",
            "  epoch: 18/20,    batch: 1353/2993    Encoder_loss: 0.6588355898857117\n",
            "  epoch: 18/20,    batch: 1354/2993    Encoder_loss: 0.7276991605758667\n",
            "  epoch: 18/20,    batch: 1355/2993    Encoder_loss: 0.6348129510879517\n",
            "  epoch: 18/20,    batch: 1356/2993    Encoder_loss: 0.6546239852905273\n",
            "  epoch: 18/20,    batch: 1357/2993    Encoder_loss: 0.7039517760276794\n",
            "  epoch: 18/20,    batch: 1358/2993    Encoder_loss: 0.6086790561676025\n",
            "  epoch: 18/20,    batch: 1359/2993    Encoder_loss: 0.6776191592216492\n",
            "  epoch: 18/20,    batch: 1360/2993    Encoder_loss: 0.699833869934082\n",
            "  epoch: 18/20,    batch: 1361/2993    Encoder_loss: 0.586722195148468\n",
            "  epoch: 18/20,    batch: 1362/2993    Encoder_loss: 0.535669207572937\n",
            "  epoch: 18/20,    batch: 1363/2993    Encoder_loss: 0.639856219291687\n",
            "  epoch: 18/20,    batch: 1364/2993    Encoder_loss: 0.6935616135597229\n",
            "  epoch: 18/20,    batch: 1365/2993    Encoder_loss: 0.6199696660041809\n",
            "  epoch: 18/20,    batch: 1366/2993    Encoder_loss: 0.6539186239242554\n",
            "  epoch: 18/20,    batch: 1367/2993    Encoder_loss: 0.6857369542121887\n",
            "  epoch: 18/20,    batch: 1368/2993    Encoder_loss: 0.5941320657730103\n",
            "  epoch: 18/20,    batch: 1369/2993    Encoder_loss: 0.5787551999092102\n",
            "  epoch: 18/20,    batch: 1370/2993    Encoder_loss: 0.668609082698822\n",
            "  epoch: 18/20,    batch: 1371/2993    Encoder_loss: 0.6797715425491333\n",
            "  epoch: 18/20,    batch: 1372/2993    Encoder_loss: 0.5503936409950256\n",
            "  epoch: 18/20,    batch: 1373/2993    Encoder_loss: 0.6149314045906067\n",
            "  epoch: 18/20,    batch: 1374/2993    Encoder_loss: 0.7024526000022888\n",
            "  epoch: 18/20,    batch: 1375/2993    Encoder_loss: 0.6379526257514954\n",
            "  epoch: 18/20,    batch: 1376/2993    Encoder_loss: 0.6050600409507751\n",
            "  epoch: 18/20,    batch: 1377/2993    Encoder_loss: 0.6726987957954407\n",
            "  epoch: 18/20,    batch: 1378/2993    Encoder_loss: 0.6752282381057739\n",
            "  epoch: 18/20,    batch: 1379/2993    Encoder_loss: 0.5957708954811096\n",
            "  epoch: 18/20,    batch: 1380/2993    Encoder_loss: 0.6545895934104919\n",
            "  epoch: 18/20,    batch: 1381/2993    Encoder_loss: 0.6820133924484253\n",
            "  epoch: 18/20,    batch: 1382/2993    Encoder_loss: 0.6019755005836487\n",
            "  epoch: 18/20,    batch: 1383/2993    Encoder_loss: 0.6427491307258606\n",
            "  epoch: 18/20,    batch: 1384/2993    Encoder_loss: 0.6400545835494995\n",
            "  epoch: 18/20,    batch: 1385/2993    Encoder_loss: 0.5900065302848816\n",
            "  epoch: 18/20,    batch: 1386/2993    Encoder_loss: 0.6382474303245544\n",
            "  epoch: 18/20,    batch: 1387/2993    Encoder_loss: 0.6029199957847595\n",
            "  epoch: 18/20,    batch: 1388/2993    Encoder_loss: 0.5969142913818359\n",
            "  epoch: 18/20,    batch: 1389/2993    Encoder_loss: 0.6627560257911682\n",
            "  epoch: 18/20,    batch: 1390/2993    Encoder_loss: 0.5920085906982422\n",
            "  epoch: 18/20,    batch: 1391/2993    Encoder_loss: 0.6138615012168884\n",
            "  epoch: 18/20,    batch: 1392/2993    Encoder_loss: 0.6795979142189026\n",
            "  epoch: 18/20,    batch: 1393/2993    Encoder_loss: 0.5722914338111877\n",
            "  epoch: 18/20,    batch: 1394/2993    Encoder_loss: 0.6139153838157654\n",
            "  epoch: 18/20,    batch: 1395/2993    Encoder_loss: 0.6392726898193359\n",
            "  epoch: 18/20,    batch: 1396/2993    Encoder_loss: 0.5698344111442566\n",
            "  epoch: 18/20,    batch: 1397/2993    Encoder_loss: 0.5850897431373596\n",
            "  epoch: 18/20,    batch: 1398/2993    Encoder_loss: 0.632818877696991\n",
            "  epoch: 18/20,    batch: 1399/2993    Encoder_loss: 0.6329915523529053\n",
            "  epoch: 18/20,    batch: 1400/2993    Encoder_loss: 0.5744999051094055\n",
            "  epoch: 18/20,    batch: 1401/2993    Encoder_loss: 0.6358838677406311\n",
            "  epoch: 18/20,    batch: 1402/2993    Encoder_loss: 0.6454278230667114\n",
            "  epoch: 18/20,    batch: 1403/2993    Encoder_loss: 0.5698718428611755\n",
            "  epoch: 18/20,    batch: 1404/2993    Encoder_loss: 0.6013699173927307\n",
            "  epoch: 18/20,    batch: 1405/2993    Encoder_loss: 0.6678901314735413\n",
            "  epoch: 18/20,    batch: 1406/2993    Encoder_loss: 0.6470587253570557\n",
            "  epoch: 18/20,    batch: 1407/2993    Encoder_loss: 0.5866586565971375\n",
            "  epoch: 18/20,    batch: 1408/2993    Encoder_loss: 0.6658612489700317\n",
            "  epoch: 18/20,    batch: 1409/2993    Encoder_loss: 0.6721900701522827\n",
            "  epoch: 18/20,    batch: 1410/2993    Encoder_loss: 0.5811995267868042\n",
            "  epoch: 18/20,    batch: 1411/2993    Encoder_loss: 0.620621383190155\n",
            "  epoch: 18/20,    batch: 1412/2993    Encoder_loss: 0.7059403657913208\n",
            "  epoch: 18/20,    batch: 1413/2993    Encoder_loss: 0.6225157380104065\n",
            "  epoch: 18/20,    batch: 1414/2993    Encoder_loss: 0.5781748294830322\n",
            "  epoch: 18/20,    batch: 1415/2993    Encoder_loss: 0.6577698588371277\n",
            "  epoch: 18/20,    batch: 1416/2993    Encoder_loss: 0.630172073841095\n",
            "  epoch: 18/20,    batch: 1417/2993    Encoder_loss: 0.6271858811378479\n",
            "  epoch: 18/20,    batch: 1418/2993    Encoder_loss: 0.6661829352378845\n",
            "  epoch: 18/20,    batch: 1419/2993    Encoder_loss: 0.6105127334594727\n",
            "  epoch: 18/20,    batch: 1420/2993    Encoder_loss: 0.6250758767127991\n",
            "  epoch: 18/20,    batch: 1421/2993    Encoder_loss: 0.6695623993873596\n",
            "  epoch: 18/20,    batch: 1422/2993    Encoder_loss: 0.5887203216552734\n",
            "  epoch: 18/20,    batch: 1423/2993    Encoder_loss: 0.6377174258232117\n",
            "  epoch: 18/20,    batch: 1424/2993    Encoder_loss: 0.6722363829612732\n",
            "  epoch: 18/20,    batch: 1425/2993    Encoder_loss: 0.597327470779419\n",
            "  epoch: 18/20,    batch: 1426/2993    Encoder_loss: 0.6535987257957458\n",
            "  epoch: 18/20,    batch: 1427/2993    Encoder_loss: 0.6759240031242371\n",
            "  epoch: 18/20,    batch: 1428/2993    Encoder_loss: 0.6351864337921143\n",
            "  epoch: 18/20,    batch: 1429/2993    Encoder_loss: 0.6647882461547852\n",
            "  epoch: 18/20,    batch: 1430/2993    Encoder_loss: 0.6502644419670105\n",
            "  epoch: 18/20,    batch: 1431/2993    Encoder_loss: 0.6312186121940613\n",
            "  epoch: 18/20,    batch: 1432/2993    Encoder_loss: 0.6854565739631653\n",
            "  epoch: 18/20,    batch: 1433/2993    Encoder_loss: 0.6982128024101257\n",
            "  epoch: 18/20,    batch: 1434/2993    Encoder_loss: 0.6296911239624023\n",
            "  epoch: 18/20,    batch: 1435/2993    Encoder_loss: 0.6811805367469788\n",
            "  epoch: 18/20,    batch: 1436/2993    Encoder_loss: 0.699941098690033\n",
            "  epoch: 18/20,    batch: 1437/2993    Encoder_loss: 0.6210582852363586\n",
            "  epoch: 18/20,    batch: 1438/2993    Encoder_loss: 0.6666193008422852\n",
            "  epoch: 18/20,    batch: 1439/2993    Encoder_loss: 0.7121738195419312\n",
            "  epoch: 18/20,    batch: 1440/2993    Encoder_loss: 0.6421499848365784\n",
            "  epoch: 18/20,    batch: 1441/2993    Encoder_loss: 0.6861753463745117\n",
            "  epoch: 18/20,    batch: 1442/2993    Encoder_loss: 0.7222002744674683\n",
            "  epoch: 18/20,    batch: 1443/2993    Encoder_loss: 0.6443503499031067\n",
            "  epoch: 18/20,    batch: 1444/2993    Encoder_loss: 0.628008246421814\n",
            "  epoch: 18/20,    batch: 1445/2993    Encoder_loss: 0.6824551224708557\n",
            "  epoch: 18/20,    batch: 1446/2993    Encoder_loss: 0.6758038401603699\n",
            "  epoch: 18/20,    batch: 1447/2993    Encoder_loss: 0.6693040132522583\n",
            "  epoch: 18/20,    batch: 1448/2993    Encoder_loss: 0.7044524550437927\n",
            "  epoch: 18/20,    batch: 1449/2993    Encoder_loss: 0.6674020290374756\n",
            "  epoch: 18/20,    batch: 1450/2993    Encoder_loss: 0.685339093208313\n",
            "  epoch: 18/20,    batch: 1451/2993    Encoder_loss: 0.7370508909225464\n",
            "  epoch: 18/20,    batch: 1452/2993    Encoder_loss: 0.6515551209449768\n",
            "  epoch: 18/20,    batch: 1453/2993    Encoder_loss: 0.6731349229812622\n",
            "  epoch: 18/20,    batch: 1454/2993    Encoder_loss: 0.7373947501182556\n",
            "  epoch: 18/20,    batch: 1455/2993    Encoder_loss: 0.65296471118927\n",
            "  epoch: 18/20,    batch: 1456/2993    Encoder_loss: 0.701943576335907\n",
            "  epoch: 18/20,    batch: 1457/2993    Encoder_loss: 0.7237814664840698\n",
            "  epoch: 18/20,    batch: 1458/2993    Encoder_loss: 0.6468598246574402\n",
            "  epoch: 18/20,    batch: 1459/2993    Encoder_loss: 0.6969484686851501\n",
            "  epoch: 18/20,    batch: 1460/2993    Encoder_loss: 0.7076348662376404\n",
            "  epoch: 18/20,    batch: 1461/2993    Encoder_loss: 0.67525315284729\n",
            "  epoch: 18/20,    batch: 1462/2993    Encoder_loss: 0.7203145623207092\n",
            "  epoch: 18/20,    batch: 1463/2993    Encoder_loss: 0.7055701613426208\n",
            "  epoch: 18/20,    batch: 1464/2993    Encoder_loss: 0.6304420232772827\n",
            "  epoch: 18/20,    batch: 1465/2993    Encoder_loss: 0.6774068474769592\n",
            "  epoch: 18/20,    batch: 1466/2993    Encoder_loss: 0.7299498915672302\n",
            "  epoch: 18/20,    batch: 1467/2993    Encoder_loss: 0.6859273910522461\n",
            "  epoch: 18/20,    batch: 1468/2993    Encoder_loss: 0.6904230713844299\n",
            "  epoch: 18/20,    batch: 1469/2993    Encoder_loss: 0.7282123565673828\n",
            "  epoch: 18/20,    batch: 1470/2993    Encoder_loss: 0.6684982180595398\n",
            "  epoch: 18/20,    batch: 1471/2993    Encoder_loss: 0.595101535320282\n",
            "  epoch: 18/20,    batch: 1472/2993    Encoder_loss: 0.6735615134239197\n",
            "  epoch: 18/20,    batch: 1473/2993    Encoder_loss: 0.7522430419921875\n",
            "  epoch: 18/20,    batch: 1474/2993    Encoder_loss: 0.6737492084503174\n",
            "  epoch: 18/20,    batch: 1475/2993    Encoder_loss: 0.6730528473854065\n",
            "  epoch: 18/20,    batch: 1476/2993    Encoder_loss: 0.7368835210800171\n",
            "  epoch: 18/20,    batch: 1477/2993    Encoder_loss: 0.6726019382476807\n",
            "  epoch: 18/20,    batch: 1478/2993    Encoder_loss: 0.6144171357154846\n",
            "  epoch: 18/20,    batch: 1479/2993    Encoder_loss: 0.703024685382843\n",
            "  epoch: 18/20,    batch: 1480/2993    Encoder_loss: 0.731642484664917\n",
            "  epoch: 18/20,    batch: 1481/2993    Encoder_loss: 0.6227272748947144\n",
            "  epoch: 18/20,    batch: 1482/2993    Encoder_loss: 0.6778182983398438\n",
            "  epoch: 18/20,    batch: 1483/2993    Encoder_loss: 0.7479419708251953\n",
            "  epoch: 18/20,    batch: 1484/2993    Encoder_loss: 0.6381906270980835\n",
            "  epoch: 18/20,    batch: 1485/2993    Encoder_loss: 0.7139797210693359\n",
            "  epoch: 18/20,    batch: 1486/2993    Encoder_loss: 0.7424394488334656\n",
            "  epoch: 18/20,    batch: 1487/2993    Encoder_loss: 0.6314612627029419\n",
            "  epoch: 18/20,    batch: 1488/2993    Encoder_loss: 0.6961462497711182\n",
            "  epoch: 18/20,    batch: 1489/2993    Encoder_loss: 0.688714325428009\n",
            "  epoch: 18/20,    batch: 1490/2993    Encoder_loss: 0.6449474692344666\n",
            "  epoch: 18/20,    batch: 1491/2993    Encoder_loss: 0.7097399234771729\n",
            "  epoch: 18/20,    batch: 1492/2993    Encoder_loss: 0.6667518615722656\n",
            "  epoch: 18/20,    batch: 1493/2993    Encoder_loss: 0.658060610294342\n",
            "  epoch: 18/20,    batch: 1494/2993    Encoder_loss: 0.70290207862854\n",
            "  epoch: 18/20,    batch: 1495/2993    Encoder_loss: 0.6420348882675171\n",
            "  epoch: 18/20,    batch: 1496/2993    Encoder_loss: 0.5979516506195068\n",
            "  epoch: 18/20,    batch: 1497/2993    Encoder_loss: 0.5956982374191284\n",
            "  epoch: 18/20,    batch: 1498/2993    Encoder_loss: 0.5959435701370239\n",
            "  epoch: 18/20,    batch: 1499/2993    Encoder_loss: 0.5975294709205627\n",
            "  epoch: 18/20,    batch: 1500/2993    Encoder_loss: 0.594612181186676\n",
            "  epoch: 18/20,    batch: 1501/2993    Encoder_loss: 0.5875046253204346\n",
            "  epoch: 18/20,    batch: 1502/2993    Encoder_loss: 0.5818420052528381\n",
            "  epoch: 18/20,    batch: 1503/2993    Encoder_loss: 0.5812296271324158\n",
            "  epoch: 18/20,    batch: 1504/2993    Encoder_loss: 0.5870392322540283\n",
            "  epoch: 18/20,    batch: 1505/2993    Encoder_loss: 0.588271975517273\n",
            "  epoch: 18/20,    batch: 1506/2993    Encoder_loss: 0.5856614708900452\n",
            "  epoch: 18/20,    batch: 1507/2993    Encoder_loss: 0.5829007625579834\n",
            "  epoch: 18/20,    batch: 1508/2993    Encoder_loss: 0.5834351181983948\n",
            "  epoch: 18/20,    batch: 1509/2993    Encoder_loss: 0.5871021151542664\n",
            "  epoch: 18/20,    batch: 1510/2993    Encoder_loss: 0.5863721370697021\n",
            "  epoch: 18/20,    batch: 1511/2993    Encoder_loss: 0.5853908061981201\n",
            "  epoch: 18/20,    batch: 1512/2993    Encoder_loss: 0.5866648554801941\n",
            "  epoch: 18/20,    batch: 1513/2993    Encoder_loss: 0.5875155329704285\n",
            "  epoch: 18/20,    batch: 1514/2993    Encoder_loss: 0.591864824295044\n",
            "  epoch: 18/20,    batch: 1515/2993    Encoder_loss: 0.5923165678977966\n",
            "  epoch: 18/20,    batch: 1516/2993    Encoder_loss: 0.5879902243614197\n",
            "  epoch: 18/20,    batch: 1517/2993    Encoder_loss: 0.5850101709365845\n",
            "  epoch: 18/20,    batch: 1518/2993    Encoder_loss: 0.583457887172699\n",
            "  epoch: 18/20,    batch: 1519/2993    Encoder_loss: 0.5818923711776733\n",
            "  epoch: 18/20,    batch: 1520/2993    Encoder_loss: 0.5820814371109009\n",
            "  epoch: 18/20,    batch: 1521/2993    Encoder_loss: 0.5825822353363037\n",
            "  epoch: 18/20,    batch: 1522/2993    Encoder_loss: 0.5806684494018555\n",
            "  epoch: 18/20,    batch: 1523/2993    Encoder_loss: 0.5766460299491882\n",
            "  epoch: 18/20,    batch: 1524/2993    Encoder_loss: 0.5752469301223755\n",
            "  epoch: 18/20,    batch: 1525/2993    Encoder_loss: 0.5759352445602417\n",
            "  epoch: 18/20,    batch: 1526/2993    Encoder_loss: 0.576287567615509\n",
            "  epoch: 18/20,    batch: 1527/2993    Encoder_loss: 0.574171781539917\n",
            "  epoch: 18/20,    batch: 1528/2993    Encoder_loss: 0.5741671323776245\n",
            "  epoch: 18/20,    batch: 1529/2993    Encoder_loss: 0.5984887480735779\n",
            "  epoch: 18/20,    batch: 1530/2993    Encoder_loss: 0.7016446590423584\n",
            "  epoch: 18/20,    batch: 1531/2993    Encoder_loss: 0.6997614502906799\n",
            "  epoch: 18/20,    batch: 1532/2993    Encoder_loss: 0.6220961213111877\n",
            "  epoch: 18/20,    batch: 1533/2993    Encoder_loss: 0.5900170207023621\n",
            "  epoch: 18/20,    batch: 1534/2993    Encoder_loss: 0.6396172046661377\n",
            "  epoch: 18/20,    batch: 1535/2993    Encoder_loss: 0.68715900182724\n",
            "  epoch: 18/20,    batch: 1536/2993    Encoder_loss: 0.6040235757827759\n",
            "  epoch: 18/20,    batch: 1537/2993    Encoder_loss: 0.6659114956855774\n",
            "  epoch: 18/20,    batch: 1538/2993    Encoder_loss: 0.7087149024009705\n",
            "  epoch: 18/20,    batch: 1539/2993    Encoder_loss: 0.6250288486480713\n",
            "  epoch: 18/20,    batch: 1540/2993    Encoder_loss: 0.6231955289840698\n",
            "  epoch: 18/20,    batch: 1541/2993    Encoder_loss: 0.6959278583526611\n",
            "  epoch: 18/20,    batch: 1542/2993    Encoder_loss: 0.6756320595741272\n",
            "  epoch: 18/20,    batch: 1543/2993    Encoder_loss: 0.5859377384185791\n",
            "  epoch: 18/20,    batch: 1544/2993    Encoder_loss: 0.6968082189559937\n",
            "  epoch: 18/20,    batch: 1545/2993    Encoder_loss: 0.6950909495353699\n",
            "  epoch: 18/20,    batch: 1546/2993    Encoder_loss: 0.6039450764656067\n",
            "  epoch: 18/20,    batch: 1547/2993    Encoder_loss: 0.6374370455741882\n",
            "  epoch: 18/20,    batch: 1548/2993    Encoder_loss: 0.6769894361495972\n",
            "  epoch: 18/20,    batch: 1549/2993    Encoder_loss: 0.6490360498428345\n",
            "  epoch: 18/20,    batch: 1550/2993    Encoder_loss: 0.5846331119537354\n",
            "  epoch: 18/20,    batch: 1551/2993    Encoder_loss: 0.648297905921936\n",
            "  epoch: 18/20,    batch: 1552/2993    Encoder_loss: 0.6440422534942627\n",
            "  epoch: 18/20,    batch: 1553/2993    Encoder_loss: 0.6168562769889832\n",
            "  epoch: 18/20,    batch: 1554/2993    Encoder_loss: 0.6569913029670715\n",
            "  epoch: 18/20,    batch: 1555/2993    Encoder_loss: 0.6174503564834595\n",
            "  epoch: 18/20,    batch: 1556/2993    Encoder_loss: 0.6090033054351807\n",
            "  epoch: 18/20,    batch: 1557/2993    Encoder_loss: 0.6866086721420288\n",
            "  epoch: 18/20,    batch: 1558/2993    Encoder_loss: 0.6211441159248352\n",
            "  epoch: 18/20,    batch: 1559/2993    Encoder_loss: 0.6087281703948975\n",
            "  epoch: 18/20,    batch: 1560/2993    Encoder_loss: 0.6783745884895325\n",
            "  epoch: 18/20,    batch: 1561/2993    Encoder_loss: 0.593927264213562\n",
            "  epoch: 18/20,    batch: 1562/2993    Encoder_loss: 0.6252890229225159\n",
            "  epoch: 18/20,    batch: 1563/2993    Encoder_loss: 0.6791658401489258\n",
            "  epoch: 18/20,    batch: 1564/2993    Encoder_loss: 0.5932883024215698\n",
            "  epoch: 18/20,    batch: 1565/2993    Encoder_loss: 0.6362226009368896\n",
            "  epoch: 18/20,    batch: 1566/2993    Encoder_loss: 0.6581582427024841\n",
            "  epoch: 18/20,    batch: 1567/2993    Encoder_loss: 0.6088340878486633\n",
            "  epoch: 18/20,    batch: 1568/2993    Encoder_loss: 0.6487264037132263\n",
            "  epoch: 18/20,    batch: 1569/2993    Encoder_loss: 0.6835992336273193\n",
            "  epoch: 18/20,    batch: 1570/2993    Encoder_loss: 0.6320452094078064\n",
            "  epoch: 18/20,    batch: 1571/2993    Encoder_loss: 0.6660550832748413\n",
            "  epoch: 18/20,    batch: 1572/2993    Encoder_loss: 0.6997292041778564\n",
            "  epoch: 18/20,    batch: 1573/2993    Encoder_loss: 0.6063801050186157\n",
            "  epoch: 18/20,    batch: 1574/2993    Encoder_loss: 0.6095594763755798\n",
            "  epoch: 18/20,    batch: 1575/2993    Encoder_loss: 0.6511299014091492\n",
            "  epoch: 18/20,    batch: 1576/2993    Encoder_loss: 0.6005228757858276\n",
            "  epoch: 18/20,    batch: 1577/2993    Encoder_loss: 0.6150252223014832\n",
            "  epoch: 18/20,    batch: 1578/2993    Encoder_loss: 0.6731091737747192\n",
            "  epoch: 18/20,    batch: 1579/2993    Encoder_loss: 0.6047029495239258\n",
            "  epoch: 18/20,    batch: 1580/2993    Encoder_loss: 0.5774630308151245\n",
            "  epoch: 18/20,    batch: 1581/2993    Encoder_loss: 0.6513017416000366\n",
            "  epoch: 18/20,    batch: 1582/2993    Encoder_loss: 0.6460104584693909\n",
            "  epoch: 18/20,    batch: 1583/2993    Encoder_loss: 0.6135936379432678\n",
            "  epoch: 18/20,    batch: 1584/2993    Encoder_loss: 0.6932538151741028\n",
            "  epoch: 18/20,    batch: 1585/2993    Encoder_loss: 0.6591960191726685\n",
            "  epoch: 18/20,    batch: 1586/2993    Encoder_loss: 0.6439899206161499\n",
            "  epoch: 18/20,    batch: 1587/2993    Encoder_loss: 0.6955758929252625\n",
            "  epoch: 18/20,    batch: 1588/2993    Encoder_loss: 0.592959463596344\n",
            "  epoch: 18/20,    batch: 1589/2993    Encoder_loss: 0.6107893586158752\n",
            "  epoch: 18/20,    batch: 1590/2993    Encoder_loss: 0.7027072906494141\n",
            "  epoch: 18/20,    batch: 1591/2993    Encoder_loss: 0.6170423626899719\n",
            "  epoch: 18/20,    batch: 1592/2993    Encoder_loss: 0.6565968990325928\n",
            "  epoch: 18/20,    batch: 1593/2993    Encoder_loss: 0.6876389384269714\n",
            "  epoch: 18/20,    batch: 1594/2993    Encoder_loss: 0.5752285122871399\n",
            "  epoch: 18/20,    batch: 1595/2993    Encoder_loss: 0.6559380888938904\n",
            "  epoch: 18/20,    batch: 1596/2993    Encoder_loss: 0.6771668791770935\n",
            "  epoch: 18/20,    batch: 1597/2993    Encoder_loss: 0.6158735156059265\n",
            "  epoch: 18/20,    batch: 1598/2993    Encoder_loss: 0.6936682462692261\n",
            "  epoch: 18/20,    batch: 1599/2993    Encoder_loss: 0.6749823093414307\n",
            "  epoch: 18/20,    batch: 1600/2993    Encoder_loss: 0.593510091304779\n",
            "  epoch: 18/20,    batch: 1601/2993    Encoder_loss: 0.6438395977020264\n",
            "  epoch: 18/20,    batch: 1602/2993    Encoder_loss: 0.7131271362304688\n",
            "  epoch: 18/20,    batch: 1603/2993    Encoder_loss: 0.6640412211418152\n",
            "  epoch: 18/20,    batch: 1604/2993    Encoder_loss: 0.9115273356437683\n",
            "  epoch: 18/20,    batch: 1605/2993    Encoder_loss: 1.078535795211792\n",
            "  epoch: 18/20,    batch: 1606/2993    Encoder_loss: 0.8439985513687134\n",
            "  epoch: 18/20,    batch: 1607/2993    Encoder_loss: 0.7881152629852295\n",
            "  epoch: 18/20,    batch: 1608/2993    Encoder_loss: 0.8412004113197327\n",
            "  epoch: 18/20,    batch: 1609/2993    Encoder_loss: 0.8527374267578125\n",
            "  epoch: 18/20,    batch: 1610/2993    Encoder_loss: 0.804536759853363\n",
            "  epoch: 18/20,    batch: 1611/2993    Encoder_loss: 0.8127672672271729\n",
            "  epoch: 18/20,    batch: 1612/2993    Encoder_loss: 0.7684561610221863\n",
            "  epoch: 18/20,    batch: 1613/2993    Encoder_loss: 0.6618862152099609\n",
            "  epoch: 18/20,    batch: 1614/2993    Encoder_loss: 0.5820443630218506\n",
            "  epoch: 18/20,    batch: 1615/2993    Encoder_loss: 0.6714339852333069\n",
            "  epoch: 18/20,    batch: 1616/2993    Encoder_loss: 0.7165750861167908\n",
            "  epoch: 18/20,    batch: 1617/2993    Encoder_loss: 0.6506727933883667\n",
            "  epoch: 18/20,    batch: 1618/2993    Encoder_loss: 0.6515243649482727\n",
            "  epoch: 18/20,    batch: 1619/2993    Encoder_loss: 0.7044981122016907\n",
            "  epoch: 18/20,    batch: 1620/2993    Encoder_loss: 0.6323556303977966\n",
            "  epoch: 18/20,    batch: 1621/2993    Encoder_loss: 0.6708963513374329\n",
            "  epoch: 18/20,    batch: 1622/2993    Encoder_loss: 0.6981940865516663\n",
            "  epoch: 18/20,    batch: 1623/2993    Encoder_loss: 0.6117614507675171\n",
            "  epoch: 18/20,    batch: 1624/2993    Encoder_loss: 0.6824252605438232\n",
            "  epoch: 18/20,    batch: 1625/2993    Encoder_loss: 0.7262307405471802\n",
            "  epoch: 18/20,    batch: 1626/2993    Encoder_loss: 0.6616608500480652\n",
            "  epoch: 18/20,    batch: 1627/2993    Encoder_loss: 0.6989428997039795\n",
            "  epoch: 18/20,    batch: 1628/2993    Encoder_loss: 0.6846324801445007\n",
            "  epoch: 18/20,    batch: 1629/2993    Encoder_loss: 0.6646785140037537\n",
            "  epoch: 18/20,    batch: 1630/2993    Encoder_loss: 0.7156561017036438\n",
            "  epoch: 18/20,    batch: 1631/2993    Encoder_loss: 0.6603739261627197\n",
            "  epoch: 18/20,    batch: 1632/2993    Encoder_loss: 0.6297950744628906\n",
            "  epoch: 18/20,    batch: 1633/2993    Encoder_loss: 0.677661120891571\n",
            "  epoch: 18/20,    batch: 1634/2993    Encoder_loss: 0.6346655488014221\n",
            "  epoch: 18/20,    batch: 1635/2993    Encoder_loss: 0.5986366271972656\n",
            "  epoch: 18/20,    batch: 1636/2993    Encoder_loss: 0.6804567575454712\n",
            "  epoch: 18/20,    batch: 1637/2993    Encoder_loss: 0.6933451294898987\n",
            "  epoch: 18/20,    batch: 1638/2993    Encoder_loss: 0.5986358523368835\n",
            "  epoch: 18/20,    batch: 1639/2993    Encoder_loss: 0.6272245049476624\n",
            "  epoch: 18/20,    batch: 1640/2993    Encoder_loss: 0.6826993823051453\n",
            "  epoch: 18/20,    batch: 1641/2993    Encoder_loss: 0.6236883997917175\n",
            "  epoch: 18/20,    batch: 1642/2993    Encoder_loss: 0.5968066453933716\n",
            "  epoch: 18/20,    batch: 1643/2993    Encoder_loss: 0.6706522107124329\n",
            "  epoch: 18/20,    batch: 1644/2993    Encoder_loss: 0.7099506258964539\n",
            "  epoch: 18/20,    batch: 1645/2993    Encoder_loss: 0.6372734308242798\n",
            "  epoch: 18/20,    batch: 1646/2993    Encoder_loss: 0.67094486951828\n",
            "  epoch: 18/20,    batch: 1647/2993    Encoder_loss: 0.7055132985115051\n",
            "  epoch: 18/20,    batch: 1648/2993    Encoder_loss: 0.6387912631034851\n",
            "  epoch: 18/20,    batch: 1649/2993    Encoder_loss: 0.6215984225273132\n",
            "  epoch: 18/20,    batch: 1650/2993    Encoder_loss: 0.6794493198394775\n",
            "  epoch: 18/20,    batch: 1651/2993    Encoder_loss: 0.7207390069961548\n",
            "  epoch: 18/20,    batch: 1652/2993    Encoder_loss: 0.6153249144554138\n",
            "  epoch: 18/20,    batch: 1653/2993    Encoder_loss: 0.6757557392120361\n",
            "  epoch: 18/20,    batch: 1654/2993    Encoder_loss: 0.7093480825424194\n",
            "  epoch: 18/20,    batch: 1655/2993    Encoder_loss: 0.6160364747047424\n",
            "  epoch: 18/20,    batch: 1656/2993    Encoder_loss: 0.7042175531387329\n",
            "  epoch: 18/20,    batch: 1657/2993    Encoder_loss: 0.6960253119468689\n",
            "  epoch: 18/20,    batch: 1658/2993    Encoder_loss: 0.6415167450904846\n",
            "  epoch: 18/20,    batch: 1659/2993    Encoder_loss: 0.7138320207595825\n",
            "  epoch: 18/20,    batch: 1660/2993    Encoder_loss: 0.6678858995437622\n",
            "  epoch: 18/20,    batch: 1661/2993    Encoder_loss: 0.6547359228134155\n",
            "  epoch: 18/20,    batch: 1662/2993    Encoder_loss: 0.7305327653884888\n",
            "  epoch: 18/20,    batch: 1663/2993    Encoder_loss: 0.6512927412986755\n",
            "  epoch: 18/20,    batch: 1664/2993    Encoder_loss: 0.6656123995780945\n",
            "  epoch: 18/20,    batch: 1665/2993    Encoder_loss: 0.7261508107185364\n",
            "  epoch: 18/20,    batch: 1666/2993    Encoder_loss: 0.6254646182060242\n",
            "  epoch: 18/20,    batch: 1667/2993    Encoder_loss: 0.6820678114891052\n",
            "  epoch: 18/20,    batch: 1668/2993    Encoder_loss: 0.7036891579627991\n",
            "  epoch: 18/20,    batch: 1669/2993    Encoder_loss: 0.6150744557380676\n",
            "  epoch: 18/20,    batch: 1670/2993    Encoder_loss: 0.636605978012085\n",
            "  epoch: 18/20,    batch: 1671/2993    Encoder_loss: 0.7013576030731201\n",
            "  epoch: 18/20,    batch: 1672/2993    Encoder_loss: 0.6890407204627991\n",
            "  epoch: 18/20,    batch: 1673/2993    Encoder_loss: 0.6569563746452332\n",
            "  epoch: 18/20,    batch: 1674/2993    Encoder_loss: 0.7080664038658142\n",
            "  epoch: 18/20,    batch: 1675/2993    Encoder_loss: 0.6639391183853149\n",
            "  epoch: 18/20,    batch: 1676/2993    Encoder_loss: 0.6027894616127014\n",
            "  epoch: 18/20,    batch: 1677/2993    Encoder_loss: 0.6517254114151001\n",
            "  epoch: 18/20,    batch: 1678/2993    Encoder_loss: 0.6928814649581909\n",
            "  epoch: 18/20,    batch: 1679/2993    Encoder_loss: 0.6541971564292908\n",
            "  epoch: 18/20,    batch: 1680/2993    Encoder_loss: 0.6805309057235718\n",
            "  epoch: 18/20,    batch: 1681/2993    Encoder_loss: 0.664406955242157\n",
            "  epoch: 18/20,    batch: 1682/2993    Encoder_loss: 0.598301351070404\n",
            "  epoch: 18/20,    batch: 1683/2993    Encoder_loss: 0.6433605551719666\n",
            "  epoch: 18/20,    batch: 1684/2993    Encoder_loss: 0.6703759431838989\n",
            "  epoch: 18/20,    batch: 1685/2993    Encoder_loss: 0.6130416989326477\n",
            "  epoch: 18/20,    batch: 1686/2993    Encoder_loss: 0.6061614751815796\n",
            "  epoch: 18/20,    batch: 1687/2993    Encoder_loss: 0.6913027167320251\n",
            "  epoch: 18/20,    batch: 1688/2993    Encoder_loss: 0.6261098980903625\n",
            "  epoch: 18/20,    batch: 1689/2993    Encoder_loss: 0.6422570943832397\n",
            "  epoch: 18/20,    batch: 1690/2993    Encoder_loss: 0.7187749147415161\n",
            "  epoch: 18/20,    batch: 1691/2993    Encoder_loss: 0.5877171754837036\n",
            "  epoch: 18/20,    batch: 1692/2993    Encoder_loss: 0.6420859694480896\n",
            "  epoch: 18/20,    batch: 1693/2993    Encoder_loss: 0.6988872289657593\n",
            "  epoch: 18/20,    batch: 1694/2993    Encoder_loss: 0.5976030826568604\n",
            "  epoch: 18/20,    batch: 1695/2993    Encoder_loss: 0.6834423542022705\n",
            "  epoch: 18/20,    batch: 1696/2993    Encoder_loss: 0.669320821762085\n",
            "  epoch: 18/20,    batch: 1697/2993    Encoder_loss: 0.5770660638809204\n",
            "  epoch: 18/20,    batch: 1698/2993    Encoder_loss: 0.6714449524879456\n",
            "  epoch: 18/20,    batch: 1699/2993    Encoder_loss: 0.6382629871368408\n",
            "  epoch: 18/20,    batch: 1700/2993    Encoder_loss: 0.6203686594963074\n",
            "  epoch: 18/20,    batch: 1701/2993    Encoder_loss: 0.6976268291473389\n",
            "  epoch: 18/20,    batch: 1702/2993    Encoder_loss: 0.6469297409057617\n",
            "  epoch: 18/20,    batch: 1703/2993    Encoder_loss: 0.5429585576057434\n",
            "  epoch: 18/20,    batch: 1704/2993    Encoder_loss: 0.610903799533844\n",
            "  epoch: 18/20,    batch: 1705/2993    Encoder_loss: 0.6952135562896729\n",
            "  epoch: 18/20,    batch: 1706/2993    Encoder_loss: 0.6447519659996033\n",
            "  epoch: 18/20,    batch: 1707/2993    Encoder_loss: 0.6488265991210938\n",
            "  epoch: 18/20,    batch: 1708/2993    Encoder_loss: 0.7037425637245178\n",
            "  epoch: 18/20,    batch: 1709/2993    Encoder_loss: 0.6359068155288696\n",
            "  epoch: 18/20,    batch: 1710/2993    Encoder_loss: 0.5738571286201477\n",
            "  epoch: 18/20,    batch: 1711/2993    Encoder_loss: 0.6628921627998352\n",
            "  epoch: 18/20,    batch: 1712/2993    Encoder_loss: 0.6920663714408875\n",
            "  epoch: 18/20,    batch: 1713/2993    Encoder_loss: 0.5941859483718872\n",
            "  epoch: 18/20,    batch: 1714/2993    Encoder_loss: 0.6246510744094849\n",
            "  epoch: 18/20,    batch: 1715/2993    Encoder_loss: 0.6697319746017456\n",
            "  epoch: 18/20,    batch: 1716/2993    Encoder_loss: 0.6080204844474792\n",
            "  epoch: 18/20,    batch: 1717/2993    Encoder_loss: 0.5891263484954834\n",
            "  epoch: 18/20,    batch: 1718/2993    Encoder_loss: 0.684345543384552\n",
            "  epoch: 18/20,    batch: 1719/2993    Encoder_loss: 0.6946648955345154\n",
            "  epoch: 18/20,    batch: 1720/2993    Encoder_loss: 0.5709368586540222\n",
            "  epoch: 18/20,    batch: 1721/2993    Encoder_loss: 0.6065985560417175\n",
            "  epoch: 18/20,    batch: 1722/2993    Encoder_loss: 0.6769541501998901\n",
            "  epoch: 18/20,    batch: 1723/2993    Encoder_loss: 0.6283572316169739\n",
            "  epoch: 18/20,    batch: 1724/2993    Encoder_loss: 0.6782788634300232\n",
            "  epoch: 18/20,    batch: 1725/2993    Encoder_loss: 0.6668387651443481\n",
            "  epoch: 18/20,    batch: 1726/2993    Encoder_loss: 0.6192706823348999\n",
            "  epoch: 18/20,    batch: 1727/2993    Encoder_loss: 0.6828143000602722\n",
            "  epoch: 18/20,    batch: 1728/2993    Encoder_loss: 0.6585460305213928\n",
            "  epoch: 18/20,    batch: 1729/2993    Encoder_loss: 0.6114713549613953\n",
            "  epoch: 18/20,    batch: 1730/2993    Encoder_loss: 0.6570857167243958\n",
            "  epoch: 18/20,    batch: 1731/2993    Encoder_loss: 0.6257999539375305\n",
            "  epoch: 18/20,    batch: 1732/2993    Encoder_loss: 0.6046848297119141\n",
            "  epoch: 18/20,    batch: 1733/2993    Encoder_loss: 0.6589938402175903\n",
            "  epoch: 18/20,    batch: 1734/2993    Encoder_loss: 0.5952473878860474\n",
            "  epoch: 18/20,    batch: 1735/2993    Encoder_loss: 0.6085003614425659\n",
            "  epoch: 18/20,    batch: 1736/2993    Encoder_loss: 0.647117018699646\n",
            "  epoch: 18/20,    batch: 1737/2993    Encoder_loss: 0.5911064147949219\n",
            "  epoch: 18/20,    batch: 1738/2993    Encoder_loss: 0.5918382406234741\n",
            "  epoch: 18/20,    batch: 1739/2993    Encoder_loss: 0.6330823302268982\n",
            "  epoch: 18/20,    batch: 1740/2993    Encoder_loss: 0.6115623116493225\n",
            "  epoch: 18/20,    batch: 1741/2993    Encoder_loss: 0.6403109431266785\n",
            "  epoch: 18/20,    batch: 1742/2993    Encoder_loss: 0.6805774569511414\n",
            "  epoch: 18/20,    batch: 1743/2993    Encoder_loss: 0.6225423216819763\n",
            "  epoch: 18/20,    batch: 1744/2993    Encoder_loss: 0.6139770746231079\n",
            "  epoch: 18/20,    batch: 1745/2993    Encoder_loss: 0.6847074627876282\n",
            "  epoch: 18/20,    batch: 1746/2993    Encoder_loss: 0.6561734676361084\n",
            "  epoch: 18/20,    batch: 1747/2993    Encoder_loss: 0.6123716831207275\n",
            "  epoch: 18/20,    batch: 1748/2993    Encoder_loss: 0.6806907057762146\n",
            "  epoch: 18/20,    batch: 1749/2993    Encoder_loss: 0.6575855612754822\n",
            "  epoch: 18/20,    batch: 1750/2993    Encoder_loss: 0.6091299057006836\n",
            "  epoch: 18/20,    batch: 1751/2993    Encoder_loss: 0.6629124879837036\n",
            "  epoch: 18/20,    batch: 1752/2993    Encoder_loss: 0.6974332928657532\n",
            "  epoch: 18/20,    batch: 1753/2993    Encoder_loss: 0.6246470808982849\n",
            "  epoch: 18/20,    batch: 1754/2993    Encoder_loss: 0.64185631275177\n",
            "  epoch: 18/20,    batch: 1755/2993    Encoder_loss: 0.6724969148635864\n",
            "  epoch: 18/20,    batch: 1756/2993    Encoder_loss: 0.6217935681343079\n",
            "  epoch: 18/20,    batch: 1757/2993    Encoder_loss: 0.6537559628486633\n",
            "  epoch: 18/20,    batch: 1758/2993    Encoder_loss: 0.6574899554252625\n",
            "  epoch: 18/20,    batch: 1759/2993    Encoder_loss: 0.6334274411201477\n",
            "  epoch: 18/20,    batch: 1760/2993    Encoder_loss: 0.6614780426025391\n",
            "  epoch: 18/20,    batch: 1761/2993    Encoder_loss: 0.6354944109916687\n",
            "  epoch: 18/20,    batch: 1762/2993    Encoder_loss: 0.6208549737930298\n",
            "  epoch: 18/20,    batch: 1763/2993    Encoder_loss: 0.6789275407791138\n",
            "  epoch: 18/20,    batch: 1764/2993    Encoder_loss: 0.6208016276359558\n",
            "  epoch: 18/20,    batch: 1765/2993    Encoder_loss: 0.6147872805595398\n",
            "  epoch: 18/20,    batch: 1766/2993    Encoder_loss: 0.6739460229873657\n",
            "  epoch: 18/20,    batch: 1767/2993    Encoder_loss: 0.5917443633079529\n",
            "  epoch: 18/20,    batch: 1768/2993    Encoder_loss: 0.6381540894508362\n",
            "  epoch: 18/20,    batch: 1769/2993    Encoder_loss: 0.661866307258606\n",
            "  epoch: 18/20,    batch: 1770/2993    Encoder_loss: 0.5875170230865479\n",
            "  epoch: 18/20,    batch: 1771/2993    Encoder_loss: 0.6039654612541199\n",
            "  epoch: 18/20,    batch: 1772/2993    Encoder_loss: 0.6696919202804565\n",
            "  epoch: 18/20,    batch: 1773/2993    Encoder_loss: 0.63997483253479\n",
            "  epoch: 18/20,    batch: 1774/2993    Encoder_loss: 0.6478748321533203\n",
            "  epoch: 18/20,    batch: 1775/2993    Encoder_loss: 0.658380389213562\n",
            "  epoch: 18/20,    batch: 1776/2993    Encoder_loss: 0.5957313776016235\n",
            "  epoch: 18/20,    batch: 1777/2993    Encoder_loss: 0.6137860417366028\n",
            "  epoch: 18/20,    batch: 1778/2993    Encoder_loss: 0.6726768612861633\n",
            "  epoch: 18/20,    batch: 1779/2993    Encoder_loss: 0.6389443278312683\n",
            "  epoch: 18/20,    batch: 1780/2993    Encoder_loss: 0.6251164674758911\n",
            "  epoch: 18/20,    batch: 1781/2993    Encoder_loss: 0.6748828887939453\n",
            "  epoch: 18/20,    batch: 1782/2993    Encoder_loss: 0.6423847079277039\n",
            "  epoch: 18/20,    batch: 1783/2993    Encoder_loss: 0.5797454714775085\n",
            "  epoch: 18/20,    batch: 1784/2993    Encoder_loss: 0.6766355037689209\n",
            "  epoch: 18/20,    batch: 1785/2993    Encoder_loss: 0.6996884942054749\n",
            "  epoch: 18/20,    batch: 1786/2993    Encoder_loss: 0.6018370389938354\n",
            "  epoch: 18/20,    batch: 1787/2993    Encoder_loss: 0.6717481017112732\n",
            "  epoch: 18/20,    batch: 1788/2993    Encoder_loss: 0.6708739995956421\n",
            "  epoch: 18/20,    batch: 1789/2993    Encoder_loss: 0.6209255456924438\n",
            "  epoch: 18/20,    batch: 1790/2993    Encoder_loss: 0.6955248713493347\n",
            "  epoch: 18/20,    batch: 1791/2993    Encoder_loss: 0.6344042420387268\n",
            "  epoch: 18/20,    batch: 1792/2993    Encoder_loss: 0.6059362888336182\n",
            "  epoch: 18/20,    batch: 1793/2993    Encoder_loss: 0.6981240510940552\n",
            "  epoch: 18/20,    batch: 1794/2993    Encoder_loss: 0.651256263256073\n",
            "  epoch: 18/20,    batch: 1795/2993    Encoder_loss: 0.6852479577064514\n",
            "  epoch: 18/20,    batch: 1796/2993    Encoder_loss: 0.731163740158081\n",
            "  epoch: 18/20,    batch: 1797/2993    Encoder_loss: 0.5934121608734131\n",
            "  epoch: 18/20,    batch: 1798/2993    Encoder_loss: 0.6506555080413818\n",
            "  epoch: 18/20,    batch: 1799/2993    Encoder_loss: 0.7081647515296936\n",
            "  epoch: 18/20,    batch: 1800/2993    Encoder_loss: 0.5994612574577332\n",
            "  epoch: 18/20,    batch: 1801/2993    Encoder_loss: 0.6829091906547546\n",
            "  epoch: 18/20,    batch: 1802/2993    Encoder_loss: 0.6844825744628906\n",
            "  epoch: 18/20,    batch: 1803/2993    Encoder_loss: 0.5725664496421814\n",
            "  epoch: 18/20,    batch: 1804/2993    Encoder_loss: 0.5785223841667175\n",
            "  epoch: 18/20,    batch: 1805/2993    Encoder_loss: 0.6817827820777893\n",
            "  epoch: 18/20,    batch: 1806/2993    Encoder_loss: 0.682933509349823\n",
            "  epoch: 18/20,    batch: 1807/2993    Encoder_loss: 0.6459723114967346\n",
            "  epoch: 18/20,    batch: 1808/2993    Encoder_loss: 0.7135973572731018\n",
            "  epoch: 18/20,    batch: 1809/2993    Encoder_loss: 0.6736108660697937\n",
            "  epoch: 18/20,    batch: 1810/2993    Encoder_loss: 0.5623462200164795\n",
            "  epoch: 18/20,    batch: 1811/2993    Encoder_loss: 0.592007577419281\n",
            "  epoch: 18/20,    batch: 1812/2993    Encoder_loss: 0.683473527431488\n",
            "  epoch: 18/20,    batch: 1813/2993    Encoder_loss: 0.6319788098335266\n",
            "  epoch: 18/20,    batch: 1814/2993    Encoder_loss: 0.5896242260932922\n",
            "  epoch: 18/20,    batch: 1815/2993    Encoder_loss: 0.6803932189941406\n",
            "  epoch: 18/20,    batch: 1816/2993    Encoder_loss: 0.6380630135536194\n",
            "  epoch: 18/20,    batch: 1817/2993    Encoder_loss: 0.5318531394004822\n",
            "  epoch: 18/20,    batch: 1818/2993    Encoder_loss: 0.605694055557251\n",
            "  epoch: 18/20,    batch: 1819/2993    Encoder_loss: 0.6961292624473572\n",
            "  epoch: 18/20,    batch: 1820/2993    Encoder_loss: 0.6156454086303711\n",
            "  epoch: 18/20,    batch: 1821/2993    Encoder_loss: 0.5909317135810852\n",
            "  epoch: 18/20,    batch: 1822/2993    Encoder_loss: 0.678659975528717\n",
            "  epoch: 18/20,    batch: 1823/2993    Encoder_loss: 0.6294864416122437\n",
            "  epoch: 18/20,    batch: 1824/2993    Encoder_loss: 0.612664520740509\n",
            "  epoch: 18/20,    batch: 1825/2993    Encoder_loss: 0.6842037439346313\n",
            "  epoch: 18/20,    batch: 1826/2993    Encoder_loss: 0.6279802322387695\n",
            "  epoch: 18/20,    batch: 1827/2993    Encoder_loss: 0.6403669118881226\n",
            "  epoch: 18/20,    batch: 1828/2993    Encoder_loss: 0.711151659488678\n",
            "  epoch: 18/20,    batch: 1829/2993    Encoder_loss: 0.615543782711029\n",
            "  epoch: 18/20,    batch: 1830/2993    Encoder_loss: 0.6508522033691406\n",
            "  epoch: 18/20,    batch: 1831/2993    Encoder_loss: 0.6934500336647034\n",
            "  epoch: 18/20,    batch: 1832/2993    Encoder_loss: 0.6276508569717407\n",
            "  epoch: 18/20,    batch: 1833/2993    Encoder_loss: 0.675873339176178\n",
            "  epoch: 18/20,    batch: 1834/2993    Encoder_loss: 0.6623495817184448\n",
            "  epoch: 18/20,    batch: 1835/2993    Encoder_loss: 0.6015452146530151\n",
            "  epoch: 18/20,    batch: 1836/2993    Encoder_loss: 0.6317352056503296\n",
            "  epoch: 18/20,    batch: 1837/2993    Encoder_loss: 0.5928413271903992\n",
            "  epoch: 18/20,    batch: 1838/2993    Encoder_loss: 0.542181670665741\n",
            "  epoch: 18/20,    batch: 1839/2993    Encoder_loss: 0.6109742522239685\n",
            "  epoch: 18/20,    batch: 1840/2993    Encoder_loss: 0.6339082717895508\n",
            "  epoch: 18/20,    batch: 1841/2993    Encoder_loss: 0.5680738687515259\n",
            "  epoch: 18/20,    batch: 1842/2993    Encoder_loss: 0.6457340121269226\n",
            "  epoch: 18/20,    batch: 1843/2993    Encoder_loss: 0.6378556489944458\n",
            "  epoch: 18/20,    batch: 1844/2993    Encoder_loss: 0.5354355573654175\n",
            "  epoch: 18/20,    batch: 1845/2993    Encoder_loss: 0.6104163527488708\n",
            "  epoch: 18/20,    batch: 1846/2993    Encoder_loss: 0.6693568825721741\n",
            "  epoch: 18/20,    batch: 1847/2993    Encoder_loss: 0.5807787179946899\n",
            "  epoch: 18/20,    batch: 1848/2993    Encoder_loss: 0.6166479587554932\n",
            "  epoch: 18/20,    batch: 1849/2993    Encoder_loss: 0.664322555065155\n",
            "  epoch: 18/20,    batch: 1850/2993    Encoder_loss: 0.5754216313362122\n",
            "  epoch: 18/20,    batch: 1851/2993    Encoder_loss: 0.5875282287597656\n",
            "  epoch: 18/20,    batch: 1852/2993    Encoder_loss: 0.6634138822555542\n",
            "  epoch: 18/20,    batch: 1853/2993    Encoder_loss: 0.6246010065078735\n",
            "  epoch: 18/20,    batch: 1854/2993    Encoder_loss: 0.6076726913452148\n",
            "  epoch: 18/20,    batch: 1855/2993    Encoder_loss: 0.6614392399787903\n",
            "  epoch: 18/20,    batch: 1856/2993    Encoder_loss: 0.6101242899894714\n",
            "  epoch: 18/20,    batch: 1857/2993    Encoder_loss: 0.6371256113052368\n",
            "  epoch: 18/20,    batch: 1858/2993    Encoder_loss: 0.7005760073661804\n",
            "  epoch: 18/20,    batch: 1859/2993    Encoder_loss: 0.6141577363014221\n",
            "  epoch: 18/20,    batch: 1860/2993    Encoder_loss: 0.6564816236495972\n",
            "  epoch: 18/20,    batch: 1861/2993    Encoder_loss: 0.6993223428726196\n",
            "  epoch: 18/20,    batch: 1862/2993    Encoder_loss: 0.6243131756782532\n",
            "  epoch: 18/20,    batch: 1863/2993    Encoder_loss: 0.678030252456665\n",
            "  epoch: 18/20,    batch: 1864/2993    Encoder_loss: 0.6761168837547302\n",
            "  epoch: 18/20,    batch: 1865/2993    Encoder_loss: 0.6161978244781494\n",
            "  epoch: 18/20,    batch: 1866/2993    Encoder_loss: 0.6726524233818054\n",
            "  epoch: 18/20,    batch: 1867/2993    Encoder_loss: 0.6479455828666687\n",
            "  epoch: 18/20,    batch: 1868/2993    Encoder_loss: 0.6090032458305359\n",
            "  epoch: 18/20,    batch: 1869/2993    Encoder_loss: 0.6459599137306213\n",
            "  epoch: 18/20,    batch: 1870/2993    Encoder_loss: 0.5993072390556335\n",
            "  epoch: 18/20,    batch: 1871/2993    Encoder_loss: 0.5778907537460327\n",
            "  epoch: 18/20,    batch: 1872/2993    Encoder_loss: 0.6378742456436157\n",
            "  epoch: 18/20,    batch: 1873/2993    Encoder_loss: 0.6348732113838196\n",
            "  epoch: 18/20,    batch: 1874/2993    Encoder_loss: 0.6175767183303833\n",
            "  epoch: 18/20,    batch: 1875/2993    Encoder_loss: 0.6796867251396179\n",
            "  epoch: 18/20,    batch: 1876/2993    Encoder_loss: 0.6418446898460388\n",
            "  epoch: 18/20,    batch: 1877/2993    Encoder_loss: 0.5740739107131958\n",
            "  epoch: 18/20,    batch: 1878/2993    Encoder_loss: 0.6662871241569519\n",
            "  epoch: 18/20,    batch: 1879/2993    Encoder_loss: 0.6861680150032043\n",
            "  epoch: 18/20,    batch: 1880/2993    Encoder_loss: 0.5940322279930115\n",
            "  epoch: 18/20,    batch: 1881/2993    Encoder_loss: 0.6529194712638855\n",
            "  epoch: 18/20,    batch: 1882/2993    Encoder_loss: 0.6605228781700134\n",
            "  epoch: 18/20,    batch: 1883/2993    Encoder_loss: 0.5854219198226929\n",
            "  epoch: 18/20,    batch: 1884/2993    Encoder_loss: 0.6327781677246094\n",
            "  epoch: 18/20,    batch: 1885/2993    Encoder_loss: 0.6742480397224426\n",
            "  epoch: 18/20,    batch: 1886/2993    Encoder_loss: 0.5974725484848022\n",
            "  epoch: 18/20,    batch: 1887/2993    Encoder_loss: 0.6287938356399536\n",
            "  epoch: 18/20,    batch: 1888/2993    Encoder_loss: 0.7021096348762512\n",
            "  epoch: 18/20,    batch: 1889/2993    Encoder_loss: 0.6301357746124268\n",
            "  epoch: 18/20,    batch: 1890/2993    Encoder_loss: 0.6826838254928589\n",
            "  epoch: 18/20,    batch: 1891/2993    Encoder_loss: 0.7197104096412659\n",
            "  epoch: 18/20,    batch: 1892/2993    Encoder_loss: 0.623855471611023\n",
            "  epoch: 18/20,    batch: 1893/2993    Encoder_loss: 0.6639867424964905\n",
            "  epoch: 18/20,    batch: 1894/2993    Encoder_loss: 0.6528364419937134\n",
            "  epoch: 18/20,    batch: 1895/2993    Encoder_loss: 0.6027230620384216\n",
            "  epoch: 18/20,    batch: 1896/2993    Encoder_loss: 0.6857231259346008\n",
            "  epoch: 18/20,    batch: 1897/2993    Encoder_loss: 0.6391038298606873\n",
            "  epoch: 18/20,    batch: 1898/2993    Encoder_loss: 0.6155977249145508\n",
            "  epoch: 18/20,    batch: 1899/2993    Encoder_loss: 0.717980682849884\n",
            "  epoch: 18/20,    batch: 1900/2993    Encoder_loss: 0.6302961111068726\n",
            "  epoch: 18/20,    batch: 1901/2993    Encoder_loss: 0.6197077631950378\n",
            "  epoch: 18/20,    batch: 1902/2993    Encoder_loss: 0.6914178729057312\n",
            "  epoch: 18/20,    batch: 1903/2993    Encoder_loss: 0.6067681908607483\n",
            "  epoch: 18/20,    batch: 1904/2993    Encoder_loss: 0.5811856985092163\n",
            "  epoch: 18/20,    batch: 1905/2993    Encoder_loss: 0.6546526551246643\n",
            "  epoch: 18/20,    batch: 1906/2993    Encoder_loss: 0.6592470407485962\n",
            "  epoch: 18/20,    batch: 1907/2993    Encoder_loss: 0.6545708775520325\n",
            "  epoch: 18/20,    batch: 1908/2993    Encoder_loss: 0.6763384342193604\n",
            "  epoch: 18/20,    batch: 1909/2993    Encoder_loss: 0.6118563413619995\n",
            "  epoch: 18/20,    batch: 1910/2993    Encoder_loss: 0.5784097909927368\n",
            "  epoch: 18/20,    batch: 1911/2993    Encoder_loss: 0.6582304835319519\n",
            "  epoch: 18/20,    batch: 1912/2993    Encoder_loss: 0.671114981174469\n",
            "  epoch: 18/20,    batch: 1913/2993    Encoder_loss: 0.6258934140205383\n",
            "  epoch: 18/20,    batch: 1914/2993    Encoder_loss: 0.7030428647994995\n",
            "  epoch: 18/20,    batch: 1915/2993    Encoder_loss: 0.6627644300460815\n",
            "  epoch: 18/20,    batch: 1916/2993    Encoder_loss: 0.5670270323753357\n",
            "  epoch: 18/20,    batch: 1917/2993    Encoder_loss: 0.6334657669067383\n",
            "  epoch: 18/20,    batch: 1918/2993    Encoder_loss: 0.7041627168655396\n",
            "  epoch: 18/20,    batch: 1919/2993    Encoder_loss: 0.634531557559967\n",
            "  epoch: 18/20,    batch: 1920/2993    Encoder_loss: 0.6780210137367249\n",
            "  epoch: 18/20,    batch: 1921/2993    Encoder_loss: 0.7183018922805786\n",
            "  epoch: 18/20,    batch: 1922/2993    Encoder_loss: 0.6238747835159302\n",
            "  epoch: 18/20,    batch: 1923/2993    Encoder_loss: 0.6870289444923401\n",
            "  epoch: 18/20,    batch: 1924/2993    Encoder_loss: 0.6637991666793823\n",
            "  epoch: 18/20,    batch: 1925/2993    Encoder_loss: 0.5969938635826111\n",
            "  epoch: 18/20,    batch: 1926/2993    Encoder_loss: 0.6979976892471313\n",
            "  epoch: 18/20,    batch: 1927/2993    Encoder_loss: 0.6551986932754517\n",
            "  epoch: 18/20,    batch: 1928/2993    Encoder_loss: 0.6137263178825378\n",
            "  epoch: 18/20,    batch: 1929/2993    Encoder_loss: 0.7094253301620483\n",
            "  epoch: 18/20,    batch: 1930/2993    Encoder_loss: 0.6403149962425232\n",
            "  epoch: 18/20,    batch: 1931/2993    Encoder_loss: 0.6510862708091736\n",
            "  epoch: 18/20,    batch: 1932/2993    Encoder_loss: 0.7374286651611328\n",
            "  epoch: 18/20,    batch: 1933/2993    Encoder_loss: 0.6280191540718079\n",
            "  epoch: 18/20,    batch: 1934/2993    Encoder_loss: 0.6500483155250549\n",
            "  epoch: 18/20,    batch: 1935/2993    Encoder_loss: 0.6961688995361328\n",
            "  epoch: 18/20,    batch: 1936/2993    Encoder_loss: 0.6047979593276978\n",
            "  epoch: 18/20,    batch: 1937/2993    Encoder_loss: 0.5635271668434143\n",
            "  epoch: 18/20,    batch: 1938/2993    Encoder_loss: 0.6605671048164368\n",
            "  epoch: 18/20,    batch: 1939/2993    Encoder_loss: 0.7141633629798889\n",
            "  epoch: 18/20,    batch: 1940/2993    Encoder_loss: 0.6152027249336243\n",
            "  epoch: 18/20,    batch: 1941/2993    Encoder_loss: 0.6660345792770386\n",
            "  epoch: 18/20,    batch: 1942/2993    Encoder_loss: 0.6912777423858643\n",
            "  epoch: 18/20,    batch: 1943/2993    Encoder_loss: 0.5997413396835327\n",
            "  epoch: 18/20,    batch: 1944/2993    Encoder_loss: 0.6086398959159851\n",
            "  epoch: 18/20,    batch: 1945/2993    Encoder_loss: 0.7064253091812134\n",
            "  epoch: 18/20,    batch: 1946/2993    Encoder_loss: 0.6825670599937439\n",
            "  epoch: 18/20,    batch: 1947/2993    Encoder_loss: 0.585372805595398\n",
            "  epoch: 18/20,    batch: 1948/2993    Encoder_loss: 0.6966093182563782\n",
            "  epoch: 18/20,    batch: 1949/2993    Encoder_loss: 0.6842051148414612\n",
            "  epoch: 18/20,    batch: 1950/2993    Encoder_loss: 0.5640061497688293\n",
            "  epoch: 18/20,    batch: 1951/2993    Encoder_loss: 0.5963422060012817\n",
            "  epoch: 18/20,    batch: 1952/2993    Encoder_loss: 0.6976998448371887\n",
            "  epoch: 18/20,    batch: 1953/2993    Encoder_loss: 0.650547206401825\n",
            "  epoch: 18/20,    batch: 1954/2993    Encoder_loss: 0.5698794722557068\n",
            "  epoch: 18/20,    batch: 1955/2993    Encoder_loss: 0.655188262462616\n",
            "  epoch: 18/20,    batch: 1956/2993    Encoder_loss: 0.6364029049873352\n",
            "  epoch: 18/20,    batch: 1957/2993    Encoder_loss: 0.6044608354568481\n",
            "  epoch: 18/20,    batch: 1958/2993    Encoder_loss: 0.6745418310165405\n",
            "  epoch: 18/20,    batch: 1959/2993    Encoder_loss: 0.6315447688102722\n",
            "  epoch: 18/20,    batch: 1960/2993    Encoder_loss: 0.612079918384552\n",
            "  epoch: 18/20,    batch: 1961/2993    Encoder_loss: 0.6793690919876099\n",
            "  epoch: 18/20,    batch: 1962/2993    Encoder_loss: 0.604593813419342\n",
            "  epoch: 18/20,    batch: 1963/2993    Encoder_loss: 0.6141534447669983\n",
            "  epoch: 18/20,    batch: 1964/2993    Encoder_loss: 0.6882132291793823\n",
            "  epoch: 18/20,    batch: 1965/2993    Encoder_loss: 0.6026737093925476\n",
            "  epoch: 18/20,    batch: 1966/2993    Encoder_loss: 0.6377503275871277\n",
            "  epoch: 18/20,    batch: 1967/2993    Encoder_loss: 0.6837937235832214\n",
            "  epoch: 18/20,    batch: 1968/2993    Encoder_loss: 0.6099470853805542\n",
            "  epoch: 18/20,    batch: 1969/2993    Encoder_loss: 0.6398882269859314\n",
            "  epoch: 18/20,    batch: 1970/2993    Encoder_loss: 0.6356527805328369\n",
            "  epoch: 18/20,    batch: 1971/2993    Encoder_loss: 0.5722386837005615\n",
            "  epoch: 18/20,    batch: 1972/2993    Encoder_loss: 0.6078216433525085\n",
            "  epoch: 18/20,    batch: 1973/2993    Encoder_loss: 0.6763447523117065\n",
            "  epoch: 18/20,    batch: 1974/2993    Encoder_loss: 0.6423035860061646\n",
            "  epoch: 18/20,    batch: 1975/2993    Encoder_loss: 0.6946693658828735\n",
            "  epoch: 18/20,    batch: 1976/2993    Encoder_loss: 0.7010447978973389\n",
            "  epoch: 18/20,    batch: 1977/2993    Encoder_loss: 0.6019795536994934\n",
            "  epoch: 18/20,    batch: 1978/2993    Encoder_loss: 0.6075202226638794\n",
            "  epoch: 18/20,    batch: 1979/2993    Encoder_loss: 0.642708957195282\n",
            "  epoch: 18/20,    batch: 1980/2993    Encoder_loss: 0.6143909096717834\n",
            "  epoch: 18/20,    batch: 1981/2993    Encoder_loss: 0.6320713758468628\n",
            "  epoch: 18/20,    batch: 1982/2993    Encoder_loss: 0.6778255105018616\n",
            "  epoch: 18/20,    batch: 1983/2993    Encoder_loss: 0.6378762722015381\n",
            "  epoch: 18/20,    batch: 1984/2993    Encoder_loss: 0.5972057580947876\n",
            "  epoch: 18/20,    batch: 1985/2993    Encoder_loss: 0.6476406455039978\n",
            "  epoch: 18/20,    batch: 1986/2993    Encoder_loss: 0.6378479599952698\n",
            "  epoch: 18/20,    batch: 1987/2993    Encoder_loss: 0.5988543629646301\n",
            "  epoch: 18/20,    batch: 1988/2993    Encoder_loss: 0.6679009795188904\n",
            "  epoch: 18/20,    batch: 1989/2993    Encoder_loss: 0.6339666843414307\n",
            "  epoch: 18/20,    batch: 1990/2993    Encoder_loss: 0.6014633178710938\n",
            "  epoch: 18/20,    batch: 1991/2993    Encoder_loss: 0.6673778891563416\n",
            "  epoch: 18/20,    batch: 1992/2993    Encoder_loss: 0.5917990803718567\n",
            "  epoch: 18/20,    batch: 1993/2993    Encoder_loss: 0.5996028184890747\n",
            "  epoch: 18/20,    batch: 1994/2993    Encoder_loss: 0.6851567029953003\n",
            "  epoch: 18/20,    batch: 1995/2993    Encoder_loss: 0.5993055701255798\n",
            "  epoch: 18/20,    batch: 1996/2993    Encoder_loss: 0.6596983075141907\n",
            "  epoch: 18/20,    batch: 1997/2993    Encoder_loss: 0.7041329145431519\n",
            "  epoch: 18/20,    batch: 1998/2993    Encoder_loss: 0.5743193030357361\n",
            "  epoch: 18/20,    batch: 1999/2993    Encoder_loss: 0.6418885588645935\n",
            "  epoch: 18/20,    batch: 2000/2993    Encoder_loss: 0.6646371483802795\n",
            "  epoch: 18/20,    batch: 2001/2993    Encoder_loss: 0.6054249405860901\n",
            "  epoch: 18/20,    batch: 2002/2993    Encoder_loss: 0.6832820177078247\n",
            "  epoch: 18/20,    batch: 2003/2993    Encoder_loss: 0.6503101587295532\n",
            "  epoch: 18/20,    batch: 2004/2993    Encoder_loss: 0.5730637311935425\n",
            "  epoch: 18/20,    batch: 2005/2993    Encoder_loss: 0.6169145107269287\n",
            "  epoch: 18/20,    batch: 2006/2993    Encoder_loss: 0.6864855289459229\n",
            "  epoch: 18/20,    batch: 2007/2993    Encoder_loss: 0.6496527194976807\n",
            "  epoch: 18/20,    batch: 2008/2993    Encoder_loss: 0.624195396900177\n",
            "  epoch: 18/20,    batch: 2009/2993    Encoder_loss: 0.6933225989341736\n",
            "  epoch: 18/20,    batch: 2010/2993    Encoder_loss: 0.6643794775009155\n",
            "  epoch: 18/20,    batch: 2011/2993    Encoder_loss: 0.5894705057144165\n",
            "  epoch: 18/20,    batch: 2012/2993    Encoder_loss: 0.6544265747070312\n",
            "  epoch: 18/20,    batch: 2013/2993    Encoder_loss: 0.7195736169815063\n",
            "  epoch: 18/20,    batch: 2014/2993    Encoder_loss: 0.6539602875709534\n",
            "  epoch: 18/20,    batch: 2015/2993    Encoder_loss: 0.6477890610694885\n",
            "  epoch: 18/20,    batch: 2016/2993    Encoder_loss: 0.7223442792892456\n",
            "  epoch: 18/20,    batch: 2017/2993    Encoder_loss: 0.6710087060928345\n",
            "  epoch: 18/20,    batch: 2018/2993    Encoder_loss: 0.5719004273414612\n",
            "  epoch: 18/20,    batch: 2019/2993    Encoder_loss: 0.6477966904640198\n",
            "  epoch: 18/20,    batch: 2020/2993    Encoder_loss: 0.6830793619155884\n",
            "  epoch: 18/20,    batch: 2021/2993    Encoder_loss: 0.592976987361908\n",
            "  epoch: 18/20,    batch: 2022/2993    Encoder_loss: 0.6068866848945618\n",
            "  epoch: 18/20,    batch: 2023/2993    Encoder_loss: 0.6922590136528015\n",
            "  epoch: 18/20,    batch: 2024/2993    Encoder_loss: 0.6192408800125122\n",
            "  epoch: 18/20,    batch: 2025/2993    Encoder_loss: 0.6733987331390381\n",
            "  epoch: 18/20,    batch: 2026/2993    Encoder_loss: 0.7124185562133789\n",
            "  epoch: 18/20,    batch: 2027/2993    Encoder_loss: 0.6223064661026001\n",
            "  epoch: 18/20,    batch: 2028/2993    Encoder_loss: 0.693429172039032\n",
            "  epoch: 18/20,    batch: 2029/2993    Encoder_loss: 0.6947404742240906\n",
            "  epoch: 18/20,    batch: 2030/2993    Encoder_loss: 0.6147981882095337\n",
            "  epoch: 18/20,    batch: 2031/2993    Encoder_loss: 0.6720823645591736\n",
            "  epoch: 18/20,    batch: 2032/2993    Encoder_loss: 0.6609752178192139\n",
            "  epoch: 18/20,    batch: 2033/2993    Encoder_loss: 0.6345881819725037\n",
            "  epoch: 18/20,    batch: 2034/2993    Encoder_loss: 0.7024747133255005\n",
            "  epoch: 18/20,    batch: 2035/2993    Encoder_loss: 0.6595665216445923\n",
            "  epoch: 18/20,    batch: 2036/2993    Encoder_loss: 0.6313913464546204\n",
            "  epoch: 18/20,    batch: 2037/2993    Encoder_loss: 0.6656057834625244\n",
            "  epoch: 18/20,    batch: 2038/2993    Encoder_loss: 0.6198829412460327\n",
            "  epoch: 18/20,    batch: 2039/2993    Encoder_loss: 0.5851832628250122\n",
            "  epoch: 18/20,    batch: 2040/2993    Encoder_loss: 0.6651695966720581\n",
            "  epoch: 18/20,    batch: 2041/2993    Encoder_loss: 0.6740918755531311\n",
            "  epoch: 18/20,    batch: 2042/2993    Encoder_loss: 0.6136294603347778\n",
            "  epoch: 18/20,    batch: 2043/2993    Encoder_loss: 0.6340366005897522\n",
            "  epoch: 18/20,    batch: 2044/2993    Encoder_loss: 0.6852866411209106\n",
            "  epoch: 18/20,    batch: 2045/2993    Encoder_loss: 0.6275680065155029\n",
            "  epoch: 18/20,    batch: 2046/2993    Encoder_loss: 0.6029569506645203\n",
            "  epoch: 18/20,    batch: 2047/2993    Encoder_loss: 0.6876755952835083\n",
            "  epoch: 18/20,    batch: 2048/2993    Encoder_loss: 0.7202354073524475\n",
            "  epoch: 18/20,    batch: 2049/2993    Encoder_loss: 0.635399580001831\n",
            "  epoch: 18/20,    batch: 2050/2993    Encoder_loss: 0.6675037145614624\n",
            "  epoch: 18/20,    batch: 2051/2993    Encoder_loss: 0.7010108828544617\n",
            "  epoch: 18/20,    batch: 2052/2993    Encoder_loss: 0.6225535869598389\n",
            "  epoch: 18/20,    batch: 2053/2993    Encoder_loss: 0.614219069480896\n",
            "  epoch: 18/20,    batch: 2054/2993    Encoder_loss: 0.6962679624557495\n",
            "  epoch: 18/20,    batch: 2055/2993    Encoder_loss: 0.7145357728004456\n",
            "  epoch: 18/20,    batch: 2056/2993    Encoder_loss: 0.6028377413749695\n",
            "  epoch: 18/20,    batch: 2057/2993    Encoder_loss: 0.6734808683395386\n",
            "  epoch: 18/20,    batch: 2058/2993    Encoder_loss: 0.6893361210823059\n",
            "  epoch: 18/20,    batch: 2059/2993    Encoder_loss: 0.6155949234962463\n",
            "  epoch: 18/20,    batch: 2060/2993    Encoder_loss: 0.7126543521881104\n",
            "  epoch: 18/20,    batch: 2061/2993    Encoder_loss: 0.6814775466918945\n",
            "  epoch: 18/20,    batch: 2062/2993    Encoder_loss: 0.639258086681366\n",
            "  epoch: 18/20,    batch: 2063/2993    Encoder_loss: 0.7230261564254761\n",
            "  epoch: 18/20,    batch: 2064/2993    Encoder_loss: 0.6653305888175964\n",
            "  epoch: 18/20,    batch: 2065/2993    Encoder_loss: 0.6466434001922607\n",
            "  epoch: 18/20,    batch: 2066/2993    Encoder_loss: 0.7271393537521362\n",
            "  epoch: 18/20,    batch: 2067/2993    Encoder_loss: 0.6446663737297058\n",
            "  epoch: 18/20,    batch: 2068/2993    Encoder_loss: 0.6662574410438538\n",
            "  epoch: 18/20,    batch: 2069/2993    Encoder_loss: 0.7342219948768616\n",
            "  epoch: 18/20,    batch: 2070/2993    Encoder_loss: 0.6164581775665283\n",
            "  epoch: 18/20,    batch: 2071/2993    Encoder_loss: 0.6929675340652466\n",
            "  epoch: 18/20,    batch: 2072/2993    Encoder_loss: 0.7371427416801453\n",
            "  epoch: 18/20,    batch: 2073/2993    Encoder_loss: 0.6274164319038391\n",
            "  epoch: 18/20,    batch: 2074/2993    Encoder_loss: 0.6124846339225769\n",
            "  epoch: 18/20,    batch: 2075/2993    Encoder_loss: 0.7231350541114807\n",
            "  epoch: 18/20,    batch: 2076/2993    Encoder_loss: 0.7060612440109253\n",
            "  epoch: 18/20,    batch: 2077/2993    Encoder_loss: 0.6381970643997192\n",
            "  epoch: 18/20,    batch: 2078/2993    Encoder_loss: 0.6844856142997742\n",
            "  epoch: 18/20,    batch: 2079/2993    Encoder_loss: 0.6578792333602905\n",
            "  epoch: 18/20,    batch: 2080/2993    Encoder_loss: 0.6255998015403748\n",
            "  epoch: 18/20,    batch: 2081/2993    Encoder_loss: 0.6953843832015991\n",
            "  epoch: 18/20,    batch: 2082/2993    Encoder_loss: 0.7293997406959534\n",
            "  epoch: 18/20,    batch: 2083/2993    Encoder_loss: 0.6796415448188782\n",
            "  epoch: 18/20,    batch: 2084/2993    Encoder_loss: 0.7254732251167297\n",
            "  epoch: 18/20,    batch: 2085/2993    Encoder_loss: 0.7138060331344604\n",
            "  epoch: 18/20,    batch: 2086/2993    Encoder_loss: 0.6223117113113403\n",
            "  epoch: 18/20,    batch: 2087/2993    Encoder_loss: 0.6592836976051331\n",
            "  epoch: 18/20,    batch: 2088/2993    Encoder_loss: 0.7039081454277039\n",
            "  epoch: 18/20,    batch: 2089/2993    Encoder_loss: 0.6447321772575378\n",
            "  epoch: 18/20,    batch: 2090/2993    Encoder_loss: 0.6809999346733093\n",
            "  epoch: 18/20,    batch: 2091/2993    Encoder_loss: 0.7274253964424133\n",
            "  epoch: 18/20,    batch: 2092/2993    Encoder_loss: 0.613789439201355\n",
            "  epoch: 18/20,    batch: 2093/2993    Encoder_loss: 0.7099837064743042\n",
            "  epoch: 18/20,    batch: 2094/2993    Encoder_loss: 0.7227665185928345\n",
            "  epoch: 18/20,    batch: 2095/2993    Encoder_loss: 0.6285660266876221\n",
            "  epoch: 18/20,    batch: 2096/2993    Encoder_loss: 0.7113578915596008\n",
            "  epoch: 18/20,    batch: 2097/2993    Encoder_loss: 0.6879605650901794\n",
            "  epoch: 18/20,    batch: 2098/2993    Encoder_loss: 0.6484944224357605\n",
            "  epoch: 18/20,    batch: 2099/2993    Encoder_loss: 0.7409954071044922\n",
            "  epoch: 18/20,    batch: 2100/2993    Encoder_loss: 0.6616759896278381\n",
            "  epoch: 18/20,    batch: 2101/2993    Encoder_loss: 0.6465187072753906\n",
            "  epoch: 18/20,    batch: 2102/2993    Encoder_loss: 0.7328068017959595\n",
            "  epoch: 18/20,    batch: 2103/2993    Encoder_loss: 0.6446463465690613\n",
            "  epoch: 18/20,    batch: 2104/2993    Encoder_loss: 0.6595756411552429\n",
            "  epoch: 18/20,    batch: 2105/2993    Encoder_loss: 0.7534587383270264\n",
            "  epoch: 18/20,    batch: 2106/2993    Encoder_loss: 0.6337665915489197\n",
            "  epoch: 18/20,    batch: 2107/2993    Encoder_loss: 0.5683313012123108\n",
            "  epoch: 18/20,    batch: 2108/2993    Encoder_loss: 0.6872747540473938\n",
            "  epoch: 18/20,    batch: 2109/2993    Encoder_loss: 0.7040204405784607\n",
            "  epoch: 18/20,    batch: 2110/2993    Encoder_loss: 0.5684750080108643\n",
            "  epoch: 18/20,    batch: 2111/2993    Encoder_loss: 0.6410966515541077\n",
            "  epoch: 18/20,    batch: 2112/2993    Encoder_loss: 0.7482806444168091\n",
            "  epoch: 18/20,    batch: 2113/2993    Encoder_loss: 0.7052723169326782\n",
            "  epoch: 18/20,    batch: 2114/2993    Encoder_loss: 0.7296637892723083\n",
            "  epoch: 18/20,    batch: 2115/2993    Encoder_loss: 0.7769908905029297\n",
            "  epoch: 18/20,    batch: 2116/2993    Encoder_loss: 0.7519720196723938\n",
            "  epoch: 18/20,    batch: 2117/2993    Encoder_loss: 0.6670255661010742\n",
            "  epoch: 18/20,    batch: 2118/2993    Encoder_loss: 0.6988147497177124\n",
            "  epoch: 18/20,    batch: 2119/2993    Encoder_loss: 0.686825692653656\n",
            "  epoch: 18/20,    batch: 2120/2993    Encoder_loss: 0.5933175683021545\n",
            "  epoch: 18/20,    batch: 2121/2993    Encoder_loss: 0.6081807613372803\n",
            "  epoch: 18/20,    batch: 2122/2993    Encoder_loss: 0.6906920671463013\n",
            "  epoch: 18/20,    batch: 2123/2993    Encoder_loss: 0.6705895066261292\n",
            "  epoch: 18/20,    batch: 2124/2993    Encoder_loss: 0.6003879308700562\n",
            "  epoch: 18/20,    batch: 2125/2993    Encoder_loss: 0.7023833990097046\n",
            "  epoch: 18/20,    batch: 2126/2993    Encoder_loss: 0.6805112361907959\n",
            "  epoch: 18/20,    batch: 2127/2993    Encoder_loss: 0.5988949537277222\n",
            "  epoch: 18/20,    batch: 2128/2993    Encoder_loss: 0.7037237286567688\n",
            "  epoch: 18/20,    batch: 2129/2993    Encoder_loss: 0.6608864068984985\n",
            "  epoch: 18/20,    batch: 2130/2993    Encoder_loss: 0.5976172089576721\n",
            "  epoch: 18/20,    batch: 2131/2993    Encoder_loss: 0.6895490288734436\n",
            "  epoch: 18/20,    batch: 2132/2993    Encoder_loss: 0.608055830001831\n",
            "  epoch: 18/20,    batch: 2133/2993    Encoder_loss: 0.6049460768699646\n",
            "  epoch: 18/20,    batch: 2134/2993    Encoder_loss: 0.6998241543769836\n",
            "  epoch: 18/20,    batch: 2135/2993    Encoder_loss: 0.582990825176239\n",
            "  epoch: 18/20,    batch: 2136/2993    Encoder_loss: 0.6562992334365845\n",
            "  epoch: 18/20,    batch: 2137/2993    Encoder_loss: 0.7205694317817688\n",
            "  epoch: 18/20,    batch: 2138/2993    Encoder_loss: 0.5838172435760498\n",
            "  epoch: 18/20,    batch: 2139/2993    Encoder_loss: 0.6656002402305603\n",
            "  epoch: 18/20,    batch: 2140/2993    Encoder_loss: 0.6861460208892822\n",
            "  epoch: 18/20,    batch: 2141/2993    Encoder_loss: 0.6019283533096313\n",
            "  epoch: 18/20,    batch: 2142/2993    Encoder_loss: 0.6487753987312317\n",
            "  epoch: 18/20,    batch: 2143/2993    Encoder_loss: 0.7247535586357117\n",
            "  epoch: 18/20,    batch: 2144/2993    Encoder_loss: 0.6479149460792542\n",
            "  epoch: 18/20,    batch: 2145/2993    Encoder_loss: 0.6457881927490234\n",
            "  epoch: 18/20,    batch: 2146/2993    Encoder_loss: 0.6846644282341003\n",
            "  epoch: 18/20,    batch: 2147/2993    Encoder_loss: 0.635620653629303\n",
            "  epoch: 18/20,    batch: 2148/2993    Encoder_loss: 0.6495168209075928\n",
            "  epoch: 18/20,    batch: 2149/2993    Encoder_loss: 0.7031210660934448\n",
            "  epoch: 18/20,    batch: 2150/2993    Encoder_loss: 0.6538097262382507\n",
            "  epoch: 18/20,    batch: 2151/2993    Encoder_loss: 0.6448237895965576\n",
            "  epoch: 18/20,    batch: 2152/2993    Encoder_loss: 0.7152526378631592\n",
            "  epoch: 18/20,    batch: 2153/2993    Encoder_loss: 0.6491392850875854\n",
            "  epoch: 18/20,    batch: 2154/2993    Encoder_loss: 0.619260847568512\n",
            "  epoch: 18/20,    batch: 2155/2993    Encoder_loss: 0.7062893509864807\n",
            "  epoch: 18/20,    batch: 2156/2993    Encoder_loss: 0.6808388829231262\n",
            "  epoch: 18/20,    batch: 2157/2993    Encoder_loss: 0.6078203320503235\n",
            "  epoch: 18/20,    batch: 2158/2993    Encoder_loss: 0.7008180022239685\n",
            "  epoch: 18/20,    batch: 2159/2993    Encoder_loss: 0.6514589786529541\n",
            "  epoch: 18/20,    batch: 2160/2993    Encoder_loss: 0.6095578670501709\n",
            "  epoch: 18/20,    batch: 2161/2993    Encoder_loss: 0.6937002539634705\n",
            "  epoch: 18/20,    batch: 2162/2993    Encoder_loss: 0.6212080717086792\n",
            "  epoch: 18/20,    batch: 2163/2993    Encoder_loss: 0.6148473024368286\n",
            "  epoch: 18/20,    batch: 2164/2993    Encoder_loss: 0.7012029886245728\n",
            "  epoch: 18/20,    batch: 2165/2993    Encoder_loss: 0.5952127575874329\n",
            "  epoch: 18/20,    batch: 2166/2993    Encoder_loss: 0.6489962935447693\n",
            "  epoch: 18/20,    batch: 2167/2993    Encoder_loss: 0.7017341256141663\n",
            "  epoch: 18/20,    batch: 2168/2993    Encoder_loss: 0.5837776064872742\n",
            "  epoch: 18/20,    batch: 2169/2993    Encoder_loss: 0.6656641364097595\n",
            "  epoch: 18/20,    batch: 2170/2993    Encoder_loss: 0.6817832589149475\n",
            "  epoch: 18/20,    batch: 2171/2993    Encoder_loss: 0.6042159199714661\n",
            "  epoch: 18/20,    batch: 2172/2993    Encoder_loss: 0.6920021176338196\n",
            "  epoch: 18/20,    batch: 2173/2993    Encoder_loss: 0.6769392490386963\n",
            "  epoch: 18/20,    batch: 2174/2993    Encoder_loss: 0.5996490716934204\n",
            "  epoch: 18/20,    batch: 2175/2993    Encoder_loss: 0.6856104731559753\n",
            "  epoch: 18/20,    batch: 2176/2993    Encoder_loss: 0.7541943192481995\n",
            "  epoch: 18/20,    batch: 2177/2993    Encoder_loss: 0.6586118340492249\n",
            "  epoch: 18/20,    batch: 2178/2993    Encoder_loss: 0.6829870343208313\n",
            "  epoch: 18/20,    batch: 2179/2993    Encoder_loss: 0.6956619024276733\n",
            "  epoch: 18/20,    batch: 2180/2993    Encoder_loss: 0.6524847149848938\n",
            "  epoch: 18/20,    batch: 2181/2993    Encoder_loss: 0.694348931312561\n",
            "  epoch: 18/20,    batch: 2182/2993    Encoder_loss: 0.730936586856842\n",
            "  epoch: 18/20,    batch: 2183/2993    Encoder_loss: 0.669241726398468\n",
            "  epoch: 18/20,    batch: 2184/2993    Encoder_loss: 0.6851269602775574\n",
            "  epoch: 18/20,    batch: 2185/2993    Encoder_loss: 0.7276248931884766\n",
            "  epoch: 18/20,    batch: 2186/2993    Encoder_loss: 0.6578224301338196\n",
            "  epoch: 18/20,    batch: 2187/2993    Encoder_loss: 0.6727867126464844\n",
            "  epoch: 18/20,    batch: 2188/2993    Encoder_loss: 0.7446323037147522\n",
            "  epoch: 18/20,    batch: 2189/2993    Encoder_loss: 0.6772873997688293\n",
            "  epoch: 18/20,    batch: 2190/2993    Encoder_loss: 0.6556092500686646\n",
            "  epoch: 18/20,    batch: 2191/2993    Encoder_loss: 0.7433883547782898\n",
            "  epoch: 18/20,    batch: 2192/2993    Encoder_loss: 0.695426344871521\n",
            "  epoch: 18/20,    batch: 2193/2993    Encoder_loss: 0.6848914623260498\n",
            "  epoch: 18/20,    batch: 2194/2993    Encoder_loss: 0.7318392992019653\n",
            "  epoch: 18/20,    batch: 2195/2993    Encoder_loss: 0.6334513425827026\n",
            "  epoch: 18/20,    batch: 2196/2993    Encoder_loss: 0.6647807359695435\n",
            "  epoch: 18/20,    batch: 2197/2993    Encoder_loss: 0.7281542420387268\n",
            "  epoch: 18/20,    batch: 2198/2993    Encoder_loss: 0.6302238702774048\n",
            "  epoch: 18/20,    batch: 2199/2993    Encoder_loss: 0.6817194819450378\n",
            "  epoch: 18/20,    batch: 2200/2993    Encoder_loss: 0.6985153555870056\n",
            "  epoch: 18/20,    batch: 2201/2993    Encoder_loss: 0.623454749584198\n",
            "  epoch: 18/20,    batch: 2202/2993    Encoder_loss: 0.7197329998016357\n",
            "  epoch: 18/20,    batch: 2203/2993    Encoder_loss: 0.7052958011627197\n",
            "  epoch: 18/20,    batch: 2204/2993    Encoder_loss: 0.6610779166221619\n",
            "  epoch: 18/20,    batch: 2205/2993    Encoder_loss: 0.7336318492889404\n",
            "  epoch: 18/20,    batch: 2206/2993    Encoder_loss: 0.6786168217658997\n",
            "  epoch: 18/20,    batch: 2207/2993    Encoder_loss: 0.5897393822669983\n",
            "  epoch: 18/20,    batch: 2208/2993    Encoder_loss: 0.6690078973770142\n",
            "  epoch: 18/20,    batch: 2209/2993    Encoder_loss: 0.7394647002220154\n",
            "  epoch: 18/20,    batch: 2210/2993    Encoder_loss: 0.6531944274902344\n",
            "  epoch: 18/20,    batch: 2211/2993    Encoder_loss: 0.6488008499145508\n",
            "  epoch: 18/20,    batch: 2212/2993    Encoder_loss: 0.7177945971488953\n",
            "  epoch: 18/20,    batch: 2213/2993    Encoder_loss: 0.6461511254310608\n",
            "  epoch: 18/20,    batch: 2214/2993    Encoder_loss: 0.6301763653755188\n",
            "  epoch: 18/20,    batch: 2215/2993    Encoder_loss: 0.7327825427055359\n",
            "  epoch: 18/20,    batch: 2216/2993    Encoder_loss: 0.7281296253204346\n",
            "  epoch: 18/20,    batch: 2217/2993    Encoder_loss: 0.6549039483070374\n",
            "  epoch: 18/20,    batch: 2218/2993    Encoder_loss: 0.7202423214912415\n",
            "  epoch: 18/20,    batch: 2219/2993    Encoder_loss: 0.686644971370697\n",
            "  epoch: 18/20,    batch: 2220/2993    Encoder_loss: 0.5964520573616028\n",
            "  epoch: 18/20,    batch: 2221/2993    Encoder_loss: 0.6459100246429443\n",
            "  epoch: 18/20,    batch: 2222/2993    Encoder_loss: 0.7233026027679443\n",
            "  epoch: 18/20,    batch: 2223/2993    Encoder_loss: 0.7021952271461487\n",
            "  epoch: 18/20,    batch: 2224/2993    Encoder_loss: 0.6978472471237183\n",
            "  epoch: 18/20,    batch: 2225/2993    Encoder_loss: 0.7370293736457825\n",
            "  epoch: 18/20,    batch: 2226/2993    Encoder_loss: 0.644165575504303\n",
            "  epoch: 18/20,    batch: 2227/2993    Encoder_loss: 0.6640711426734924\n",
            "  epoch: 18/20,    batch: 2228/2993    Encoder_loss: 0.7221102118492126\n",
            "  epoch: 18/20,    batch: 2229/2993    Encoder_loss: 0.6463379263877869\n",
            "  epoch: 18/20,    batch: 2230/2993    Encoder_loss: 0.6975509524345398\n",
            "  epoch: 18/20,    batch: 2231/2993    Encoder_loss: 0.7302114963531494\n",
            "  epoch: 18/20,    batch: 2232/2993    Encoder_loss: 0.6633347868919373\n",
            "  epoch: 18/20,    batch: 2233/2993    Encoder_loss: 0.7048834562301636\n",
            "  epoch: 18/20,    batch: 2234/2993    Encoder_loss: 0.7040407657623291\n",
            "  epoch: 18/20,    batch: 2235/2993    Encoder_loss: 0.6041109561920166\n",
            "  epoch: 18/20,    batch: 2236/2993    Encoder_loss: 0.5765825510025024\n",
            "  epoch: 18/20,    batch: 2237/2993    Encoder_loss: 0.5709218978881836\n",
            "  epoch: 18/20,    batch: 2238/2993    Encoder_loss: 0.58083176612854\n",
            "  epoch: 18/20,    batch: 2239/2993    Encoder_loss: 0.5846961140632629\n",
            "  epoch: 18/20,    batch: 2240/2993    Encoder_loss: 0.5794587731361389\n",
            "  epoch: 18/20,    batch: 2241/2993    Encoder_loss: 0.5797055959701538\n",
            "  epoch: 18/20,    batch: 2242/2993    Encoder_loss: 0.5761889219284058\n",
            "  epoch: 18/20,    batch: 2243/2993    Encoder_loss: 0.5698597431182861\n",
            "  epoch: 18/20,    batch: 2244/2993    Encoder_loss: 0.5795609354972839\n",
            "  epoch: 18/20,    batch: 2245/2993    Encoder_loss: 0.583260715007782\n",
            "  epoch: 18/20,    batch: 2246/2993    Encoder_loss: 0.5770503282546997\n",
            "  epoch: 18/20,    batch: 2247/2993    Encoder_loss: 0.5703442692756653\n",
            "  epoch: 18/20,    batch: 2248/2993    Encoder_loss: 0.5753398537635803\n",
            "  epoch: 18/20,    batch: 2249/2993    Encoder_loss: 0.5754559636116028\n",
            "  epoch: 18/20,    batch: 2250/2993    Encoder_loss: 0.5770168900489807\n",
            "  epoch: 18/20,    batch: 2251/2993    Encoder_loss: 0.637812077999115\n",
            "  epoch: 18/20,    batch: 2252/2993    Encoder_loss: 0.7221157550811768\n",
            "  epoch: 18/20,    batch: 2253/2993    Encoder_loss: 0.7001632452011108\n",
            "  epoch: 18/20,    batch: 2254/2993    Encoder_loss: 0.6425897479057312\n",
            "  epoch: 18/20,    batch: 2255/2993    Encoder_loss: 0.6294986009597778\n",
            "  epoch: 18/20,    batch: 2256/2993    Encoder_loss: 0.6888301968574524\n",
            "  epoch: 18/20,    batch: 2257/2993    Encoder_loss: 0.6907833814620972\n",
            "  epoch: 18/20,    batch: 2258/2993    Encoder_loss: 0.6544461846351624\n",
            "  epoch: 18/20,    batch: 2259/2993    Encoder_loss: 0.6904388666152954\n",
            "  epoch: 18/20,    batch: 2260/2993    Encoder_loss: 0.6848975419998169\n",
            "  epoch: 18/20,    batch: 2261/2993    Encoder_loss: 0.6036627888679504\n",
            "  epoch: 18/20,    batch: 2262/2993    Encoder_loss: 0.6048615574836731\n",
            "  epoch: 18/20,    batch: 2263/2993    Encoder_loss: 0.7013834714889526\n",
            "  epoch: 18/20,    batch: 2264/2993    Encoder_loss: 0.6606423854827881\n",
            "  epoch: 18/20,    batch: 2265/2993    Encoder_loss: 0.6004297137260437\n",
            "  epoch: 18/20,    batch: 2266/2993    Encoder_loss: 0.6853377223014832\n",
            "  epoch: 18/20,    batch: 2267/2993    Encoder_loss: 0.6697800755500793\n",
            "  epoch: 18/20,    batch: 2268/2993    Encoder_loss: 0.5744674205780029\n",
            "  epoch: 18/20,    batch: 2269/2993    Encoder_loss: 0.6337169408798218\n",
            "  epoch: 18/20,    batch: 2270/2993    Encoder_loss: 0.7108393907546997\n",
            "  epoch: 18/20,    batch: 2271/2993    Encoder_loss: 0.6404789090156555\n",
            "  epoch: 18/20,    batch: 2272/2993    Encoder_loss: 0.6076624989509583\n",
            "  epoch: 18/20,    batch: 2273/2993    Encoder_loss: 0.6729839444160461\n",
            "  epoch: 18/20,    batch: 2274/2993    Encoder_loss: 0.6425544023513794\n",
            "  epoch: 18/20,    batch: 2275/2993    Encoder_loss: 0.632673442363739\n",
            "  epoch: 18/20,    batch: 2276/2993    Encoder_loss: 0.6875576376914978\n",
            "  epoch: 18/20,    batch: 2277/2993    Encoder_loss: 0.5956393480300903\n",
            "  epoch: 18/20,    batch: 2278/2993    Encoder_loss: 0.6131620407104492\n",
            "  epoch: 18/20,    batch: 2279/2993    Encoder_loss: 0.6810749769210815\n",
            "  epoch: 18/20,    batch: 2280/2993    Encoder_loss: 0.6063874363899231\n",
            "  epoch: 18/20,    batch: 2281/2993    Encoder_loss: 0.6378323435783386\n",
            "  epoch: 18/20,    batch: 2282/2993    Encoder_loss: 0.6829144358634949\n",
            "  epoch: 18/20,    batch: 2283/2993    Encoder_loss: 0.6210486888885498\n",
            "  epoch: 18/20,    batch: 2284/2993    Encoder_loss: 0.6552109122276306\n",
            "  epoch: 18/20,    batch: 2285/2993    Encoder_loss: 0.6614822149276733\n",
            "  epoch: 18/20,    batch: 2286/2993    Encoder_loss: 0.6365101337432861\n",
            "  epoch: 18/20,    batch: 2287/2993    Encoder_loss: 0.6759558320045471\n",
            "  epoch: 18/20,    batch: 2288/2993    Encoder_loss: 0.6473715305328369\n",
            "  epoch: 18/20,    batch: 2289/2993    Encoder_loss: 0.5791972279548645\n",
            "  epoch: 18/20,    batch: 2290/2993    Encoder_loss: 0.6369036436080933\n",
            "  epoch: 18/20,    batch: 2291/2993    Encoder_loss: 0.6642589569091797\n",
            "  epoch: 18/20,    batch: 2292/2993    Encoder_loss: 0.6092901229858398\n",
            "  epoch: 18/20,    batch: 2293/2993    Encoder_loss: 0.6177581548690796\n",
            "  epoch: 18/20,    batch: 2294/2993    Encoder_loss: 0.7122157216072083\n",
            "  epoch: 18/20,    batch: 2295/2993    Encoder_loss: 0.6563632488250732\n",
            "  epoch: 18/20,    batch: 2296/2993    Encoder_loss: 0.5725871920585632\n",
            "  epoch: 18/20,    batch: 2297/2993    Encoder_loss: 0.6487420797348022\n",
            "  epoch: 18/20,    batch: 2298/2993    Encoder_loss: 0.6935136914253235\n",
            "  epoch: 18/20,    batch: 2299/2993    Encoder_loss: 0.6260583400726318\n",
            "  epoch: 18/20,    batch: 2300/2993    Encoder_loss: 0.6247880458831787\n",
            "  epoch: 18/20,    batch: 2301/2993    Encoder_loss: 0.6983180642127991\n",
            "  epoch: 18/20,    batch: 2302/2993    Encoder_loss: 0.6415600180625916\n",
            "  epoch: 18/20,    batch: 2303/2993    Encoder_loss: 0.5585329532623291\n",
            "  epoch: 18/20,    batch: 2304/2993    Encoder_loss: 0.6545140743255615\n",
            "  epoch: 18/20,    batch: 2305/2993    Encoder_loss: 0.7147258520126343\n",
            "  epoch: 18/20,    batch: 2306/2993    Encoder_loss: 0.6030513644218445\n",
            "  epoch: 18/20,    batch: 2307/2993    Encoder_loss: 0.6302205324172974\n",
            "  epoch: 18/20,    batch: 2308/2993    Encoder_loss: 0.7274993062019348\n",
            "  epoch: 18/20,    batch: 2309/2993    Encoder_loss: 0.624671995639801\n",
            "  epoch: 18/20,    batch: 2310/2993    Encoder_loss: 0.6763113737106323\n",
            "  epoch: 18/20,    batch: 2311/2993    Encoder_loss: 0.7151159644126892\n",
            "  epoch: 18/20,    batch: 2312/2993    Encoder_loss: 0.5781742930412292\n",
            "  epoch: 18/20,    batch: 2313/2993    Encoder_loss: 0.6434521079063416\n",
            "  epoch: 18/20,    batch: 2314/2993    Encoder_loss: 0.7179855704307556\n",
            "  epoch: 18/20,    batch: 2315/2993    Encoder_loss: 0.5987106561660767\n",
            "  epoch: 18/20,    batch: 2316/2993    Encoder_loss: 0.6750475764274597\n",
            "  epoch: 18/20,    batch: 2317/2993    Encoder_loss: 0.7258539199829102\n",
            "  epoch: 18/20,    batch: 2318/2993    Encoder_loss: 0.6276692748069763\n",
            "  epoch: 18/20,    batch: 2319/2993    Encoder_loss: 0.7096105217933655\n",
            "  epoch: 18/20,    batch: 2320/2993    Encoder_loss: 0.6772660613059998\n",
            "  epoch: 18/20,    batch: 2321/2993    Encoder_loss: 0.6050707101821899\n",
            "  epoch: 18/20,    batch: 2322/2993    Encoder_loss: 0.7179543972015381\n",
            "  epoch: 18/20,    batch: 2323/2993    Encoder_loss: 0.6956994533538818\n",
            "  epoch: 18/20,    batch: 2324/2993    Encoder_loss: 0.5847751498222351\n",
            "  epoch: 18/20,    batch: 2325/2993    Encoder_loss: 0.664904773235321\n",
            "  epoch: 18/20,    batch: 2326/2993    Encoder_loss: 0.7565816044807434\n",
            "  epoch: 18/20,    batch: 2327/2993    Encoder_loss: 0.6755720376968384\n",
            "  epoch: 18/20,    batch: 2328/2993    Encoder_loss: 0.6448385715484619\n",
            "  epoch: 18/20,    batch: 2329/2993    Encoder_loss: 0.7148223519325256\n",
            "  epoch: 18/20,    batch: 2330/2993    Encoder_loss: 0.6793674826622009\n",
            "  epoch: 18/20,    batch: 2331/2993    Encoder_loss: 0.6080052852630615\n",
            "  epoch: 18/20,    batch: 2332/2993    Encoder_loss: 0.684855580329895\n",
            "  epoch: 18/20,    batch: 2333/2993    Encoder_loss: 0.7293544411659241\n",
            "  epoch: 18/20,    batch: 2334/2993    Encoder_loss: 0.6751866936683655\n",
            "  epoch: 18/20,    batch: 2335/2993    Encoder_loss: 0.6570819616317749\n",
            "  epoch: 18/20,    batch: 2336/2993    Encoder_loss: 0.7110070586204529\n",
            "  epoch: 18/20,    batch: 2337/2993    Encoder_loss: 0.6688404083251953\n",
            "  epoch: 18/20,    batch: 2338/2993    Encoder_loss: 0.5945339202880859\n",
            "  epoch: 18/20,    batch: 2339/2993    Encoder_loss: 0.6713799834251404\n",
            "  epoch: 18/20,    batch: 2340/2993    Encoder_loss: 0.7102628946304321\n",
            "  epoch: 18/20,    batch: 2341/2993    Encoder_loss: 0.6580601930618286\n",
            "  epoch: 18/20,    batch: 2342/2993    Encoder_loss: 0.6702936887741089\n",
            "  epoch: 18/20,    batch: 2343/2993    Encoder_loss: 0.729773759841919\n",
            "  epoch: 18/20,    batch: 2344/2993    Encoder_loss: 0.6028140187263489\n",
            "  epoch: 18/20,    batch: 2345/2993    Encoder_loss: 0.6436445116996765\n",
            "  epoch: 18/20,    batch: 2346/2993    Encoder_loss: 0.7100988030433655\n",
            "  epoch: 18/20,    batch: 2347/2993    Encoder_loss: 0.6141133904457092\n",
            "  epoch: 18/20,    batch: 2348/2993    Encoder_loss: 0.6951276063919067\n",
            "  epoch: 18/20,    batch: 2349/2993    Encoder_loss: 0.7007004022598267\n",
            "  epoch: 18/20,    batch: 2350/2993    Encoder_loss: 0.5995896458625793\n",
            "  epoch: 18/20,    batch: 2351/2993    Encoder_loss: 0.6960743069648743\n",
            "  epoch: 18/20,    batch: 2352/2993    Encoder_loss: 0.6653310060501099\n",
            "  epoch: 18/20,    batch: 2353/2993    Encoder_loss: 0.6283337473869324\n",
            "  epoch: 18/20,    batch: 2354/2993    Encoder_loss: 0.7274588942527771\n",
            "  epoch: 18/20,    batch: 2355/2993    Encoder_loss: 0.633614718914032\n",
            "  epoch: 18/20,    batch: 2356/2993    Encoder_loss: 0.6114670634269714\n",
            "  epoch: 18/20,    batch: 2357/2993    Encoder_loss: 0.7153422832489014\n",
            "  epoch: 18/20,    batch: 2358/2993    Encoder_loss: 0.6348362565040588\n",
            "  epoch: 18/20,    batch: 2359/2993    Encoder_loss: 0.5733116269111633\n",
            "  epoch: 18/20,    batch: 2360/2993    Encoder_loss: 0.6691290736198425\n",
            "  epoch: 18/20,    batch: 2361/2993    Encoder_loss: 0.7058257460594177\n",
            "  epoch: 18/20,    batch: 2362/2993    Encoder_loss: 0.6062607169151306\n",
            "  epoch: 18/20,    batch: 2363/2993    Encoder_loss: 0.6466582417488098\n",
            "  epoch: 18/20,    batch: 2364/2993    Encoder_loss: 0.7201604247093201\n",
            "  epoch: 18/20,    batch: 2365/2993    Encoder_loss: 0.6190956234931946\n",
            "  epoch: 18/20,    batch: 2366/2993    Encoder_loss: 0.5835586190223694\n",
            "  epoch: 18/20,    batch: 2367/2993    Encoder_loss: 0.7000291347503662\n",
            "  epoch: 18/20,    batch: 2368/2993    Encoder_loss: 0.7082495093345642\n",
            "  epoch: 18/20,    batch: 2369/2993    Encoder_loss: 0.5630935430526733\n",
            "  epoch: 18/20,    batch: 2370/2993    Encoder_loss: 0.6355525851249695\n",
            "  epoch: 18/20,    batch: 2371/2993    Encoder_loss: 0.7038523554801941\n",
            "  epoch: 18/20,    batch: 2372/2993    Encoder_loss: 0.5991750359535217\n",
            "  epoch: 18/20,    batch: 2373/2993    Encoder_loss: 0.5981866121292114\n",
            "  epoch: 18/20,    batch: 2374/2993    Encoder_loss: 0.6920211315155029\n",
            "  epoch: 18/20,    batch: 2375/2993    Encoder_loss: 0.6726610660552979\n",
            "  epoch: 18/20,    batch: 2376/2993    Encoder_loss: 0.5655423402786255\n",
            "  epoch: 18/20,    batch: 2377/2993    Encoder_loss: 0.6438345313072205\n",
            "  epoch: 18/20,    batch: 2378/2993    Encoder_loss: 0.6623378396034241\n",
            "  epoch: 18/20,    batch: 2379/2993    Encoder_loss: 0.5808089971542358\n",
            "  epoch: 18/20,    batch: 2380/2993    Encoder_loss: 0.6575509309768677\n",
            "  epoch: 18/20,    batch: 2381/2993    Encoder_loss: 0.6527784466743469\n",
            "  epoch: 18/20,    batch: 2382/2993    Encoder_loss: 0.6032665371894836\n",
            "  epoch: 18/20,    batch: 2383/2993    Encoder_loss: 0.6697317957878113\n",
            "  epoch: 18/20,    batch: 2384/2993    Encoder_loss: 0.6300084590911865\n",
            "  epoch: 18/20,    batch: 2385/2993    Encoder_loss: 0.6060588955879211\n",
            "  epoch: 18/20,    batch: 2386/2993    Encoder_loss: 0.69208824634552\n",
            "  epoch: 18/20,    batch: 2387/2993    Encoder_loss: 0.641190767288208\n",
            "  epoch: 18/20,    batch: 2388/2993    Encoder_loss: 0.6331943273544312\n",
            "  epoch: 18/20,    batch: 2389/2993    Encoder_loss: 0.7095499634742737\n",
            "  epoch: 18/20,    batch: 2390/2993    Encoder_loss: 0.6236699223518372\n",
            "  epoch: 18/20,    batch: 2391/2993    Encoder_loss: 0.6474214792251587\n",
            "  epoch: 18/20,    batch: 2392/2993    Encoder_loss: 0.6627032160758972\n",
            "  epoch: 18/20,    batch: 2393/2993    Encoder_loss: 0.5682573914527893\n",
            "  epoch: 18/20,    batch: 2394/2993    Encoder_loss: 0.5851516127586365\n",
            "  epoch: 18/20,    batch: 2395/2993    Encoder_loss: 0.6633975505828857\n",
            "  epoch: 18/20,    batch: 2396/2993    Encoder_loss: 0.6457908153533936\n",
            "  epoch: 18/20,    batch: 2397/2993    Encoder_loss: 0.6142275333404541\n",
            "  epoch: 18/20,    batch: 2398/2993    Encoder_loss: 0.6846628189086914\n",
            "  epoch: 18/20,    batch: 2399/2993    Encoder_loss: 0.6594417691230774\n",
            "  epoch: 18/20,    batch: 2400/2993    Encoder_loss: 0.5943499207496643\n",
            "  epoch: 18/20,    batch: 2401/2993    Encoder_loss: 0.6767562031745911\n",
            "  epoch: 18/20,    batch: 2402/2993    Encoder_loss: 0.6936098337173462\n",
            "  epoch: 18/20,    batch: 2403/2993    Encoder_loss: 0.6120663285255432\n",
            "  epoch: 18/20,    batch: 2404/2993    Encoder_loss: 0.6598395109176636\n",
            "  epoch: 18/20,    batch: 2405/2993    Encoder_loss: 0.6547116637229919\n",
            "  epoch: 18/20,    batch: 2406/2993    Encoder_loss: 0.5808793306350708\n",
            "  epoch: 18/20,    batch: 2407/2993    Encoder_loss: 0.6294251680374146\n",
            "  epoch: 18/20,    batch: 2408/2993    Encoder_loss: 0.7024151086807251\n",
            "  epoch: 18/20,    batch: 2409/2993    Encoder_loss: 0.6536259055137634\n",
            "  epoch: 18/20,    batch: 2410/2993    Encoder_loss: 0.6791478395462036\n",
            "  epoch: 18/20,    batch: 2411/2993    Encoder_loss: 0.739145815372467\n",
            "  epoch: 18/20,    batch: 2412/2993    Encoder_loss: 0.6488592028617859\n",
            "  epoch: 18/20,    batch: 2413/2993    Encoder_loss: 0.7079651951789856\n",
            "  epoch: 18/20,    batch: 2414/2993    Encoder_loss: 0.7350627779960632\n",
            "  epoch: 18/20,    batch: 2415/2993    Encoder_loss: 0.6522780656814575\n",
            "  epoch: 18/20,    batch: 2416/2993    Encoder_loss: 0.715568482875824\n",
            "  epoch: 18/20,    batch: 2417/2993    Encoder_loss: 0.7102396488189697\n",
            "  epoch: 18/20,    batch: 2418/2993    Encoder_loss: 0.642257034778595\n",
            "  epoch: 18/20,    batch: 2419/2993    Encoder_loss: 0.7204342484474182\n",
            "  epoch: 18/20,    batch: 2420/2993    Encoder_loss: 0.6953507661819458\n",
            "  epoch: 18/20,    batch: 2421/2993    Encoder_loss: 0.6722003221511841\n",
            "  epoch: 18/20,    batch: 2422/2993    Encoder_loss: 0.7424032688140869\n",
            "  epoch: 18/20,    batch: 2423/2993    Encoder_loss: 0.6753700375556946\n",
            "  epoch: 18/20,    batch: 2424/2993    Encoder_loss: 0.6741989254951477\n",
            "  epoch: 18/20,    batch: 2425/2993    Encoder_loss: 0.7424755096435547\n",
            "  epoch: 18/20,    batch: 2426/2993    Encoder_loss: 0.6673673987388611\n",
            "  epoch: 18/20,    batch: 2427/2993    Encoder_loss: 0.6158227324485779\n",
            "  epoch: 18/20,    batch: 2428/2993    Encoder_loss: 0.7060819864273071\n",
            "  epoch: 18/20,    batch: 2429/2993    Encoder_loss: 0.7365379333496094\n",
            "  epoch: 18/20,    batch: 2430/2993    Encoder_loss: 0.6203230619430542\n",
            "  epoch: 18/20,    batch: 2431/2993    Encoder_loss: 0.6736942529678345\n",
            "  epoch: 18/20,    batch: 2432/2993    Encoder_loss: 0.745012104511261\n",
            "  epoch: 18/20,    batch: 2433/2993    Encoder_loss: 0.6456918716430664\n",
            "  epoch: 18/20,    batch: 2434/2993    Encoder_loss: 0.5928971767425537\n",
            "  epoch: 18/20,    batch: 2435/2993    Encoder_loss: 0.6934489011764526\n",
            "  epoch: 18/20,    batch: 2436/2993    Encoder_loss: 0.717353880405426\n",
            "  epoch: 18/20,    batch: 2437/2993    Encoder_loss: 0.598889946937561\n",
            "  epoch: 18/20,    batch: 2438/2993    Encoder_loss: 0.6850692629814148\n",
            "  epoch: 18/20,    batch: 2439/2993    Encoder_loss: 0.744338870048523\n",
            "  epoch: 18/20,    batch: 2440/2993    Encoder_loss: 0.6196023225784302\n",
            "  epoch: 18/20,    batch: 2441/2993    Encoder_loss: 0.6046717166900635\n",
            "  epoch: 18/20,    batch: 2442/2993    Encoder_loss: 0.6998847723007202\n",
            "  epoch: 18/20,    batch: 2443/2993    Encoder_loss: 0.6901942491531372\n",
            "  epoch: 18/20,    batch: 2444/2993    Encoder_loss: 0.6169540286064148\n",
            "  epoch: 18/20,    batch: 2445/2993    Encoder_loss: 0.7178710699081421\n",
            "  epoch: 18/20,    batch: 2446/2993    Encoder_loss: 0.7084949612617493\n",
            "  epoch: 18/20,    batch: 2447/2993    Encoder_loss: 0.6440305709838867\n",
            "  epoch: 18/20,    batch: 2448/2993    Encoder_loss: 0.7195303440093994\n",
            "  epoch: 18/20,    batch: 2449/2993    Encoder_loss: 0.6642188429832458\n",
            "  epoch: 18/20,    batch: 2450/2993    Encoder_loss: 0.6528106927871704\n",
            "  epoch: 18/20,    batch: 2451/2993    Encoder_loss: 0.7295857667922974\n",
            "  epoch: 18/20,    batch: 2452/2993    Encoder_loss: 0.6505113244056702\n",
            "  epoch: 18/20,    batch: 2453/2993    Encoder_loss: 0.6704245209693909\n",
            "  epoch: 18/20,    batch: 2454/2993    Encoder_loss: 0.7585144639015198\n",
            "  epoch: 18/20,    batch: 2455/2993    Encoder_loss: 0.6347568035125732\n",
            "  epoch: 18/20,    batch: 2456/2993    Encoder_loss: 0.6729046106338501\n",
            "  epoch: 18/20,    batch: 2457/2993    Encoder_loss: 0.7355780005455017\n",
            "  epoch: 18/20,    batch: 2458/2993    Encoder_loss: 0.6503519415855408\n",
            "  epoch: 18/20,    batch: 2459/2993    Encoder_loss: 0.7172272801399231\n",
            "  epoch: 18/20,    batch: 2460/2993    Encoder_loss: 0.7060322165489197\n",
            "  epoch: 18/20,    batch: 2461/2993    Encoder_loss: 0.6357506513595581\n",
            "  epoch: 18/20,    batch: 2462/2993    Encoder_loss: 0.6908463835716248\n",
            "  epoch: 18/20,    batch: 2463/2993    Encoder_loss: 0.7331469058990479\n",
            "  epoch: 18/20,    batch: 2464/2993    Encoder_loss: 0.6443597078323364\n",
            "  epoch: 18/20,    batch: 2465/2993    Encoder_loss: 0.6741138696670532\n",
            "  epoch: 18/20,    batch: 2466/2993    Encoder_loss: 0.7444683909416199\n",
            "  epoch: 18/20,    batch: 2467/2993    Encoder_loss: 0.6471657156944275\n",
            "  epoch: 18/20,    batch: 2468/2993    Encoder_loss: 0.6373679041862488\n",
            "  epoch: 18/20,    batch: 2469/2993    Encoder_loss: 0.749127209186554\n",
            "  epoch: 18/20,    batch: 2470/2993    Encoder_loss: 0.7071949243545532\n",
            "  epoch: 18/20,    batch: 2471/2993    Encoder_loss: 0.6732962727546692\n",
            "  epoch: 18/20,    batch: 2472/2993    Encoder_loss: 0.7160148620605469\n",
            "  epoch: 18/20,    batch: 2473/2993    Encoder_loss: 0.6725022196769714\n",
            "  epoch: 18/20,    batch: 2474/2993    Encoder_loss: 0.6300714015960693\n",
            "  epoch: 18/20,    batch: 2475/2993    Encoder_loss: 0.6998409032821655\n",
            "  epoch: 18/20,    batch: 2476/2993    Encoder_loss: 0.7348376512527466\n",
            "  epoch: 18/20,    batch: 2477/2993    Encoder_loss: 0.6493539214134216\n",
            "  epoch: 18/20,    batch: 2478/2993    Encoder_loss: 0.7066458463668823\n",
            "  epoch: 18/20,    batch: 2479/2993    Encoder_loss: 0.7230256795883179\n",
            "  epoch: 18/20,    batch: 2480/2993    Encoder_loss: 0.6522497534751892\n",
            "  epoch: 18/20,    batch: 2481/2993    Encoder_loss: 0.7403566241264343\n",
            "  epoch: 18/20,    batch: 2482/2993    Encoder_loss: 0.7248379588127136\n",
            "  epoch: 18/20,    batch: 2483/2993    Encoder_loss: 0.6817081570625305\n",
            "  epoch: 18/20,    batch: 2484/2993    Encoder_loss: 0.7445312142372131\n",
            "  epoch: 18/20,    batch: 2485/2993    Encoder_loss: 0.7121971249580383\n",
            "  epoch: 18/20,    batch: 2486/2993    Encoder_loss: 0.7179564833641052\n",
            "  epoch: 18/20,    batch: 2487/2993    Encoder_loss: 0.78288733959198\n",
            "  epoch: 18/20,    batch: 2488/2993    Encoder_loss: 0.6951563358306885\n",
            "  epoch: 18/20,    batch: 2489/2993    Encoder_loss: 0.7003442049026489\n",
            "  epoch: 18/20,    batch: 2490/2993    Encoder_loss: 0.7710869312286377\n",
            "  epoch: 18/20,    batch: 2491/2993    Encoder_loss: 0.6736719012260437\n",
            "  epoch: 18/20,    batch: 2492/2993    Encoder_loss: 0.723728597164154\n",
            "  epoch: 18/20,    batch: 2493/2993    Encoder_loss: 0.7602883577346802\n",
            "  epoch: 18/20,    batch: 2494/2993    Encoder_loss: 0.6662935614585876\n",
            "  epoch: 18/20,    batch: 2495/2993    Encoder_loss: 0.6871920824050903\n",
            "  epoch: 18/20,    batch: 2496/2993    Encoder_loss: 0.7832701206207275\n",
            "  epoch: 18/20,    batch: 2497/2993    Encoder_loss: 0.7037794589996338\n",
            "  epoch: 18/20,    batch: 2498/2993    Encoder_loss: 0.6799315214157104\n",
            "  epoch: 18/20,    batch: 2499/2993    Encoder_loss: 0.7574998736381531\n",
            "  epoch: 18/20,    batch: 2500/2993    Encoder_loss: 0.6973403692245483\n",
            "  epoch: 18/20,    batch: 2501/2993    Encoder_loss: 0.6890904903411865\n",
            "  epoch: 18/20,    batch: 2502/2993    Encoder_loss: 0.7522312998771667\n",
            "  epoch: 18/20,    batch: 2503/2993    Encoder_loss: 0.7266729474067688\n",
            "  epoch: 18/20,    batch: 2504/2993    Encoder_loss: 0.7091004848480225\n",
            "  epoch: 18/20,    batch: 2505/2993    Encoder_loss: 0.7502638101577759\n",
            "  epoch: 18/20,    batch: 2506/2993    Encoder_loss: 0.6976510286331177\n",
            "  epoch: 18/20,    batch: 2507/2993    Encoder_loss: 0.6428057551383972\n",
            "  epoch: 18/20,    batch: 2508/2993    Encoder_loss: 0.7315022349357605\n",
            "  epoch: 18/20,    batch: 2509/2993    Encoder_loss: 0.7294394373893738\n",
            "  epoch: 18/20,    batch: 2510/2993    Encoder_loss: 0.6693066358566284\n",
            "  epoch: 18/20,    batch: 2511/2993    Encoder_loss: 0.7728342413902283\n",
            "  epoch: 18/20,    batch: 2512/2993    Encoder_loss: 0.7575056552886963\n",
            "  epoch: 18/20,    batch: 2513/2993    Encoder_loss: 0.6908520460128784\n",
            "  epoch: 18/20,    batch: 2514/2993    Encoder_loss: 0.7848883271217346\n",
            "  epoch: 18/20,    batch: 2515/2993    Encoder_loss: 0.7381401658058167\n",
            "  epoch: 18/20,    batch: 2516/2993    Encoder_loss: 0.7008530497550964\n",
            "  epoch: 18/20,    batch: 2517/2993    Encoder_loss: 0.7874709367752075\n",
            "  epoch: 18/20,    batch: 2518/2993    Encoder_loss: 0.6870654821395874\n",
            "  epoch: 18/20,    batch: 2519/2993    Encoder_loss: 0.694683313369751\n",
            "  epoch: 18/20,    batch: 2520/2993    Encoder_loss: 0.8059813380241394\n",
            "  epoch: 18/20,    batch: 2521/2993    Encoder_loss: 0.6877465844154358\n",
            "  epoch: 18/20,    batch: 2522/2993    Encoder_loss: 0.7135066986083984\n",
            "  epoch: 18/20,    batch: 2523/2993    Encoder_loss: 0.7534477710723877\n",
            "  epoch: 18/20,    batch: 2524/2993    Encoder_loss: 0.691574215888977\n",
            "  epoch: 18/20,    batch: 2525/2993    Encoder_loss: 0.7890387177467346\n",
            "  epoch: 18/20,    batch: 2526/2993    Encoder_loss: 0.7437531352043152\n",
            "  epoch: 18/20,    batch: 2527/2993    Encoder_loss: 0.6401564478874207\n",
            "  epoch: 18/20,    batch: 2528/2993    Encoder_loss: 0.6943369507789612\n",
            "  epoch: 18/20,    batch: 2529/2993    Encoder_loss: 0.768380343914032\n",
            "  epoch: 18/20,    batch: 2530/2993    Encoder_loss: 0.6835657954216003\n",
            "  epoch: 18/20,    batch: 2531/2993    Encoder_loss: 0.7141197323799133\n",
            "  epoch: 18/20,    batch: 2532/2993    Encoder_loss: 0.7585888504981995\n",
            "  epoch: 18/20,    batch: 2533/2993    Encoder_loss: 0.660770833492279\n",
            "  epoch: 18/20,    batch: 2534/2993    Encoder_loss: 0.6353844404220581\n",
            "  epoch: 18/20,    batch: 2535/2993    Encoder_loss: 0.7387720942497253\n",
            "  epoch: 18/20,    batch: 2536/2993    Encoder_loss: 0.6974745988845825\n",
            "  epoch: 18/20,    batch: 2537/2993    Encoder_loss: 0.6662060618400574\n",
            "  epoch: 18/20,    batch: 2538/2993    Encoder_loss: 0.7301114797592163\n",
            "  epoch: 18/20,    batch: 2539/2993    Encoder_loss: 0.6731714010238647\n",
            "  epoch: 18/20,    batch: 2540/2993    Encoder_loss: 0.6667521595954895\n",
            "  epoch: 18/20,    batch: 2541/2993    Encoder_loss: 0.7415866255760193\n",
            "  epoch: 18/20,    batch: 2542/2993    Encoder_loss: 0.69648677110672\n",
            "  epoch: 18/20,    batch: 2543/2993    Encoder_loss: 0.6617088317871094\n",
            "  epoch: 18/20,    batch: 2544/2993    Encoder_loss: 0.7585307359695435\n",
            "  epoch: 18/20,    batch: 2545/2993    Encoder_loss: 0.6999428272247314\n",
            "  epoch: 18/20,    batch: 2546/2993    Encoder_loss: 0.6646347045898438\n",
            "  epoch: 18/20,    batch: 2547/2993    Encoder_loss: 0.7637796998023987\n",
            "  epoch: 18/20,    batch: 2548/2993    Encoder_loss: 0.6736873984336853\n",
            "  epoch: 18/20,    batch: 2549/2993    Encoder_loss: 0.6802366375923157\n",
            "  epoch: 18/20,    batch: 2550/2993    Encoder_loss: 0.7646712064743042\n",
            "  epoch: 18/20,    batch: 2551/2993    Encoder_loss: 0.6454930901527405\n",
            "  epoch: 18/20,    batch: 2552/2993    Encoder_loss: 0.6834014654159546\n",
            "  epoch: 18/20,    batch: 2553/2993    Encoder_loss: 0.7264679670333862\n",
            "  epoch: 18/20,    batch: 2554/2993    Encoder_loss: 0.6407862901687622\n",
            "  epoch: 18/20,    batch: 2555/2993    Encoder_loss: 0.7322905659675598\n",
            "  epoch: 18/20,    batch: 2556/2993    Encoder_loss: 0.7164891958236694\n",
            "  epoch: 18/20,    batch: 2557/2993    Encoder_loss: 0.629361093044281\n",
            "  epoch: 18/20,    batch: 2558/2993    Encoder_loss: 0.6877392530441284\n",
            "  epoch: 18/20,    batch: 2559/2993    Encoder_loss: 0.6518622636795044\n",
            "  epoch: 18/20,    batch: 2560/2993    Encoder_loss: 0.5648130774497986\n",
            "  epoch: 18/20,    batch: 2561/2993    Encoder_loss: 0.6577237248420715\n",
            "  epoch: 18/20,    batch: 2562/2993    Encoder_loss: 0.7116730213165283\n",
            "  epoch: 18/20,    batch: 2563/2993    Encoder_loss: 0.6118126511573792\n",
            "  epoch: 18/20,    batch: 2564/2993    Encoder_loss: 0.6491618752479553\n",
            "  epoch: 18/20,    batch: 2565/2993    Encoder_loss: 0.6649771332740784\n",
            "  epoch: 18/20,    batch: 2566/2993    Encoder_loss: 0.5861896872520447\n",
            "  epoch: 18/20,    batch: 2567/2993    Encoder_loss: 0.6169812679290771\n",
            "  epoch: 18/20,    batch: 2568/2993    Encoder_loss: 0.6661271452903748\n",
            "  epoch: 18/20,    batch: 2569/2993    Encoder_loss: 0.6063814163208008\n",
            "  epoch: 18/20,    batch: 2570/2993    Encoder_loss: 0.6297337412834167\n",
            "  epoch: 18/20,    batch: 2571/2993    Encoder_loss: 0.6618391871452332\n",
            "  epoch: 18/20,    batch: 2572/2993    Encoder_loss: 0.5830493569374084\n",
            "  epoch: 18/20,    batch: 2573/2993    Encoder_loss: 0.6222029328346252\n",
            "  epoch: 18/20,    batch: 2574/2993    Encoder_loss: 0.7112267017364502\n",
            "  epoch: 18/20,    batch: 2575/2993    Encoder_loss: 0.6386388540267944\n",
            "  epoch: 18/20,    batch: 2576/2993    Encoder_loss: 0.6202372312545776\n",
            "  epoch: 18/20,    batch: 2577/2993    Encoder_loss: 0.7012887597084045\n",
            "  epoch: 18/20,    batch: 2578/2993    Encoder_loss: 0.6124551892280579\n",
            "  epoch: 18/20,    batch: 2579/2993    Encoder_loss: 0.6210713982582092\n",
            "  epoch: 18/20,    batch: 2580/2993    Encoder_loss: 0.7031124234199524\n",
            "  epoch: 18/20,    batch: 2581/2993    Encoder_loss: 0.6060423254966736\n",
            "  epoch: 18/20,    batch: 2582/2993    Encoder_loss: 0.6718246340751648\n",
            "  epoch: 18/20,    batch: 2583/2993    Encoder_loss: 0.6992073059082031\n",
            "  epoch: 18/20,    batch: 2584/2993    Encoder_loss: 0.5849955081939697\n",
            "  epoch: 18/20,    batch: 2585/2993    Encoder_loss: 0.6717531681060791\n",
            "  epoch: 18/20,    batch: 2586/2993    Encoder_loss: 0.6708531975746155\n",
            "  epoch: 18/20,    batch: 2587/2993    Encoder_loss: 0.6115882992744446\n",
            "  epoch: 18/20,    batch: 2588/2993    Encoder_loss: 0.6997309327125549\n",
            "  epoch: 18/20,    batch: 2589/2993    Encoder_loss: 0.6526930928230286\n",
            "  epoch: 18/20,    batch: 2590/2993    Encoder_loss: 0.6282187104225159\n",
            "  epoch: 18/20,    batch: 2591/2993    Encoder_loss: 0.6885741949081421\n",
            "  epoch: 18/20,    batch: 2592/2993    Encoder_loss: 0.6172075867652893\n",
            "  epoch: 18/20,    batch: 2593/2993    Encoder_loss: 0.580531895160675\n",
            "  epoch: 18/20,    batch: 2594/2993    Encoder_loss: 0.6638997197151184\n",
            "  epoch: 18/20,    batch: 2595/2993    Encoder_loss: 0.6656858921051025\n",
            "  epoch: 18/20,    batch: 2596/2993    Encoder_loss: 0.5962265133857727\n",
            "  epoch: 18/20,    batch: 2597/2993    Encoder_loss: 0.6477325558662415\n",
            "  epoch: 18/20,    batch: 2598/2993    Encoder_loss: 0.6423937678337097\n",
            "  epoch: 18/20,    batch: 2599/2993    Encoder_loss: 0.5749086141586304\n",
            "  epoch: 18/20,    batch: 2600/2993    Encoder_loss: 0.6286430358886719\n",
            "  epoch: 18/20,    batch: 2601/2993    Encoder_loss: 0.6671281456947327\n",
            "  epoch: 18/20,    batch: 2602/2993    Encoder_loss: 0.6081403493881226\n",
            "  epoch: 18/20,    batch: 2603/2993    Encoder_loss: 0.6575172543525696\n",
            "  epoch: 18/20,    batch: 2604/2993    Encoder_loss: 0.6461650133132935\n",
            "  epoch: 18/20,    batch: 2605/2993    Encoder_loss: 0.5656574368476868\n",
            "  epoch: 18/20,    batch: 2606/2993    Encoder_loss: 0.6158527731895447\n",
            "  epoch: 18/20,    batch: 2607/2993    Encoder_loss: 0.6633349061012268\n",
            "  epoch: 18/20,    batch: 2608/2993    Encoder_loss: 0.5934045314788818\n",
            "  epoch: 18/20,    batch: 2609/2993    Encoder_loss: 0.6316196918487549\n",
            "  epoch: 18/20,    batch: 2610/2993    Encoder_loss: 0.7224910855293274\n",
            "  epoch: 18/20,    batch: 2611/2993    Encoder_loss: 0.6252103447914124\n",
            "  epoch: 18/20,    batch: 2612/2993    Encoder_loss: 0.6727129220962524\n",
            "  epoch: 18/20,    batch: 2613/2993    Encoder_loss: 0.7088165879249573\n",
            "  epoch: 18/20,    batch: 2614/2993    Encoder_loss: 0.5959880948066711\n",
            "  epoch: 18/20,    batch: 2615/2993    Encoder_loss: 0.6913851499557495\n",
            "  epoch: 18/20,    batch: 2616/2993    Encoder_loss: 0.6921389102935791\n",
            "  epoch: 18/20,    batch: 2617/2993    Encoder_loss: 0.627552330493927\n",
            "  epoch: 18/20,    batch: 2618/2993    Encoder_loss: 0.7097278237342834\n",
            "  epoch: 18/20,    batch: 2619/2993    Encoder_loss: 0.6681236624717712\n",
            "  epoch: 18/20,    batch: 2620/2993    Encoder_loss: 0.6422091126441956\n",
            "  epoch: 18/20,    batch: 2621/2993    Encoder_loss: 0.7218275666236877\n",
            "  epoch: 18/20,    batch: 2622/2993    Encoder_loss: 0.6612340211868286\n",
            "  epoch: 18/20,    batch: 2623/2993    Encoder_loss: 0.6544302701950073\n",
            "  epoch: 18/20,    batch: 2624/2993    Encoder_loss: 0.6922293901443481\n",
            "  epoch: 18/20,    batch: 2625/2993    Encoder_loss: 0.5954385995864868\n",
            "  epoch: 18/20,    batch: 2626/2993    Encoder_loss: 0.5860454440116882\n",
            "  epoch: 18/20,    batch: 2627/2993    Encoder_loss: 0.6920322775840759\n",
            "  epoch: 18/20,    batch: 2628/2993    Encoder_loss: 0.6587726473808289\n",
            "  epoch: 18/20,    batch: 2629/2993    Encoder_loss: 0.608324408531189\n",
            "  epoch: 18/20,    batch: 2630/2993    Encoder_loss: 0.6911504864692688\n",
            "  epoch: 18/20,    batch: 2631/2993    Encoder_loss: 0.653961718082428\n",
            "  epoch: 18/20,    batch: 2632/2993    Encoder_loss: 0.5698133111000061\n",
            "  epoch: 18/20,    batch: 2633/2993    Encoder_loss: 0.6587940454483032\n",
            "  epoch: 18/20,    batch: 2634/2993    Encoder_loss: 0.7078198194503784\n",
            "  epoch: 18/20,    batch: 2635/2993    Encoder_loss: 0.643294095993042\n",
            "  epoch: 18/20,    batch: 2636/2993    Encoder_loss: 0.6888484954833984\n",
            "  epoch: 18/20,    batch: 2637/2993    Encoder_loss: 0.6648578643798828\n",
            "  epoch: 18/20,    batch: 2638/2993    Encoder_loss: 0.5865230560302734\n",
            "  epoch: 18/20,    batch: 2639/2993    Encoder_loss: 0.649372935295105\n",
            "  epoch: 18/20,    batch: 2640/2993    Encoder_loss: 0.7061498165130615\n",
            "  epoch: 18/20,    batch: 2641/2993    Encoder_loss: 0.6374561786651611\n",
            "  epoch: 18/20,    batch: 2642/2993    Encoder_loss: 0.6978093385696411\n",
            "  epoch: 18/20,    batch: 2643/2993    Encoder_loss: 0.7307554483413696\n",
            "  epoch: 18/20,    batch: 2644/2993    Encoder_loss: 0.6312704086303711\n",
            "  epoch: 18/20,    batch: 2645/2993    Encoder_loss: 0.7338769435882568\n",
            "  epoch: 18/20,    batch: 2646/2993    Encoder_loss: 0.7167142629623413\n",
            "  epoch: 18/20,    batch: 2647/2993    Encoder_loss: 0.648375928401947\n",
            "  epoch: 18/20,    batch: 2648/2993    Encoder_loss: 0.7309341430664062\n",
            "  epoch: 18/20,    batch: 2649/2993    Encoder_loss: 0.6683643460273743\n",
            "  epoch: 18/20,    batch: 2650/2993    Encoder_loss: 0.6348736882209778\n",
            "  epoch: 18/20,    batch: 2651/2993    Encoder_loss: 0.7228811383247375\n",
            "  epoch: 18/20,    batch: 2652/2993    Encoder_loss: 0.6567481160163879\n",
            "  epoch: 18/20,    batch: 2653/2993    Encoder_loss: 0.6616376042366028\n",
            "  epoch: 18/20,    batch: 2654/2993    Encoder_loss: 0.7444450259208679\n",
            "  epoch: 18/20,    batch: 2655/2993    Encoder_loss: 0.638641357421875\n",
            "  epoch: 18/20,    batch: 2656/2993    Encoder_loss: 0.6621982455253601\n",
            "  epoch: 18/20,    batch: 2657/2993    Encoder_loss: 0.694277822971344\n",
            "  epoch: 18/20,    batch: 2658/2993    Encoder_loss: 0.623568594455719\n",
            "  epoch: 18/20,    batch: 2659/2993    Encoder_loss: 0.6300873160362244\n",
            "  epoch: 18/20,    batch: 2660/2993    Encoder_loss: 0.6998401880264282\n",
            "  epoch: 18/20,    batch: 2661/2993    Encoder_loss: 0.6885906457901001\n",
            "  epoch: 18/20,    batch: 2662/2993    Encoder_loss: 0.6208217144012451\n",
            "  epoch: 18/20,    batch: 2663/2993    Encoder_loss: 0.6885690093040466\n",
            "  epoch: 18/20,    batch: 2664/2993    Encoder_loss: 0.6964133381843567\n",
            "  epoch: 18/20,    batch: 2665/2993    Encoder_loss: 0.6411848664283752\n",
            "  epoch: 18/20,    batch: 2666/2993    Encoder_loss: 0.6801522970199585\n",
            "  epoch: 18/20,    batch: 2667/2993    Encoder_loss: 0.7368861436843872\n",
            "  epoch: 18/20,    batch: 2668/2993    Encoder_loss: 0.6367114186286926\n",
            "  epoch: 18/20,    batch: 2669/2993    Encoder_loss: 0.644721269607544\n",
            "  epoch: 18/20,    batch: 2670/2993    Encoder_loss: 0.7167778015136719\n",
            "  epoch: 18/20,    batch: 2671/2993    Encoder_loss: 0.6427258253097534\n",
            "  epoch: 18/20,    batch: 2672/2993    Encoder_loss: 0.6260024905204773\n",
            "  epoch: 18/20,    batch: 2673/2993    Encoder_loss: 0.6957003474235535\n",
            "  epoch: 18/20,    batch: 2674/2993    Encoder_loss: 0.6778526902198792\n",
            "  epoch: 18/20,    batch: 2675/2993    Encoder_loss: 0.5847691893577576\n",
            "  epoch: 18/20,    batch: 2676/2993    Encoder_loss: 0.6608596444129944\n",
            "  epoch: 18/20,    batch: 2677/2993    Encoder_loss: 0.6837155818939209\n",
            "  epoch: 18/20,    batch: 2678/2993    Encoder_loss: 0.6213828921318054\n",
            "  epoch: 18/20,    batch: 2679/2993    Encoder_loss: 0.6870572566986084\n",
            "  epoch: 18/20,    batch: 2680/2993    Encoder_loss: 0.667963445186615\n",
            "  epoch: 18/20,    batch: 2681/2993    Encoder_loss: 0.6218463182449341\n",
            "  epoch: 18/20,    batch: 2682/2993    Encoder_loss: 0.7023394703865051\n",
            "  epoch: 18/20,    batch: 2683/2993    Encoder_loss: 0.6378716230392456\n",
            "  epoch: 18/20,    batch: 2684/2993    Encoder_loss: 0.6300333142280579\n",
            "  epoch: 18/20,    batch: 2685/2993    Encoder_loss: 0.7246444821357727\n",
            "  epoch: 18/20,    batch: 2686/2993    Encoder_loss: 0.6126077175140381\n",
            "  epoch: 18/20,    batch: 2687/2993    Encoder_loss: 0.6433859467506409\n",
            "  epoch: 18/20,    batch: 2688/2993    Encoder_loss: 0.7210903167724609\n",
            "  epoch: 18/20,    batch: 2689/2993    Encoder_loss: 0.6052414178848267\n",
            "  epoch: 18/20,    batch: 2690/2993    Encoder_loss: 0.6600267291069031\n",
            "  epoch: 18/20,    batch: 2691/2993    Encoder_loss: 0.6982051134109497\n",
            "  epoch: 18/20,    batch: 2692/2993    Encoder_loss: 0.6386010646820068\n",
            "  epoch: 18/20,    batch: 2693/2993    Encoder_loss: 0.6714122295379639\n",
            "  epoch: 18/20,    batch: 2694/2993    Encoder_loss: 0.7324175238609314\n",
            "  epoch: 18/20,    batch: 2695/2993    Encoder_loss: 0.6193417906761169\n",
            "  epoch: 18/20,    batch: 2696/2993    Encoder_loss: 0.5939408540725708\n",
            "  epoch: 18/20,    batch: 2697/2993    Encoder_loss: 0.714331328868866\n",
            "  epoch: 18/20,    batch: 2698/2993    Encoder_loss: 0.6787465810775757\n",
            "  epoch: 18/20,    batch: 2699/2993    Encoder_loss: 0.5675224661827087\n",
            "  epoch: 18/20,    batch: 2700/2993    Encoder_loss: 0.6570642590522766\n",
            "  epoch: 18/20,    batch: 2701/2993    Encoder_loss: 0.715118408203125\n",
            "  epoch: 18/20,    batch: 2702/2993    Encoder_loss: 0.6013266444206238\n",
            "  epoch: 18/20,    batch: 2703/2993    Encoder_loss: 0.6093531847000122\n",
            "  epoch: 18/20,    batch: 2704/2993    Encoder_loss: 0.6974074244499207\n",
            "  epoch: 18/20,    batch: 2705/2993    Encoder_loss: 0.6366803050041199\n",
            "  epoch: 18/20,    batch: 2706/2993    Encoder_loss: 0.5796412825584412\n",
            "  epoch: 18/20,    batch: 2707/2993    Encoder_loss: 0.6692807674407959\n",
            "  epoch: 18/20,    batch: 2708/2993    Encoder_loss: 0.6860604882240295\n",
            "  epoch: 18/20,    batch: 2709/2993    Encoder_loss: 0.5902444124221802\n",
            "  epoch: 18/20,    batch: 2710/2993    Encoder_loss: 0.6616572141647339\n",
            "  epoch: 18/20,    batch: 2711/2993    Encoder_loss: 0.7486061453819275\n",
            "  epoch: 18/20,    batch: 2712/2993    Encoder_loss: 0.6323192119598389\n",
            "  epoch: 18/20,    batch: 2713/2993    Encoder_loss: 0.6648485660552979\n",
            "  epoch: 18/20,    batch: 2714/2993    Encoder_loss: 0.6848371624946594\n",
            "  epoch: 18/20,    batch: 2715/2993    Encoder_loss: 0.570097804069519\n",
            "  epoch: 18/20,    batch: 2716/2993    Encoder_loss: 0.6534585356712341\n",
            "  epoch: 18/20,    batch: 2717/2993    Encoder_loss: 0.6778488755226135\n",
            "  epoch: 18/20,    batch: 2718/2993    Encoder_loss: 0.6286787390708923\n",
            "  epoch: 18/20,    batch: 2719/2993    Encoder_loss: 0.711022675037384\n",
            "  epoch: 18/20,    batch: 2720/2993    Encoder_loss: 0.6609634757041931\n",
            "  epoch: 18/20,    batch: 2721/2993    Encoder_loss: 0.6142287850379944\n",
            "  epoch: 18/20,    batch: 2722/2993    Encoder_loss: 0.6989173889160156\n",
            "  epoch: 18/20,    batch: 2723/2993    Encoder_loss: 0.6274985074996948\n",
            "  epoch: 18/20,    batch: 2724/2993    Encoder_loss: 0.6340968012809753\n",
            "  epoch: 18/20,    batch: 2725/2993    Encoder_loss: 0.7345271706581116\n",
            "  epoch: 18/20,    batch: 2726/2993    Encoder_loss: 0.6723419427871704\n",
            "  epoch: 18/20,    batch: 2727/2993    Encoder_loss: 0.5896984338760376\n",
            "  epoch: 18/20,    batch: 2728/2993    Encoder_loss: 0.6585144400596619\n",
            "  epoch: 18/20,    batch: 2729/2993    Encoder_loss: 0.708196759223938\n",
            "  epoch: 18/20,    batch: 2730/2993    Encoder_loss: 0.6276504397392273\n",
            "  epoch: 18/20,    batch: 2731/2993    Encoder_loss: 0.6838483214378357\n",
            "  epoch: 18/20,    batch: 2732/2993    Encoder_loss: 0.758522093296051\n",
            "  epoch: 18/20,    batch: 2733/2993    Encoder_loss: 0.6560527682304382\n",
            "  epoch: 18/20,    batch: 2734/2993    Encoder_loss: 0.6086624264717102\n",
            "  epoch: 18/20,    batch: 2735/2993    Encoder_loss: 0.70576012134552\n",
            "  epoch: 18/20,    batch: 2736/2993    Encoder_loss: 0.7226884961128235\n",
            "  epoch: 18/20,    batch: 2737/2993    Encoder_loss: 0.6044245958328247\n",
            "  epoch: 18/20,    batch: 2738/2993    Encoder_loss: 0.6717766523361206\n",
            "  epoch: 18/20,    batch: 2739/2993    Encoder_loss: 0.7232391834259033\n",
            "  epoch: 18/20,    batch: 2740/2993    Encoder_loss: 0.6352934241294861\n",
            "  epoch: 18/20,    batch: 2741/2993    Encoder_loss: 0.6222572326660156\n",
            "  epoch: 18/20,    batch: 2742/2993    Encoder_loss: 0.7149283289909363\n",
            "  epoch: 18/20,    batch: 2743/2993    Encoder_loss: 0.7095765471458435\n",
            "  epoch: 18/20,    batch: 2744/2993    Encoder_loss: 0.6035218834877014\n",
            "  epoch: 18/20,    batch: 2745/2993    Encoder_loss: 0.6712496280670166\n",
            "  epoch: 18/20,    batch: 2746/2993    Encoder_loss: 0.7019522190093994\n",
            "  epoch: 18/20,    batch: 2747/2993    Encoder_loss: 0.6343923211097717\n",
            "  epoch: 18/20,    batch: 2748/2993    Encoder_loss: 0.6787424683570862\n",
            "  epoch: 18/20,    batch: 2749/2993    Encoder_loss: 0.6737619042396545\n",
            "  epoch: 18/20,    batch: 2750/2993    Encoder_loss: 0.643929123878479\n",
            "  epoch: 18/20,    batch: 2751/2993    Encoder_loss: 0.6922593712806702\n",
            "  epoch: 18/20,    batch: 2752/2993    Encoder_loss: 0.6431704759597778\n",
            "  epoch: 18/20,    batch: 2753/2993    Encoder_loss: 0.6161300539970398\n",
            "  epoch: 18/20,    batch: 2754/2993    Encoder_loss: 0.6961233615875244\n",
            "  epoch: 18/20,    batch: 2755/2993    Encoder_loss: 0.6595060229301453\n",
            "  epoch: 18/20,    batch: 2756/2993    Encoder_loss: 0.6609634160995483\n",
            "  epoch: 18/20,    batch: 2757/2993    Encoder_loss: 0.7056143283843994\n",
            "  epoch: 18/20,    batch: 2758/2993    Encoder_loss: 0.6130019426345825\n",
            "  epoch: 18/20,    batch: 2759/2993    Encoder_loss: 0.6341126561164856\n",
            "  epoch: 18/20,    batch: 2760/2993    Encoder_loss: 0.6545948386192322\n",
            "  epoch: 18/20,    batch: 2761/2993    Encoder_loss: 0.5993890762329102\n",
            "  epoch: 18/20,    batch: 2762/2993    Encoder_loss: 0.6298809051513672\n",
            "  epoch: 18/20,    batch: 2763/2993    Encoder_loss: 0.7148390412330627\n",
            "  epoch: 18/20,    batch: 2764/2993    Encoder_loss: 0.6682995557785034\n",
            "  epoch: 18/20,    batch: 2765/2993    Encoder_loss: 0.6725875735282898\n",
            "  epoch: 18/20,    batch: 2766/2993    Encoder_loss: 0.7220668196678162\n",
            "  epoch: 18/20,    batch: 2767/2993    Encoder_loss: 0.6444239020347595\n",
            "  epoch: 18/20,    batch: 2768/2993    Encoder_loss: 0.6319122314453125\n",
            "  epoch: 18/20,    batch: 2769/2993    Encoder_loss: 0.6988073587417603\n",
            "  epoch: 18/20,    batch: 2770/2993    Encoder_loss: 0.6703722476959229\n",
            "  epoch: 18/20,    batch: 2771/2993    Encoder_loss: 0.6650512218475342\n",
            "  epoch: 18/20,    batch: 2772/2993    Encoder_loss: 0.7240484952926636\n",
            "  epoch: 18/20,    batch: 2773/2993    Encoder_loss: 0.6957016587257385\n",
            "  epoch: 18/20,    batch: 2774/2993    Encoder_loss: 0.6781399846076965\n",
            "  epoch: 18/20,    batch: 2775/2993    Encoder_loss: 0.7145340442657471\n",
            "  epoch: 18/20,    batch: 2776/2993    Encoder_loss: 0.7051635384559631\n",
            "  epoch: 18/20,    batch: 2777/2993    Encoder_loss: 0.6208935379981995\n",
            "  epoch: 18/20,    batch: 2778/2993    Encoder_loss: 0.6661475896835327\n",
            "  epoch: 18/20,    batch: 2779/2993    Encoder_loss: 0.6572369337081909\n",
            "  epoch: 18/20,    batch: 2780/2993    Encoder_loss: 0.5970377326011658\n",
            "  epoch: 18/20,    batch: 2781/2993    Encoder_loss: 0.6638253331184387\n",
            "  epoch: 18/20,    batch: 2782/2993    Encoder_loss: 0.6647140979766846\n",
            "  epoch: 18/20,    batch: 2783/2993    Encoder_loss: 0.6542395949363708\n",
            "  epoch: 18/20,    batch: 2784/2993    Encoder_loss: 0.7165329456329346\n",
            "  epoch: 18/20,    batch: 2785/2993    Encoder_loss: 0.6454885005950928\n",
            "  epoch: 18/20,    batch: 2786/2993    Encoder_loss: 0.645666241645813\n",
            "  epoch: 18/20,    batch: 2787/2993    Encoder_loss: 0.721265435218811\n",
            "  epoch: 18/20,    batch: 2788/2993    Encoder_loss: 0.6234544515609741\n",
            "  epoch: 18/20,    batch: 2789/2993    Encoder_loss: 0.6576988101005554\n",
            "  epoch: 18/20,    batch: 2790/2993    Encoder_loss: 0.7246519923210144\n",
            "  epoch: 18/20,    batch: 2791/2993    Encoder_loss: 0.6404266953468323\n",
            "  epoch: 18/20,    batch: 2792/2993    Encoder_loss: 0.6889464259147644\n",
            "  epoch: 18/20,    batch: 2793/2993    Encoder_loss: 0.7000760436058044\n",
            "  epoch: 18/20,    batch: 2794/2993    Encoder_loss: 0.6385537385940552\n",
            "  epoch: 18/20,    batch: 2795/2993    Encoder_loss: 0.6529762148857117\n",
            "  epoch: 18/20,    batch: 2796/2993    Encoder_loss: 0.6962584257125854\n",
            "  epoch: 18/20,    batch: 2797/2993    Encoder_loss: 0.6673955917358398\n",
            "  epoch: 18/20,    batch: 2798/2993    Encoder_loss: 0.6227062344551086\n",
            "  epoch: 18/20,    batch: 2799/2993    Encoder_loss: 0.6852924227714539\n",
            "  epoch: 18/20,    batch: 2800/2993    Encoder_loss: 0.6946848630905151\n",
            "  epoch: 18/20,    batch: 2801/2993    Encoder_loss: 0.6034701466560364\n",
            "  epoch: 18/20,    batch: 2802/2993    Encoder_loss: 0.6324272155761719\n",
            "  epoch: 18/20,    batch: 2803/2993    Encoder_loss: 0.7340968251228333\n",
            "  epoch: 18/20,    batch: 2804/2993    Encoder_loss: 0.6945599317550659\n",
            "  epoch: 18/20,    batch: 2805/2993    Encoder_loss: 0.6515903472900391\n",
            "  epoch: 18/20,    batch: 2806/2993    Encoder_loss: 0.7203434109687805\n",
            "  epoch: 18/20,    batch: 2807/2993    Encoder_loss: 0.7021164298057556\n",
            "  epoch: 18/20,    batch: 2808/2993    Encoder_loss: 0.6220948100090027\n",
            "  epoch: 18/20,    batch: 2809/2993    Encoder_loss: 0.688523530960083\n",
            "  epoch: 18/20,    batch: 2810/2993    Encoder_loss: 0.7442813515663147\n",
            "  epoch: 18/20,    batch: 2811/2993    Encoder_loss: 0.6396217346191406\n",
            "  epoch: 18/20,    batch: 2812/2993    Encoder_loss: 0.6304689049720764\n",
            "  epoch: 18/20,    batch: 2813/2993    Encoder_loss: 0.7453497052192688\n",
            "  epoch: 18/20,    batch: 2814/2993    Encoder_loss: 0.7011331915855408\n",
            "  epoch: 18/20,    batch: 2815/2993    Encoder_loss: 0.7139202356338501\n",
            "  epoch: 18/20,    batch: 2816/2993    Encoder_loss: 0.7736915349960327\n",
            "  epoch: 18/20,    batch: 2817/2993    Encoder_loss: 0.6856755018234253\n",
            "  epoch: 18/20,    batch: 2818/2993    Encoder_loss: 0.7017814517021179\n",
            "  epoch: 18/20,    batch: 2819/2993    Encoder_loss: 0.7462782263755798\n",
            "  epoch: 18/20,    batch: 2820/2993    Encoder_loss: 0.6673047542572021\n",
            "  epoch: 18/20,    batch: 2821/2993    Encoder_loss: 0.7057145237922668\n",
            "  epoch: 18/20,    batch: 2822/2993    Encoder_loss: 0.7414680123329163\n",
            "  epoch: 18/20,    batch: 2823/2993    Encoder_loss: 0.6679608821868896\n",
            "  epoch: 18/20,    batch: 2824/2993    Encoder_loss: 0.7216729521751404\n",
            "  epoch: 18/20,    batch: 2825/2993    Encoder_loss: 0.7324801087379456\n",
            "  epoch: 18/20,    batch: 2826/2993    Encoder_loss: 0.695381224155426\n",
            "  epoch: 18/20,    batch: 2827/2993    Encoder_loss: 0.7351667881011963\n",
            "  epoch: 18/20,    batch: 2828/2993    Encoder_loss: 0.7000064849853516\n",
            "  epoch: 18/20,    batch: 2829/2993    Encoder_loss: 0.6037797927856445\n",
            "  epoch: 18/20,    batch: 2830/2993    Encoder_loss: 0.6684802770614624\n",
            "  epoch: 18/20,    batch: 2831/2993    Encoder_loss: 0.7538183927536011\n",
            "  epoch: 18/20,    batch: 2832/2993    Encoder_loss: 0.6786584258079529\n",
            "  epoch: 18/20,    batch: 2833/2993    Encoder_loss: 0.6675489544868469\n",
            "  epoch: 18/20,    batch: 2834/2993    Encoder_loss: 0.7309616804122925\n",
            "  epoch: 18/20,    batch: 2835/2993    Encoder_loss: 0.7032092809677124\n",
            "  epoch: 18/20,    batch: 2836/2993    Encoder_loss: 0.6324034929275513\n",
            "  epoch: 18/20,    batch: 2837/2993    Encoder_loss: 0.7035253643989563\n",
            "  epoch: 18/20,    batch: 2838/2993    Encoder_loss: 0.7603400945663452\n",
            "  epoch: 18/20,    batch: 2839/2993    Encoder_loss: 0.6767590641975403\n",
            "  epoch: 18/20,    batch: 2840/2993    Encoder_loss: 0.6664963364601135\n",
            "  epoch: 18/20,    batch: 2841/2993    Encoder_loss: 0.750415563583374\n",
            "  epoch: 18/20,    batch: 2842/2993    Encoder_loss: 0.6897702813148499\n",
            "  epoch: 18/20,    batch: 2843/2993    Encoder_loss: 0.5949661135673523\n",
            "  epoch: 18/20,    batch: 2844/2993    Encoder_loss: 0.7068011164665222\n",
            "  epoch: 18/20,    batch: 2845/2993    Encoder_loss: 0.7659658789634705\n",
            "  epoch: 18/20,    batch: 2846/2993    Encoder_loss: 0.6674293875694275\n",
            "  epoch: 18/20,    batch: 2847/2993    Encoder_loss: 0.7069498896598816\n",
            "  epoch: 18/20,    batch: 2848/2993    Encoder_loss: 0.764019250869751\n",
            "  epoch: 18/20,    batch: 2849/2993    Encoder_loss: 0.6669535040855408\n",
            "  epoch: 18/20,    batch: 2850/2993    Encoder_loss: 0.7418941855430603\n",
            "  epoch: 18/20,    batch: 2851/2993    Encoder_loss: 0.7573697566986084\n",
            "  epoch: 18/20,    batch: 2852/2993    Encoder_loss: 0.671798825263977\n",
            "  epoch: 18/20,    batch: 2853/2993    Encoder_loss: 0.7699326872825623\n",
            "  epoch: 18/20,    batch: 2854/2993    Encoder_loss: 0.7321401834487915\n",
            "  epoch: 18/20,    batch: 2855/2993    Encoder_loss: 0.6723421812057495\n",
            "  epoch: 18/20,    batch: 2856/2993    Encoder_loss: 0.7624228000640869\n",
            "  epoch: 18/20,    batch: 2857/2993    Encoder_loss: 0.7084476351737976\n",
            "  epoch: 18/20,    batch: 2858/2993    Encoder_loss: 0.6904550194740295\n",
            "  epoch: 18/20,    batch: 2859/2993    Encoder_loss: 0.7569541931152344\n",
            "  epoch: 18/20,    batch: 2860/2993    Encoder_loss: 0.6810246109962463\n",
            "  epoch: 18/20,    batch: 2861/2993    Encoder_loss: 0.7110503315925598\n",
            "  epoch: 18/20,    batch: 2862/2993    Encoder_loss: 0.7565212249755859\n",
            "  epoch: 18/20,    batch: 2863/2993    Encoder_loss: 0.6721941232681274\n",
            "  epoch: 18/20,    batch: 2864/2993    Encoder_loss: 0.6690720319747925\n",
            "  epoch: 18/20,    batch: 2865/2993    Encoder_loss: 0.751934289932251\n",
            "  epoch: 18/20,    batch: 2866/2993    Encoder_loss: 0.7001280188560486\n",
            "  epoch: 18/20,    batch: 2867/2993    Encoder_loss: 0.6780569553375244\n",
            "  epoch: 18/20,    batch: 2868/2993    Encoder_loss: 0.7447746992111206\n",
            "  epoch: 18/20,    batch: 2869/2993    Encoder_loss: 0.7087739109992981\n",
            "  epoch: 18/20,    batch: 2870/2993    Encoder_loss: 0.6794131398200989\n",
            "  epoch: 18/20,    batch: 2871/2993    Encoder_loss: 0.7511909008026123\n",
            "  epoch: 18/20,    batch: 2872/2993    Encoder_loss: 0.7487316727638245\n",
            "  epoch: 18/20,    batch: 2873/2993    Encoder_loss: 0.6897880434989929\n",
            "  epoch: 18/20,    batch: 2874/2993    Encoder_loss: 0.7277100682258606\n",
            "  epoch: 18/20,    batch: 2875/2993    Encoder_loss: 0.6998454928398132\n",
            "  epoch: 18/20,    batch: 2876/2993    Encoder_loss: 0.6390663981437683\n",
            "  epoch: 18/20,    batch: 2877/2993    Encoder_loss: 0.7055965065956116\n",
            "  epoch: 18/20,    batch: 2878/2993    Encoder_loss: 0.7511254549026489\n",
            "  epoch: 18/20,    batch: 2879/2993    Encoder_loss: 0.6736587882041931\n",
            "  epoch: 18/20,    batch: 2880/2993    Encoder_loss: 0.7434565424919128\n",
            "  epoch: 18/20,    batch: 2881/2993    Encoder_loss: 0.7591596841812134\n",
            "  epoch: 18/20,    batch: 2882/2993    Encoder_loss: 0.6588817834854126\n",
            "  epoch: 18/20,    batch: 2883/2993    Encoder_loss: 0.7513679265975952\n",
            "  epoch: 18/20,    batch: 2884/2993    Encoder_loss: 0.7289981245994568\n",
            "  epoch: 18/20,    batch: 2885/2993    Encoder_loss: 0.6808741092681885\n",
            "  epoch: 18/20,    batch: 2886/2993    Encoder_loss: 0.7714996337890625\n",
            "  epoch: 18/20,    batch: 2887/2993    Encoder_loss: 0.710213303565979\n",
            "  epoch: 18/20,    batch: 2888/2993    Encoder_loss: 0.700319230556488\n",
            "  epoch: 18/20,    batch: 2889/2993    Encoder_loss: 0.770793080329895\n",
            "  epoch: 18/20,    batch: 2890/2993    Encoder_loss: 0.6993333101272583\n",
            "  epoch: 18/20,    batch: 2891/2993    Encoder_loss: 0.7318078875541687\n",
            "  epoch: 18/20,    batch: 2892/2993    Encoder_loss: 0.7883835434913635\n",
            "  epoch: 18/20,    batch: 2893/2993    Encoder_loss: 0.6865317225456238\n",
            "  epoch: 18/20,    batch: 2894/2993    Encoder_loss: 0.7379776239395142\n",
            "  epoch: 18/20,    batch: 2895/2993    Encoder_loss: 0.7541273832321167\n",
            "  epoch: 18/20,    batch: 2896/2993    Encoder_loss: 0.6773585677146912\n",
            "  epoch: 18/20,    batch: 2897/2993    Encoder_loss: 0.7072625756263733\n",
            "  epoch: 18/20,    batch: 2898/2993    Encoder_loss: 0.7729535698890686\n",
            "  epoch: 18/20,    batch: 2899/2993    Encoder_loss: 0.6958054304122925\n",
            "  epoch: 18/20,    batch: 2900/2993    Encoder_loss: 0.716123640537262\n",
            "  epoch: 18/20,    batch: 2901/2993    Encoder_loss: 0.767480731010437\n",
            "  epoch: 18/20,    batch: 2902/2993    Encoder_loss: 0.7066566944122314\n",
            "  epoch: 18/20,    batch: 2903/2993    Encoder_loss: 0.6844186186790466\n",
            "  epoch: 18/20,    batch: 2904/2993    Encoder_loss: 0.7673436403274536\n",
            "  epoch: 18/20,    batch: 2905/2993    Encoder_loss: 0.7620260715484619\n",
            "  epoch: 18/20,    batch: 2906/2993    Encoder_loss: 0.7206251621246338\n",
            "  epoch: 18/20,    batch: 2907/2993    Encoder_loss: 0.7424123287200928\n",
            "  epoch: 18/20,    batch: 2908/2993    Encoder_loss: 0.7267473936080933\n",
            "  epoch: 18/20,    batch: 2909/2993    Encoder_loss: 0.7195476293563843\n",
            "  epoch: 18/20,    batch: 2910/2993    Encoder_loss: 0.7698119878768921\n",
            "  epoch: 18/20,    batch: 2911/2993    Encoder_loss: 0.752867579460144\n",
            "  epoch: 18/20,    batch: 2912/2993    Encoder_loss: 0.6833418011665344\n",
            "  epoch: 18/20,    batch: 2913/2993    Encoder_loss: 0.7507381439208984\n",
            "  epoch: 18/20,    batch: 2914/2993    Encoder_loss: 0.7519862651824951\n",
            "  epoch: 18/20,    batch: 2915/2993    Encoder_loss: 0.7117669582366943\n",
            "  epoch: 18/20,    batch: 2916/2993    Encoder_loss: 0.7772753834724426\n",
            "  epoch: 18/20,    batch: 2917/2993    Encoder_loss: 0.7428882718086243\n",
            "  epoch: 18/20,    batch: 2918/2993    Encoder_loss: 0.7106487154960632\n",
            "  epoch: 18/20,    batch: 2919/2993    Encoder_loss: 0.7663726806640625\n",
            "  epoch: 18/20,    batch: 2920/2993    Encoder_loss: 0.7139543890953064\n",
            "  epoch: 18/20,    batch: 2921/2993    Encoder_loss: 0.7272666692733765\n",
            "  epoch: 18/20,    batch: 2922/2993    Encoder_loss: 0.7828070521354675\n",
            "  epoch: 18/20,    batch: 2923/2993    Encoder_loss: 0.700107216835022\n",
            "  epoch: 18/20,    batch: 2924/2993    Encoder_loss: 0.7233516573905945\n",
            "  epoch: 18/20,    batch: 2925/2993    Encoder_loss: 0.7821176648139954\n",
            "  epoch: 18/20,    batch: 2926/2993    Encoder_loss: 0.7039896249771118\n",
            "  epoch: 18/20,    batch: 2927/2993    Encoder_loss: 0.7559317946434021\n",
            "  epoch: 18/20,    batch: 2928/2993    Encoder_loss: 0.7445297837257385\n",
            "  epoch: 18/20,    batch: 2929/2993    Encoder_loss: 0.6346290707588196\n",
            "  epoch: 18/20,    batch: 2930/2993    Encoder_loss: 0.6538814306259155\n",
            "  epoch: 18/20,    batch: 2931/2993    Encoder_loss: 0.7518559098243713\n",
            "  epoch: 18/20,    batch: 2932/2993    Encoder_loss: 0.7239599227905273\n",
            "  epoch: 18/20,    batch: 2933/2993    Encoder_loss: 0.659929096698761\n",
            "  epoch: 18/20,    batch: 2934/2993    Encoder_loss: 0.7582470774650574\n",
            "  epoch: 18/20,    batch: 2935/2993    Encoder_loss: 0.7309223413467407\n",
            "  epoch: 18/20,    batch: 2936/2993    Encoder_loss: 0.6628921627998352\n",
            "  epoch: 18/20,    batch: 2937/2993    Encoder_loss: 0.6953011751174927\n",
            "  epoch: 18/20,    batch: 2938/2993    Encoder_loss: 0.7461452484130859\n",
            "  epoch: 18/20,    batch: 2939/2993    Encoder_loss: 0.6780567765235901\n",
            "  epoch: 18/20,    batch: 2940/2993    Encoder_loss: 0.6757854223251343\n",
            "  epoch: 18/20,    batch: 2941/2993    Encoder_loss: 0.7607403993606567\n",
            "  epoch: 18/20,    batch: 2942/2993    Encoder_loss: 0.7213907837867737\n",
            "  epoch: 18/20,    batch: 2943/2993    Encoder_loss: 0.6057628989219666\n",
            "  epoch: 18/20,    batch: 2944/2993    Encoder_loss: 0.6427310109138489\n",
            "  epoch: 18/20,    batch: 2945/2993    Encoder_loss: 0.7334606051445007\n",
            "  epoch: 18/20,    batch: 2946/2993    Encoder_loss: 0.68983393907547\n",
            "  epoch: 18/20,    batch: 2947/2993    Encoder_loss: 0.6996985077857971\n",
            "  epoch: 18/20,    batch: 2948/2993    Encoder_loss: 0.7542209625244141\n",
            "  epoch: 18/20,    batch: 2949/2993    Encoder_loss: 0.6685041785240173\n",
            "  epoch: 18/20,    batch: 2950/2993    Encoder_loss: 0.6898162961006165\n",
            "  epoch: 18/20,    batch: 2951/2993    Encoder_loss: 0.7628648281097412\n",
            "  epoch: 18/20,    batch: 2952/2993    Encoder_loss: 0.6508389711380005\n",
            "  epoch: 18/20,    batch: 2953/2993    Encoder_loss: 0.6991919279098511\n",
            "  epoch: 18/20,    batch: 2954/2993    Encoder_loss: 0.7477586269378662\n",
            "  epoch: 18/20,    batch: 2955/2993    Encoder_loss: 0.622086226940155\n",
            "  epoch: 18/20,    batch: 2956/2993    Encoder_loss: 0.7076113224029541\n",
            "  epoch: 18/20,    batch: 2957/2993    Encoder_loss: 0.740578830242157\n",
            "  epoch: 18/20,    batch: 2958/2993    Encoder_loss: 0.6457436084747314\n",
            "  epoch: 18/20,    batch: 2959/2993    Encoder_loss: 0.746904194355011\n",
            "  epoch: 18/20,    batch: 2960/2993    Encoder_loss: 0.7210708856582642\n",
            "  epoch: 18/20,    batch: 2961/2993    Encoder_loss: 0.6415396928787231\n",
            "  epoch: 18/20,    batch: 2962/2993    Encoder_loss: 0.718507707118988\n",
            "  epoch: 18/20,    batch: 2963/2993    Encoder_loss: 0.6819491982460022\n",
            "  epoch: 18/20,    batch: 2964/2993    Encoder_loss: 0.5929720401763916\n",
            "  epoch: 18/20,    batch: 2965/2993    Encoder_loss: 0.6725084185600281\n",
            "  epoch: 18/20,    batch: 2966/2993    Encoder_loss: 0.7102100849151611\n",
            "  epoch: 18/20,    batch: 2967/2993    Encoder_loss: 0.6178607940673828\n",
            "  epoch: 18/20,    batch: 2968/2993    Encoder_loss: 0.6738882064819336\n",
            "  epoch: 18/20,    batch: 2969/2993    Encoder_loss: 0.6887219548225403\n",
            "  epoch: 18/20,    batch: 2970/2993    Encoder_loss: 0.6083729267120361\n",
            "  epoch: 18/20,    batch: 2971/2993    Encoder_loss: 0.6557936072349548\n",
            "  epoch: 18/20,    batch: 2972/2993    Encoder_loss: 0.7162474989891052\n",
            "  epoch: 18/20,    batch: 2973/2993    Encoder_loss: 0.6421535015106201\n",
            "  epoch: 18/20,    batch: 2974/2993    Encoder_loss: 0.6615588665008545\n",
            "  epoch: 18/20,    batch: 2975/2993    Encoder_loss: 0.6940838098526001\n",
            "  epoch: 18/20,    batch: 2976/2993    Encoder_loss: 0.6141485571861267\n",
            "  epoch: 18/20,    batch: 2977/2993    Encoder_loss: 0.6230138540267944\n",
            "  epoch: 18/20,    batch: 2978/2993    Encoder_loss: 0.6950051188468933\n",
            "  epoch: 18/20,    batch: 2979/2993    Encoder_loss: 0.6389402747154236\n",
            "  epoch: 18/20,    batch: 2980/2993    Encoder_loss: 0.6529338955879211\n",
            "  epoch: 18/20,    batch: 2981/2993    Encoder_loss: 0.726872444152832\n",
            "  epoch: 18/20,    batch: 2982/2993    Encoder_loss: 0.6260077357292175\n",
            "  epoch: 18/20,    batch: 2983/2993    Encoder_loss: 0.6677915453910828\n",
            "  epoch: 18/20,    batch: 2984/2993    Encoder_loss: 0.741504430770874\n",
            "  epoch: 18/20,    batch: 2985/2993    Encoder_loss: 0.6388412117958069\n",
            "  epoch: 18/20,    batch: 2986/2993    Encoder_loss: 0.6999022364616394\n",
            "  epoch: 18/20,    batch: 2987/2993    Encoder_loss: 0.7236946225166321\n",
            "  epoch: 18/20,    batch: 2988/2993    Encoder_loss: 0.6426408886909485\n",
            "  epoch: 18/20,    batch: 2989/2993    Encoder_loss: 0.7335253357887268\n",
            "  epoch: 18/20,    batch: 2990/2993    Encoder_loss: 0.7116385102272034\n",
            "  epoch: 18/20,    batch: 2991/2993    Encoder_loss: 0.6618990302085876\n",
            "  epoch: 18/20,    batch: 2992/2993    Encoder_loss: 0.7067268490791321\n",
            "epoch: 18/20,  Tot_epoch_loss: 2000.777587890625\n",
            "  adding: encoder_checkpoints/ (stored 0%)\n",
            "  adding: encoder_checkpoints/encoder_epoch10.h5 (deflated 9%)\n",
            "  adding: encoder_checkpoints/encoder_epoch4.h5 (deflated 9%)\n",
            "  adding: encoder_checkpoints/encoder_epoch16.h5 (deflated 9%)\n",
            "  adding: encoder_checkpoints/encoder_epoch3.h5 (deflated 9%)\n",
            "  adding: encoder_checkpoints/encoder_epoch8.h5 (deflated 9%)\n",
            "  adding: encoder_checkpoints/encoder_epoch15.h5 (deflated 9%)\n",
            "  adding: encoder_checkpoints/encoder_epoch17.h5 (deflated 9%)\n",
            "  adding: encoder_checkpoints/encoder_epoch13.h5 (deflated 9%)\n",
            "  adding: encoder_checkpoints/encoder_epoch18.h5 (deflated 9%)\n",
            "  adding: encoder_checkpoints/encoder_epoch9.h5 (deflated 9%)\n",
            "  adding: encoder_checkpoints/encoder_epoch0.h5 (deflated 10%)\n",
            "  adding: encoder_checkpoints/encoder_epoch1.h5 (deflated 10%)\n",
            "  adding: encoder_checkpoints/encoder_epoch2.h5 (deflated 10%)\n",
            "  adding: encoder_checkpoints/encoder_epoch12.h5 (deflated 9%)\n",
            "  adding: encoder_checkpoints/encoder_epoch6.h5 (deflated 9%)\n",
            "  adding: encoder_checkpoints/encoder_epoch7.h5 (deflated 9%)\n",
            "  adding: encoder_checkpoints/.ipynb_checkpoints/ (stored 0%)\n",
            "  adding: encoder_checkpoints/encoder_epoch5.h5 (deflated 9%)\n",
            "  adding: encoder_checkpoints/encoder_epoch11.h5 (deflated 9%)\n",
            "  adding: encoder_checkpoints/encoder_epoch14.h5 (deflated 9%)\n",
            "  epoch: 19/20,    batch: 0/2993    Encoder_loss: 0.8142172694206238\n",
            "  epoch: 19/20,    batch: 1/2993    Encoder_loss: 0.8144480586051941\n",
            "  epoch: 19/20,    batch: 2/2993    Encoder_loss: 0.8075341582298279\n",
            "  epoch: 19/20,    batch: 3/2993    Encoder_loss: 0.8038474917411804\n",
            "  epoch: 19/20,    batch: 4/2993    Encoder_loss: 0.8026058077812195\n",
            "  epoch: 19/20,    batch: 5/2993    Encoder_loss: 0.8047828674316406\n",
            "  epoch: 19/20,    batch: 6/2993    Encoder_loss: 0.8057029247283936\n",
            "  epoch: 19/20,    batch: 7/2993    Encoder_loss: 0.8080205917358398\n",
            "  epoch: 19/20,    batch: 8/2993    Encoder_loss: 0.81129390001297\n",
            "  epoch: 19/20,    batch: 9/2993    Encoder_loss: 0.8141663670539856\n",
            "  epoch: 19/20,    batch: 10/2993    Encoder_loss: 0.8196849226951599\n",
            "  epoch: 19/20,    batch: 11/2993    Encoder_loss: 0.8172345757484436\n",
            "  epoch: 19/20,    batch: 12/2993    Encoder_loss: 0.8159508109092712\n",
            "  epoch: 19/20,    batch: 13/2993    Encoder_loss: 0.820712149143219\n",
            "  epoch: 19/20,    batch: 14/2993    Encoder_loss: 0.8231174349784851\n",
            "  epoch: 19/20,    batch: 15/2993    Encoder_loss: 0.8207311034202576\n",
            "  epoch: 19/20,    batch: 16/2993    Encoder_loss: 0.8186413049697876\n",
            "  epoch: 19/20,    batch: 17/2993    Encoder_loss: 0.8230577111244202\n",
            "  epoch: 19/20,    batch: 18/2993    Encoder_loss: 0.8335115909576416\n",
            "  epoch: 19/20,    batch: 19/2993    Encoder_loss: 0.9060817360877991\n",
            "  epoch: 19/20,    batch: 20/2993    Encoder_loss: 0.8851486444473267\n",
            "  epoch: 19/20,    batch: 21/2993    Encoder_loss: 0.8111927509307861\n",
            "  epoch: 19/20,    batch: 22/2993    Encoder_loss: 0.6930204033851624\n",
            "  epoch: 19/20,    batch: 23/2993    Encoder_loss: 0.7392251491546631\n",
            "  epoch: 19/20,    batch: 24/2993    Encoder_loss: 0.8192625641822815\n",
            "  epoch: 19/20,    batch: 25/2993    Encoder_loss: 0.7339052557945251\n",
            "  epoch: 19/20,    batch: 26/2993    Encoder_loss: 0.7263573408126831\n",
            "  epoch: 19/20,    batch: 27/2993    Encoder_loss: 0.8101281523704529\n",
            "  epoch: 19/20,    batch: 28/2993    Encoder_loss: 0.7885448336601257\n",
            "  epoch: 19/20,    batch: 29/2993    Encoder_loss: 0.7328348159790039\n",
            "  epoch: 19/20,    batch: 30/2993    Encoder_loss: 0.7738875150680542\n",
            "  epoch: 19/20,    batch: 31/2993    Encoder_loss: 0.8192254304885864\n",
            "  epoch: 19/20,    batch: 32/2993    Encoder_loss: 0.7395569682121277\n",
            "  epoch: 19/20,    batch: 33/2993    Encoder_loss: 0.7276099920272827\n",
            "  epoch: 19/20,    batch: 34/2993    Encoder_loss: 0.7614177465438843\n",
            "  epoch: 19/20,    batch: 35/2993    Encoder_loss: 0.7390638589859009\n",
            "  epoch: 19/20,    batch: 36/2993    Encoder_loss: 0.6992594599723816\n",
            "  epoch: 19/20,    batch: 37/2993    Encoder_loss: 0.766346275806427\n",
            "  epoch: 19/20,    batch: 38/2993    Encoder_loss: 0.7985556721687317\n",
            "  epoch: 19/20,    batch: 39/2993    Encoder_loss: 0.7017158269882202\n",
            "  epoch: 19/20,    batch: 40/2993    Encoder_loss: 0.7077244520187378\n",
            "  epoch: 19/20,    batch: 41/2993    Encoder_loss: 0.7648758292198181\n",
            "  epoch: 19/20,    batch: 42/2993    Encoder_loss: 0.6829184889793396\n",
            "  epoch: 19/20,    batch: 43/2993    Encoder_loss: 0.735554575920105\n",
            "  epoch: 19/20,    batch: 44/2993    Encoder_loss: 0.7820682525634766\n",
            "  epoch: 19/20,    batch: 45/2993    Encoder_loss: 0.6464751958847046\n",
            "  epoch: 19/20,    batch: 46/2993    Encoder_loss: 0.7261011600494385\n",
            "  epoch: 19/20,    batch: 47/2993    Encoder_loss: 0.7672647833824158\n",
            "  epoch: 19/20,    batch: 48/2993    Encoder_loss: 0.6886740326881409\n",
            "  epoch: 19/20,    batch: 49/2993    Encoder_loss: 0.7698438763618469\n",
            "  epoch: 19/20,    batch: 50/2993    Encoder_loss: 0.721287190914154\n",
            "  epoch: 19/20,    batch: 51/2993    Encoder_loss: 0.6645370721817017\n",
            "  epoch: 19/20,    batch: 52/2993    Encoder_loss: 0.7477671504020691\n",
            "  epoch: 19/20,    batch: 53/2993    Encoder_loss: 0.6839615106582642\n",
            "  epoch: 19/20,    batch: 54/2993    Encoder_loss: 0.6719927191734314\n",
            "  epoch: 19/20,    batch: 55/2993    Encoder_loss: 0.7388820648193359\n",
            "  epoch: 19/20,    batch: 56/2993    Encoder_loss: 0.7028721570968628\n",
            "  epoch: 19/20,    batch: 57/2993    Encoder_loss: 0.643179178237915\n",
            "  epoch: 19/20,    batch: 58/2993    Encoder_loss: 0.7336734533309937\n",
            "  epoch: 19/20,    batch: 59/2993    Encoder_loss: 0.7857806086540222\n",
            "  epoch: 19/20,    batch: 60/2993    Encoder_loss: 0.6970509886741638\n",
            "  epoch: 19/20,    batch: 61/2993    Encoder_loss: 0.7265155911445618\n",
            "  epoch: 19/20,    batch: 62/2993    Encoder_loss: 0.7975711822509766\n",
            "  epoch: 19/20,    batch: 63/2993    Encoder_loss: 0.7198092341423035\n",
            "  epoch: 19/20,    batch: 64/2993    Encoder_loss: 0.6656367778778076\n",
            "  epoch: 19/20,    batch: 65/2993    Encoder_loss: 0.7551699876785278\n",
            "  epoch: 19/20,    batch: 66/2993    Encoder_loss: 0.7613643407821655\n",
            "  epoch: 19/20,    batch: 67/2993    Encoder_loss: 0.6422199606895447\n",
            "  epoch: 19/20,    batch: 68/2993    Encoder_loss: 0.6970796585083008\n",
            "  epoch: 19/20,    batch: 69/2993    Encoder_loss: 0.7575082182884216\n",
            "  epoch: 19/20,    batch: 70/2993    Encoder_loss: 0.6794971227645874\n",
            "  epoch: 19/20,    batch: 71/2993    Encoder_loss: 0.6550715565681458\n",
            "  epoch: 19/20,    batch: 72/2993    Encoder_loss: 0.7279987335205078\n",
            "  epoch: 19/20,    batch: 73/2993    Encoder_loss: 0.7517334818840027\n",
            "  epoch: 19/20,    batch: 74/2993    Encoder_loss: 0.6615212559700012\n",
            "  epoch: 19/20,    batch: 75/2993    Encoder_loss: 0.7092298865318298\n",
            "  epoch: 19/20,    batch: 76/2993    Encoder_loss: 0.7407746911048889\n",
            "  epoch: 19/20,    batch: 77/2993    Encoder_loss: 0.6644229888916016\n",
            "  epoch: 19/20,    batch: 78/2993    Encoder_loss: 0.7112038731575012\n",
            "  epoch: 19/20,    batch: 79/2993    Encoder_loss: 0.7337935566902161\n",
            "  epoch: 19/20,    batch: 80/2993    Encoder_loss: 0.6775872111320496\n",
            "  epoch: 19/20,    batch: 81/2993    Encoder_loss: 0.7261305451393127\n",
            "  epoch: 19/20,    batch: 82/2993    Encoder_loss: 0.7341832518577576\n",
            "  epoch: 19/20,    batch: 83/2993    Encoder_loss: 0.7097615599632263\n",
            "  epoch: 19/20,    batch: 84/2993    Encoder_loss: 0.7420953512191772\n",
            "  epoch: 19/20,    batch: 85/2993    Encoder_loss: 0.6773104071617126\n",
            "  epoch: 19/20,    batch: 86/2993    Encoder_loss: 0.6670418977737427\n",
            "  epoch: 19/20,    batch: 87/2993    Encoder_loss: 0.7389101386070251\n",
            "  epoch: 19/20,    batch: 88/2993    Encoder_loss: 0.686862051486969\n",
            "  epoch: 19/20,    batch: 89/2993    Encoder_loss: 0.7100850939750671\n",
            "  epoch: 19/20,    batch: 90/2993    Encoder_loss: 0.7489296793937683\n",
            "  epoch: 19/20,    batch: 91/2993    Encoder_loss: 0.6740933060646057\n",
            "  epoch: 19/20,    batch: 92/2993    Encoder_loss: 0.6457594633102417\n",
            "  epoch: 19/20,    batch: 93/2993    Encoder_loss: 0.7171879410743713\n",
            "  epoch: 19/20,    batch: 94/2993    Encoder_loss: 0.7388664484024048\n",
            "  epoch: 19/20,    batch: 95/2993    Encoder_loss: 0.659310519695282\n",
            "  epoch: 19/20,    batch: 96/2993    Encoder_loss: 0.7313165664672852\n",
            "  epoch: 19/20,    batch: 97/2993    Encoder_loss: 0.762224555015564\n",
            "  epoch: 19/20,    batch: 98/2993    Encoder_loss: 0.6604333519935608\n",
            "  epoch: 19/20,    batch: 99/2993    Encoder_loss: 0.6463896632194519\n",
            "  epoch: 19/20,    batch: 100/2993    Encoder_loss: 0.7197083830833435\n",
            "  epoch: 19/20,    batch: 101/2993    Encoder_loss: 0.7215794920921326\n",
            "  epoch: 19/20,    batch: 102/2993    Encoder_loss: 0.6461832523345947\n",
            "  epoch: 19/20,    batch: 103/2993    Encoder_loss: 0.7549050450325012\n",
            "  epoch: 19/20,    batch: 104/2993    Encoder_loss: 0.7563230395317078\n",
            "  epoch: 19/20,    batch: 105/2993    Encoder_loss: 0.6617707014083862\n",
            "  epoch: 19/20,    batch: 106/2993    Encoder_loss: 0.6856610178947449\n",
            "  epoch: 19/20,    batch: 107/2993    Encoder_loss: 0.7614454030990601\n",
            "  epoch: 19/20,    batch: 108/2993    Encoder_loss: 0.7181226015090942\n",
            "  epoch: 19/20,    batch: 109/2993    Encoder_loss: 0.654247522354126\n",
            "  epoch: 19/20,    batch: 110/2993    Encoder_loss: 0.7606800198554993\n",
            "  epoch: 19/20,    batch: 111/2993    Encoder_loss: 0.7266811728477478\n",
            "  epoch: 19/20,    batch: 112/2993    Encoder_loss: 0.6984283328056335\n",
            "  epoch: 19/20,    batch: 113/2993    Encoder_loss: 0.7793000340461731\n",
            "  epoch: 19/20,    batch: 114/2993    Encoder_loss: 0.7220333814620972\n",
            "  epoch: 19/20,    batch: 115/2993    Encoder_loss: 0.7144733667373657\n",
            "  epoch: 19/20,    batch: 116/2993    Encoder_loss: 0.7530984282493591\n",
            "  epoch: 19/20,    batch: 117/2993    Encoder_loss: 0.687558114528656\n",
            "  epoch: 19/20,    batch: 118/2993    Encoder_loss: 0.7081118822097778\n",
            "  epoch: 19/20,    batch: 119/2993    Encoder_loss: 0.7423550486564636\n",
            "  epoch: 19/20,    batch: 120/2993    Encoder_loss: 0.6541667580604553\n",
            "  epoch: 19/20,    batch: 121/2993    Encoder_loss: 0.7220056056976318\n",
            "  epoch: 19/20,    batch: 122/2993    Encoder_loss: 0.7541853189468384\n",
            "  epoch: 19/20,    batch: 123/2993    Encoder_loss: 0.6683882474899292\n",
            "  epoch: 19/20,    batch: 124/2993    Encoder_loss: 0.6946138739585876\n",
            "  epoch: 19/20,    batch: 125/2993    Encoder_loss: 0.6884027719497681\n",
            "  epoch: 19/20,    batch: 126/2993    Encoder_loss: 0.6401300430297852\n",
            "  epoch: 19/20,    batch: 127/2993    Encoder_loss: 0.6956884264945984\n",
            "  epoch: 19/20,    batch: 128/2993    Encoder_loss: 0.7416597008705139\n",
            "  epoch: 19/20,    batch: 129/2993    Encoder_loss: 0.6894600987434387\n",
            "  epoch: 19/20,    batch: 130/2993    Encoder_loss: 0.7214744687080383\n",
            "  epoch: 19/20,    batch: 131/2993    Encoder_loss: 0.7539735436439514\n",
            "  epoch: 19/20,    batch: 132/2993    Encoder_loss: 0.6733428239822388\n",
            "  epoch: 19/20,    batch: 133/2993    Encoder_loss: 0.6918571591377258\n",
            "  epoch: 19/20,    batch: 134/2993    Encoder_loss: 0.7614169716835022\n",
            "  epoch: 19/20,    batch: 135/2993    Encoder_loss: 0.6821566224098206\n",
            "  epoch: 19/20,    batch: 136/2993    Encoder_loss: 0.6453176736831665\n",
            "  epoch: 19/20,    batch: 137/2993    Encoder_loss: 0.7054396867752075\n",
            "  epoch: 19/20,    batch: 138/2993    Encoder_loss: 0.7144124507904053\n",
            "  epoch: 19/20,    batch: 139/2993    Encoder_loss: 0.6751110553741455\n",
            "  epoch: 19/20,    batch: 140/2993    Encoder_loss: 0.7256702184677124\n",
            "  epoch: 19/20,    batch: 141/2993    Encoder_loss: 0.7707740068435669\n",
            "  epoch: 19/20,    batch: 142/2993    Encoder_loss: 0.7343721985816956\n",
            "  epoch: 19/20,    batch: 143/2993    Encoder_loss: 0.7975545525550842\n",
            "  epoch: 19/20,    batch: 144/2993    Encoder_loss: 0.7534059882164001\n",
            "  epoch: 19/20,    batch: 145/2993    Encoder_loss: 0.679656982421875\n",
            "  epoch: 19/20,    batch: 146/2993    Encoder_loss: 0.7764682769775391\n",
            "  epoch: 19/20,    batch: 147/2993    Encoder_loss: 0.7386795878410339\n",
            "  epoch: 19/20,    batch: 148/2993    Encoder_loss: 0.7151678800582886\n",
            "  epoch: 19/20,    batch: 149/2993    Encoder_loss: 0.7684043049812317\n",
            "  epoch: 19/20,    batch: 150/2993    Encoder_loss: 0.7050865292549133\n",
            "  epoch: 19/20,    batch: 151/2993    Encoder_loss: 0.7322179675102234\n",
            "  epoch: 19/20,    batch: 152/2993    Encoder_loss: 0.7891546487808228\n",
            "  epoch: 19/20,    batch: 153/2993    Encoder_loss: 0.710343599319458\n",
            "  epoch: 19/20,    batch: 154/2993    Encoder_loss: 0.7771958708763123\n",
            "  epoch: 19/20,    batch: 155/2993    Encoder_loss: 0.808502733707428\n",
            "  epoch: 19/20,    batch: 156/2993    Encoder_loss: 0.6825312972068787\n",
            "  epoch: 19/20,    batch: 157/2993    Encoder_loss: 0.7434853911399841\n",
            "  epoch: 19/20,    batch: 158/2993    Encoder_loss: 0.7487590909004211\n",
            "  epoch: 19/20,    batch: 159/2993    Encoder_loss: 0.6696966886520386\n",
            "  epoch: 19/20,    batch: 160/2993    Encoder_loss: 0.7065653204917908\n",
            "  epoch: 19/20,    batch: 161/2993    Encoder_loss: 0.788074791431427\n",
            "  epoch: 19/20,    batch: 162/2993    Encoder_loss: 0.738381564617157\n",
            "  epoch: 19/20,    batch: 163/2993    Encoder_loss: 0.7224138379096985\n",
            "  epoch: 19/20,    batch: 164/2993    Encoder_loss: 0.790390133857727\n",
            "  epoch: 19/20,    batch: 165/2993    Encoder_loss: 0.7520741820335388\n",
            "  epoch: 19/20,    batch: 166/2993    Encoder_loss: 0.6824194192886353\n",
            "  epoch: 19/20,    batch: 167/2993    Encoder_loss: 0.748702347278595\n",
            "  epoch: 19/20,    batch: 168/2993    Encoder_loss: 0.7813228964805603\n",
            "  epoch: 19/20,    batch: 169/2993    Encoder_loss: 0.7147216200828552\n",
            "  epoch: 19/20,    batch: 170/2993    Encoder_loss: 0.7806584239006042\n",
            "  epoch: 19/20,    batch: 171/2993    Encoder_loss: 0.8192018866539001\n",
            "  epoch: 19/20,    batch: 172/2993    Encoder_loss: 0.6964532732963562\n",
            "  epoch: 19/20,    batch: 173/2993    Encoder_loss: 0.6635810136795044\n",
            "  epoch: 19/20,    batch: 174/2993    Encoder_loss: 0.7568067908287048\n",
            "  epoch: 19/20,    batch: 175/2993    Encoder_loss: 0.7699583172798157\n",
            "  epoch: 19/20,    batch: 176/2993    Encoder_loss: 0.7128384113311768\n",
            "  epoch: 19/20,    batch: 177/2993    Encoder_loss: 0.8013468384742737\n",
            "  epoch: 19/20,    batch: 178/2993    Encoder_loss: 0.7653859257698059\n",
            "  epoch: 19/20,    batch: 179/2993    Encoder_loss: 0.6970873475074768\n",
            "  epoch: 19/20,    batch: 180/2993    Encoder_loss: 0.7641236782073975\n",
            "  epoch: 19/20,    batch: 181/2993    Encoder_loss: 0.7128321528434753\n",
            "  epoch: 19/20,    batch: 182/2993    Encoder_loss: 0.7084261775016785\n",
            "  epoch: 19/20,    batch: 183/2993    Encoder_loss: 0.8043553829193115\n",
            "  epoch: 19/20,    batch: 184/2993    Encoder_loss: 0.7071278095245361\n",
            "  epoch: 19/20,    batch: 185/2993    Encoder_loss: 0.7247673869132996\n",
            "  epoch: 19/20,    batch: 186/2993    Encoder_loss: 0.782643735408783\n",
            "  epoch: 19/20,    batch: 187/2993    Encoder_loss: 0.664192259311676\n",
            "  epoch: 19/20,    batch: 188/2993    Encoder_loss: 0.733722984790802\n",
            "  epoch: 19/20,    batch: 189/2993    Encoder_loss: 0.7691850662231445\n",
            "  epoch: 19/20,    batch: 190/2993    Encoder_loss: 0.699476420879364\n",
            "  epoch: 19/20,    batch: 191/2993    Encoder_loss: 0.7952185869216919\n",
            "  epoch: 19/20,    batch: 192/2993    Encoder_loss: 0.7689314484596252\n",
            "  epoch: 19/20,    batch: 193/2993    Encoder_loss: 0.648954451084137\n",
            "  epoch: 19/20,    batch: 194/2993    Encoder_loss: 0.6771231293678284\n",
            "  epoch: 19/20,    batch: 195/2993    Encoder_loss: 0.7837560772895813\n",
            "  epoch: 19/20,    batch: 196/2993    Encoder_loss: 0.7540112137794495\n",
            "  epoch: 19/20,    batch: 197/2993    Encoder_loss: 0.7265424728393555\n",
            "  epoch: 19/20,    batch: 198/2993    Encoder_loss: 0.7976372838020325\n",
            "  epoch: 19/20,    batch: 199/2993    Encoder_loss: 0.7620964646339417\n",
            "  epoch: 19/20,    batch: 200/2993    Encoder_loss: 0.6683557629585266\n",
            "  epoch: 19/20,    batch: 201/2993    Encoder_loss: 0.7253642678260803\n",
            "  epoch: 19/20,    batch: 202/2993    Encoder_loss: 0.7933143973350525\n",
            "  epoch: 19/20,    batch: 203/2993    Encoder_loss: 0.7004587650299072\n",
            "  epoch: 19/20,    batch: 204/2993    Encoder_loss: 0.6918126344680786\n",
            "  epoch: 19/20,    batch: 205/2993    Encoder_loss: 0.7905625104904175\n",
            "  epoch: 19/20,    batch: 206/2993    Encoder_loss: 0.7242879271507263\n",
            "  epoch: 19/20,    batch: 207/2993    Encoder_loss: 0.6256193518638611\n",
            "  epoch: 19/20,    batch: 208/2993    Encoder_loss: 0.7164420485496521\n",
            "  epoch: 19/20,    batch: 209/2993    Encoder_loss: 0.775229811668396\n",
            "  epoch: 19/20,    batch: 210/2993    Encoder_loss: 0.6697129607200623\n",
            "  epoch: 19/20,    batch: 211/2993    Encoder_loss: 0.691458523273468\n",
            "  epoch: 19/20,    batch: 212/2993    Encoder_loss: 0.788916289806366\n",
            "  epoch: 19/20,    batch: 213/2993    Encoder_loss: 0.710871160030365\n",
            "  epoch: 19/20,    batch: 214/2993    Encoder_loss: 0.7414542436599731\n",
            "  epoch: 19/20,    batch: 215/2993    Encoder_loss: 0.7949712872505188\n",
            "  epoch: 19/20,    batch: 216/2993    Encoder_loss: 0.7094904184341431\n",
            "  epoch: 19/20,    batch: 217/2993    Encoder_loss: 0.7794655561447144\n",
            "  epoch: 19/20,    batch: 218/2993    Encoder_loss: 0.8031607866287231\n",
            "  epoch: 19/20,    batch: 219/2993    Encoder_loss: 0.7135568261146545\n",
            "  epoch: 19/20,    batch: 220/2993    Encoder_loss: 0.7685303092002869\n",
            "  epoch: 19/20,    batch: 221/2993    Encoder_loss: 0.7697643041610718\n",
            "  epoch: 19/20,    batch: 222/2993    Encoder_loss: 0.7169609665870667\n",
            "  epoch: 19/20,    batch: 223/2993    Encoder_loss: 0.7897825837135315\n",
            "  epoch: 19/20,    batch: 224/2993    Encoder_loss: 0.776263952255249\n",
            "  epoch: 19/20,    batch: 225/2993    Encoder_loss: 0.7418779134750366\n",
            "  epoch: 19/20,    batch: 226/2993    Encoder_loss: 0.7471250891685486\n",
            "  epoch: 19/20,    batch: 227/2993    Encoder_loss: 0.7015702724456787\n",
            "  epoch: 19/20,    batch: 228/2993    Encoder_loss: 0.6783237457275391\n",
            "  epoch: 19/20,    batch: 229/2993    Encoder_loss: 0.7420398592948914\n",
            "  epoch: 19/20,    batch: 230/2993    Encoder_loss: 0.7419110536575317\n",
            "  epoch: 19/20,    batch: 231/2993    Encoder_loss: 0.7000662088394165\n",
            "  epoch: 19/20,    batch: 232/2993    Encoder_loss: 0.7818900346755981\n",
            "  epoch: 19/20,    batch: 233/2993    Encoder_loss: 0.7654337286949158\n",
            "  epoch: 19/20,    batch: 234/2993    Encoder_loss: 0.6827664971351624\n",
            "  epoch: 19/20,    batch: 235/2993    Encoder_loss: 0.7561861872673035\n",
            "  epoch: 19/20,    batch: 236/2993    Encoder_loss: 0.7952049374580383\n",
            "  epoch: 19/20,    batch: 237/2993    Encoder_loss: 0.6850966215133667\n",
            "  epoch: 19/20,    batch: 238/2993    Encoder_loss: 0.754515528678894\n",
            "  epoch: 19/20,    batch: 239/2993    Encoder_loss: 0.76920485496521\n",
            "  epoch: 19/20,    batch: 240/2993    Encoder_loss: 0.6744972467422485\n",
            "  epoch: 19/20,    batch: 241/2993    Encoder_loss: 0.706775963306427\n",
            "  epoch: 19/20,    batch: 242/2993    Encoder_loss: 0.788558840751648\n",
            "  epoch: 19/20,    batch: 243/2993    Encoder_loss: 0.740537703037262\n",
            "  epoch: 19/20,    batch: 244/2993    Encoder_loss: 0.7477691769599915\n",
            "  epoch: 19/20,    batch: 245/2993    Encoder_loss: 0.7776654362678528\n",
            "  epoch: 19/20,    batch: 246/2993    Encoder_loss: 0.6893197894096375\n",
            "  epoch: 19/20,    batch: 247/2993    Encoder_loss: 0.7428520917892456\n",
            "  epoch: 19/20,    batch: 248/2993    Encoder_loss: 0.7553276419639587\n",
            "  epoch: 19/20,    batch: 249/2993    Encoder_loss: 0.6922301054000854\n",
            "  epoch: 19/20,    batch: 250/2993    Encoder_loss: 0.7564657926559448\n",
            "  epoch: 19/20,    batch: 251/2993    Encoder_loss: 0.7604811787605286\n",
            "  epoch: 19/20,    batch: 252/2993    Encoder_loss: 0.714775800704956\n",
            "  epoch: 19/20,    batch: 253/2993    Encoder_loss: 0.7452042102813721\n",
            "  epoch: 19/20,    batch: 254/2993    Encoder_loss: 0.7244234681129456\n",
            "  epoch: 19/20,    batch: 255/2993    Encoder_loss: 0.7117685675621033\n",
            "  epoch: 19/20,    batch: 256/2993    Encoder_loss: 0.7641304731369019\n",
            "  epoch: 19/20,    batch: 257/2993    Encoder_loss: 0.7279992699623108\n",
            "  epoch: 19/20,    batch: 258/2993    Encoder_loss: 0.7344333529472351\n",
            "  epoch: 19/20,    batch: 259/2993    Encoder_loss: 0.7559420466423035\n",
            "  epoch: 19/20,    batch: 260/2993    Encoder_loss: 0.6910995244979858\n",
            "  epoch: 19/20,    batch: 261/2993    Encoder_loss: 0.689915657043457\n",
            "  epoch: 19/20,    batch: 262/2993    Encoder_loss: 0.7607165575027466\n",
            "  epoch: 19/20,    batch: 263/2993    Encoder_loss: 0.7395142316818237\n",
            "  epoch: 19/20,    batch: 264/2993    Encoder_loss: 0.7288133502006531\n",
            "  epoch: 19/20,    batch: 265/2993    Encoder_loss: 0.7834675312042236\n",
            "  epoch: 19/20,    batch: 266/2993    Encoder_loss: 0.7341628670692444\n",
            "  epoch: 19/20,    batch: 267/2993    Encoder_loss: 0.6655781269073486\n",
            "  epoch: 19/20,    batch: 268/2993    Encoder_loss: 0.7643352746963501\n",
            "  epoch: 19/20,    batch: 269/2993    Encoder_loss: 0.7699114680290222\n",
            "  epoch: 19/20,    batch: 270/2993    Encoder_loss: 0.6830518841743469\n",
            "  epoch: 19/20,    batch: 271/2993    Encoder_loss: 0.7652984261512756\n",
            "  epoch: 19/20,    batch: 272/2993    Encoder_loss: 0.7558450102806091\n",
            "  epoch: 19/20,    batch: 273/2993    Encoder_loss: 0.6597488522529602\n",
            "  epoch: 19/20,    batch: 274/2993    Encoder_loss: 0.7233310341835022\n",
            "  epoch: 19/20,    batch: 275/2993    Encoder_loss: 0.7861730456352234\n",
            "  epoch: 19/20,    batch: 276/2993    Encoder_loss: 0.7142314314842224\n",
            "  epoch: 19/20,    batch: 277/2993    Encoder_loss: 0.7854601740837097\n",
            "  epoch: 19/20,    batch: 278/2993    Encoder_loss: 0.8182028532028198\n",
            "  epoch: 19/20,    batch: 279/2993    Encoder_loss: 0.7026612758636475\n",
            "  epoch: 19/20,    batch: 280/2993    Encoder_loss: 0.7369897365570068\n",
            "  epoch: 19/20,    batch: 281/2993    Encoder_loss: 0.7417775988578796\n",
            "  epoch: 19/20,    batch: 282/2993    Encoder_loss: 0.6804813742637634\n",
            "  epoch: 19/20,    batch: 283/2993    Encoder_loss: 0.7289186120033264\n",
            "  epoch: 19/20,    batch: 284/2993    Encoder_loss: 0.7120934724807739\n",
            "  epoch: 19/20,    batch: 285/2993    Encoder_loss: 0.701688826084137\n",
            "  epoch: 19/20,    batch: 286/2993    Encoder_loss: 0.7468278408050537\n",
            "  epoch: 19/20,    batch: 287/2993    Encoder_loss: 0.6683334708213806\n",
            "  epoch: 19/20,    batch: 288/2993    Encoder_loss: 0.6713765859603882\n",
            "  epoch: 19/20,    batch: 289/2993    Encoder_loss: 0.7361603379249573\n",
            "  epoch: 19/20,    batch: 290/2993    Encoder_loss: 0.6693856716156006\n",
            "  epoch: 19/20,    batch: 291/2993    Encoder_loss: 0.7215169072151184\n",
            "  epoch: 19/20,    batch: 292/2993    Encoder_loss: 0.7684866189956665\n",
            "  epoch: 19/20,    batch: 293/2993    Encoder_loss: 0.676666796207428\n",
            "  epoch: 19/20,    batch: 294/2993    Encoder_loss: 0.6404837369918823\n",
            "  epoch: 19/20,    batch: 295/2993    Encoder_loss: 0.7245099544525146\n",
            "  epoch: 19/20,    batch: 296/2993    Encoder_loss: 0.7421590685844421\n",
            "  epoch: 19/20,    batch: 297/2993    Encoder_loss: 0.6381723284721375\n",
            "  epoch: 19/20,    batch: 298/2993    Encoder_loss: 0.7126478552818298\n",
            "  epoch: 19/20,    batch: 299/2993    Encoder_loss: 0.7625380754470825\n",
            "  epoch: 19/20,    batch: 300/2993    Encoder_loss: 0.6566097140312195\n",
            "  epoch: 19/20,    batch: 301/2993    Encoder_loss: 0.6491769552230835\n",
            "  epoch: 19/20,    batch: 302/2993    Encoder_loss: 0.7336640954017639\n",
            "  epoch: 19/20,    batch: 303/2993    Encoder_loss: 0.7472130656242371\n",
            "  epoch: 19/20,    batch: 304/2993    Encoder_loss: 0.6718782186508179\n",
            "  epoch: 19/20,    batch: 305/2993    Encoder_loss: 0.7724038362503052\n",
            "  epoch: 19/20,    batch: 306/2993    Encoder_loss: 0.7636114358901978\n",
            "  epoch: 19/20,    batch: 307/2993    Encoder_loss: 0.6484642028808594\n",
            "  epoch: 19/20,    batch: 308/2993    Encoder_loss: 0.6640605926513672\n",
            "  epoch: 19/20,    batch: 309/2993    Encoder_loss: 0.7666189074516296\n",
            "  epoch: 19/20,    batch: 310/2993    Encoder_loss: 0.7355092167854309\n",
            "  epoch: 19/20,    batch: 311/2993    Encoder_loss: 0.6406092047691345\n",
            "  epoch: 19/20,    batch: 312/2993    Encoder_loss: 0.7556947469711304\n",
            "  epoch: 19/20,    batch: 313/2993    Encoder_loss: 0.749010443687439\n",
            "  epoch: 19/20,    batch: 314/2993    Encoder_loss: 0.7154052257537842\n",
            "  epoch: 19/20,    batch: 315/2993    Encoder_loss: 0.8122879266738892\n",
            "  epoch: 19/20,    batch: 316/2993    Encoder_loss: 0.7523571848869324\n",
            "  epoch: 19/20,    batch: 317/2993    Encoder_loss: 0.7131640315055847\n",
            "  epoch: 19/20,    batch: 318/2993    Encoder_loss: 0.7858397960662842\n",
            "  epoch: 19/20,    batch: 319/2993    Encoder_loss: 0.7213858962059021\n",
            "  epoch: 19/20,    batch: 320/2993    Encoder_loss: 0.7235382199287415\n",
            "  epoch: 19/20,    batch: 321/2993    Encoder_loss: 0.7806600332260132\n",
            "  epoch: 19/20,    batch: 322/2993    Encoder_loss: 0.6903577446937561\n",
            "  epoch: 19/20,    batch: 323/2993    Encoder_loss: 0.7726497054100037\n",
            "  epoch: 19/20,    batch: 324/2993    Encoder_loss: 0.8036673069000244\n",
            "  epoch: 19/20,    batch: 325/2993    Encoder_loss: 0.7224887013435364\n",
            "  epoch: 19/20,    batch: 326/2993    Encoder_loss: 0.7719915509223938\n",
            "  epoch: 19/20,    batch: 327/2993    Encoder_loss: 0.7354097366333008\n",
            "  epoch: 19/20,    batch: 328/2993    Encoder_loss: 0.6692829132080078\n",
            "  epoch: 19/20,    batch: 329/2993    Encoder_loss: 0.7376226782798767\n",
            "  epoch: 19/20,    batch: 330/2993    Encoder_loss: 0.7565264105796814\n",
            "  epoch: 19/20,    batch: 331/2993    Encoder_loss: 0.6542779207229614\n",
            "  epoch: 19/20,    batch: 332/2993    Encoder_loss: 0.7227701544761658\n",
            "  epoch: 19/20,    batch: 333/2993    Encoder_loss: 0.7873550653457642\n",
            "  epoch: 19/20,    batch: 334/2993    Encoder_loss: 0.6703879237174988\n",
            "  epoch: 19/20,    batch: 335/2993    Encoder_loss: 0.6720253825187683\n",
            "  epoch: 19/20,    batch: 336/2993    Encoder_loss: 0.772456169128418\n",
            "  epoch: 19/20,    batch: 337/2993    Encoder_loss: 0.7266805768013\n",
            "  epoch: 19/20,    batch: 338/2993    Encoder_loss: 0.7121713161468506\n",
            "  epoch: 19/20,    batch: 339/2993    Encoder_loss: 0.7560492157936096\n",
            "  epoch: 19/20,    batch: 340/2993    Encoder_loss: 0.6881334185600281\n",
            "  epoch: 19/20,    batch: 341/2993    Encoder_loss: 0.6774721741676331\n",
            "  epoch: 19/20,    batch: 342/2993    Encoder_loss: 0.7337647676467896\n",
            "  epoch: 19/20,    batch: 343/2993    Encoder_loss: 0.7194997668266296\n",
            "  epoch: 19/20,    batch: 344/2993    Encoder_loss: 0.6988485455513\n",
            "  epoch: 19/20,    batch: 345/2993    Encoder_loss: 0.7714932560920715\n",
            "  epoch: 19/20,    batch: 346/2993    Encoder_loss: 0.7236879467964172\n",
            "  epoch: 19/20,    batch: 347/2993    Encoder_loss: 0.7097036838531494\n",
            "  epoch: 19/20,    batch: 348/2993    Encoder_loss: 0.7655362486839294\n",
            "  epoch: 19/20,    batch: 349/2993    Encoder_loss: 0.6908921599388123\n",
            "  epoch: 19/20,    batch: 350/2993    Encoder_loss: 0.6973298788070679\n",
            "  epoch: 19/20,    batch: 351/2993    Encoder_loss: 0.7578390836715698\n",
            "  epoch: 19/20,    batch: 352/2993    Encoder_loss: 0.6678304672241211\n",
            "  epoch: 19/20,    batch: 353/2993    Encoder_loss: 0.7192463278770447\n",
            "  epoch: 19/20,    batch: 354/2993    Encoder_loss: 0.762650728225708\n",
            "  epoch: 19/20,    batch: 355/2993    Encoder_loss: 0.6827985644340515\n",
            "  epoch: 19/20,    batch: 356/2993    Encoder_loss: 0.7363876700401306\n",
            "  epoch: 19/20,    batch: 357/2993    Encoder_loss: 0.7428673505783081\n",
            "  epoch: 19/20,    batch: 358/2993    Encoder_loss: 0.6977366209030151\n",
            "  epoch: 19/20,    batch: 359/2993    Encoder_loss: 0.7253725528717041\n",
            "  epoch: 19/20,    batch: 360/2993    Encoder_loss: 0.6897542476654053\n",
            "  epoch: 19/20,    batch: 361/2993    Encoder_loss: 0.6388881206512451\n",
            "  epoch: 19/20,    batch: 362/2993    Encoder_loss: 0.7075462937355042\n",
            "  epoch: 19/20,    batch: 363/2993    Encoder_loss: 0.7165684103965759\n",
            "  epoch: 19/20,    batch: 364/2993    Encoder_loss: 0.6391799449920654\n",
            "  epoch: 19/20,    batch: 365/2993    Encoder_loss: 0.7325271368026733\n",
            "  epoch: 19/20,    batch: 366/2993    Encoder_loss: 0.7535440325737\n",
            "  epoch: 19/20,    batch: 367/2993    Encoder_loss: 0.641620397567749\n",
            "  epoch: 19/20,    batch: 368/2993    Encoder_loss: 0.6910193562507629\n",
            "  epoch: 19/20,    batch: 369/2993    Encoder_loss: 0.7675313353538513\n",
            "  epoch: 19/20,    batch: 370/2993    Encoder_loss: 0.6784482598304749\n",
            "  epoch: 19/20,    batch: 371/2993    Encoder_loss: 0.6922101378440857\n",
            "  epoch: 19/20,    batch: 372/2993    Encoder_loss: 0.7355569005012512\n",
            "  epoch: 19/20,    batch: 373/2993    Encoder_loss: 0.6537109613418579\n",
            "  epoch: 19/20,    batch: 374/2993    Encoder_loss: 0.6846193671226501\n",
            "  epoch: 19/20,    batch: 375/2993    Encoder_loss: 0.7337801456451416\n",
            "  epoch: 19/20,    batch: 376/2993    Encoder_loss: 0.672156572341919\n",
            "  epoch: 19/20,    batch: 377/2993    Encoder_loss: 0.6749327778816223\n",
            "  epoch: 19/20,    batch: 378/2993    Encoder_loss: 0.7528856992721558\n",
            "  epoch: 19/20,    batch: 379/2993    Encoder_loss: 0.6918867230415344\n",
            "  epoch: 19/20,    batch: 380/2993    Encoder_loss: 0.6844168901443481\n",
            "  epoch: 19/20,    batch: 381/2993    Encoder_loss: 0.7530456781387329\n",
            "  epoch: 19/20,    batch: 382/2993    Encoder_loss: 0.6674988865852356\n",
            "  epoch: 19/20,    batch: 383/2993    Encoder_loss: 0.6984442472457886\n",
            "  epoch: 19/20,    batch: 384/2993    Encoder_loss: 0.7564286589622498\n",
            "  epoch: 19/20,    batch: 385/2993    Encoder_loss: 0.6575824618339539\n",
            "  epoch: 19/20,    batch: 386/2993    Encoder_loss: 0.708453893661499\n",
            "  epoch: 19/20,    batch: 387/2993    Encoder_loss: 0.7153720259666443\n",
            "  epoch: 19/20,    batch: 388/2993    Encoder_loss: 0.6319892406463623\n",
            "  epoch: 19/20,    batch: 389/2993    Encoder_loss: 0.715534508228302\n",
            "  epoch: 19/20,    batch: 390/2993    Encoder_loss: 0.7086594104766846\n",
            "  epoch: 19/20,    batch: 391/2993    Encoder_loss: 0.6638826131820679\n",
            "  epoch: 19/20,    batch: 392/2993    Encoder_loss: 0.7191091775894165\n",
            "  epoch: 19/20,    batch: 393/2993    Encoder_loss: 0.7099320888519287\n",
            "  epoch: 19/20,    batch: 394/2993    Encoder_loss: 0.6792379021644592\n",
            "  epoch: 19/20,    batch: 395/2993    Encoder_loss: 0.7270451188087463\n",
            "  epoch: 19/20,    batch: 396/2993    Encoder_loss: 0.7086703777313232\n",
            "  epoch: 19/20,    batch: 397/2993    Encoder_loss: 0.6396770477294922\n",
            "  epoch: 19/20,    batch: 398/2993    Encoder_loss: 0.7063038945198059\n",
            "  epoch: 19/20,    batch: 399/2993    Encoder_loss: 0.6951965689659119\n",
            "  epoch: 19/20,    batch: 400/2993    Encoder_loss: 0.6401007175445557\n",
            "  epoch: 19/20,    batch: 401/2993    Encoder_loss: 0.715770423412323\n",
            "  epoch: 19/20,    batch: 402/2993    Encoder_loss: 0.7398089170455933\n",
            "  epoch: 19/20,    batch: 403/2993    Encoder_loss: 0.6396892070770264\n",
            "  epoch: 19/20,    batch: 404/2993    Encoder_loss: 0.7088345885276794\n",
            "  epoch: 19/20,    batch: 405/2993    Encoder_loss: 0.7536017298698425\n",
            "  epoch: 19/20,    batch: 406/2993    Encoder_loss: 0.6378981471061707\n",
            "  epoch: 19/20,    batch: 407/2993    Encoder_loss: 0.6758822202682495\n",
            "  epoch: 19/20,    batch: 408/2993    Encoder_loss: 0.763484001159668\n",
            "  epoch: 19/20,    batch: 409/2993    Encoder_loss: 0.667281985282898\n",
            "  epoch: 19/20,    batch: 410/2993    Encoder_loss: 0.6574628353118896\n",
            "  epoch: 19/20,    batch: 411/2993    Encoder_loss: 0.7339140176773071\n",
            "  epoch: 19/20,    batch: 412/2993    Encoder_loss: 0.6397440433502197\n",
            "  epoch: 19/20,    batch: 413/2993    Encoder_loss: 0.6633223295211792\n",
            "  epoch: 19/20,    batch: 414/2993    Encoder_loss: 0.707785427570343\n",
            "  epoch: 19/20,    batch: 415/2993    Encoder_loss: 0.6023716330528259\n",
            "  epoch: 19/20,    batch: 416/2993    Encoder_loss: 0.6827061176300049\n",
            "  epoch: 19/20,    batch: 417/2993    Encoder_loss: 0.7137598395347595\n",
            "  epoch: 19/20,    batch: 418/2993    Encoder_loss: 0.6300337910652161\n",
            "  epoch: 19/20,    batch: 419/2993    Encoder_loss: 0.7070197463035583\n",
            "  epoch: 19/20,    batch: 420/2993    Encoder_loss: 0.6740052700042725\n",
            "  epoch: 19/20,    batch: 421/2993    Encoder_loss: 0.644436240196228\n",
            "  epoch: 19/20,    batch: 422/2993    Encoder_loss: 0.7303427457809448\n",
            "  epoch: 19/20,    batch: 423/2993    Encoder_loss: 0.6587190628051758\n",
            "  epoch: 19/20,    batch: 424/2993    Encoder_loss: 0.6660194396972656\n",
            "  epoch: 19/20,    batch: 425/2993    Encoder_loss: 0.7259043455123901\n",
            "  epoch: 19/20,    batch: 426/2993    Encoder_loss: 0.6612647175788879\n",
            "  epoch: 19/20,    batch: 427/2993    Encoder_loss: 0.6103413701057434\n",
            "  epoch: 19/20,    batch: 428/2993    Encoder_loss: 0.6984595060348511\n",
            "  epoch: 19/20,    batch: 429/2993    Encoder_loss: 0.7326700091362\n",
            "  epoch: 19/20,    batch: 430/2993    Encoder_loss: 0.6277088522911072\n",
            "  epoch: 19/20,    batch: 431/2993    Encoder_loss: 0.6472164392471313\n",
            "  epoch: 19/20,    batch: 432/2993    Encoder_loss: 0.7246628999710083\n",
            "  epoch: 19/20,    batch: 433/2993    Encoder_loss: 0.6483051180839539\n",
            "  epoch: 19/20,    batch: 434/2993    Encoder_loss: 0.6131400465965271\n",
            "  epoch: 19/20,    batch: 435/2993    Encoder_loss: 0.7145427465438843\n",
            "  epoch: 19/20,    batch: 436/2993    Encoder_loss: 0.7270486354827881\n",
            "  epoch: 19/20,    batch: 437/2993    Encoder_loss: 0.6024085879325867\n",
            "  epoch: 19/20,    batch: 438/2993    Encoder_loss: 0.6673739552497864\n",
            "  epoch: 19/20,    batch: 439/2993    Encoder_loss: 0.7502889037132263\n",
            "  epoch: 19/20,    batch: 440/2993    Encoder_loss: 0.6505984663963318\n",
            "  epoch: 19/20,    batch: 441/2993    Encoder_loss: 0.6404868364334106\n",
            "  epoch: 19/20,    batch: 442/2993    Encoder_loss: 0.741432249546051\n",
            "  epoch: 19/20,    batch: 443/2993    Encoder_loss: 0.7240771055221558\n",
            "  epoch: 19/20,    batch: 444/2993    Encoder_loss: 0.6243933439254761\n",
            "  epoch: 19/20,    batch: 445/2993    Encoder_loss: 0.7176673412322998\n",
            "  epoch: 19/20,    batch: 446/2993    Encoder_loss: 0.715596616268158\n",
            "  epoch: 19/20,    batch: 447/2993    Encoder_loss: 0.6251243352890015\n",
            "  epoch: 19/20,    batch: 448/2993    Encoder_loss: 0.6952383518218994\n",
            "  epoch: 19/20,    batch: 449/2993    Encoder_loss: 0.6925713419914246\n",
            "  epoch: 19/20,    batch: 450/2993    Encoder_loss: 0.6602584719657898\n",
            "  epoch: 19/20,    batch: 451/2993    Encoder_loss: 0.7222142815589905\n",
            "  epoch: 19/20,    batch: 452/2993    Encoder_loss: 0.6927065253257751\n",
            "  epoch: 19/20,    batch: 453/2993    Encoder_loss: 0.6740322113037109\n",
            "  epoch: 19/20,    batch: 454/2993    Encoder_loss: 0.7189072370529175\n",
            "  epoch: 19/20,    batch: 455/2993    Encoder_loss: 0.678159773349762\n",
            "  epoch: 19/20,    batch: 456/2993    Encoder_loss: 0.6972348690032959\n",
            "  epoch: 19/20,    batch: 457/2993    Encoder_loss: 0.733313798904419\n",
            "  epoch: 19/20,    batch: 458/2993    Encoder_loss: 0.6255448460578918\n",
            "  epoch: 19/20,    batch: 459/2993    Encoder_loss: 0.6690630316734314\n",
            "  epoch: 19/20,    batch: 460/2993    Encoder_loss: 0.7077663540840149\n",
            "  epoch: 19/20,    batch: 461/2993    Encoder_loss: 0.642342209815979\n",
            "  epoch: 19/20,    batch: 462/2993    Encoder_loss: 0.6503824591636658\n",
            "  epoch: 19/20,    batch: 463/2993    Encoder_loss: 0.7098255753517151\n",
            "  epoch: 19/20,    batch: 464/2993    Encoder_loss: 0.7038838863372803\n",
            "  epoch: 19/20,    batch: 465/2993    Encoder_loss: 0.6065873503684998\n",
            "  epoch: 19/20,    batch: 466/2993    Encoder_loss: 0.6829522252082825\n",
            "  epoch: 19/20,    batch: 467/2993    Encoder_loss: 0.7191693782806396\n",
            "  epoch: 19/20,    batch: 468/2993    Encoder_loss: 0.6247685551643372\n",
            "  epoch: 19/20,    batch: 469/2993    Encoder_loss: 0.6394603848457336\n",
            "  epoch: 19/20,    batch: 470/2993    Encoder_loss: 0.705686628818512\n",
            "  epoch: 19/20,    batch: 471/2993    Encoder_loss: 0.7185971736907959\n",
            "  epoch: 19/20,    batch: 472/2993    Encoder_loss: 0.6453483700752258\n",
            "  epoch: 19/20,    batch: 473/2993    Encoder_loss: 0.6906629204750061\n",
            "  epoch: 19/20,    batch: 474/2993    Encoder_loss: 0.7062480449676514\n",
            "  epoch: 19/20,    batch: 475/2993    Encoder_loss: 0.619525671005249\n",
            "  epoch: 19/20,    batch: 476/2993    Encoder_loss: 0.6603121161460876\n",
            "  epoch: 19/20,    batch: 477/2993    Encoder_loss: 0.7385488152503967\n",
            "  epoch: 19/20,    batch: 478/2993    Encoder_loss: 0.6596304774284363\n",
            "  epoch: 19/20,    batch: 479/2993    Encoder_loss: 0.6668002605438232\n",
            "  epoch: 19/20,    batch: 480/2993    Encoder_loss: 0.7403532862663269\n",
            "  epoch: 19/20,    batch: 481/2993    Encoder_loss: 0.6539422869682312\n",
            "  epoch: 19/20,    batch: 482/2993    Encoder_loss: 0.7093971371650696\n",
            "  epoch: 19/20,    batch: 483/2993    Encoder_loss: 0.7142806649208069\n",
            "  epoch: 19/20,    batch: 484/2993    Encoder_loss: 0.6185393929481506\n",
            "  epoch: 19/20,    batch: 485/2993    Encoder_loss: 0.6954442262649536\n",
            "  epoch: 19/20,    batch: 486/2993    Encoder_loss: 0.6940487623214722\n",
            "  epoch: 19/20,    batch: 487/2993    Encoder_loss: 0.6360570788383484\n",
            "  epoch: 19/20,    batch: 488/2993    Encoder_loss: 0.7153284549713135\n",
            "  epoch: 19/20,    batch: 489/2993    Encoder_loss: 0.6627925038337708\n",
            "  epoch: 19/20,    batch: 490/2993    Encoder_loss: 0.6391658186912537\n",
            "  epoch: 19/20,    batch: 491/2993    Encoder_loss: 0.7305604219436646\n",
            "  epoch: 19/20,    batch: 492/2993    Encoder_loss: 0.6500261425971985\n",
            "  epoch: 19/20,    batch: 493/2993    Encoder_loss: 0.6817079186439514\n",
            "  epoch: 19/20,    batch: 494/2993    Encoder_loss: 0.7544612884521484\n",
            "  epoch: 19/20,    batch: 495/2993    Encoder_loss: 0.6506702303886414\n",
            "  epoch: 19/20,    batch: 496/2993    Encoder_loss: 0.6096305251121521\n",
            "  epoch: 19/20,    batch: 497/2993    Encoder_loss: 0.7006604671478271\n",
            "  epoch: 19/20,    batch: 498/2993    Encoder_loss: 0.7382273077964783\n",
            "  epoch: 19/20,    batch: 499/2993    Encoder_loss: 0.6192895174026489\n",
            "  epoch: 19/20,    batch: 500/2993    Encoder_loss: 0.6731597185134888\n",
            "  epoch: 19/20,    batch: 501/2993    Encoder_loss: 0.7565520405769348\n",
            "  epoch: 19/20,    batch: 502/2993    Encoder_loss: 0.6626959443092346\n",
            "  epoch: 19/20,    batch: 503/2993    Encoder_loss: 0.6402522325515747\n",
            "  epoch: 19/20,    batch: 504/2993    Encoder_loss: 0.7146312594413757\n",
            "  epoch: 19/20,    batch: 505/2993    Encoder_loss: 0.7173105478286743\n",
            "  epoch: 19/20,    batch: 506/2993    Encoder_loss: 0.6235702633857727\n",
            "  epoch: 19/20,    batch: 507/2993    Encoder_loss: 0.717016875743866\n",
            "  epoch: 19/20,    batch: 508/2993    Encoder_loss: 0.7346941828727722\n",
            "  epoch: 19/20,    batch: 509/2993    Encoder_loss: 0.6454465985298157\n",
            "  epoch: 19/20,    batch: 510/2993    Encoder_loss: 0.6540795564651489\n",
            "  epoch: 19/20,    batch: 511/2993    Encoder_loss: 0.7463117241859436\n",
            "  epoch: 19/20,    batch: 512/2993    Encoder_loss: 0.7022078037261963\n",
            "  epoch: 19/20,    batch: 513/2993    Encoder_loss: 0.6048171520233154\n",
            "  epoch: 19/20,    batch: 514/2993    Encoder_loss: 0.7045753598213196\n",
            "  epoch: 19/20,    batch: 515/2993    Encoder_loss: 0.7088986039161682\n",
            "  epoch: 19/20,    batch: 516/2993    Encoder_loss: 0.6748349070549011\n",
            "  epoch: 19/20,    batch: 517/2993    Encoder_loss: 0.7535281777381897\n",
            "  epoch: 19/20,    batch: 518/2993    Encoder_loss: 0.6785081028938293\n",
            "  epoch: 19/20,    batch: 519/2993    Encoder_loss: 0.6542672514915466\n",
            "  epoch: 19/20,    batch: 520/2993    Encoder_loss: 0.7422783970832825\n",
            "  epoch: 19/20,    batch: 521/2993    Encoder_loss: 0.6910310983657837\n",
            "  epoch: 19/20,    batch: 522/2993    Encoder_loss: 0.6962680816650391\n",
            "  epoch: 19/20,    batch: 523/2993    Encoder_loss: 0.7522940039634705\n",
            "  epoch: 19/20,    batch: 524/2993    Encoder_loss: 0.6528710126876831\n",
            "  epoch: 19/20,    batch: 525/2993    Encoder_loss: 0.7050698399543762\n",
            "  epoch: 19/20,    batch: 526/2993    Encoder_loss: 0.7571538686752319\n",
            "  epoch: 19/20,    batch: 527/2993    Encoder_loss: 0.6660913228988647\n",
            "  epoch: 19/20,    batch: 528/2993    Encoder_loss: 0.706759512424469\n",
            "  epoch: 19/20,    batch: 529/2993    Encoder_loss: 0.6985796093940735\n",
            "  epoch: 19/20,    batch: 530/2993    Encoder_loss: 0.6115440130233765\n",
            "  epoch: 19/20,    batch: 531/2993    Encoder_loss: 0.6546072363853455\n",
            "  epoch: 19/20,    batch: 532/2993    Encoder_loss: 0.7283140420913696\n",
            "  epoch: 19/20,    batch: 533/2993    Encoder_loss: 0.6842545866966248\n",
            "  epoch: 19/20,    batch: 534/2993    Encoder_loss: 0.6456976532936096\n",
            "  epoch: 19/20,    batch: 535/2993    Encoder_loss: 0.7077891826629639\n",
            "  epoch: 19/20,    batch: 536/2993    Encoder_loss: 0.7014252543449402\n",
            "  epoch: 19/20,    batch: 537/2993    Encoder_loss: 0.619808554649353\n",
            "  epoch: 19/20,    batch: 538/2993    Encoder_loss: 0.6741048097610474\n",
            "  epoch: 19/20,    batch: 539/2993    Encoder_loss: 0.7331321239471436\n",
            "  epoch: 19/20,    batch: 540/2993    Encoder_loss: 0.6737412810325623\n",
            "  epoch: 19/20,    batch: 541/2993    Encoder_loss: 0.6767123341560364\n",
            "  epoch: 19/20,    batch: 542/2993    Encoder_loss: 0.7403956055641174\n",
            "  epoch: 19/20,    batch: 543/2993    Encoder_loss: 0.7144740223884583\n",
            "  epoch: 19/20,    batch: 544/2993    Encoder_loss: 0.5988380908966064\n",
            "  epoch: 19/20,    batch: 545/2993    Encoder_loss: 0.643792450428009\n",
            "  epoch: 19/20,    batch: 546/2993    Encoder_loss: 0.7219655513763428\n",
            "  epoch: 19/20,    batch: 547/2993    Encoder_loss: 0.6825451254844666\n",
            "  epoch: 19/20,    batch: 548/2993    Encoder_loss: 0.6820942163467407\n",
            "  epoch: 19/20,    batch: 549/2993    Encoder_loss: 0.7323305606842041\n",
            "  epoch: 19/20,    batch: 550/2993    Encoder_loss: 0.6536116003990173\n",
            "  epoch: 19/20,    batch: 551/2993    Encoder_loss: 0.6702407002449036\n",
            "  epoch: 19/20,    batch: 552/2993    Encoder_loss: 0.7453256845474243\n",
            "  epoch: 19/20,    batch: 553/2993    Encoder_loss: 0.634042501449585\n",
            "  epoch: 19/20,    batch: 554/2993    Encoder_loss: 0.6898936033248901\n",
            "  epoch: 19/20,    batch: 555/2993    Encoder_loss: 0.75016188621521\n",
            "  epoch: 19/20,    batch: 556/2993    Encoder_loss: 0.6429761052131653\n",
            "  epoch: 19/20,    batch: 557/2993    Encoder_loss: 0.7262929081916809\n",
            "  epoch: 19/20,    batch: 558/2993    Encoder_loss: 0.7267686724662781\n",
            "  epoch: 19/20,    batch: 559/2993    Encoder_loss: 0.6528300642967224\n",
            "  epoch: 19/20,    batch: 560/2993    Encoder_loss: 0.7452438473701477\n",
            "  epoch: 19/20,    batch: 561/2993    Encoder_loss: 0.6912024021148682\n",
            "  epoch: 19/20,    batch: 562/2993    Encoder_loss: 0.6589210033416748\n",
            "  epoch: 19/20,    batch: 563/2993    Encoder_loss: 0.7341955900192261\n",
            "  epoch: 19/20,    batch: 564/2993    Encoder_loss: 0.6985241174697876\n",
            "  epoch: 19/20,    batch: 565/2993    Encoder_loss: 0.5794520974159241\n",
            "  epoch: 19/20,    batch: 566/2993    Encoder_loss: 0.6824465394020081\n",
            "  epoch: 19/20,    batch: 567/2993    Encoder_loss: 0.7472808957099915\n",
            "  epoch: 19/20,    batch: 568/2993    Encoder_loss: 0.6416346430778503\n",
            "  epoch: 19/20,    batch: 569/2993    Encoder_loss: 0.6595321297645569\n",
            "  epoch: 19/20,    batch: 570/2993    Encoder_loss: 0.7184021472930908\n",
            "  epoch: 19/20,    batch: 571/2993    Encoder_loss: 0.6486421227455139\n",
            "  epoch: 19/20,    batch: 572/2993    Encoder_loss: 0.6683634519577026\n",
            "  epoch: 19/20,    batch: 573/2993    Encoder_loss: 0.7329248785972595\n",
            "  epoch: 19/20,    batch: 574/2993    Encoder_loss: 0.7026176452636719\n",
            "  epoch: 19/20,    batch: 575/2993    Encoder_loss: 0.7021322846412659\n",
            "  epoch: 19/20,    batch: 576/2993    Encoder_loss: 0.7449255585670471\n",
            "  epoch: 19/20,    batch: 577/2993    Encoder_loss: 0.6687164306640625\n",
            "  epoch: 19/20,    batch: 578/2993    Encoder_loss: 0.6552097797393799\n",
            "  epoch: 19/20,    batch: 579/2993    Encoder_loss: 0.7144116163253784\n",
            "  epoch: 19/20,    batch: 580/2993    Encoder_loss: 0.682571530342102\n",
            "  epoch: 19/20,    batch: 581/2993    Encoder_loss: 0.6459925770759583\n",
            "  epoch: 19/20,    batch: 582/2993    Encoder_loss: 0.7196524739265442\n",
            "  epoch: 19/20,    batch: 583/2993    Encoder_loss: 0.6634976267814636\n",
            "  epoch: 19/20,    batch: 584/2993    Encoder_loss: 0.6511207222938538\n",
            "  epoch: 19/20,    batch: 585/2993    Encoder_loss: 0.7273786664009094\n",
            "  epoch: 19/20,    batch: 586/2993    Encoder_loss: 0.6683499813079834\n",
            "  epoch: 19/20,    batch: 587/2993    Encoder_loss: 0.6665608882904053\n",
            "  epoch: 19/20,    batch: 588/2993    Encoder_loss: 0.7155610918998718\n",
            "  epoch: 19/20,    batch: 589/2993    Encoder_loss: 0.6220806837081909\n",
            "  epoch: 19/20,    batch: 590/2993    Encoder_loss: 0.6864430904388428\n",
            "  epoch: 19/20,    batch: 591/2993    Encoder_loss: 0.7294451594352722\n",
            "  epoch: 19/20,    batch: 592/2993    Encoder_loss: 0.6136079430580139\n",
            "  epoch: 19/20,    batch: 593/2993    Encoder_loss: 0.706616997718811\n",
            "  epoch: 19/20,    batch: 594/2993    Encoder_loss: 0.7217718362808228\n",
            "  epoch: 19/20,    batch: 595/2993    Encoder_loss: 0.6557691097259521\n",
            "  epoch: 19/20,    batch: 596/2993    Encoder_loss: 0.7506688833236694\n",
            "  epoch: 19/20,    batch: 597/2993    Encoder_loss: 0.7157198786735535\n",
            "  epoch: 19/20,    batch: 598/2993    Encoder_loss: 0.6080867648124695\n",
            "  epoch: 19/20,    batch: 599/2993    Encoder_loss: 0.6571321487426758\n",
            "  epoch: 19/20,    batch: 600/2993    Encoder_loss: 0.7609750628471375\n",
            "  epoch: 19/20,    batch: 601/2993    Encoder_loss: 0.6842073202133179\n",
            "  epoch: 19/20,    batch: 602/2993    Encoder_loss: 0.6476777195930481\n",
            "  epoch: 19/20,    batch: 603/2993    Encoder_loss: 0.7224778532981873\n",
            "  epoch: 19/20,    batch: 604/2993    Encoder_loss: 0.6987422704696655\n",
            "  epoch: 19/20,    batch: 605/2993    Encoder_loss: 0.6125996708869934\n",
            "  epoch: 19/20,    batch: 606/2993    Encoder_loss: 0.6799694299697876\n",
            "  epoch: 19/20,    batch: 607/2993    Encoder_loss: 0.7722182869911194\n",
            "  epoch: 19/20,    batch: 608/2993    Encoder_loss: 0.7024436593055725\n",
            "  epoch: 19/20,    batch: 609/2993    Encoder_loss: 0.701763391494751\n",
            "  epoch: 19/20,    batch: 610/2993    Encoder_loss: 0.7435606718063354\n",
            "  epoch: 19/20,    batch: 611/2993    Encoder_loss: 0.700157105922699\n",
            "  epoch: 19/20,    batch: 612/2993    Encoder_loss: 0.6120617985725403\n",
            "  epoch: 19/20,    batch: 613/2993    Encoder_loss: 0.7012599110603333\n",
            "  epoch: 19/20,    batch: 614/2993    Encoder_loss: 0.7801638245582581\n",
            "  epoch: 19/20,    batch: 615/2993    Encoder_loss: 0.690678060054779\n",
            "  epoch: 19/20,    batch: 616/2993    Encoder_loss: 0.6760794520378113\n",
            "  epoch: 19/20,    batch: 617/2993    Encoder_loss: 0.7496594190597534\n",
            "  epoch: 19/20,    batch: 618/2993    Encoder_loss: 0.6755161285400391\n",
            "  epoch: 19/20,    batch: 619/2993    Encoder_loss: 0.7115402817726135\n",
            "  epoch: 19/20,    batch: 620/2993    Encoder_loss: 0.7652924060821533\n",
            "  epoch: 19/20,    batch: 621/2993    Encoder_loss: 0.6434376239776611\n",
            "  epoch: 19/20,    batch: 622/2993    Encoder_loss: 0.7226765751838684\n",
            "  epoch: 19/20,    batch: 623/2993    Encoder_loss: 0.7415754795074463\n",
            "  epoch: 19/20,    batch: 624/2993    Encoder_loss: 0.6347888112068176\n",
            "  epoch: 19/20,    batch: 625/2993    Encoder_loss: 0.7517033815383911\n",
            "  epoch: 19/20,    batch: 626/2993    Encoder_loss: 0.7392660975456238\n",
            "  epoch: 19/20,    batch: 627/2993    Encoder_loss: 0.6406391263008118\n",
            "  epoch: 19/20,    batch: 628/2993    Encoder_loss: 0.7451027631759644\n",
            "  epoch: 19/20,    batch: 629/2993    Encoder_loss: 0.7020636200904846\n",
            "  epoch: 19/20,    batch: 630/2993    Encoder_loss: 0.6869050860404968\n",
            "  epoch: 19/20,    batch: 631/2993    Encoder_loss: 0.7478084564208984\n",
            "  epoch: 19/20,    batch: 632/2993    Encoder_loss: 0.6798350214958191\n",
            "  epoch: 19/20,    batch: 633/2993    Encoder_loss: 0.6533899903297424\n",
            "  epoch: 19/20,    batch: 634/2993    Encoder_loss: 0.7235491275787354\n",
            "  epoch: 19/20,    batch: 635/2993    Encoder_loss: 0.7176171541213989\n",
            "  epoch: 19/20,    batch: 636/2993    Encoder_loss: 0.67388516664505\n",
            "  epoch: 19/20,    batch: 637/2993    Encoder_loss: 0.7043149471282959\n",
            "  epoch: 19/20,    batch: 638/2993    Encoder_loss: 0.6651137471199036\n",
            "  epoch: 19/20,    batch: 639/2993    Encoder_loss: 0.6131333112716675\n",
            "  epoch: 19/20,    batch: 640/2993    Encoder_loss: 0.6605878472328186\n",
            "  epoch: 19/20,    batch: 641/2993    Encoder_loss: 0.6777898073196411\n",
            "  epoch: 19/20,    batch: 642/2993    Encoder_loss: 0.6069484949111938\n",
            "  epoch: 19/20,    batch: 643/2993    Encoder_loss: 0.7065094113349915\n",
            "  epoch: 19/20,    batch: 644/2993    Encoder_loss: 0.7248312830924988\n",
            "  epoch: 19/20,    batch: 645/2993    Encoder_loss: 0.6331177353858948\n",
            "  epoch: 19/20,    batch: 646/2993    Encoder_loss: 0.6785686016082764\n",
            "  epoch: 19/20,    batch: 647/2993    Encoder_loss: 0.7236650586128235\n",
            "  epoch: 19/20,    batch: 648/2993    Encoder_loss: 0.6259171962738037\n",
            "  epoch: 19/20,    batch: 649/2993    Encoder_loss: 0.6521754860877991\n",
            "  epoch: 19/20,    batch: 650/2993    Encoder_loss: 0.731184720993042\n",
            "  epoch: 19/20,    batch: 651/2993    Encoder_loss: 0.6124013066291809\n",
            "  epoch: 19/20,    batch: 652/2993    Encoder_loss: 0.6797128915786743\n",
            "  epoch: 19/20,    batch: 653/2993    Encoder_loss: 0.7256326675415039\n",
            "  epoch: 19/20,    batch: 654/2993    Encoder_loss: 0.6099290251731873\n",
            "  epoch: 19/20,    batch: 655/2993    Encoder_loss: 0.7012742757797241\n",
            "  epoch: 19/20,    batch: 656/2993    Encoder_loss: 0.6863919496536255\n",
            "  epoch: 19/20,    batch: 657/2993    Encoder_loss: 0.6189908385276794\n",
            "  epoch: 19/20,    batch: 658/2993    Encoder_loss: 0.7181605696678162\n",
            "  epoch: 19/20,    batch: 659/2993    Encoder_loss: 0.6637609601020813\n",
            "  epoch: 19/20,    batch: 660/2993    Encoder_loss: 0.639645516872406\n",
            "  epoch: 19/20,    batch: 661/2993    Encoder_loss: 0.7203585505485535\n",
            "  epoch: 19/20,    batch: 662/2993    Encoder_loss: 0.6376971006393433\n",
            "  epoch: 19/20,    batch: 663/2993    Encoder_loss: 0.6526906490325928\n",
            "  epoch: 19/20,    batch: 664/2993    Encoder_loss: 0.7219745516777039\n",
            "  epoch: 19/20,    batch: 665/2993    Encoder_loss: 0.6472488641738892\n",
            "  epoch: 19/20,    batch: 666/2993    Encoder_loss: 0.6463936567306519\n",
            "  epoch: 19/20,    batch: 667/2993    Encoder_loss: 0.7217457890510559\n",
            "  epoch: 19/20,    batch: 668/2993    Encoder_loss: 0.6874077320098877\n",
            "  epoch: 19/20,    batch: 669/2993    Encoder_loss: 0.6561439037322998\n",
            "  epoch: 19/20,    batch: 670/2993    Encoder_loss: 0.6856347322463989\n",
            "  epoch: 19/20,    batch: 671/2993    Encoder_loss: 0.6672008633613586\n",
            "  epoch: 19/20,    batch: 672/2993    Encoder_loss: 0.6442605257034302\n",
            "  epoch: 19/20,    batch: 673/2993    Encoder_loss: 0.692467987537384\n",
            "  epoch: 19/20,    batch: 674/2993    Encoder_loss: 0.6770464777946472\n",
            "  epoch: 19/20,    batch: 675/2993    Encoder_loss: 0.618678629398346\n",
            "  epoch: 19/20,    batch: 676/2993    Encoder_loss: 0.6996245980262756\n",
            "  epoch: 19/20,    batch: 677/2993    Encoder_loss: 0.6856748461723328\n",
            "  epoch: 19/20,    batch: 678/2993    Encoder_loss: 0.610784113407135\n",
            "  epoch: 19/20,    batch: 679/2993    Encoder_loss: 0.6892336010932922\n",
            "  epoch: 19/20,    batch: 680/2993    Encoder_loss: 0.7073633670806885\n",
            "  epoch: 19/20,    batch: 681/2993    Encoder_loss: 0.6080834865570068\n",
            "  epoch: 19/20,    batch: 682/2993    Encoder_loss: 0.7109521627426147\n",
            "  epoch: 19/20,    batch: 683/2993    Encoder_loss: 0.7616490721702576\n",
            "  epoch: 19/20,    batch: 684/2993    Encoder_loss: 0.6277551054954529\n",
            "  epoch: 19/20,    batch: 685/2993    Encoder_loss: 0.7155720591545105\n",
            "  epoch: 19/20,    batch: 686/2993    Encoder_loss: 0.6895389556884766\n",
            "  epoch: 19/20,    batch: 687/2993    Encoder_loss: 0.6274405121803284\n",
            "  epoch: 19/20,    batch: 688/2993    Encoder_loss: 0.7421965003013611\n",
            "  epoch: 19/20,    batch: 689/2993    Encoder_loss: 0.6893454790115356\n",
            "  epoch: 19/20,    batch: 690/2993    Encoder_loss: 0.6465736627578735\n",
            "  epoch: 19/20,    batch: 691/2993    Encoder_loss: 0.7186300754547119\n",
            "  epoch: 19/20,    batch: 692/2993    Encoder_loss: 0.657532274723053\n",
            "  epoch: 19/20,    batch: 693/2993    Encoder_loss: 0.6700084805488586\n",
            "  epoch: 19/20,    batch: 694/2993    Encoder_loss: 0.7279775738716125\n",
            "  epoch: 19/20,    batch: 695/2993    Encoder_loss: 0.6356580257415771\n",
            "  epoch: 19/20,    batch: 696/2993    Encoder_loss: 0.6938775777816772\n",
            "  epoch: 19/20,    batch: 697/2993    Encoder_loss: 0.7359803318977356\n",
            "  epoch: 19/20,    batch: 698/2993    Encoder_loss: 0.6350221037864685\n",
            "  epoch: 19/20,    batch: 699/2993    Encoder_loss: 0.6553880572319031\n",
            "  epoch: 19/20,    batch: 700/2993    Encoder_loss: 0.7409541010856628\n",
            "  epoch: 19/20,    batch: 701/2993    Encoder_loss: 0.6602643132209778\n",
            "  epoch: 19/20,    batch: 702/2993    Encoder_loss: 0.6428822875022888\n",
            "  epoch: 19/20,    batch: 703/2993    Encoder_loss: 0.7085409760475159\n",
            "  epoch: 19/20,    batch: 704/2993    Encoder_loss: 0.6627241373062134\n",
            "  epoch: 19/20,    batch: 705/2993    Encoder_loss: 0.6369123458862305\n",
            "  epoch: 19/20,    batch: 706/2993    Encoder_loss: 0.7050827145576477\n",
            "  epoch: 19/20,    batch: 707/2993    Encoder_loss: 0.6969032287597656\n",
            "  epoch: 19/20,    batch: 708/2993    Encoder_loss: 0.6562721729278564\n",
            "  epoch: 19/20,    batch: 709/2993    Encoder_loss: 0.7037079334259033\n",
            "  epoch: 19/20,    batch: 710/2993    Encoder_loss: 0.6824256777763367\n",
            "  epoch: 19/20,    batch: 711/2993    Encoder_loss: 0.6274569034576416\n",
            "  epoch: 19/20,    batch: 712/2993    Encoder_loss: 0.6989189982414246\n",
            "  epoch: 19/20,    batch: 713/2993    Encoder_loss: 0.7162653803825378\n",
            "  epoch: 19/20,    batch: 714/2993    Encoder_loss: 0.6295404434204102\n",
            "  epoch: 19/20,    batch: 715/2993    Encoder_loss: 0.7174464464187622\n",
            "  epoch: 19/20,    batch: 716/2993    Encoder_loss: 0.7128713130950928\n",
            "  epoch: 19/20,    batch: 717/2993    Encoder_loss: 0.6486715078353882\n",
            "  epoch: 19/20,    batch: 718/2993    Encoder_loss: 0.7467448115348816\n",
            "  epoch: 19/20,    batch: 719/2993    Encoder_loss: 0.680111825466156\n",
            "  epoch: 19/20,    batch: 720/2993    Encoder_loss: 0.6608267426490784\n",
            "  epoch: 19/20,    batch: 721/2993    Encoder_loss: 0.7571372985839844\n",
            "  epoch: 19/20,    batch: 722/2993    Encoder_loss: 0.6754258275032043\n",
            "  epoch: 19/20,    batch: 723/2993    Encoder_loss: 0.6926372647285461\n",
            "  epoch: 19/20,    batch: 724/2993    Encoder_loss: 0.762442409992218\n",
            "  epoch: 19/20,    batch: 725/2993    Encoder_loss: 0.644335150718689\n",
            "  epoch: 19/20,    batch: 726/2993    Encoder_loss: 0.7120769619941711\n",
            "  epoch: 19/20,    batch: 727/2993    Encoder_loss: 0.7682330012321472\n",
            "  epoch: 19/20,    batch: 728/2993    Encoder_loss: 0.6456312537193298\n",
            "  epoch: 19/20,    batch: 729/2993    Encoder_loss: 0.7129093408584595\n",
            "  epoch: 19/20,    batch: 730/2993    Encoder_loss: 0.7216318845748901\n",
            "  epoch: 19/20,    batch: 731/2993    Encoder_loss: 0.6233787536621094\n",
            "  epoch: 19/20,    batch: 732/2993    Encoder_loss: 0.6756673455238342\n",
            "  epoch: 19/20,    batch: 733/2993    Encoder_loss: 0.7535040974617004\n",
            "  epoch: 19/20,    batch: 734/2993    Encoder_loss: 0.6839948892593384\n",
            "  epoch: 19/20,    batch: 735/2993    Encoder_loss: 0.7166505455970764\n",
            "  epoch: 19/20,    batch: 736/2993    Encoder_loss: 0.7483171224594116\n",
            "  epoch: 19/20,    batch: 737/2993    Encoder_loss: 0.6527839303016663\n",
            "  epoch: 19/20,    batch: 738/2993    Encoder_loss: 0.6601612567901611\n",
            "  epoch: 19/20,    batch: 739/2993    Encoder_loss: 0.7214502692222595\n",
            "  epoch: 19/20,    batch: 740/2993    Encoder_loss: 0.6710812449455261\n",
            "  epoch: 19/20,    batch: 741/2993    Encoder_loss: 0.6571835875511169\n",
            "  epoch: 19/20,    batch: 742/2993    Encoder_loss: 0.7149305939674377\n",
            "  epoch: 19/20,    batch: 743/2993    Encoder_loss: 0.6495720148086548\n",
            "  epoch: 19/20,    batch: 744/2993    Encoder_loss: 0.6052398681640625\n",
            "  epoch: 19/20,    batch: 745/2993    Encoder_loss: 0.6920862197875977\n",
            "  epoch: 19/20,    batch: 746/2993    Encoder_loss: 0.6868720650672913\n",
            "  epoch: 19/20,    batch: 747/2993    Encoder_loss: 0.6532554626464844\n",
            "  epoch: 19/20,    batch: 748/2993    Encoder_loss: 0.7534088492393494\n",
            "  epoch: 19/20,    batch: 749/2993    Encoder_loss: 0.6710459589958191\n",
            "  epoch: 19/20,    batch: 750/2993    Encoder_loss: 0.6470813751220703\n",
            "  epoch: 19/20,    batch: 751/2993    Encoder_loss: 0.7361734509468079\n",
            "  epoch: 19/20,    batch: 752/2993    Encoder_loss: 0.671923041343689\n",
            "  epoch: 19/20,    batch: 753/2993    Encoder_loss: 0.6875903010368347\n",
            "  epoch: 19/20,    batch: 754/2993    Encoder_loss: 0.7491501569747925\n",
            "  epoch: 19/20,    batch: 755/2993    Encoder_loss: 0.6176992058753967\n",
            "  epoch: 19/20,    batch: 756/2993    Encoder_loss: 0.6716453433036804\n",
            "  epoch: 19/20,    batch: 757/2993    Encoder_loss: 0.7294284105300903\n",
            "  epoch: 19/20,    batch: 758/2993    Encoder_loss: 0.6038964986801147\n",
            "  epoch: 19/20,    batch: 759/2993    Encoder_loss: 0.6911939978599548\n",
            "  epoch: 19/20,    batch: 760/2993    Encoder_loss: 0.7118877172470093\n",
            "  epoch: 19/20,    batch: 761/2993    Encoder_loss: 0.6276798844337463\n",
            "  epoch: 19/20,    batch: 762/2993    Encoder_loss: 0.6997014880180359\n",
            "  epoch: 19/20,    batch: 763/2993    Encoder_loss: 0.6686770915985107\n",
            "  epoch: 19/20,    batch: 764/2993    Encoder_loss: 0.5688894391059875\n",
            "  epoch: 19/20,    batch: 765/2993    Encoder_loss: 0.6552163362503052\n",
            "  epoch: 19/20,    batch: 766/2993    Encoder_loss: 0.7088201642036438\n",
            "  epoch: 19/20,    batch: 767/2993    Encoder_loss: 0.5834938287734985\n",
            "  epoch: 19/20,    batch: 768/2993    Encoder_loss: 0.6231161952018738\n",
            "  epoch: 19/20,    batch: 769/2993    Encoder_loss: 0.6817148923873901\n",
            "  epoch: 19/20,    batch: 770/2993    Encoder_loss: 0.5663240551948547\n",
            "  epoch: 19/20,    batch: 771/2993    Encoder_loss: 0.5667688250541687\n",
            "  epoch: 19/20,    batch: 772/2993    Encoder_loss: 0.6497170925140381\n",
            "  epoch: 19/20,    batch: 773/2993    Encoder_loss: 0.6305802464485168\n",
            "  epoch: 19/20,    batch: 774/2993    Encoder_loss: 0.6310967803001404\n",
            "  epoch: 19/20,    batch: 775/2993    Encoder_loss: 0.7040751576423645\n",
            "  epoch: 19/20,    batch: 776/2993    Encoder_loss: 0.6402329802513123\n",
            "  epoch: 19/20,    batch: 777/2993    Encoder_loss: 0.5737170577049255\n",
            "  epoch: 19/20,    batch: 778/2993    Encoder_loss: 0.6613239645957947\n",
            "  epoch: 19/20,    batch: 779/2993    Encoder_loss: 0.674629807472229\n",
            "  epoch: 19/20,    batch: 780/2993    Encoder_loss: 0.5795409083366394\n",
            "  epoch: 19/20,    batch: 781/2993    Encoder_loss: 0.6734579801559448\n",
            "  epoch: 19/20,    batch: 782/2993    Encoder_loss: 0.6835963726043701\n",
            "  epoch: 19/20,    batch: 783/2993    Encoder_loss: 0.6104363203048706\n",
            "  epoch: 19/20,    batch: 784/2993    Encoder_loss: 0.7028539776802063\n",
            "  epoch: 19/20,    batch: 785/2993    Encoder_loss: 0.6331713199615479\n",
            "  epoch: 19/20,    batch: 786/2993    Encoder_loss: 0.6003128290176392\n",
            "  epoch: 19/20,    batch: 787/2993    Encoder_loss: 0.6832911968231201\n",
            "  epoch: 19/20,    batch: 788/2993    Encoder_loss: 0.6098869442939758\n",
            "  epoch: 19/20,    batch: 789/2993    Encoder_loss: 0.6462996602058411\n",
            "  epoch: 19/20,    batch: 790/2993    Encoder_loss: 0.7261061072349548\n",
            "  epoch: 19/20,    batch: 791/2993    Encoder_loss: 0.6059176325798035\n",
            "  epoch: 19/20,    batch: 792/2993    Encoder_loss: 0.6616331338882446\n",
            "  epoch: 19/20,    batch: 793/2993    Encoder_loss: 0.7119519710540771\n",
            "  epoch: 19/20,    batch: 794/2993    Encoder_loss: 0.584630012512207\n",
            "  epoch: 19/20,    batch: 795/2993    Encoder_loss: 0.6534214019775391\n",
            "  epoch: 19/20,    batch: 796/2993    Encoder_loss: 0.6830182671546936\n",
            "  epoch: 19/20,    batch: 797/2993    Encoder_loss: 0.5734946727752686\n",
            "  epoch: 19/20,    batch: 798/2993    Encoder_loss: 0.6240412592887878\n",
            "  epoch: 19/20,    batch: 799/2993    Encoder_loss: 0.6905109286308289\n",
            "  epoch: 19/20,    batch: 800/2993    Encoder_loss: 0.5936301946640015\n",
            "  epoch: 19/20,    batch: 801/2993    Encoder_loss: 0.6029446721076965\n",
            "  epoch: 19/20,    batch: 802/2993    Encoder_loss: 0.6592445373535156\n",
            "  epoch: 19/20,    batch: 803/2993    Encoder_loss: 0.583104133605957\n",
            "  epoch: 19/20,    batch: 804/2993    Encoder_loss: 0.5771893262863159\n",
            "  epoch: 19/20,    batch: 805/2993    Encoder_loss: 0.6519612073898315\n",
            "  epoch: 19/20,    batch: 806/2993    Encoder_loss: 0.6225736141204834\n",
            "  epoch: 19/20,    batch: 807/2993    Encoder_loss: 0.6064837574958801\n",
            "  epoch: 19/20,    batch: 808/2993    Encoder_loss: 0.6514400243759155\n",
            "  epoch: 19/20,    batch: 809/2993    Encoder_loss: 0.5939275026321411\n",
            "  epoch: 19/20,    batch: 810/2993    Encoder_loss: 0.5773675441741943\n",
            "  epoch: 19/20,    batch: 811/2993    Encoder_loss: 0.6729094982147217\n",
            "  epoch: 19/20,    batch: 812/2993    Encoder_loss: 0.6358212828636169\n",
            "  epoch: 19/20,    batch: 813/2993    Encoder_loss: 0.5923916101455688\n",
            "  epoch: 19/20,    batch: 814/2993    Encoder_loss: 0.6908349990844727\n",
            "  epoch: 19/20,    batch: 815/2993    Encoder_loss: 0.6096192598342896\n",
            "  epoch: 19/20,    batch: 816/2993    Encoder_loss: 0.5849840641021729\n",
            "  epoch: 19/20,    batch: 817/2993    Encoder_loss: 0.6971555352210999\n",
            "  epoch: 19/20,    batch: 818/2993    Encoder_loss: 0.6115785837173462\n",
            "  epoch: 19/20,    batch: 819/2993    Encoder_loss: 0.6185070276260376\n",
            "  epoch: 19/20,    batch: 820/2993    Encoder_loss: 0.7164362668991089\n",
            "  epoch: 19/20,    batch: 821/2993    Encoder_loss: 0.5892002582550049\n",
            "  epoch: 19/20,    batch: 822/2993    Encoder_loss: 0.6492800116539001\n",
            "  epoch: 19/20,    batch: 823/2993    Encoder_loss: 0.7124613523483276\n",
            "  epoch: 19/20,    batch: 824/2993    Encoder_loss: 0.5688151121139526\n",
            "  epoch: 19/20,    batch: 825/2993    Encoder_loss: 0.668332040309906\n",
            "  epoch: 19/20,    batch: 826/2993    Encoder_loss: 0.6751732230186462\n",
            "  epoch: 19/20,    batch: 827/2993    Encoder_loss: 0.5808008909225464\n",
            "  epoch: 19/20,    batch: 828/2993    Encoder_loss: 0.67731112241745\n",
            "  epoch: 19/20,    batch: 829/2993    Encoder_loss: 0.681494414806366\n",
            "  epoch: 19/20,    batch: 830/2993    Encoder_loss: 0.5689030885696411\n",
            "  epoch: 19/20,    batch: 831/2993    Encoder_loss: 0.6273860931396484\n",
            "  epoch: 19/20,    batch: 832/2993    Encoder_loss: 0.6603057384490967\n",
            "  epoch: 19/20,    batch: 833/2993    Encoder_loss: 0.5814163684844971\n",
            "  epoch: 19/20,    batch: 834/2993    Encoder_loss: 0.6310043931007385\n",
            "  epoch: 19/20,    batch: 835/2993    Encoder_loss: 0.6816549301147461\n",
            "  epoch: 19/20,    batch: 836/2993    Encoder_loss: 0.5971218347549438\n",
            "  epoch: 19/20,    batch: 837/2993    Encoder_loss: 0.6024876832962036\n",
            "  epoch: 19/20,    batch: 838/2993    Encoder_loss: 0.6884738206863403\n",
            "  epoch: 19/20,    batch: 839/2993    Encoder_loss: 0.6169866323471069\n",
            "  epoch: 19/20,    batch: 840/2993    Encoder_loss: 0.6159037947654724\n",
            "  epoch: 19/20,    batch: 841/2993    Encoder_loss: 0.714587926864624\n",
            "  epoch: 19/20,    batch: 842/2993    Encoder_loss: 0.6849834322929382\n",
            "  epoch: 19/20,    batch: 843/2993    Encoder_loss: 0.5951964855194092\n",
            "  epoch: 19/20,    batch: 844/2993    Encoder_loss: 0.6745319366455078\n",
            "  epoch: 19/20,    batch: 845/2993    Encoder_loss: 0.7094689011573792\n",
            "  epoch: 19/20,    batch: 846/2993    Encoder_loss: 0.6211051940917969\n",
            "  epoch: 19/20,    batch: 847/2993    Encoder_loss: 0.6422345042228699\n",
            "  epoch: 19/20,    batch: 848/2993    Encoder_loss: 0.7037263512611389\n",
            "  epoch: 19/20,    batch: 849/2993    Encoder_loss: 0.6421763896942139\n",
            "  epoch: 19/20,    batch: 850/2993    Encoder_loss: 0.6726809144020081\n",
            "  epoch: 19/20,    batch: 851/2993    Encoder_loss: 0.6902514100074768\n",
            "  epoch: 19/20,    batch: 852/2993    Encoder_loss: 0.6260865926742554\n",
            "  epoch: 19/20,    batch: 853/2993    Encoder_loss: 0.6691606044769287\n",
            "  epoch: 19/20,    batch: 854/2993    Encoder_loss: 0.6727264523506165\n",
            "  epoch: 19/20,    batch: 855/2993    Encoder_loss: 0.6459453701972961\n",
            "  epoch: 19/20,    batch: 856/2993    Encoder_loss: 0.6678037047386169\n",
            "  epoch: 19/20,    batch: 857/2993    Encoder_loss: 0.6080426573753357\n",
            "  epoch: 19/20,    batch: 858/2993    Encoder_loss: 0.5909961462020874\n",
            "  epoch: 19/20,    batch: 859/2993    Encoder_loss: 0.5812853574752808\n",
            "  epoch: 19/20,    batch: 860/2993    Encoder_loss: 0.5902349352836609\n",
            "  epoch: 19/20,    batch: 861/2993    Encoder_loss: 0.5977155566215515\n",
            "  epoch: 19/20,    batch: 862/2993    Encoder_loss: 0.59565269947052\n",
            "  epoch: 19/20,    batch: 863/2993    Encoder_loss: 0.5906150937080383\n",
            "  epoch: 19/20,    batch: 864/2993    Encoder_loss: 0.5903188586235046\n",
            "  epoch: 19/20,    batch: 865/2993    Encoder_loss: 0.593031644821167\n",
            "  epoch: 19/20,    batch: 866/2993    Encoder_loss: 0.5932552814483643\n",
            "  epoch: 19/20,    batch: 867/2993    Encoder_loss: 0.5872563123703003\n",
            "  epoch: 19/20,    batch: 868/2993    Encoder_loss: 0.584004819393158\n",
            "  epoch: 19/20,    batch: 869/2993    Encoder_loss: 0.5834134221076965\n",
            "  epoch: 19/20,    batch: 870/2993    Encoder_loss: 0.5869351625442505\n",
            "  epoch: 19/20,    batch: 871/2993    Encoder_loss: 0.5903788208961487\n",
            "  epoch: 19/20,    batch: 872/2993    Encoder_loss: 0.5858376622200012\n",
            "  epoch: 19/20,    batch: 873/2993    Encoder_loss: 0.5841346383094788\n",
            "  epoch: 19/20,    batch: 874/2993    Encoder_loss: 0.583749532699585\n",
            "  epoch: 19/20,    batch: 875/2993    Encoder_loss: 0.5857141017913818\n",
            "  epoch: 19/20,    batch: 876/2993    Encoder_loss: 0.5872475504875183\n",
            "  epoch: 19/20,    batch: 877/2993    Encoder_loss: 0.5831871032714844\n",
            "  epoch: 19/20,    batch: 878/2993    Encoder_loss: 0.5822880864143372\n",
            "  epoch: 19/20,    batch: 879/2993    Encoder_loss: 0.5819265246391296\n",
            "  epoch: 19/20,    batch: 880/2993    Encoder_loss: 0.5809891819953918\n",
            "  epoch: 19/20,    batch: 881/2993    Encoder_loss: 0.5863410830497742\n",
            "  epoch: 19/20,    batch: 882/2993    Encoder_loss: 0.5937162637710571\n",
            "  epoch: 19/20,    batch: 883/2993    Encoder_loss: 0.7071081399917603\n",
            "  epoch: 19/20,    batch: 884/2993    Encoder_loss: 0.7012714147567749\n",
            "  epoch: 19/20,    batch: 885/2993    Encoder_loss: 0.6293281316757202\n",
            "  epoch: 19/20,    batch: 886/2993    Encoder_loss: 0.5790298581123352\n",
            "  epoch: 19/20,    batch: 887/2993    Encoder_loss: 0.6707563996315002\n",
            "  epoch: 19/20,    batch: 888/2993    Encoder_loss: 0.6975096464157104\n",
            "  epoch: 19/20,    batch: 889/2993    Encoder_loss: 0.5911277532577515\n",
            "  epoch: 19/20,    batch: 890/2993    Encoder_loss: 0.6507589221000671\n",
            "  epoch: 19/20,    batch: 891/2993    Encoder_loss: 0.7133943438529968\n",
            "  epoch: 19/20,    batch: 892/2993    Encoder_loss: 0.644819974899292\n",
            "  epoch: 19/20,    batch: 893/2993    Encoder_loss: 0.6175521612167358\n",
            "  epoch: 19/20,    batch: 894/2993    Encoder_loss: 0.6733248233795166\n",
            "  epoch: 19/20,    batch: 895/2993    Encoder_loss: 0.6595394015312195\n",
            "  epoch: 19/20,    batch: 896/2993    Encoder_loss: 0.5725430846214294\n",
            "  epoch: 19/20,    batch: 897/2993    Encoder_loss: 0.6287875771522522\n",
            "  epoch: 19/20,    batch: 898/2993    Encoder_loss: 0.667930006980896\n",
            "  epoch: 19/20,    batch: 899/2993    Encoder_loss: 0.6046113967895508\n",
            "  epoch: 19/20,    batch: 900/2993    Encoder_loss: 0.5887901186943054\n",
            "  epoch: 19/20,    batch: 901/2993    Encoder_loss: 0.6526204347610474\n",
            "  epoch: 19/20,    batch: 902/2993    Encoder_loss: 0.6655227541923523\n",
            "  epoch: 19/20,    batch: 903/2993    Encoder_loss: 0.582500696182251\n",
            "  epoch: 19/20,    batch: 904/2993    Encoder_loss: 0.6490724682807922\n",
            "  epoch: 19/20,    batch: 905/2993    Encoder_loss: 0.6911290287971497\n",
            "  epoch: 19/20,    batch: 906/2993    Encoder_loss: 0.6064597368240356\n",
            "  epoch: 19/20,    batch: 907/2993    Encoder_loss: 0.6768186092376709\n",
            "  epoch: 19/20,    batch: 908/2993    Encoder_loss: 0.6793709397315979\n",
            "  epoch: 19/20,    batch: 909/2993    Encoder_loss: 0.609508216381073\n",
            "  epoch: 19/20,    batch: 910/2993    Encoder_loss: 0.6927957534790039\n",
            "  epoch: 19/20,    batch: 911/2993    Encoder_loss: 0.6499828100204468\n",
            "  epoch: 19/20,    batch: 912/2993    Encoder_loss: 0.6222737431526184\n",
            "  epoch: 19/20,    batch: 913/2993    Encoder_loss: 0.7075669765472412\n",
            "  epoch: 19/20,    batch: 914/2993    Encoder_loss: 0.6191028952598572\n",
            "  epoch: 19/20,    batch: 915/2993    Encoder_loss: 0.6226558685302734\n",
            "  epoch: 19/20,    batch: 916/2993    Encoder_loss: 0.699672281742096\n",
            "  epoch: 19/20,    batch: 917/2993    Encoder_loss: 0.5813284516334534\n",
            "  epoch: 19/20,    batch: 918/2993    Encoder_loss: 0.6353985071182251\n",
            "  epoch: 19/20,    batch: 919/2993    Encoder_loss: 0.7001955509185791\n",
            "  epoch: 19/20,    batch: 920/2993    Encoder_loss: 0.6130520105361938\n",
            "  epoch: 19/20,    batch: 921/2993    Encoder_loss: 0.6200682520866394\n",
            "  epoch: 19/20,    batch: 922/2993    Encoder_loss: 0.6813365817070007\n",
            "  epoch: 19/20,    batch: 923/2993    Encoder_loss: 0.6860134601593018\n",
            "  epoch: 19/20,    batch: 924/2993    Encoder_loss: 0.6042883992195129\n",
            "  epoch: 19/20,    batch: 925/2993    Encoder_loss: 0.6704856753349304\n",
            "  epoch: 19/20,    batch: 926/2993    Encoder_loss: 0.6961826086044312\n",
            "  epoch: 19/20,    batch: 927/2993    Encoder_loss: 0.572167694568634\n",
            "  epoch: 19/20,    batch: 928/2993    Encoder_loss: 0.5720942616462708\n",
            "  epoch: 19/20,    batch: 929/2993    Encoder_loss: 0.6690763831138611\n",
            "  epoch: 19/20,    batch: 930/2993    Encoder_loss: 0.6441762447357178\n",
            "  epoch: 19/20,    batch: 931/2993    Encoder_loss: 0.5497885346412659\n",
            "  epoch: 19/20,    batch: 932/2993    Encoder_loss: 0.6496719121932983\n",
            "  epoch: 19/20,    batch: 933/2993    Encoder_loss: 0.6627344489097595\n",
            "  epoch: 19/20,    batch: 934/2993    Encoder_loss: 0.5798702239990234\n",
            "  epoch: 19/20,    batch: 935/2993    Encoder_loss: 0.6076189875602722\n",
            "  epoch: 19/20,    batch: 936/2993    Encoder_loss: 0.6585983633995056\n",
            "  epoch: 19/20,    batch: 937/2993    Encoder_loss: 0.590467095375061\n",
            "  epoch: 19/20,    batch: 938/2993    Encoder_loss: 0.5617967247962952\n",
            "  epoch: 19/20,    batch: 939/2993    Encoder_loss: 0.6649529933929443\n",
            "  epoch: 19/20,    batch: 940/2993    Encoder_loss: 0.7965023517608643\n",
            "  epoch: 19/20,    batch: 941/2993    Encoder_loss: 0.7437790632247925\n",
            "  epoch: 19/20,    batch: 942/2993    Encoder_loss: 0.603344738483429\n",
            "  epoch: 19/20,    batch: 943/2993    Encoder_loss: 0.6690191030502319\n",
            "  epoch: 19/20,    batch: 944/2993    Encoder_loss: 0.6334051489830017\n",
            "  epoch: 19/20,    batch: 945/2993    Encoder_loss: 0.5771323442459106\n",
            "  epoch: 19/20,    batch: 946/2993    Encoder_loss: 0.6486114263534546\n",
            "  epoch: 19/20,    batch: 947/2993    Encoder_loss: 0.5888243913650513\n",
            "  epoch: 19/20,    batch: 948/2993    Encoder_loss: 0.5920934677124023\n",
            "  epoch: 19/20,    batch: 949/2993    Encoder_loss: 0.6696134209632874\n",
            "  epoch: 19/20,    batch: 950/2993    Encoder_loss: 0.5653895139694214\n",
            "  epoch: 19/20,    batch: 951/2993    Encoder_loss: 0.5883355736732483\n",
            "  epoch: 19/20,    batch: 952/2993    Encoder_loss: 0.6841155886650085\n",
            "  epoch: 19/20,    batch: 953/2993    Encoder_loss: 0.5867844820022583\n",
            "  epoch: 19/20,    batch: 954/2993    Encoder_loss: 0.6504948735237122\n",
            "  epoch: 19/20,    batch: 955/2993    Encoder_loss: 0.6885899305343628\n",
            "  epoch: 19/20,    batch: 956/2993    Encoder_loss: 0.5786932110786438\n",
            "  epoch: 19/20,    batch: 957/2993    Encoder_loss: 0.5638074278831482\n",
            "  epoch: 19/20,    batch: 958/2993    Encoder_loss: 0.6376925110816956\n",
            "  epoch: 19/20,    batch: 959/2993    Encoder_loss: 0.656460165977478\n",
            "  epoch: 19/20,    batch: 960/2993    Encoder_loss: 0.5467942357063293\n",
            "  epoch: 19/20,    batch: 961/2993    Encoder_loss: 0.6305261254310608\n",
            "  epoch: 19/20,    batch: 962/2993    Encoder_loss: 0.7256802916526794\n",
            "  epoch: 19/20,    batch: 963/2993    Encoder_loss: 0.6564438343048096\n",
            "  epoch: 19/20,    batch: 964/2993    Encoder_loss: 0.6750988364219666\n",
            "  epoch: 19/20,    batch: 965/2993    Encoder_loss: 0.7274433374404907\n",
            "  epoch: 19/20,    batch: 966/2993    Encoder_loss: 0.6912075877189636\n",
            "  epoch: 19/20,    batch: 967/2993    Encoder_loss: 0.6287534236907959\n",
            "  epoch: 19/20,    batch: 968/2993    Encoder_loss: 0.6882304549217224\n",
            "  epoch: 19/20,    batch: 969/2993    Encoder_loss: 0.6488624811172485\n",
            "  epoch: 19/20,    batch: 970/2993    Encoder_loss: 0.5619888305664062\n",
            "  epoch: 19/20,    batch: 971/2993    Encoder_loss: 0.603399395942688\n",
            "  epoch: 19/20,    batch: 972/2993    Encoder_loss: 0.6757148504257202\n",
            "  epoch: 19/20,    batch: 973/2993    Encoder_loss: 0.6145193576812744\n",
            "  epoch: 19/20,    batch: 974/2993    Encoder_loss: 0.5345142483711243\n",
            "  epoch: 19/20,    batch: 975/2993    Encoder_loss: 0.6126989722251892\n",
            "  epoch: 19/20,    batch: 976/2993    Encoder_loss: 0.634495198726654\n",
            "  epoch: 19/20,    batch: 977/2993    Encoder_loss: 0.6178097128868103\n",
            "  epoch: 19/20,    batch: 978/2993    Encoder_loss: 0.6425492763519287\n",
            "  epoch: 19/20,    batch: 979/2993    Encoder_loss: 0.5885006189346313\n",
            "  epoch: 19/20,    batch: 980/2993    Encoder_loss: 0.6021050214767456\n",
            "  epoch: 19/20,    batch: 981/2993    Encoder_loss: 0.6637203693389893\n",
            "  epoch: 19/20,    batch: 982/2993    Encoder_loss: 0.5883646011352539\n",
            "  epoch: 19/20,    batch: 983/2993    Encoder_loss: 0.6079924702644348\n",
            "  epoch: 19/20,    batch: 984/2993    Encoder_loss: 0.651648223400116\n",
            "  epoch: 19/20,    batch: 985/2993    Encoder_loss: 0.5843059420585632\n",
            "  epoch: 19/20,    batch: 986/2993    Encoder_loss: 0.6312286257743835\n",
            "  epoch: 19/20,    batch: 987/2993    Encoder_loss: 0.6357697248458862\n",
            "  epoch: 19/20,    batch: 988/2993    Encoder_loss: 0.566506564617157\n",
            "  epoch: 19/20,    batch: 989/2993    Encoder_loss: 0.5955972671508789\n",
            "  epoch: 19/20,    batch: 990/2993    Encoder_loss: 0.5987136960029602\n",
            "  epoch: 19/20,    batch: 991/2993    Encoder_loss: 0.5671259164810181\n",
            "  epoch: 19/20,    batch: 992/2993    Encoder_loss: 0.6177799105644226\n",
            "  epoch: 19/20,    batch: 993/2993    Encoder_loss: 0.6460486054420471\n",
            "  epoch: 19/20,    batch: 994/2993    Encoder_loss: 0.6031416654586792\n",
            "  epoch: 19/20,    batch: 995/2993    Encoder_loss: 0.6555910706520081\n",
            "  epoch: 19/20,    batch: 996/2993    Encoder_loss: 0.6676523685455322\n",
            "  epoch: 19/20,    batch: 997/2993    Encoder_loss: 0.5799826383590698\n",
            "  epoch: 19/20,    batch: 998/2993    Encoder_loss: 0.6316825747489929\n",
            "  epoch: 19/20,    batch: 999/2993    Encoder_loss: 0.6877054572105408\n",
            "  epoch: 19/20,    batch: 1000/2993    Encoder_loss: 0.5845259428024292\n",
            "  epoch: 19/20,    batch: 1001/2993    Encoder_loss: 0.5552257895469666\n",
            "  epoch: 19/20,    batch: 1002/2993    Encoder_loss: 0.6122633218765259\n",
            "  epoch: 19/20,    batch: 1003/2993    Encoder_loss: 0.6172741055488586\n",
            "  epoch: 19/20,    batch: 1004/2993    Encoder_loss: 0.562021017074585\n",
            "  epoch: 19/20,    batch: 1005/2993    Encoder_loss: 0.626564621925354\n",
            "  epoch: 19/20,    batch: 1006/2993    Encoder_loss: 0.6530386805534363\n",
            "  epoch: 19/20,    batch: 1007/2993    Encoder_loss: 0.5859537720680237\n",
            "  epoch: 19/20,    batch: 1008/2993    Encoder_loss: 0.6044113039970398\n",
            "  epoch: 19/20,    batch: 1009/2993    Encoder_loss: 0.6601083278656006\n",
            "  epoch: 19/20,    batch: 1010/2993    Encoder_loss: 0.5893697142601013\n",
            "  epoch: 19/20,    batch: 1011/2993    Encoder_loss: 0.6140708923339844\n",
            "  epoch: 19/20,    batch: 1012/2993    Encoder_loss: 0.6826019287109375\n",
            "  epoch: 19/20,    batch: 1013/2993    Encoder_loss: 0.5743724703788757\n",
            "  epoch: 19/20,    batch: 1014/2993    Encoder_loss: 0.6422085165977478\n",
            "  epoch: 19/20,    batch: 1015/2993    Encoder_loss: 0.6818179488182068\n",
            "  epoch: 19/20,    batch: 1016/2993    Encoder_loss: 0.598567008972168\n",
            "  epoch: 19/20,    batch: 1017/2993    Encoder_loss: 0.700575053691864\n",
            "  epoch: 19/20,    batch: 1018/2993    Encoder_loss: 0.6758841276168823\n",
            "  epoch: 19/20,    batch: 1019/2993    Encoder_loss: 0.6078358292579651\n",
            "  epoch: 19/20,    batch: 1020/2993    Encoder_loss: 0.691321074962616\n",
            "  epoch: 19/20,    batch: 1021/2993    Encoder_loss: 0.6416294574737549\n",
            "  epoch: 19/20,    batch: 1022/2993    Encoder_loss: 0.6060711145401001\n",
            "  epoch: 19/20,    batch: 1023/2993    Encoder_loss: 0.6814022064208984\n",
            "  epoch: 19/20,    batch: 1024/2993    Encoder_loss: 0.6619232892990112\n",
            "  epoch: 19/20,    batch: 1025/2993    Encoder_loss: 0.5898875594139099\n",
            "  epoch: 19/20,    batch: 1026/2993    Encoder_loss: 0.6690953969955444\n",
            "  epoch: 19/20,    batch: 1027/2993    Encoder_loss: 0.7041264772415161\n",
            "  epoch: 19/20,    batch: 1028/2993    Encoder_loss: 0.6103485226631165\n",
            "  epoch: 19/20,    batch: 1029/2993    Encoder_loss: 0.6361373066902161\n",
            "  epoch: 19/20,    batch: 1030/2993    Encoder_loss: 0.7008304595947266\n",
            "  epoch: 19/20,    batch: 1031/2993    Encoder_loss: 0.6415244340896606\n",
            "  epoch: 19/20,    batch: 1032/2993    Encoder_loss: 0.6069112420082092\n",
            "  epoch: 19/20,    batch: 1033/2993    Encoder_loss: 0.6941182613372803\n",
            "  epoch: 19/20,    batch: 1034/2993    Encoder_loss: 0.6964523196220398\n",
            "  epoch: 19/20,    batch: 1035/2993    Encoder_loss: 0.5798549056053162\n",
            "  epoch: 19/20,    batch: 1036/2993    Encoder_loss: 0.6197013258934021\n",
            "  epoch: 19/20,    batch: 1037/2993    Encoder_loss: 0.6751157641410828\n",
            "  epoch: 19/20,    batch: 1038/2993    Encoder_loss: 0.6178489327430725\n",
            "  epoch: 19/20,    batch: 1039/2993    Encoder_loss: 0.5943313241004944\n",
            "  epoch: 19/20,    batch: 1040/2993    Encoder_loss: 0.6727361083030701\n",
            "  epoch: 19/20,    batch: 1041/2993    Encoder_loss: 0.6806251406669617\n",
            "  epoch: 19/20,    batch: 1042/2993    Encoder_loss: 0.6103619337081909\n",
            "  epoch: 19/20,    batch: 1043/2993    Encoder_loss: 0.6906079649925232\n",
            "  epoch: 19/20,    batch: 1044/2993    Encoder_loss: 0.737987756729126\n",
            "  epoch: 19/20,    batch: 1045/2993    Encoder_loss: 0.6289254426956177\n",
            "  epoch: 19/20,    batch: 1046/2993    Encoder_loss: 0.6671899557113647\n",
            "  epoch: 19/20,    batch: 1047/2993    Encoder_loss: 0.6797887086868286\n",
            "  epoch: 19/20,    batch: 1048/2993    Encoder_loss: 0.6089982986450195\n",
            "  epoch: 19/20,    batch: 1049/2993    Encoder_loss: 0.6775657534599304\n",
            "  epoch: 19/20,    batch: 1050/2993    Encoder_loss: 0.677184522151947\n",
            "  epoch: 19/20,    batch: 1051/2993    Encoder_loss: 0.6519501805305481\n",
            "  epoch: 19/20,    batch: 1052/2993    Encoder_loss: 0.7044320702552795\n",
            "  epoch: 19/20,    batch: 1053/2993    Encoder_loss: 0.6440077424049377\n",
            "  epoch: 19/20,    batch: 1054/2993    Encoder_loss: 0.6386626958847046\n",
            "  epoch: 19/20,    batch: 1055/2993    Encoder_loss: 0.7064180970191956\n",
            "  epoch: 19/20,    batch: 1056/2993    Encoder_loss: 0.618599534034729\n",
            "  epoch: 19/20,    batch: 1057/2993    Encoder_loss: 0.6398904323577881\n",
            "  epoch: 19/20,    batch: 1058/2993    Encoder_loss: 0.7132636308670044\n",
            "  epoch: 19/20,    batch: 1059/2993    Encoder_loss: 0.6350609660148621\n",
            "  epoch: 19/20,    batch: 1060/2993    Encoder_loss: 0.5869433879852295\n",
            "  epoch: 19/20,    batch: 1061/2993    Encoder_loss: 0.6705177426338196\n",
            "  epoch: 19/20,    batch: 1062/2993    Encoder_loss: 0.718456506729126\n",
            "  epoch: 19/20,    batch: 1063/2993    Encoder_loss: 0.613002359867096\n",
            "  epoch: 19/20,    batch: 1064/2993    Encoder_loss: 0.6625515222549438\n",
            "  epoch: 19/20,    batch: 1065/2993    Encoder_loss: 0.7189844846725464\n",
            "  epoch: 19/20,    batch: 1066/2993    Encoder_loss: 0.6286419630050659\n",
            "  epoch: 19/20,    batch: 1067/2993    Encoder_loss: 0.6225874423980713\n",
            "  epoch: 19/20,    batch: 1068/2993    Encoder_loss: 0.7048036456108093\n",
            "  epoch: 19/20,    batch: 1069/2993    Encoder_loss: 0.6993407011032104\n",
            "  epoch: 19/20,    batch: 1070/2993    Encoder_loss: 0.6090189814567566\n",
            "  epoch: 19/20,    batch: 1071/2993    Encoder_loss: 0.6966661810874939\n",
            "  epoch: 19/20,    batch: 1072/2993    Encoder_loss: 0.693630039691925\n",
            "  epoch: 19/20,    batch: 1073/2993    Encoder_loss: 0.5967381000518799\n",
            "  epoch: 19/20,    batch: 1074/2993    Encoder_loss: 0.619911253452301\n",
            "  epoch: 19/20,    batch: 1075/2993    Encoder_loss: 0.7092572450637817\n",
            "  epoch: 19/20,    batch: 1076/2993    Encoder_loss: 0.6694650053977966\n",
            "  epoch: 19/20,    batch: 1077/2993    Encoder_loss: 0.5651397705078125\n",
            "  epoch: 19/20,    batch: 1078/2993    Encoder_loss: 0.6758191585540771\n",
            "  epoch: 19/20,    batch: 1079/2993    Encoder_loss: 0.7196947932243347\n",
            "  epoch: 19/20,    batch: 1080/2993    Encoder_loss: 0.6505253314971924\n",
            "  epoch: 19/20,    batch: 1081/2993    Encoder_loss: 0.6829172968864441\n",
            "  epoch: 19/20,    batch: 1082/2993    Encoder_loss: 0.6491851806640625\n",
            "  epoch: 19/20,    batch: 1083/2993    Encoder_loss: 0.6378322243690491\n",
            "  epoch: 19/20,    batch: 1084/2993    Encoder_loss: 0.69612717628479\n",
            "  epoch: 19/20,    batch: 1085/2993    Encoder_loss: 0.64398193359375\n",
            "  epoch: 19/20,    batch: 1086/2993    Encoder_loss: 0.6368933320045471\n",
            "  epoch: 19/20,    batch: 1087/2993    Encoder_loss: 0.6861351728439331\n",
            "  epoch: 19/20,    batch: 1088/2993    Encoder_loss: 0.6179019808769226\n",
            "  epoch: 19/20,    batch: 1089/2993    Encoder_loss: 0.6513345837593079\n",
            "  epoch: 19/20,    batch: 1090/2993    Encoder_loss: 0.6908209323883057\n",
            "  epoch: 19/20,    batch: 1091/2993    Encoder_loss: 0.6006478667259216\n",
            "  epoch: 19/20,    batch: 1092/2993    Encoder_loss: 0.6193789839744568\n",
            "  epoch: 19/20,    batch: 1093/2993    Encoder_loss: 0.6139209270477295\n",
            "  epoch: 19/20,    batch: 1094/2993    Encoder_loss: 0.5569746494293213\n",
            "  epoch: 19/20,    batch: 1095/2993    Encoder_loss: 0.5973108410835266\n",
            "  epoch: 19/20,    batch: 1096/2993    Encoder_loss: 0.6468727588653564\n",
            "  epoch: 19/20,    batch: 1097/2993    Encoder_loss: 0.5964683890342712\n",
            "  epoch: 19/20,    batch: 1098/2993    Encoder_loss: 0.621957004070282\n",
            "  epoch: 19/20,    batch: 1099/2993    Encoder_loss: 0.672495424747467\n",
            "  epoch: 19/20,    batch: 1100/2993    Encoder_loss: 0.5740500092506409\n",
            "  epoch: 19/20,    batch: 1101/2993    Encoder_loss: 0.5894535779953003\n",
            "  epoch: 19/20,    batch: 1102/2993    Encoder_loss: 0.6791303157806396\n",
            "  epoch: 19/20,    batch: 1103/2993    Encoder_loss: 0.6107856631278992\n",
            "  epoch: 19/20,    batch: 1104/2993    Encoder_loss: 0.5773916244506836\n",
            "  epoch: 19/20,    batch: 1105/2993    Encoder_loss: 0.6558124423027039\n",
            "  epoch: 19/20,    batch: 1106/2993    Encoder_loss: 0.607571005821228\n",
            "  epoch: 19/20,    batch: 1107/2993    Encoder_loss: 0.5470497608184814\n",
            "  epoch: 19/20,    batch: 1108/2993    Encoder_loss: 0.609190046787262\n",
            "  epoch: 19/20,    batch: 1109/2993    Encoder_loss: 0.6411424875259399\n",
            "  epoch: 19/20,    batch: 1110/2993    Encoder_loss: 0.5968483090400696\n",
            "  epoch: 19/20,    batch: 1111/2993    Encoder_loss: 0.6249977946281433\n",
            "  epoch: 19/20,    batch: 1112/2993    Encoder_loss: 0.5749133825302124\n",
            "  epoch: 19/20,    batch: 1113/2993    Encoder_loss: 0.566274881362915\n",
            "  epoch: 19/20,    batch: 1114/2993    Encoder_loss: 0.6291674375534058\n",
            "  epoch: 19/20,    batch: 1115/2993    Encoder_loss: 0.5794703960418701\n",
            "  epoch: 19/20,    batch: 1116/2993    Encoder_loss: 0.5889938473701477\n",
            "  epoch: 19/20,    batch: 1117/2993    Encoder_loss: 0.6426271796226501\n",
            "  epoch: 19/20,    batch: 1118/2993    Encoder_loss: 0.555431067943573\n",
            "  epoch: 19/20,    batch: 1119/2993    Encoder_loss: 0.5840254426002502\n",
            "  epoch: 19/20,    batch: 1120/2993    Encoder_loss: 0.6497223973274231\n",
            "  epoch: 19/20,    batch: 1121/2993    Encoder_loss: 0.5645773410797119\n",
            "  epoch: 19/20,    batch: 1122/2993    Encoder_loss: 0.5927075743675232\n",
            "  epoch: 19/20,    batch: 1123/2993    Encoder_loss: 0.6333401799201965\n",
            "  epoch: 19/20,    batch: 1124/2993    Encoder_loss: 0.5729610919952393\n",
            "  epoch: 19/20,    batch: 1125/2993    Encoder_loss: 0.6008446216583252\n",
            "  epoch: 19/20,    batch: 1126/2993    Encoder_loss: 0.5906545519828796\n",
            "  epoch: 19/20,    batch: 1127/2993    Encoder_loss: 0.5229895114898682\n",
            "  epoch: 19/20,    batch: 1128/2993    Encoder_loss: 0.5728873014450073\n",
            "  epoch: 19/20,    batch: 1129/2993    Encoder_loss: 0.6081847548484802\n",
            "  epoch: 19/20,    batch: 1130/2993    Encoder_loss: 0.5575267672538757\n",
            "  epoch: 19/20,    batch: 1131/2993    Encoder_loss: 0.6235660910606384\n",
            "  epoch: 19/20,    batch: 1132/2993    Encoder_loss: 0.6361294984817505\n",
            "  epoch: 19/20,    batch: 1133/2993    Encoder_loss: 0.5383318662643433\n",
            "  epoch: 19/20,    batch: 1134/2993    Encoder_loss: 0.5891086459159851\n",
            "  epoch: 19/20,    batch: 1135/2993    Encoder_loss: 0.640730082988739\n",
            "  epoch: 19/20,    batch: 1136/2993    Encoder_loss: 0.5592756867408752\n",
            "  epoch: 19/20,    batch: 1137/2993    Encoder_loss: 0.5699107050895691\n",
            "  epoch: 19/20,    batch: 1138/2993    Encoder_loss: 0.6301268935203552\n",
            "  epoch: 19/20,    batch: 1139/2993    Encoder_loss: 0.5525265336036682\n",
            "  epoch: 19/20,    batch: 1140/2993    Encoder_loss: 0.5395655035972595\n",
            "  epoch: 19/20,    batch: 1141/2993    Encoder_loss: 0.6270027160644531\n",
            "  epoch: 19/20,    batch: 1142/2993    Encoder_loss: 0.626659095287323\n",
            "  epoch: 19/20,    batch: 1143/2993    Encoder_loss: 0.6069692969322205\n",
            "  epoch: 19/20,    batch: 1144/2993    Encoder_loss: 0.6555866599082947\n",
            "  epoch: 19/20,    batch: 1145/2993    Encoder_loss: 0.6093977689743042\n",
            "  epoch: 19/20,    batch: 1146/2993    Encoder_loss: 0.6151838898658752\n",
            "  epoch: 19/20,    batch: 1147/2993    Encoder_loss: 0.663167417049408\n",
            "  epoch: 19/20,    batch: 1148/2993    Encoder_loss: 0.5610453486442566\n",
            "  epoch: 19/20,    batch: 1149/2993    Encoder_loss: 0.5827662348747253\n",
            "  epoch: 19/20,    batch: 1150/2993    Encoder_loss: 0.6594416499137878\n",
            "  epoch: 19/20,    batch: 1151/2993    Encoder_loss: 0.5950140357017517\n",
            "  epoch: 19/20,    batch: 1152/2993    Encoder_loss: 0.6545355319976807\n",
            "  epoch: 19/20,    batch: 1153/2993    Encoder_loss: 0.663628876209259\n",
            "  epoch: 19/20,    batch: 1154/2993    Encoder_loss: 0.5945024490356445\n",
            "  epoch: 19/20,    batch: 1155/2993    Encoder_loss: 0.667871356010437\n",
            "  epoch: 19/20,    batch: 1156/2993    Encoder_loss: 0.6343921422958374\n",
            "  epoch: 19/20,    batch: 1157/2993    Encoder_loss: 0.5688101649284363\n",
            "  epoch: 19/20,    batch: 1158/2993    Encoder_loss: 0.6348289251327515\n",
            "  epoch: 19/20,    batch: 1159/2993    Encoder_loss: 0.6256577372550964\n",
            "  epoch: 19/20,    batch: 1160/2993    Encoder_loss: 0.5222163796424866\n",
            "  epoch: 19/20,    batch: 1161/2993    Encoder_loss: 0.5773618221282959\n",
            "  epoch: 19/20,    batch: 1162/2993    Encoder_loss: 0.6439718008041382\n",
            "  epoch: 19/20,    batch: 1163/2993    Encoder_loss: 0.5598092675209045\n",
            "  epoch: 19/20,    batch: 1164/2993    Encoder_loss: 0.5707201361656189\n",
            "  epoch: 19/20,    batch: 1165/2993    Encoder_loss: 0.644827127456665\n",
            "  epoch: 19/20,    batch: 1166/2993    Encoder_loss: 0.6085078120231628\n",
            "  epoch: 19/20,    batch: 1167/2993    Encoder_loss: 0.545638918876648\n",
            "  epoch: 19/20,    batch: 1168/2993    Encoder_loss: 0.6326111555099487\n",
            "  epoch: 19/20,    batch: 1169/2993    Encoder_loss: 0.6759450435638428\n",
            "  epoch: 19/20,    batch: 1170/2993    Encoder_loss: 0.5849609375\n",
            "  epoch: 19/20,    batch: 1171/2993    Encoder_loss: 0.6081123948097229\n",
            "  epoch: 19/20,    batch: 1172/2993    Encoder_loss: 0.6852208375930786\n",
            "  epoch: 19/20,    batch: 1173/2993    Encoder_loss: 0.6139573454856873\n",
            "  epoch: 19/20,    batch: 1174/2993    Encoder_loss: 0.553196907043457\n",
            "  epoch: 19/20,    batch: 1175/2993    Encoder_loss: 0.6523086428642273\n",
            "  epoch: 19/20,    batch: 1176/2993    Encoder_loss: 0.6955816745758057\n",
            "  epoch: 19/20,    batch: 1177/2993    Encoder_loss: 0.5923219323158264\n",
            "  epoch: 19/20,    batch: 1178/2993    Encoder_loss: 0.6346647143363953\n",
            "  epoch: 19/20,    batch: 1179/2993    Encoder_loss: 0.6805793642997742\n",
            "  epoch: 19/20,    batch: 1180/2993    Encoder_loss: 0.574118435382843\n",
            "  epoch: 19/20,    batch: 1181/2993    Encoder_loss: 0.6409388184547424\n",
            "  epoch: 19/20,    batch: 1182/2993    Encoder_loss: 0.6731775999069214\n",
            "  epoch: 19/20,    batch: 1183/2993    Encoder_loss: 0.5778841376304626\n",
            "  epoch: 19/20,    batch: 1184/2993    Encoder_loss: 0.6441376209259033\n",
            "  epoch: 19/20,    batch: 1185/2993    Encoder_loss: 0.649267315864563\n",
            "  epoch: 19/20,    batch: 1186/2993    Encoder_loss: 0.597847044467926\n",
            "  epoch: 19/20,    batch: 1187/2993    Encoder_loss: 0.6620244979858398\n",
            "  epoch: 19/20,    batch: 1188/2993    Encoder_loss: 0.6365058422088623\n",
            "  epoch: 19/20,    batch: 1189/2993    Encoder_loss: 0.6071574687957764\n",
            "  epoch: 19/20,    batch: 1190/2993    Encoder_loss: 0.6675984859466553\n",
            "  epoch: 19/20,    batch: 1191/2993    Encoder_loss: 0.623005747795105\n",
            "  epoch: 19/20,    batch: 1192/2993    Encoder_loss: 0.6055659055709839\n",
            "  epoch: 19/20,    batch: 1193/2993    Encoder_loss: 0.6387342810630798\n",
            "  epoch: 19/20,    batch: 1194/2993    Encoder_loss: 0.5693470239639282\n",
            "  epoch: 19/20,    batch: 1195/2993    Encoder_loss: 0.5845082998275757\n",
            "  epoch: 19/20,    batch: 1196/2993    Encoder_loss: 0.6514542698860168\n",
            "  epoch: 19/20,    batch: 1197/2993    Encoder_loss: 0.607995331287384\n",
            "  epoch: 19/20,    batch: 1198/2993    Encoder_loss: 0.5972046256065369\n",
            "  epoch: 19/20,    batch: 1199/2993    Encoder_loss: 0.6828669309616089\n",
            "  epoch: 19/20,    batch: 1200/2993    Encoder_loss: 0.6255624294281006\n",
            "  epoch: 19/20,    batch: 1201/2993    Encoder_loss: 0.5411653518676758\n",
            "  epoch: 19/20,    batch: 1202/2993    Encoder_loss: 0.6379500031471252\n",
            "  epoch: 19/20,    batch: 1203/2993    Encoder_loss: 0.6663164496421814\n",
            "  epoch: 19/20,    batch: 1204/2993    Encoder_loss: 0.5911785960197449\n",
            "  epoch: 19/20,    batch: 1205/2993    Encoder_loss: 0.6579139828681946\n",
            "  epoch: 19/20,    batch: 1206/2993    Encoder_loss: 0.6437450647354126\n",
            "  epoch: 19/20,    batch: 1207/2993    Encoder_loss: 0.5689191222190857\n",
            "  epoch: 19/20,    batch: 1208/2993    Encoder_loss: 0.6501986384391785\n",
            "  epoch: 19/20,    batch: 1209/2993    Encoder_loss: 0.685387909412384\n",
            "  epoch: 19/20,    batch: 1210/2993    Encoder_loss: 0.6108719110488892\n",
            "  epoch: 19/20,    batch: 1211/2993    Encoder_loss: 0.6556921005249023\n",
            "  epoch: 19/20,    batch: 1212/2993    Encoder_loss: 0.6857171654701233\n",
            "  epoch: 19/20,    batch: 1213/2993    Encoder_loss: 0.5915675759315491\n",
            "  epoch: 19/20,    batch: 1214/2993    Encoder_loss: 0.6400245428085327\n",
            "  epoch: 19/20,    batch: 1215/2993    Encoder_loss: 0.6524149775505066\n",
            "  epoch: 19/20,    batch: 1216/2993    Encoder_loss: 0.5909262895584106\n",
            "  epoch: 19/20,    batch: 1217/2993    Encoder_loss: 0.6438310146331787\n",
            "  epoch: 19/20,    batch: 1218/2993    Encoder_loss: 0.6530043482780457\n",
            "  epoch: 19/20,    batch: 1219/2993    Encoder_loss: 0.6279258131980896\n",
            "  epoch: 19/20,    batch: 1220/2993    Encoder_loss: 0.668423056602478\n",
            "  epoch: 19/20,    batch: 1221/2993    Encoder_loss: 0.6299450397491455\n",
            "  epoch: 19/20,    batch: 1222/2993    Encoder_loss: 0.6061858534812927\n",
            "  epoch: 19/20,    batch: 1223/2993    Encoder_loss: 0.6696571111679077\n",
            "  epoch: 19/20,    batch: 1224/2993    Encoder_loss: 0.6123444437980652\n",
            "  epoch: 19/20,    batch: 1225/2993    Encoder_loss: 0.608863890171051\n",
            "  epoch: 19/20,    batch: 1226/2993    Encoder_loss: 0.6297687888145447\n",
            "  epoch: 19/20,    batch: 1227/2993    Encoder_loss: 0.5682557225227356\n",
            "  epoch: 19/20,    batch: 1228/2993    Encoder_loss: 0.6051446199417114\n",
            "  epoch: 19/20,    batch: 1229/2993    Encoder_loss: 0.6500563025474548\n",
            "  epoch: 19/20,    batch: 1230/2993    Encoder_loss: 0.5816916823387146\n",
            "  epoch: 19/20,    batch: 1231/2993    Encoder_loss: 0.6010590195655823\n",
            "  epoch: 19/20,    batch: 1232/2993    Encoder_loss: 0.6706745624542236\n",
            "  epoch: 19/20,    batch: 1233/2993    Encoder_loss: 0.5918979644775391\n",
            "  epoch: 19/20,    batch: 1234/2993    Encoder_loss: 0.5611807703971863\n",
            "  epoch: 19/20,    batch: 1235/2993    Encoder_loss: 0.6387483477592468\n",
            "  epoch: 19/20,    batch: 1236/2993    Encoder_loss: 0.6498010158538818\n",
            "  epoch: 19/20,    batch: 1237/2993    Encoder_loss: 0.5981481075286865\n",
            "  epoch: 19/20,    batch: 1238/2993    Encoder_loss: 0.6351211071014404\n",
            "  epoch: 19/20,    batch: 1239/2993    Encoder_loss: 0.6266729235649109\n",
            "  epoch: 19/20,    batch: 1240/2993    Encoder_loss: 0.5882710814476013\n",
            "  epoch: 19/20,    batch: 1241/2993    Encoder_loss: 0.6368535161018372\n",
            "  epoch: 19/20,    batch: 1242/2993    Encoder_loss: 0.6374596953392029\n",
            "  epoch: 19/20,    batch: 1243/2993    Encoder_loss: 0.5705119967460632\n",
            "  epoch: 19/20,    batch: 1244/2993    Encoder_loss: 0.6330701112747192\n",
            "  epoch: 19/20,    batch: 1245/2993    Encoder_loss: 0.6859676241874695\n",
            "  epoch: 19/20,    batch: 1246/2993    Encoder_loss: 0.6250115633010864\n",
            "  epoch: 19/20,    batch: 1247/2993    Encoder_loss: 0.6728695631027222\n",
            "  epoch: 19/20,    batch: 1248/2993    Encoder_loss: 0.6483955979347229\n",
            "  epoch: 19/20,    batch: 1249/2993    Encoder_loss: 0.5916374921798706\n",
            "  epoch: 19/20,    batch: 1250/2993    Encoder_loss: 0.6649996638298035\n",
            "  epoch: 19/20,    batch: 1251/2993    Encoder_loss: 0.6370400786399841\n",
            "  epoch: 19/20,    batch: 1252/2993    Encoder_loss: 0.6377786993980408\n",
            "  epoch: 19/20,    batch: 1253/2993    Encoder_loss: 0.6947717666625977\n",
            "  epoch: 19/20,    batch: 1254/2993    Encoder_loss: 0.586922824382782\n",
            "  epoch: 19/20,    batch: 1255/2993    Encoder_loss: 0.6042054295539856\n",
            "  epoch: 19/20,    batch: 1256/2993    Encoder_loss: 0.6891846060752869\n",
            "  epoch: 19/20,    batch: 1257/2993    Encoder_loss: 0.605157196521759\n",
            "  epoch: 19/20,    batch: 1258/2993    Encoder_loss: 0.6519906520843506\n",
            "  epoch: 19/20,    batch: 1259/2993    Encoder_loss: 0.674932599067688\n",
            "  epoch: 19/20,    batch: 1260/2993    Encoder_loss: 0.5936359167098999\n",
            "  epoch: 19/20,    batch: 1261/2993    Encoder_loss: 0.6166723370552063\n",
            "  epoch: 19/20,    batch: 1262/2993    Encoder_loss: 0.6685873866081238\n",
            "  epoch: 19/20,    batch: 1263/2993    Encoder_loss: 0.6319859027862549\n",
            "  epoch: 19/20,    batch: 1264/2993    Encoder_loss: 0.6378864049911499\n",
            "  epoch: 19/20,    batch: 1265/2993    Encoder_loss: 0.6579275727272034\n",
            "  epoch: 19/20,    batch: 1266/2993    Encoder_loss: 0.578271746635437\n",
            "  epoch: 19/20,    batch: 1267/2993    Encoder_loss: 0.6139865517616272\n",
            "  epoch: 19/20,    batch: 1268/2993    Encoder_loss: 0.6845373511314392\n",
            "  epoch: 19/20,    batch: 1269/2993    Encoder_loss: 0.6252256035804749\n",
            "  epoch: 19/20,    batch: 1270/2993    Encoder_loss: 0.6185433268547058\n",
            "  epoch: 19/20,    batch: 1271/2993    Encoder_loss: 0.6737485527992249\n",
            "  epoch: 19/20,    batch: 1272/2993    Encoder_loss: 0.6179088950157166\n",
            "  epoch: 19/20,    batch: 1273/2993    Encoder_loss: 0.5818153619766235\n",
            "  epoch: 19/20,    batch: 1274/2993    Encoder_loss: 0.645904541015625\n",
            "  epoch: 19/20,    batch: 1275/2993    Encoder_loss: 0.6613379120826721\n",
            "  epoch: 19/20,    batch: 1276/2993    Encoder_loss: 0.6107458472251892\n",
            "  epoch: 19/20,    batch: 1277/2993    Encoder_loss: 0.6711724400520325\n",
            "  epoch: 19/20,    batch: 1278/2993    Encoder_loss: 0.6495449542999268\n",
            "  epoch: 19/20,    batch: 1279/2993    Encoder_loss: 0.5940946340560913\n",
            "  epoch: 19/20,    batch: 1280/2993    Encoder_loss: 0.6675164103507996\n",
            "  epoch: 19/20,    batch: 1281/2993    Encoder_loss: 0.6438531875610352\n",
            "  epoch: 19/20,    batch: 1282/2993    Encoder_loss: 0.6414011716842651\n",
            "  epoch: 19/20,    batch: 1283/2993    Encoder_loss: 0.6960547566413879\n",
            "  epoch: 19/20,    batch: 1284/2993    Encoder_loss: 0.5946043133735657\n",
            "  epoch: 19/20,    batch: 1285/2993    Encoder_loss: 0.6027908325195312\n",
            "  epoch: 19/20,    batch: 1286/2993    Encoder_loss: 0.6755062937736511\n",
            "  epoch: 19/20,    batch: 1287/2993    Encoder_loss: 0.5727888345718384\n",
            "  epoch: 19/20,    batch: 1288/2993    Encoder_loss: 0.6227225065231323\n",
            "  epoch: 19/20,    batch: 1289/2993    Encoder_loss: 0.6717448830604553\n",
            "  epoch: 19/20,    batch: 1290/2993    Encoder_loss: 0.5685452222824097\n",
            "  epoch: 19/20,    batch: 1291/2993    Encoder_loss: 0.6404486298561096\n",
            "  epoch: 19/20,    batch: 1292/2993    Encoder_loss: 0.6606282591819763\n",
            "  epoch: 19/20,    batch: 1293/2993    Encoder_loss: 0.5630805492401123\n",
            "  epoch: 19/20,    batch: 1294/2993    Encoder_loss: 0.5891708731651306\n",
            "  epoch: 19/20,    batch: 1295/2993    Encoder_loss: 0.6682566404342651\n",
            "  epoch: 19/20,    batch: 1296/2993    Encoder_loss: 0.654593288898468\n",
            "  epoch: 19/20,    batch: 1297/2993    Encoder_loss: 0.6059840321540833\n",
            "  epoch: 19/20,    batch: 1298/2993    Encoder_loss: 0.667555034160614\n",
            "  epoch: 19/20,    batch: 1299/2993    Encoder_loss: 0.6710031032562256\n",
            "  epoch: 19/20,    batch: 1300/2993    Encoder_loss: 0.5935134291648865\n",
            "  epoch: 19/20,    batch: 1301/2993    Encoder_loss: 0.6306401491165161\n",
            "  epoch: 19/20,    batch: 1302/2993    Encoder_loss: 0.6973590850830078\n",
            "  epoch: 19/20,    batch: 1303/2993    Encoder_loss: 0.6130107045173645\n",
            "  epoch: 19/20,    batch: 1304/2993    Encoder_loss: 0.5754414200782776\n",
            "  epoch: 19/20,    batch: 1305/2993    Encoder_loss: 0.6784792542457581\n",
            "  epoch: 19/20,    batch: 1306/2993    Encoder_loss: 0.6640967726707458\n",
            "  epoch: 19/20,    batch: 1307/2993    Encoder_loss: 0.577431857585907\n",
            "  epoch: 19/20,    batch: 1308/2993    Encoder_loss: 0.6669174432754517\n",
            "  epoch: 19/20,    batch: 1309/2993    Encoder_loss: 0.6949926018714905\n",
            "  epoch: 19/20,    batch: 1310/2993    Encoder_loss: 0.5875175595283508\n",
            "  epoch: 19/20,    batch: 1311/2993    Encoder_loss: 0.6185657978057861\n",
            "  epoch: 19/20,    batch: 1312/2993    Encoder_loss: 0.708916962146759\n",
            "  epoch: 19/20,    batch: 1313/2993    Encoder_loss: 0.6537980437278748\n",
            "  epoch: 19/20,    batch: 1314/2993    Encoder_loss: 0.6641406416893005\n",
            "  epoch: 19/20,    batch: 1315/2993    Encoder_loss: 0.7038732171058655\n",
            "  epoch: 19/20,    batch: 1316/2993    Encoder_loss: 0.5987243056297302\n",
            "  epoch: 19/20,    batch: 1317/2993    Encoder_loss: 0.6406202912330627\n",
            "  epoch: 19/20,    batch: 1318/2993    Encoder_loss: 0.6816155910491943\n",
            "  epoch: 19/20,    batch: 1319/2993    Encoder_loss: 0.6006520390510559\n",
            "  epoch: 19/20,    batch: 1320/2993    Encoder_loss: 0.6503928899765015\n",
            "  epoch: 19/20,    batch: 1321/2993    Encoder_loss: 0.6642725467681885\n",
            "  epoch: 19/20,    batch: 1322/2993    Encoder_loss: 0.6141015291213989\n",
            "  epoch: 19/20,    batch: 1323/2993    Encoder_loss: 0.6549508571624756\n",
            "  epoch: 19/20,    batch: 1324/2993    Encoder_loss: 0.6456964015960693\n",
            "  epoch: 19/20,    batch: 1325/2993    Encoder_loss: 0.6369274854660034\n",
            "  epoch: 19/20,    batch: 1326/2993    Encoder_loss: 0.6639444828033447\n",
            "  epoch: 19/20,    batch: 1327/2993    Encoder_loss: 0.6402841210365295\n",
            "  epoch: 19/20,    batch: 1328/2993    Encoder_loss: 0.5844532251358032\n",
            "  epoch: 19/20,    batch: 1329/2993    Encoder_loss: 0.65083909034729\n",
            "  epoch: 19/20,    batch: 1330/2993    Encoder_loss: 0.6657252907752991\n",
            "  epoch: 19/20,    batch: 1331/2993    Encoder_loss: 0.6082689762115479\n",
            "  epoch: 19/20,    batch: 1332/2993    Encoder_loss: 0.6483681797981262\n",
            "  epoch: 19/20,    batch: 1333/2993    Encoder_loss: 0.6787530183792114\n",
            "  epoch: 19/20,    batch: 1334/2993    Encoder_loss: 0.5995842218399048\n",
            "  epoch: 19/20,    batch: 1335/2993    Encoder_loss: 0.6095443367958069\n",
            "  epoch: 19/20,    batch: 1336/2993    Encoder_loss: 0.682400107383728\n",
            "  epoch: 19/20,    batch: 1337/2993    Encoder_loss: 0.6309642791748047\n",
            "  epoch: 19/20,    batch: 1338/2993    Encoder_loss: 0.6052295565605164\n",
            "  epoch: 19/20,    batch: 1339/2993    Encoder_loss: 0.6459503173828125\n",
            "  epoch: 19/20,    batch: 1340/2993    Encoder_loss: 0.605590283870697\n",
            "  epoch: 19/20,    batch: 1341/2993    Encoder_loss: 0.589816689491272\n",
            "  epoch: 19/20,    batch: 1342/2993    Encoder_loss: 0.6421385407447815\n",
            "  epoch: 19/20,    batch: 1343/2993    Encoder_loss: 0.6758275628089905\n",
            "  epoch: 19/20,    batch: 1344/2993    Encoder_loss: 0.6045675873756409\n",
            "  epoch: 19/20,    batch: 1345/2993    Encoder_loss: 0.6585410833358765\n",
            "  epoch: 19/20,    batch: 1346/2993    Encoder_loss: 0.6723612546920776\n",
            "  epoch: 19/20,    batch: 1347/2993    Encoder_loss: 0.619134783744812\n",
            "  epoch: 19/20,    batch: 1348/2993    Encoder_loss: 0.7063086628913879\n",
            "  epoch: 19/20,    batch: 1349/2993    Encoder_loss: 0.6718794107437134\n",
            "  epoch: 19/20,    batch: 1350/2993    Encoder_loss: 0.6234269738197327\n",
            "  epoch: 19/20,    batch: 1351/2993    Encoder_loss: 0.6969796419143677\n",
            "  epoch: 19/20,    batch: 1352/2993    Encoder_loss: 0.6507833003997803\n",
            "  epoch: 19/20,    batch: 1353/2993    Encoder_loss: 0.6585261821746826\n",
            "  epoch: 19/20,    batch: 1354/2993    Encoder_loss: 0.7273198366165161\n",
            "  epoch: 19/20,    batch: 1355/2993    Encoder_loss: 0.6342541575431824\n",
            "  epoch: 19/20,    batch: 1356/2993    Encoder_loss: 0.6539268493652344\n",
            "  epoch: 19/20,    batch: 1357/2993    Encoder_loss: 0.7036020755767822\n",
            "  epoch: 19/20,    batch: 1358/2993    Encoder_loss: 0.6079850792884827\n",
            "  epoch: 19/20,    batch: 1359/2993    Encoder_loss: 0.677582323551178\n",
            "  epoch: 19/20,    batch: 1360/2993    Encoder_loss: 0.6993398070335388\n",
            "  epoch: 19/20,    batch: 1361/2993    Encoder_loss: 0.5863915085792542\n",
            "  epoch: 19/20,    batch: 1362/2993    Encoder_loss: 0.5346428751945496\n",
            "  epoch: 19/20,    batch: 1363/2993    Encoder_loss: 0.6392073035240173\n",
            "  epoch: 19/20,    batch: 1364/2993    Encoder_loss: 0.6935373544692993\n",
            "  epoch: 19/20,    batch: 1365/2993    Encoder_loss: 0.6192172765731812\n",
            "  epoch: 19/20,    batch: 1366/2993    Encoder_loss: 0.6531006097793579\n",
            "  epoch: 19/20,    batch: 1367/2993    Encoder_loss: 0.685248076915741\n",
            "  epoch: 19/20,    batch: 1368/2993    Encoder_loss: 0.5934303402900696\n",
            "  epoch: 19/20,    batch: 1369/2993    Encoder_loss: 0.5771673917770386\n",
            "  epoch: 19/20,    batch: 1370/2993    Encoder_loss: 0.6675835251808167\n",
            "  epoch: 19/20,    batch: 1371/2993    Encoder_loss: 0.67874675989151\n",
            "  epoch: 19/20,    batch: 1372/2993    Encoder_loss: 0.5479673147201538\n",
            "  epoch: 19/20,    batch: 1373/2993    Encoder_loss: 0.6128769516944885\n",
            "  epoch: 19/20,    batch: 1374/2993    Encoder_loss: 0.7019485235214233\n",
            "  epoch: 19/20,    batch: 1375/2993    Encoder_loss: 0.6376539468765259\n",
            "  epoch: 19/20,    batch: 1376/2993    Encoder_loss: 0.6040707230567932\n",
            "  epoch: 19/20,    batch: 1377/2993    Encoder_loss: 0.672469973564148\n",
            "  epoch: 19/20,    batch: 1378/2993    Encoder_loss: 0.6743189096450806\n",
            "  epoch: 19/20,    batch: 1379/2993    Encoder_loss: 0.5942388772964478\n",
            "  epoch: 19/20,    batch: 1380/2993    Encoder_loss: 0.6537488102912903\n",
            "  epoch: 19/20,    batch: 1381/2993    Encoder_loss: 0.6816852688789368\n",
            "  epoch: 19/20,    batch: 1382/2993    Encoder_loss: 0.6008066534996033\n",
            "  epoch: 19/20,    batch: 1383/2993    Encoder_loss: 0.6424408555030823\n",
            "  epoch: 19/20,    batch: 1384/2993    Encoder_loss: 0.6390448808670044\n",
            "  epoch: 19/20,    batch: 1385/2993    Encoder_loss: 0.5889208316802979\n",
            "  epoch: 19/20,    batch: 1386/2993    Encoder_loss: 0.6379309296607971\n",
            "  epoch: 19/20,    batch: 1387/2993    Encoder_loss: 0.6019532680511475\n",
            "  epoch: 19/20,    batch: 1388/2993    Encoder_loss: 0.5961719751358032\n",
            "  epoch: 19/20,    batch: 1389/2993    Encoder_loss: 0.6623828411102295\n",
            "  epoch: 19/20,    batch: 1390/2993    Encoder_loss: 0.5913986563682556\n",
            "  epoch: 19/20,    batch: 1391/2993    Encoder_loss: 0.6129734516143799\n",
            "  epoch: 19/20,    batch: 1392/2993    Encoder_loss: 0.6791761517524719\n",
            "  epoch: 19/20,    batch: 1393/2993    Encoder_loss: 0.5717796087265015\n",
            "  epoch: 19/20,    batch: 1394/2993    Encoder_loss: 0.6135146021842957\n",
            "  epoch: 19/20,    batch: 1395/2993    Encoder_loss: 0.6391767859458923\n",
            "  epoch: 19/20,    batch: 1396/2993    Encoder_loss: 0.5699247717857361\n",
            "  epoch: 19/20,    batch: 1397/2993    Encoder_loss: 0.5835487246513367\n",
            "  epoch: 19/20,    batch: 1398/2993    Encoder_loss: 0.6323612332344055\n",
            "  epoch: 19/20,    batch: 1399/2993    Encoder_loss: 0.6320695877075195\n",
            "  epoch: 19/20,    batch: 1400/2993    Encoder_loss: 0.5726860761642456\n",
            "  epoch: 19/20,    batch: 1401/2993    Encoder_loss: 0.6355043649673462\n",
            "  epoch: 19/20,    batch: 1402/2993    Encoder_loss: 0.6451179385185242\n",
            "  epoch: 19/20,    batch: 1403/2993    Encoder_loss: 0.5696706771850586\n",
            "  epoch: 19/20,    batch: 1404/2993    Encoder_loss: 0.601091206073761\n",
            "  epoch: 19/20,    batch: 1405/2993    Encoder_loss: 0.6674163937568665\n",
            "  epoch: 19/20,    batch: 1406/2993    Encoder_loss: 0.6463291645050049\n",
            "  epoch: 19/20,    batch: 1407/2993    Encoder_loss: 0.5860700607299805\n",
            "  epoch: 19/20,    batch: 1408/2993    Encoder_loss: 0.6656213998794556\n",
            "  epoch: 19/20,    batch: 1409/2993    Encoder_loss: 0.6719591617584229\n",
            "  epoch: 19/20,    batch: 1410/2993    Encoder_loss: 0.5813012719154358\n",
            "  epoch: 19/20,    batch: 1411/2993    Encoder_loss: 0.620410144329071\n",
            "  epoch: 19/20,    batch: 1412/2993    Encoder_loss: 0.7058373093605042\n",
            "  epoch: 19/20,    batch: 1413/2993    Encoder_loss: 0.6221989393234253\n",
            "  epoch: 19/20,    batch: 1414/2993    Encoder_loss: 0.5770122408866882\n",
            "  epoch: 19/20,    batch: 1415/2993    Encoder_loss: 0.6575153470039368\n",
            "  epoch: 19/20,    batch: 1416/2993    Encoder_loss: 0.6299712657928467\n",
            "  epoch: 19/20,    batch: 1417/2993    Encoder_loss: 0.6267171502113342\n",
            "  epoch: 19/20,    batch: 1418/2993    Encoder_loss: 0.6660498976707458\n",
            "  epoch: 19/20,    batch: 1419/2993    Encoder_loss: 0.6101929545402527\n",
            "  epoch: 19/20,    batch: 1420/2993    Encoder_loss: 0.6243635416030884\n",
            "  epoch: 19/20,    batch: 1421/2993    Encoder_loss: 0.6693294048309326\n",
            "  epoch: 19/20,    batch: 1422/2993    Encoder_loss: 0.5882877111434937\n",
            "  epoch: 19/20,    batch: 1423/2993    Encoder_loss: 0.6374014616012573\n",
            "  epoch: 19/20,    batch: 1424/2993    Encoder_loss: 0.672126054763794\n",
            "  epoch: 19/20,    batch: 1425/2993    Encoder_loss: 0.5967413783073425\n",
            "  epoch: 19/20,    batch: 1426/2993    Encoder_loss: 0.6533915400505066\n",
            "  epoch: 19/20,    batch: 1427/2993    Encoder_loss: 0.6756923794746399\n",
            "  epoch: 19/20,    batch: 1428/2993    Encoder_loss: 0.6345001459121704\n",
            "  epoch: 19/20,    batch: 1429/2993    Encoder_loss: 0.6648291349411011\n",
            "  epoch: 19/20,    batch: 1430/2993    Encoder_loss: 0.6502861380577087\n",
            "  epoch: 19/20,    batch: 1431/2993    Encoder_loss: 0.6308977007865906\n",
            "  epoch: 19/20,    batch: 1432/2993    Encoder_loss: 0.6850501894950867\n",
            "  epoch: 19/20,    batch: 1433/2993    Encoder_loss: 0.6976497173309326\n",
            "  epoch: 19/20,    batch: 1434/2993    Encoder_loss: 0.629654049873352\n",
            "  epoch: 19/20,    batch: 1435/2993    Encoder_loss: 0.680616557598114\n",
            "  epoch: 19/20,    batch: 1436/2993    Encoder_loss: 0.6997135281562805\n",
            "  epoch: 19/20,    batch: 1437/2993    Encoder_loss: 0.6205666661262512\n",
            "  epoch: 19/20,    batch: 1438/2993    Encoder_loss: 0.6662083864212036\n",
            "  epoch: 19/20,    batch: 1439/2993    Encoder_loss: 0.7118329405784607\n",
            "  epoch: 19/20,    batch: 1440/2993    Encoder_loss: 0.6422041058540344\n",
            "  epoch: 19/20,    batch: 1441/2993    Encoder_loss: 0.6862202882766724\n",
            "  epoch: 19/20,    batch: 1442/2993    Encoder_loss: 0.7219755053520203\n",
            "  epoch: 19/20,    batch: 1443/2993    Encoder_loss: 0.6439284682273865\n",
            "  epoch: 19/20,    batch: 1444/2993    Encoder_loss: 0.6275195479393005\n",
            "  epoch: 19/20,    batch: 1445/2993    Encoder_loss: 0.6821507215499878\n",
            "  epoch: 19/20,    batch: 1446/2993    Encoder_loss: 0.6755253076553345\n",
            "  epoch: 19/20,    batch: 1447/2993    Encoder_loss: 0.6700616478919983\n",
            "  epoch: 19/20,    batch: 1448/2993    Encoder_loss: 0.7039855718612671\n",
            "  epoch: 19/20,    batch: 1449/2993    Encoder_loss: 0.6669233441352844\n",
            "  epoch: 19/20,    batch: 1450/2993    Encoder_loss: 0.6848465204238892\n",
            "  epoch: 19/20,    batch: 1451/2993    Encoder_loss: 0.736763060092926\n",
            "  epoch: 19/20,    batch: 1452/2993    Encoder_loss: 0.6511324048042297\n",
            "  epoch: 19/20,    batch: 1453/2993    Encoder_loss: 0.6731583476066589\n",
            "  epoch: 19/20,    batch: 1454/2993    Encoder_loss: 0.7372419238090515\n",
            "  epoch: 19/20,    batch: 1455/2993    Encoder_loss: 0.65235835313797\n",
            "  epoch: 19/20,    batch: 1456/2993    Encoder_loss: 0.7019384503364563\n",
            "  epoch: 19/20,    batch: 1457/2993    Encoder_loss: 0.7233479619026184\n",
            "  epoch: 19/20,    batch: 1458/2993    Encoder_loss: 0.6465312242507935\n",
            "  epoch: 19/20,    batch: 1459/2993    Encoder_loss: 0.6966341733932495\n",
            "  epoch: 19/20,    batch: 1460/2993    Encoder_loss: 0.707245945930481\n",
            "  epoch: 19/20,    batch: 1461/2993    Encoder_loss: 0.6750411987304688\n",
            "  epoch: 19/20,    batch: 1462/2993    Encoder_loss: 0.7195123434066772\n",
            "  epoch: 19/20,    batch: 1463/2993    Encoder_loss: 0.7050150036811829\n",
            "  epoch: 19/20,    batch: 1464/2993    Encoder_loss: 0.6296780705451965\n",
            "  epoch: 19/20,    batch: 1465/2993    Encoder_loss: 0.6769914031028748\n",
            "  epoch: 19/20,    batch: 1466/2993    Encoder_loss: 0.7295405268669128\n",
            "  epoch: 19/20,    batch: 1467/2993    Encoder_loss: 0.6856467723846436\n",
            "  epoch: 19/20,    batch: 1468/2993    Encoder_loss: 0.6904270052909851\n",
            "  epoch: 19/20,    batch: 1469/2993    Encoder_loss: 0.7280996441841125\n",
            "  epoch: 19/20,    batch: 1470/2993    Encoder_loss: 0.6680026650428772\n",
            "  epoch: 19/20,    batch: 1471/2993    Encoder_loss: 0.5947940945625305\n",
            "  epoch: 19/20,    batch: 1472/2993    Encoder_loss: 0.6724163293838501\n",
            "  epoch: 19/20,    batch: 1473/2993    Encoder_loss: 0.7516137957572937\n",
            "  epoch: 19/20,    batch: 1474/2993    Encoder_loss: 0.6729364395141602\n",
            "  epoch: 19/20,    batch: 1475/2993    Encoder_loss: 0.6719425320625305\n",
            "  epoch: 19/20,    batch: 1476/2993    Encoder_loss: 0.7361956238746643\n",
            "  epoch: 19/20,    batch: 1477/2993    Encoder_loss: 0.6722108125686646\n",
            "  epoch: 19/20,    batch: 1478/2993    Encoder_loss: 0.6139395236968994\n",
            "  epoch: 19/20,    batch: 1479/2993    Encoder_loss: 0.702450156211853\n",
            "  epoch: 19/20,    batch: 1480/2993    Encoder_loss: 0.7314354181289673\n",
            "  epoch: 19/20,    batch: 1481/2993    Encoder_loss: 0.6216481328010559\n",
            "  epoch: 19/20,    batch: 1482/2993    Encoder_loss: 0.6778725385665894\n",
            "  epoch: 19/20,    batch: 1483/2993    Encoder_loss: 0.7476676106452942\n",
            "  epoch: 19/20,    batch: 1484/2993    Encoder_loss: 0.6379078030586243\n",
            "  epoch: 19/20,    batch: 1485/2993    Encoder_loss: 0.7139132618904114\n",
            "  epoch: 19/20,    batch: 1486/2993    Encoder_loss: 0.7419166564941406\n",
            "  epoch: 19/20,    batch: 1487/2993    Encoder_loss: 0.630756139755249\n",
            "  epoch: 19/20,    batch: 1488/2993    Encoder_loss: 0.6960816979408264\n",
            "  epoch: 19/20,    batch: 1489/2993    Encoder_loss: 0.6882765293121338\n",
            "  epoch: 19/20,    batch: 1490/2993    Encoder_loss: 0.6443051695823669\n",
            "  epoch: 19/20,    batch: 1491/2993    Encoder_loss: 0.7093854546546936\n",
            "  epoch: 19/20,    batch: 1492/2993    Encoder_loss: 0.6663649082183838\n",
            "  epoch: 19/20,    batch: 1493/2993    Encoder_loss: 0.6578797698020935\n",
            "  epoch: 19/20,    batch: 1494/2993    Encoder_loss: 0.7025796175003052\n",
            "  epoch: 19/20,    batch: 1495/2993    Encoder_loss: 0.6410132050514221\n",
            "  epoch: 19/20,    batch: 1496/2993    Encoder_loss: 0.5966442227363586\n",
            "  epoch: 19/20,    batch: 1497/2993    Encoder_loss: 0.5957440733909607\n",
            "  epoch: 19/20,    batch: 1498/2993    Encoder_loss: 0.595780611038208\n",
            "  epoch: 19/20,    batch: 1499/2993    Encoder_loss: 0.5973587036132812\n",
            "  epoch: 19/20,    batch: 1500/2993    Encoder_loss: 0.5947016477584839\n",
            "  epoch: 19/20,    batch: 1501/2993    Encoder_loss: 0.5873204469680786\n",
            "  epoch: 19/20,    batch: 1502/2993    Encoder_loss: 0.5814012885093689\n",
            "  epoch: 19/20,    batch: 1503/2993    Encoder_loss: 0.5810670852661133\n",
            "  epoch: 19/20,    batch: 1504/2993    Encoder_loss: 0.5873594284057617\n",
            "  epoch: 19/20,    batch: 1505/2993    Encoder_loss: 0.5878698825836182\n",
            "  epoch: 19/20,    batch: 1506/2993    Encoder_loss: 0.5846861600875854\n",
            "  epoch: 19/20,    batch: 1507/2993    Encoder_loss: 0.5825921297073364\n",
            "  epoch: 19/20,    batch: 1508/2993    Encoder_loss: 0.5835949182510376\n",
            "  epoch: 19/20,    batch: 1509/2993    Encoder_loss: 0.5864008665084839\n",
            "  epoch: 19/20,    batch: 1510/2993    Encoder_loss: 0.585518479347229\n",
            "  epoch: 19/20,    batch: 1511/2993    Encoder_loss: 0.5854895710945129\n",
            "  epoch: 19/20,    batch: 1512/2993    Encoder_loss: 0.5868127346038818\n",
            "  epoch: 19/20,    batch: 1513/2993    Encoder_loss: 0.5871226787567139\n",
            "  epoch: 19/20,    batch: 1514/2993    Encoder_loss: 0.5912697911262512\n",
            "  epoch: 19/20,    batch: 1515/2993    Encoder_loss: 0.5919205546379089\n",
            "  epoch: 19/20,    batch: 1516/2993    Encoder_loss: 0.5875548720359802\n",
            "  epoch: 19/20,    batch: 1517/2993    Encoder_loss: 0.5845127105712891\n",
            "  epoch: 19/20,    batch: 1518/2993    Encoder_loss: 0.5831406712532043\n",
            "  epoch: 19/20,    batch: 1519/2993    Encoder_loss: 0.5815064311027527\n",
            "  epoch: 19/20,    batch: 1520/2993    Encoder_loss: 0.5812911987304688\n",
            "  epoch: 19/20,    batch: 1521/2993    Encoder_loss: 0.5817202925682068\n",
            "  epoch: 19/20,    batch: 1522/2993    Encoder_loss: 0.5802379846572876\n",
            "  epoch: 19/20,    batch: 1523/2993    Encoder_loss: 0.5764282941818237\n",
            "  epoch: 19/20,    batch: 1524/2993    Encoder_loss: 0.5747307538986206\n",
            "  epoch: 19/20,    batch: 1525/2993    Encoder_loss: 0.5750866532325745\n",
            "  epoch: 19/20,    batch: 1526/2993    Encoder_loss: 0.5756478905677795\n",
            "  epoch: 19/20,    batch: 1527/2993    Encoder_loss: 0.5738971829414368\n",
            "  epoch: 19/20,    batch: 1528/2993    Encoder_loss: 0.5739418864250183\n",
            "  epoch: 19/20,    batch: 1529/2993    Encoder_loss: 0.5974732041358948\n",
            "  epoch: 19/20,    batch: 1530/2993    Encoder_loss: 0.6975663900375366\n",
            "  epoch: 19/20,    batch: 1531/2993    Encoder_loss: 0.7020540833473206\n",
            "  epoch: 19/20,    batch: 1532/2993    Encoder_loss: 0.6234807372093201\n",
            "  epoch: 19/20,    batch: 1533/2993    Encoder_loss: 0.5903699398040771\n",
            "  epoch: 19/20,    batch: 1534/2993    Encoder_loss: 0.6392041444778442\n",
            "  epoch: 19/20,    batch: 1535/2993    Encoder_loss: 0.6864981055259705\n",
            "  epoch: 19/20,    batch: 1536/2993    Encoder_loss: 0.6032544374465942\n",
            "  epoch: 19/20,    batch: 1537/2993    Encoder_loss: 0.6644790768623352\n",
            "  epoch: 19/20,    batch: 1538/2993    Encoder_loss: 0.7095819711685181\n",
            "  epoch: 19/20,    batch: 1539/2993    Encoder_loss: 0.6265404224395752\n",
            "  epoch: 19/20,    batch: 1540/2993    Encoder_loss: 0.6229556798934937\n",
            "  epoch: 19/20,    batch: 1541/2993    Encoder_loss: 0.696010947227478\n",
            "  epoch: 19/20,    batch: 1542/2993    Encoder_loss: 0.6759058237075806\n",
            "  epoch: 19/20,    batch: 1543/2993    Encoder_loss: 0.5845103859901428\n",
            "  epoch: 19/20,    batch: 1544/2993    Encoder_loss: 0.696556806564331\n",
            "  epoch: 19/20,    batch: 1545/2993    Encoder_loss: 0.696233332157135\n",
            "  epoch: 19/20,    batch: 1546/2993    Encoder_loss: 0.6033715605735779\n",
            "  epoch: 19/20,    batch: 1547/2993    Encoder_loss: 0.638447105884552\n",
            "  epoch: 19/20,    batch: 1548/2993    Encoder_loss: 0.6750081181526184\n",
            "  epoch: 19/20,    batch: 1549/2993    Encoder_loss: 0.6489371061325073\n",
            "  epoch: 19/20,    batch: 1550/2993    Encoder_loss: 0.584267258644104\n",
            "  epoch: 19/20,    batch: 1551/2993    Encoder_loss: 0.6477789282798767\n",
            "  epoch: 19/20,    batch: 1552/2993    Encoder_loss: 0.6434890031814575\n",
            "  epoch: 19/20,    batch: 1553/2993    Encoder_loss: 0.6170454025268555\n",
            "  epoch: 19/20,    batch: 1554/2993    Encoder_loss: 0.657011091709137\n",
            "  epoch: 19/20,    batch: 1555/2993    Encoder_loss: 0.6171976923942566\n",
            "  epoch: 19/20,    batch: 1556/2993    Encoder_loss: 0.6089333891868591\n",
            "  epoch: 19/20,    batch: 1557/2993    Encoder_loss: 0.6861513257026672\n",
            "  epoch: 19/20,    batch: 1558/2993    Encoder_loss: 0.6207600235939026\n",
            "  epoch: 19/20,    batch: 1559/2993    Encoder_loss: 0.6081321835517883\n",
            "  epoch: 19/20,    batch: 1560/2993    Encoder_loss: 0.6780155301094055\n",
            "  epoch: 19/20,    batch: 1561/2993    Encoder_loss: 0.5933728814125061\n",
            "  epoch: 19/20,    batch: 1562/2993    Encoder_loss: 0.6256599426269531\n",
            "  epoch: 19/20,    batch: 1563/2993    Encoder_loss: 0.6787620186805725\n",
            "  epoch: 19/20,    batch: 1564/2993    Encoder_loss: 0.5923418402671814\n",
            "  epoch: 19/20,    batch: 1565/2993    Encoder_loss: 0.6358890533447266\n",
            "  epoch: 19/20,    batch: 1566/2993    Encoder_loss: 0.6575185060501099\n",
            "  epoch: 19/20,    batch: 1567/2993    Encoder_loss: 0.6089014410972595\n",
            "  epoch: 19/20,    batch: 1568/2993    Encoder_loss: 0.6480013132095337\n",
            "  epoch: 19/20,    batch: 1569/2993    Encoder_loss: 0.6825888156890869\n",
            "  epoch: 19/20,    batch: 1570/2993    Encoder_loss: 0.631808876991272\n",
            "  epoch: 19/20,    batch: 1571/2993    Encoder_loss: 0.6653509736061096\n",
            "  epoch: 19/20,    batch: 1572/2993    Encoder_loss: 0.6993375420570374\n",
            "  epoch: 19/20,    batch: 1573/2993    Encoder_loss: 0.6057633757591248\n",
            "  epoch: 19/20,    batch: 1574/2993    Encoder_loss: 0.6095573306083679\n",
            "  epoch: 19/20,    batch: 1575/2993    Encoder_loss: 0.6502867937088013\n",
            "  epoch: 19/20,    batch: 1576/2993    Encoder_loss: 0.6001561284065247\n",
            "  epoch: 19/20,    batch: 1577/2993    Encoder_loss: 0.6150997281074524\n",
            "  epoch: 19/20,    batch: 1578/2993    Encoder_loss: 0.6722612977027893\n",
            "  epoch: 19/20,    batch: 1579/2993    Encoder_loss: 0.6043566465377808\n",
            "  epoch: 19/20,    batch: 1580/2993    Encoder_loss: 0.5774417519569397\n",
            "  epoch: 19/20,    batch: 1581/2993    Encoder_loss: 0.6506795883178711\n",
            "  epoch: 19/20,    batch: 1582/2993    Encoder_loss: 0.6457417607307434\n",
            "  epoch: 19/20,    batch: 1583/2993    Encoder_loss: 0.613057017326355\n",
            "  epoch: 19/20,    batch: 1584/2993    Encoder_loss: 0.693092942237854\n",
            "  epoch: 19/20,    batch: 1585/2993    Encoder_loss: 0.6587132215499878\n",
            "  epoch: 19/20,    batch: 1586/2993    Encoder_loss: 0.6436675190925598\n",
            "  epoch: 19/20,    batch: 1587/2993    Encoder_loss: 0.695327877998352\n",
            "  epoch: 19/20,    batch: 1588/2993    Encoder_loss: 0.592529296875\n",
            "  epoch: 19/20,    batch: 1589/2993    Encoder_loss: 0.6100056767463684\n",
            "  epoch: 19/20,    batch: 1590/2993    Encoder_loss: 0.7025051116943359\n",
            "  epoch: 19/20,    batch: 1591/2993    Encoder_loss: 0.6167218685150146\n",
            "  epoch: 19/20,    batch: 1592/2993    Encoder_loss: 0.6559498310089111\n",
            "  epoch: 19/20,    batch: 1593/2993    Encoder_loss: 0.6873427033424377\n",
            "  epoch: 19/20,    batch: 1594/2993    Encoder_loss: 0.573998749256134\n",
            "  epoch: 19/20,    batch: 1595/2993    Encoder_loss: 0.6555383205413818\n",
            "  epoch: 19/20,    batch: 1596/2993    Encoder_loss: 0.6767688989639282\n",
            "  epoch: 19/20,    batch: 1597/2993    Encoder_loss: 0.6158198118209839\n",
            "  epoch: 19/20,    batch: 1598/2993    Encoder_loss: 0.6929601430892944\n",
            "  epoch: 19/20,    batch: 1599/2993    Encoder_loss: 0.6746684908866882\n",
            "  epoch: 19/20,    batch: 1600/2993    Encoder_loss: 0.5931140780448914\n",
            "  epoch: 19/20,    batch: 1601/2993    Encoder_loss: 0.6434224843978882\n",
            "  epoch: 19/20,    batch: 1602/2993    Encoder_loss: 0.7123172283172607\n",
            "  epoch: 19/20,    batch: 1603/2993    Encoder_loss: 0.6635057926177979\n",
            "  epoch: 19/20,    batch: 1604/2993    Encoder_loss: 0.9078565835952759\n",
            "  epoch: 19/20,    batch: 1605/2993    Encoder_loss: 1.0796809196472168\n",
            "  epoch: 19/20,    batch: 1606/2993    Encoder_loss: 0.8436731696128845\n",
            "  epoch: 19/20,    batch: 1607/2993    Encoder_loss: 0.7886400818824768\n",
            "  epoch: 19/20,    batch: 1608/2993    Encoder_loss: 0.8409925699234009\n",
            "  epoch: 19/20,    batch: 1609/2993    Encoder_loss: 0.8512518405914307\n",
            "  epoch: 19/20,    batch: 1610/2993    Encoder_loss: 0.8031932711601257\n",
            "  epoch: 19/20,    batch: 1611/2993    Encoder_loss: 0.8119159936904907\n",
            "  epoch: 19/20,    batch: 1612/2993    Encoder_loss: 0.7669273614883423\n",
            "  epoch: 19/20,    batch: 1613/2993    Encoder_loss: 0.661460280418396\n",
            "  epoch: 19/20,    batch: 1614/2993    Encoder_loss: 0.5824056267738342\n",
            "  epoch: 19/20,    batch: 1615/2993    Encoder_loss: 0.6714443564414978\n",
            "  epoch: 19/20,    batch: 1616/2993    Encoder_loss: 0.7159520983695984\n",
            "  epoch: 19/20,    batch: 1617/2993    Encoder_loss: 0.6479976773262024\n",
            "  epoch: 19/20,    batch: 1618/2993    Encoder_loss: 0.6509521007537842\n",
            "  epoch: 19/20,    batch: 1619/2993    Encoder_loss: 0.7041435837745667\n",
            "  epoch: 19/20,    batch: 1620/2993    Encoder_loss: 0.6313655972480774\n",
            "  epoch: 19/20,    batch: 1621/2993    Encoder_loss: 0.6711747646331787\n",
            "  epoch: 19/20,    batch: 1622/2993    Encoder_loss: 0.6978600025177002\n",
            "  epoch: 19/20,    batch: 1623/2993    Encoder_loss: 0.6097443699836731\n",
            "  epoch: 19/20,    batch: 1624/2993    Encoder_loss: 0.6821818947792053\n",
            "  epoch: 19/20,    batch: 1625/2993    Encoder_loss: 0.7254221439361572\n",
            "  epoch: 19/20,    batch: 1626/2993    Encoder_loss: 0.6613206267356873\n",
            "  epoch: 19/20,    batch: 1627/2993    Encoder_loss: 0.6988459825515747\n",
            "  epoch: 19/20,    batch: 1628/2993    Encoder_loss: 0.6843955516815186\n",
            "  epoch: 19/20,    batch: 1629/2993    Encoder_loss: 0.6634417176246643\n",
            "  epoch: 19/20,    batch: 1630/2993    Encoder_loss: 0.7155160307884216\n",
            "  epoch: 19/20,    batch: 1631/2993    Encoder_loss: 0.660152018070221\n",
            "  epoch: 19/20,    batch: 1632/2993    Encoder_loss: 0.6289519667625427\n",
            "  epoch: 19/20,    batch: 1633/2993    Encoder_loss: 0.6767229437828064\n",
            "  epoch: 19/20,    batch: 1634/2993    Encoder_loss: 0.6349905729293823\n",
            "  epoch: 19/20,    batch: 1635/2993    Encoder_loss: 0.5976038575172424\n",
            "  epoch: 19/20,    batch: 1636/2993    Encoder_loss: 0.6800979375839233\n",
            "  epoch: 19/20,    batch: 1637/2993    Encoder_loss: 0.694543719291687\n",
            "  epoch: 19/20,    batch: 1638/2993    Encoder_loss: 0.598935067653656\n",
            "  epoch: 19/20,    batch: 1639/2993    Encoder_loss: 0.6257107257843018\n",
            "  epoch: 19/20,    batch: 1640/2993    Encoder_loss: 0.6821157932281494\n",
            "  epoch: 19/20,    batch: 1641/2993    Encoder_loss: 0.6230980753898621\n",
            "  epoch: 19/20,    batch: 1642/2993    Encoder_loss: 0.5969278812408447\n",
            "  epoch: 19/20,    batch: 1643/2993    Encoder_loss: 0.6710853576660156\n",
            "  epoch: 19/20,    batch: 1644/2993    Encoder_loss: 0.7097132802009583\n",
            "  epoch: 19/20,    batch: 1645/2993    Encoder_loss: 0.6368056535720825\n",
            "  epoch: 19/20,    batch: 1646/2993    Encoder_loss: 0.6697589755058289\n",
            "  epoch: 19/20,    batch: 1647/2993    Encoder_loss: 0.7046470642089844\n",
            "  epoch: 19/20,    batch: 1648/2993    Encoder_loss: 0.6389758586883545\n",
            "  epoch: 19/20,    batch: 1649/2993    Encoder_loss: 0.6212738752365112\n",
            "  epoch: 19/20,    batch: 1650/2993    Encoder_loss: 0.6795237064361572\n",
            "  epoch: 19/20,    batch: 1651/2993    Encoder_loss: 0.7206763625144958\n",
            "  epoch: 19/20,    batch: 1652/2993    Encoder_loss: 0.6150978207588196\n",
            "  epoch: 19/20,    batch: 1653/2993    Encoder_loss: 0.6745609045028687\n",
            "  epoch: 19/20,    batch: 1654/2993    Encoder_loss: 0.7091335654258728\n",
            "  epoch: 19/20,    batch: 1655/2993    Encoder_loss: 0.6153380274772644\n",
            "  epoch: 19/20,    batch: 1656/2993    Encoder_loss: 0.7042006850242615\n",
            "  epoch: 19/20,    batch: 1657/2993    Encoder_loss: 0.6959601044654846\n",
            "  epoch: 19/20,    batch: 1658/2993    Encoder_loss: 0.640423595905304\n",
            "  epoch: 19/20,    batch: 1659/2993    Encoder_loss: 0.7136886119842529\n",
            "  epoch: 19/20,    batch: 1660/2993    Encoder_loss: 0.6678318381309509\n",
            "  epoch: 19/20,    batch: 1661/2993    Encoder_loss: 0.6541473865509033\n",
            "  epoch: 19/20,    batch: 1662/2993    Encoder_loss: 0.7302932143211365\n",
            "  epoch: 19/20,    batch: 1663/2993    Encoder_loss: 0.6510258316993713\n",
            "  epoch: 19/20,    batch: 1664/2993    Encoder_loss: 0.6653085350990295\n",
            "  epoch: 19/20,    batch: 1665/2993    Encoder_loss: 0.7259172797203064\n",
            "  epoch: 19/20,    batch: 1666/2993    Encoder_loss: 0.6247766017913818\n",
            "  epoch: 19/20,    batch: 1667/2993    Encoder_loss: 0.6807794570922852\n",
            "  epoch: 19/20,    batch: 1668/2993    Encoder_loss: 0.7032933831214905\n",
            "  epoch: 19/20,    batch: 1669/2993    Encoder_loss: 0.6152935028076172\n",
            "  epoch: 19/20,    batch: 1670/2993    Encoder_loss: 0.6358119249343872\n",
            "  epoch: 19/20,    batch: 1671/2993    Encoder_loss: 0.7011603116989136\n",
            "  epoch: 19/20,    batch: 1672/2993    Encoder_loss: 0.688653290271759\n",
            "  epoch: 19/20,    batch: 1673/2993    Encoder_loss: 0.6561397314071655\n",
            "  epoch: 19/20,    batch: 1674/2993    Encoder_loss: 0.7077367901802063\n",
            "  epoch: 19/20,    batch: 1675/2993    Encoder_loss: 0.6638341546058655\n",
            "  epoch: 19/20,    batch: 1676/2993    Encoder_loss: 0.60224848985672\n",
            "  epoch: 19/20,    batch: 1677/2993    Encoder_loss: 0.6516409516334534\n",
            "  epoch: 19/20,    batch: 1678/2993    Encoder_loss: 0.6928184628486633\n",
            "  epoch: 19/20,    batch: 1679/2993    Encoder_loss: 0.6539215445518494\n",
            "  epoch: 19/20,    batch: 1680/2993    Encoder_loss: 0.6800730228424072\n",
            "  epoch: 19/20,    batch: 1681/2993    Encoder_loss: 0.6641576290130615\n",
            "  epoch: 19/20,    batch: 1682/2993    Encoder_loss: 0.5977300405502319\n",
            "  epoch: 19/20,    batch: 1683/2993    Encoder_loss: 0.6428886651992798\n",
            "  epoch: 19/20,    batch: 1684/2993    Encoder_loss: 0.6703234314918518\n",
            "  epoch: 19/20,    batch: 1685/2993    Encoder_loss: 0.6125506162643433\n",
            "  epoch: 19/20,    batch: 1686/2993    Encoder_loss: 0.6052035689353943\n",
            "  epoch: 19/20,    batch: 1687/2993    Encoder_loss: 0.6913037896156311\n",
            "  epoch: 19/20,    batch: 1688/2993    Encoder_loss: 0.6255204677581787\n",
            "  epoch: 19/20,    batch: 1689/2993    Encoder_loss: 0.6426106691360474\n",
            "  epoch: 19/20,    batch: 1690/2993    Encoder_loss: 0.7183911800384521\n",
            "  epoch: 19/20,    batch: 1691/2993    Encoder_loss: 0.5877476930618286\n",
            "  epoch: 19/20,    batch: 1692/2993    Encoder_loss: 0.6415053606033325\n",
            "  epoch: 19/20,    batch: 1693/2993    Encoder_loss: 0.6986167430877686\n",
            "  epoch: 19/20,    batch: 1694/2993    Encoder_loss: 0.5969449877738953\n",
            "  epoch: 19/20,    batch: 1695/2993    Encoder_loss: 0.6829378008842468\n",
            "  epoch: 19/20,    batch: 1696/2993    Encoder_loss: 0.6690984964370728\n",
            "  epoch: 19/20,    batch: 1697/2993    Encoder_loss: 0.5768184065818787\n",
            "  epoch: 19/20,    batch: 1698/2993    Encoder_loss: 0.6715729832649231\n",
            "  epoch: 19/20,    batch: 1699/2993    Encoder_loss: 0.6379649639129639\n",
            "  epoch: 19/20,    batch: 1700/2993    Encoder_loss: 0.6203091144561768\n",
            "  epoch: 19/20,    batch: 1701/2993    Encoder_loss: 0.6972513794898987\n",
            "  epoch: 19/20,    batch: 1702/2993    Encoder_loss: 0.6466382741928101\n",
            "  epoch: 19/20,    batch: 1703/2993    Encoder_loss: 0.5430058240890503\n",
            "  epoch: 19/20,    batch: 1704/2993    Encoder_loss: 0.612782895565033\n",
            "  epoch: 19/20,    batch: 1705/2993    Encoder_loss: 0.6949487328529358\n",
            "  epoch: 19/20,    batch: 1706/2993    Encoder_loss: 0.6449231505393982\n",
            "  epoch: 19/20,    batch: 1707/2993    Encoder_loss: 0.6487066149711609\n",
            "  epoch: 19/20,    batch: 1708/2993    Encoder_loss: 0.7032390832901001\n",
            "  epoch: 19/20,    batch: 1709/2993    Encoder_loss: 0.6358141303062439\n",
            "  epoch: 19/20,    batch: 1710/2993    Encoder_loss: 0.5740201473236084\n",
            "  epoch: 19/20,    batch: 1711/2993    Encoder_loss: 0.6628204584121704\n",
            "  epoch: 19/20,    batch: 1712/2993    Encoder_loss: 0.6916937232017517\n",
            "  epoch: 19/20,    batch: 1713/2993    Encoder_loss: 0.5939540266990662\n",
            "  epoch: 19/20,    batch: 1714/2993    Encoder_loss: 0.6247971653938293\n",
            "  epoch: 19/20,    batch: 1715/2993    Encoder_loss: 0.6691376566886902\n",
            "  epoch: 19/20,    batch: 1716/2993    Encoder_loss: 0.6082075834274292\n",
            "  epoch: 19/20,    batch: 1717/2993    Encoder_loss: 0.589635968208313\n",
            "  epoch: 19/20,    batch: 1718/2993    Encoder_loss: 0.6841278076171875\n",
            "  epoch: 19/20,    batch: 1719/2993    Encoder_loss: 0.6942993402481079\n",
            "  epoch: 19/20,    batch: 1720/2993    Encoder_loss: 0.5706353783607483\n",
            "  epoch: 19/20,    batch: 1721/2993    Encoder_loss: 0.6062954664230347\n",
            "  epoch: 19/20,    batch: 1722/2993    Encoder_loss: 0.6763724088668823\n",
            "  epoch: 19/20,    batch: 1723/2993    Encoder_loss: 0.6282093524932861\n",
            "  epoch: 19/20,    batch: 1724/2993    Encoder_loss: 0.6781727075576782\n",
            "  epoch: 19/20,    batch: 1725/2993    Encoder_loss: 0.6667382121086121\n",
            "  epoch: 19/20,    batch: 1726/2993    Encoder_loss: 0.6188600063323975\n",
            "  epoch: 19/20,    batch: 1727/2993    Encoder_loss: 0.6825945377349854\n",
            "  epoch: 19/20,    batch: 1728/2993    Encoder_loss: 0.6585977673530579\n",
            "  epoch: 19/20,    batch: 1729/2993    Encoder_loss: 0.611211895942688\n",
            "  epoch: 19/20,    batch: 1730/2993    Encoder_loss: 0.656665563583374\n",
            "  epoch: 19/20,    batch: 1731/2993    Encoder_loss: 0.6252796053886414\n",
            "  epoch: 19/20,    batch: 1732/2993    Encoder_loss: 0.6040738821029663\n",
            "  epoch: 19/20,    batch: 1733/2993    Encoder_loss: 0.658618152141571\n",
            "  epoch: 19/20,    batch: 1734/2993    Encoder_loss: 0.5949205756187439\n",
            "  epoch: 19/20,    batch: 1735/2993    Encoder_loss: 0.6084743738174438\n",
            "  epoch: 19/20,    batch: 1736/2993    Encoder_loss: 0.6464456915855408\n",
            "  epoch: 19/20,    batch: 1737/2993    Encoder_loss: 0.5906991958618164\n",
            "  epoch: 19/20,    batch: 1738/2993    Encoder_loss: 0.5915906429290771\n",
            "  epoch: 19/20,    batch: 1739/2993    Encoder_loss: 0.6328948736190796\n",
            "  epoch: 19/20,    batch: 1740/2993    Encoder_loss: 0.611431360244751\n",
            "  epoch: 19/20,    batch: 1741/2993    Encoder_loss: 0.6395933628082275\n",
            "  epoch: 19/20,    batch: 1742/2993    Encoder_loss: 0.6799781918525696\n",
            "  epoch: 19/20,    batch: 1743/2993    Encoder_loss: 0.6223467588424683\n",
            "  epoch: 19/20,    batch: 1744/2993    Encoder_loss: 0.6139061450958252\n",
            "  epoch: 19/20,    batch: 1745/2993    Encoder_loss: 0.6844460368156433\n",
            "  epoch: 19/20,    batch: 1746/2993    Encoder_loss: 0.655880331993103\n",
            "  epoch: 19/20,    batch: 1747/2993    Encoder_loss: 0.6117429137229919\n",
            "  epoch: 19/20,    batch: 1748/2993    Encoder_loss: 0.6807911396026611\n",
            "  epoch: 19/20,    batch: 1749/2993    Encoder_loss: 0.6571171283721924\n",
            "  epoch: 19/20,    batch: 1750/2993    Encoder_loss: 0.6085284352302551\n",
            "  epoch: 19/20,    batch: 1751/2993    Encoder_loss: 0.6628915071487427\n",
            "  epoch: 19/20,    batch: 1752/2993    Encoder_loss: 0.6971732378005981\n",
            "  epoch: 19/20,    batch: 1753/2993    Encoder_loss: 0.6240166425704956\n",
            "  epoch: 19/20,    batch: 1754/2993    Encoder_loss: 0.6422549486160278\n",
            "  epoch: 19/20,    batch: 1755/2993    Encoder_loss: 0.6723756194114685\n",
            "  epoch: 19/20,    batch: 1756/2993    Encoder_loss: 0.6212566494941711\n",
            "  epoch: 19/20,    batch: 1757/2993    Encoder_loss: 0.6535633206367493\n",
            "  epoch: 19/20,    batch: 1758/2993    Encoder_loss: 0.6572667956352234\n",
            "  epoch: 19/20,    batch: 1759/2993    Encoder_loss: 0.6328821182250977\n",
            "  epoch: 19/20,    batch: 1760/2993    Encoder_loss: 0.6612688302993774\n",
            "  epoch: 19/20,    batch: 1761/2993    Encoder_loss: 0.6350353956222534\n",
            "  epoch: 19/20,    batch: 1762/2993    Encoder_loss: 0.6192314028739929\n",
            "  epoch: 19/20,    batch: 1763/2993    Encoder_loss: 0.6786783933639526\n",
            "  epoch: 19/20,    batch: 1764/2993    Encoder_loss: 0.6201617121696472\n",
            "  epoch: 19/20,    batch: 1765/2993    Encoder_loss: 0.6139228343963623\n",
            "  epoch: 19/20,    batch: 1766/2993    Encoder_loss: 0.6736403107643127\n",
            "  epoch: 19/20,    batch: 1767/2993    Encoder_loss: 0.5908525586128235\n",
            "  epoch: 19/20,    batch: 1768/2993    Encoder_loss: 0.6371623277664185\n",
            "  epoch: 19/20,    batch: 1769/2993    Encoder_loss: 0.6614169478416443\n",
            "  epoch: 19/20,    batch: 1770/2993    Encoder_loss: 0.5866003632545471\n",
            "  epoch: 19/20,    batch: 1771/2993    Encoder_loss: 0.6035059690475464\n",
            "  epoch: 19/20,    batch: 1772/2993    Encoder_loss: 0.6692052483558655\n",
            "  epoch: 19/20,    batch: 1773/2993    Encoder_loss: 0.6396666765213013\n",
            "  epoch: 19/20,    batch: 1774/2993    Encoder_loss: 0.6467151641845703\n",
            "  epoch: 19/20,    batch: 1775/2993    Encoder_loss: 0.658211886882782\n",
            "  epoch: 19/20,    batch: 1776/2993    Encoder_loss: 0.5953651666641235\n",
            "  epoch: 19/20,    batch: 1777/2993    Encoder_loss: 0.6129012703895569\n",
            "  epoch: 19/20,    batch: 1778/2993    Encoder_loss: 0.6726498007774353\n",
            "  epoch: 19/20,    batch: 1779/2993    Encoder_loss: 0.6377382874488831\n",
            "  epoch: 19/20,    batch: 1780/2993    Encoder_loss: 0.6242741942405701\n",
            "  epoch: 19/20,    batch: 1781/2993    Encoder_loss: 0.6743751764297485\n",
            "  epoch: 19/20,    batch: 1782/2993    Encoder_loss: 0.6417513489723206\n",
            "  epoch: 19/20,    batch: 1783/2993    Encoder_loss: 0.579238772392273\n",
            "  epoch: 19/20,    batch: 1784/2993    Encoder_loss: 0.676718533039093\n",
            "  epoch: 19/20,    batch: 1785/2993    Encoder_loss: 0.6987495422363281\n",
            "  epoch: 19/20,    batch: 1786/2993    Encoder_loss: 0.6009842753410339\n",
            "  epoch: 19/20,    batch: 1787/2993    Encoder_loss: 0.6718012690544128\n",
            "  epoch: 19/20,    batch: 1788/2993    Encoder_loss: 0.6702432036399841\n",
            "  epoch: 19/20,    batch: 1789/2993    Encoder_loss: 0.6196613311767578\n",
            "  epoch: 19/20,    batch: 1790/2993    Encoder_loss: 0.6952024102210999\n",
            "  epoch: 19/20,    batch: 1791/2993    Encoder_loss: 0.6339303255081177\n",
            "  epoch: 19/20,    batch: 1792/2993    Encoder_loss: 0.6054139733314514\n",
            "  epoch: 19/20,    batch: 1793/2993    Encoder_loss: 0.6979278326034546\n",
            "  epoch: 19/20,    batch: 1794/2993    Encoder_loss: 0.6508991718292236\n",
            "  epoch: 19/20,    batch: 1795/2993    Encoder_loss: 0.6844218969345093\n",
            "  epoch: 19/20,    batch: 1796/2993    Encoder_loss: 0.7309068441390991\n",
            "  epoch: 19/20,    batch: 1797/2993    Encoder_loss: 0.5928344130516052\n",
            "  epoch: 19/20,    batch: 1798/2993    Encoder_loss: 0.6501190662384033\n",
            "  epoch: 19/20,    batch: 1799/2993    Encoder_loss: 0.708000123500824\n",
            "  epoch: 19/20,    batch: 1800/2993    Encoder_loss: 0.5987468957901001\n",
            "  epoch: 19/20,    batch: 1801/2993    Encoder_loss: 0.6827166080474854\n",
            "  epoch: 19/20,    batch: 1802/2993    Encoder_loss: 0.68406742811203\n",
            "  epoch: 19/20,    batch: 1803/2993    Encoder_loss: 0.571938693523407\n",
            "  epoch: 19/20,    batch: 1804/2993    Encoder_loss: 0.5775927901268005\n",
            "  epoch: 19/20,    batch: 1805/2993    Encoder_loss: 0.6815305352210999\n",
            "  epoch: 19/20,    batch: 1806/2993    Encoder_loss: 0.6833025217056274\n",
            "  epoch: 19/20,    batch: 1807/2993    Encoder_loss: 0.6441613435745239\n",
            "  epoch: 19/20,    batch: 1808/2993    Encoder_loss: 0.7136430144309998\n",
            "  epoch: 19/20,    batch: 1809/2993    Encoder_loss: 0.6733065247535706\n",
            "  epoch: 19/20,    batch: 1810/2993    Encoder_loss: 0.5627761483192444\n",
            "  epoch: 19/20,    batch: 1811/2993    Encoder_loss: 0.5916774272918701\n",
            "  epoch: 19/20,    batch: 1812/2993    Encoder_loss: 0.6831915378570557\n",
            "  epoch: 19/20,    batch: 1813/2993    Encoder_loss: 0.6323807835578918\n",
            "  epoch: 19/20,    batch: 1814/2993    Encoder_loss: 0.5888358950614929\n",
            "  epoch: 19/20,    batch: 1815/2993    Encoder_loss: 0.6799361109733582\n",
            "  epoch: 19/20,    batch: 1816/2993    Encoder_loss: 0.6377431750297546\n",
            "  epoch: 19/20,    batch: 1817/2993    Encoder_loss: 0.5329252481460571\n",
            "  epoch: 19/20,    batch: 1818/2993    Encoder_loss: 0.6051720976829529\n",
            "  epoch: 19/20,    batch: 1819/2993    Encoder_loss: 0.6956183910369873\n",
            "  epoch: 19/20,    batch: 1820/2993    Encoder_loss: 0.6159740686416626\n",
            "  epoch: 19/20,    batch: 1821/2993    Encoder_loss: 0.591027557849884\n",
            "  epoch: 19/20,    batch: 1822/2993    Encoder_loss: 0.6784011721611023\n",
            "  epoch: 19/20,    batch: 1823/2993    Encoder_loss: 0.629431426525116\n",
            "  epoch: 19/20,    batch: 1824/2993    Encoder_loss: 0.6122175455093384\n",
            "  epoch: 19/20,    batch: 1825/2993    Encoder_loss: 0.6841462850570679\n",
            "  epoch: 19/20,    batch: 1826/2993    Encoder_loss: 0.6279441714286804\n",
            "  epoch: 19/20,    batch: 1827/2993    Encoder_loss: 0.6397377252578735\n",
            "  epoch: 19/20,    batch: 1828/2993    Encoder_loss: 0.7108219861984253\n",
            "  epoch: 19/20,    batch: 1829/2993    Encoder_loss: 0.615028440952301\n",
            "  epoch: 19/20,    batch: 1830/2993    Encoder_loss: 0.6498825550079346\n",
            "  epoch: 19/20,    batch: 1831/2993    Encoder_loss: 0.6932902932167053\n",
            "  epoch: 19/20,    batch: 1832/2993    Encoder_loss: 0.6263206005096436\n",
            "  epoch: 19/20,    batch: 1833/2993    Encoder_loss: 0.675873339176178\n",
            "  epoch: 19/20,    batch: 1834/2993    Encoder_loss: 0.6620545983314514\n",
            "  epoch: 19/20,    batch: 1835/2993    Encoder_loss: 0.6011309027671814\n",
            "  epoch: 19/20,    batch: 1836/2993    Encoder_loss: 0.6315164566040039\n",
            "  epoch: 19/20,    batch: 1837/2993    Encoder_loss: 0.5927637219429016\n",
            "  epoch: 19/20,    batch: 1838/2993    Encoder_loss: 0.5414355397224426\n",
            "  epoch: 19/20,    batch: 1839/2993    Encoder_loss: 0.6109318137168884\n",
            "  epoch: 19/20,    batch: 1840/2993    Encoder_loss: 0.6337358951568604\n",
            "  epoch: 19/20,    batch: 1841/2993    Encoder_loss: 0.5672934055328369\n",
            "  epoch: 19/20,    batch: 1842/2993    Encoder_loss: 0.6456699967384338\n",
            "  epoch: 19/20,    batch: 1843/2993    Encoder_loss: 0.6374387145042419\n",
            "  epoch: 19/20,    batch: 1844/2993    Encoder_loss: 0.5351484417915344\n",
            "  epoch: 19/20,    batch: 1845/2993    Encoder_loss: 0.6099555492401123\n",
            "  epoch: 19/20,    batch: 1846/2993    Encoder_loss: 0.6689634323120117\n",
            "  epoch: 19/20,    batch: 1847/2993    Encoder_loss: 0.5804729461669922\n",
            "  epoch: 19/20,    batch: 1848/2993    Encoder_loss: 0.6164025664329529\n",
            "  epoch: 19/20,    batch: 1849/2993    Encoder_loss: 0.6641037464141846\n",
            "  epoch: 19/20,    batch: 1850/2993    Encoder_loss: 0.5747400522232056\n",
            "  epoch: 19/20,    batch: 1851/2993    Encoder_loss: 0.5871963500976562\n",
            "  epoch: 19/20,    batch: 1852/2993    Encoder_loss: 0.663192629814148\n",
            "  epoch: 19/20,    batch: 1853/2993    Encoder_loss: 0.6248739957809448\n",
            "  epoch: 19/20,    batch: 1854/2993    Encoder_loss: 0.6068795323371887\n",
            "  epoch: 19/20,    batch: 1855/2993    Encoder_loss: 0.6612592339515686\n",
            "  epoch: 19/20,    batch: 1856/2993    Encoder_loss: 0.6098006367683411\n",
            "  epoch: 19/20,    batch: 1857/2993    Encoder_loss: 0.6367469429969788\n",
            "  epoch: 19/20,    batch: 1858/2993    Encoder_loss: 0.7004590630531311\n",
            "  epoch: 19/20,    batch: 1859/2993    Encoder_loss: 0.6134126782417297\n",
            "  epoch: 19/20,    batch: 1860/2993    Encoder_loss: 0.6558467149734497\n",
            "  epoch: 19/20,    batch: 1861/2993    Encoder_loss: 0.6991510391235352\n",
            "  epoch: 19/20,    batch: 1862/2993    Encoder_loss: 0.6236667633056641\n",
            "  epoch: 19/20,    batch: 1863/2993    Encoder_loss: 0.6778634190559387\n",
            "  epoch: 19/20,    batch: 1864/2993    Encoder_loss: 0.6759408712387085\n",
            "  epoch: 19/20,    batch: 1865/2993    Encoder_loss: 0.615799605846405\n",
            "  epoch: 19/20,    batch: 1866/2993    Encoder_loss: 0.6726685762405396\n",
            "  epoch: 19/20,    batch: 1867/2993    Encoder_loss: 0.6477342844009399\n",
            "  epoch: 19/20,    batch: 1868/2993    Encoder_loss: 0.60810387134552\n",
            "  epoch: 19/20,    batch: 1869/2993    Encoder_loss: 0.6456242203712463\n",
            "  epoch: 19/20,    batch: 1870/2993    Encoder_loss: 0.5991255640983582\n",
            "  epoch: 19/20,    batch: 1871/2993    Encoder_loss: 0.5771662592887878\n",
            "  epoch: 19/20,    batch: 1872/2993    Encoder_loss: 0.6378360390663147\n",
            "  epoch: 19/20,    batch: 1873/2993    Encoder_loss: 0.6349073052406311\n",
            "  epoch: 19/20,    batch: 1874/2993    Encoder_loss: 0.6167487502098083\n",
            "  epoch: 19/20,    batch: 1875/2993    Encoder_loss: 0.6792051792144775\n",
            "  epoch: 19/20,    batch: 1876/2993    Encoder_loss: 0.6416364908218384\n",
            "  epoch: 19/20,    batch: 1877/2993    Encoder_loss: 0.5734901428222656\n",
            "  epoch: 19/20,    batch: 1878/2993    Encoder_loss: 0.6661995649337769\n",
            "  epoch: 19/20,    batch: 1879/2993    Encoder_loss: 0.6858944296836853\n",
            "  epoch: 19/20,    batch: 1880/2993    Encoder_loss: 0.5934823155403137\n",
            "  epoch: 19/20,    batch: 1881/2993    Encoder_loss: 0.6521804928779602\n",
            "  epoch: 19/20,    batch: 1882/2993    Encoder_loss: 0.6603215336799622\n",
            "  epoch: 19/20,    batch: 1883/2993    Encoder_loss: 0.5850409865379333\n",
            "  epoch: 19/20,    batch: 1884/2993    Encoder_loss: 0.6322470903396606\n",
            "  epoch: 19/20,    batch: 1885/2993    Encoder_loss: 0.6740267276763916\n",
            "  epoch: 19/20,    batch: 1886/2993    Encoder_loss: 0.5968305468559265\n",
            "  epoch: 19/20,    batch: 1887/2993    Encoder_loss: 0.6282550096511841\n",
            "  epoch: 19/20,    batch: 1888/2993    Encoder_loss: 0.7019387483596802\n",
            "  epoch: 19/20,    batch: 1889/2993    Encoder_loss: 0.6294532418251038\n",
            "  epoch: 19/20,    batch: 1890/2993    Encoder_loss: 0.6821698546409607\n",
            "  epoch: 19/20,    batch: 1891/2993    Encoder_loss: 0.7195339202880859\n",
            "  epoch: 19/20,    batch: 1892/2993    Encoder_loss: 0.6229224801063538\n",
            "  epoch: 19/20,    batch: 1893/2993    Encoder_loss: 0.6636995077133179\n",
            "  epoch: 19/20,    batch: 1894/2993    Encoder_loss: 0.6525294780731201\n",
            "  epoch: 19/20,    batch: 1895/2993    Encoder_loss: 0.6023913621902466\n",
            "  epoch: 19/20,    batch: 1896/2993    Encoder_loss: 0.6854923963546753\n",
            "  epoch: 19/20,    batch: 1897/2993    Encoder_loss: 0.6388548612594604\n",
            "  epoch: 19/20,    batch: 1898/2993    Encoder_loss: 0.6147292852401733\n",
            "  epoch: 19/20,    batch: 1899/2993    Encoder_loss: 0.7177572250366211\n",
            "  epoch: 19/20,    batch: 1900/2993    Encoder_loss: 0.6294682621955872\n",
            "  epoch: 19/20,    batch: 1901/2993    Encoder_loss: 0.6193771958351135\n",
            "  epoch: 19/20,    batch: 1902/2993    Encoder_loss: 0.6910421848297119\n",
            "  epoch: 19/20,    batch: 1903/2993    Encoder_loss: 0.6064110994338989\n",
            "  epoch: 19/20,    batch: 1904/2993    Encoder_loss: 0.5805181264877319\n",
            "  epoch: 19/20,    batch: 1905/2993    Encoder_loss: 0.6544665098190308\n",
            "  epoch: 19/20,    batch: 1906/2993    Encoder_loss: 0.6584226489067078\n",
            "  epoch: 19/20,    batch: 1907/2993    Encoder_loss: 0.6541198492050171\n",
            "  epoch: 19/20,    batch: 1908/2993    Encoder_loss: 0.6759700775146484\n",
            "  epoch: 19/20,    batch: 1909/2993    Encoder_loss: 0.6117557287216187\n",
            "  epoch: 19/20,    batch: 1910/2993    Encoder_loss: 0.5777623653411865\n",
            "  epoch: 19/20,    batch: 1911/2993    Encoder_loss: 0.6579750776290894\n",
            "  epoch: 19/20,    batch: 1912/2993    Encoder_loss: 0.6707876920700073\n",
            "  epoch: 19/20,    batch: 1913/2993    Encoder_loss: 0.6256102919578552\n",
            "  epoch: 19/20,    batch: 1914/2993    Encoder_loss: 0.7025312781333923\n",
            "  epoch: 19/20,    batch: 1915/2993    Encoder_loss: 0.6623961329460144\n",
            "  epoch: 19/20,    batch: 1916/2993    Encoder_loss: 0.5664828419685364\n",
            "  epoch: 19/20,    batch: 1917/2993    Encoder_loss: 0.633369505405426\n",
            "  epoch: 19/20,    batch: 1918/2993    Encoder_loss: 0.7039743661880493\n",
            "  epoch: 19/20,    batch: 1919/2993    Encoder_loss: 0.6341941952705383\n",
            "  epoch: 19/20,    batch: 1920/2993    Encoder_loss: 0.6777772307395935\n",
            "  epoch: 19/20,    batch: 1921/2993    Encoder_loss: 0.7182865142822266\n",
            "  epoch: 19/20,    batch: 1922/2993    Encoder_loss: 0.6232348680496216\n",
            "  epoch: 19/20,    batch: 1923/2993    Encoder_loss: 0.6867502331733704\n",
            "  epoch: 19/20,    batch: 1924/2993    Encoder_loss: 0.6636155247688293\n",
            "  epoch: 19/20,    batch: 1925/2993    Encoder_loss: 0.5961366295814514\n",
            "  epoch: 19/20,    batch: 1926/2993    Encoder_loss: 0.6977992653846741\n",
            "  epoch: 19/20,    batch: 1927/2993    Encoder_loss: 0.6552146077156067\n",
            "  epoch: 19/20,    batch: 1928/2993    Encoder_loss: 0.6132097840309143\n",
            "  epoch: 19/20,    batch: 1929/2993    Encoder_loss: 0.7092201113700867\n",
            "  epoch: 19/20,    batch: 1930/2993    Encoder_loss: 0.6400702595710754\n",
            "  epoch: 19/20,    batch: 1931/2993    Encoder_loss: 0.6504217386245728\n",
            "  epoch: 19/20,    batch: 1932/2993    Encoder_loss: 0.737208902835846\n",
            "  epoch: 19/20,    batch: 1933/2993    Encoder_loss: 0.6277787089347839\n",
            "  epoch: 19/20,    batch: 1934/2993    Encoder_loss: 0.6494340300559998\n",
            "  epoch: 19/20,    batch: 1935/2993    Encoder_loss: 0.695780336856842\n",
            "  epoch: 19/20,    batch: 1936/2993    Encoder_loss: 0.6044348478317261\n",
            "  epoch: 19/20,    batch: 1937/2993    Encoder_loss: 0.5627362728118896\n",
            "  epoch: 19/20,    batch: 1938/2993    Encoder_loss: 0.6601890921592712\n",
            "  epoch: 19/20,    batch: 1939/2993    Encoder_loss: 0.7138547897338867\n",
            "  epoch: 19/20,    batch: 1940/2993    Encoder_loss: 0.614712655544281\n",
            "  epoch: 19/20,    batch: 1941/2993    Encoder_loss: 0.6658492684364319\n",
            "  epoch: 19/20,    batch: 1942/2993    Encoder_loss: 0.6907655000686646\n",
            "  epoch: 19/20,    batch: 1943/2993    Encoder_loss: 0.5995582938194275\n",
            "  epoch: 19/20,    batch: 1944/2993    Encoder_loss: 0.6079957485198975\n",
            "  epoch: 19/20,    batch: 1945/2993    Encoder_loss: 0.7061280012130737\n",
            "  epoch: 19/20,    batch: 1946/2993    Encoder_loss: 0.6822689175605774\n",
            "  epoch: 19/20,    batch: 1947/2993    Encoder_loss: 0.5846117734909058\n",
            "  epoch: 19/20,    batch: 1948/2993    Encoder_loss: 0.6961265206336975\n",
            "  epoch: 19/20,    batch: 1949/2993    Encoder_loss: 0.6836091876029968\n",
            "  epoch: 19/20,    batch: 1950/2993    Encoder_loss: 0.5637444257736206\n",
            "  epoch: 19/20,    batch: 1951/2993    Encoder_loss: 0.5957822203636169\n",
            "  epoch: 19/20,    batch: 1952/2993    Encoder_loss: 0.6973781585693359\n",
            "  epoch: 19/20,    batch: 1953/2993    Encoder_loss: 0.650323748588562\n",
            "  epoch: 19/20,    batch: 1954/2993    Encoder_loss: 0.5694677829742432\n",
            "  epoch: 19/20,    batch: 1955/2993    Encoder_loss: 0.6551402807235718\n",
            "  epoch: 19/20,    batch: 1956/2993    Encoder_loss: 0.6363709568977356\n",
            "  epoch: 19/20,    batch: 1957/2993    Encoder_loss: 0.6039429903030396\n",
            "  epoch: 19/20,    batch: 1958/2993    Encoder_loss: 0.6744040846824646\n",
            "  epoch: 19/20,    batch: 1959/2993    Encoder_loss: 0.631399929523468\n",
            "  epoch: 19/20,    batch: 1960/2993    Encoder_loss: 0.6118183135986328\n",
            "  epoch: 19/20,    batch: 1961/2993    Encoder_loss: 0.6791918277740479\n",
            "  epoch: 19/20,    batch: 1962/2993    Encoder_loss: 0.6042688488960266\n",
            "  epoch: 19/20,    batch: 1963/2993    Encoder_loss: 0.6137656569480896\n",
            "  epoch: 19/20,    batch: 1964/2993    Encoder_loss: 0.6879581212997437\n",
            "  epoch: 19/20,    batch: 1965/2993    Encoder_loss: 0.6021329760551453\n",
            "  epoch: 19/20,    batch: 1966/2993    Encoder_loss: 0.6374304890632629\n",
            "  epoch: 19/20,    batch: 1967/2993    Encoder_loss: 0.683600127696991\n",
            "  epoch: 19/20,    batch: 1968/2993    Encoder_loss: 0.6093447804450989\n",
            "  epoch: 19/20,    batch: 1969/2993    Encoder_loss: 0.6395759582519531\n",
            "  epoch: 19/20,    batch: 1970/2993    Encoder_loss: 0.6353870630264282\n",
            "  epoch: 19/20,    batch: 1971/2993    Encoder_loss: 0.5717735886573792\n",
            "  epoch: 19/20,    batch: 1972/2993    Encoder_loss: 0.6071426272392273\n",
            "  epoch: 19/20,    batch: 1973/2993    Encoder_loss: 0.6760791540145874\n",
            "  epoch: 19/20,    batch: 1974/2993    Encoder_loss: 0.6420988440513611\n",
            "  epoch: 19/20,    batch: 1975/2993    Encoder_loss: 0.6944753527641296\n",
            "  epoch: 19/20,    batch: 1976/2993    Encoder_loss: 0.7007096409797668\n",
            "  epoch: 19/20,    batch: 1977/2993    Encoder_loss: 0.6015585660934448\n",
            "  epoch: 19/20,    batch: 1978/2993    Encoder_loss: 0.6068484783172607\n",
            "  epoch: 19/20,    batch: 1979/2993    Encoder_loss: 0.642673671245575\n",
            "  epoch: 19/20,    batch: 1980/2993    Encoder_loss: 0.6142542362213135\n",
            "  epoch: 19/20,    batch: 1981/2993    Encoder_loss: 0.6314442157745361\n",
            "  epoch: 19/20,    batch: 1982/2993    Encoder_loss: 0.6773675084114075\n",
            "  epoch: 19/20,    batch: 1983/2993    Encoder_loss: 0.6372656226158142\n",
            "  epoch: 19/20,    batch: 1984/2993    Encoder_loss: 0.5968729853630066\n",
            "  epoch: 19/20,    batch: 1985/2993    Encoder_loss: 0.6474851369857788\n",
            "  epoch: 19/20,    batch: 1986/2993    Encoder_loss: 0.6377435326576233\n",
            "  epoch: 19/20,    batch: 1987/2993    Encoder_loss: 0.5983197689056396\n",
            "  epoch: 19/20,    batch: 1988/2993    Encoder_loss: 0.6676105260848999\n",
            "  epoch: 19/20,    batch: 1989/2993    Encoder_loss: 0.633456289768219\n",
            "  epoch: 19/20,    batch: 1990/2993    Encoder_loss: 0.6010856032371521\n",
            "  epoch: 19/20,    batch: 1991/2993    Encoder_loss: 0.6671218276023865\n",
            "  epoch: 19/20,    batch: 1992/2993    Encoder_loss: 0.5916032195091248\n",
            "  epoch: 19/20,    batch: 1993/2993    Encoder_loss: 0.5992156863212585\n",
            "  epoch: 19/20,    batch: 1994/2993    Encoder_loss: 0.6849719882011414\n",
            "  epoch: 19/20,    batch: 1995/2993    Encoder_loss: 0.5985814929008484\n",
            "  epoch: 19/20,    batch: 1996/2993    Encoder_loss: 0.6590653657913208\n",
            "  epoch: 19/20,    batch: 1997/2993    Encoder_loss: 0.7039657831192017\n",
            "  epoch: 19/20,    batch: 1998/2993    Encoder_loss: 0.5734633803367615\n",
            "  epoch: 19/20,    batch: 1999/2993    Encoder_loss: 0.641476571559906\n",
            "  epoch: 19/20,    batch: 2000/2993    Encoder_loss: 0.6643794775009155\n",
            "  epoch: 19/20,    batch: 2001/2993    Encoder_loss: 0.6048696637153625\n",
            "  epoch: 19/20,    batch: 2002/2993    Encoder_loss: 0.683043897151947\n",
            "  epoch: 19/20,    batch: 2003/2993    Encoder_loss: 0.6499775052070618\n",
            "  epoch: 19/20,    batch: 2004/2993    Encoder_loss: 0.5724694728851318\n",
            "  epoch: 19/20,    batch: 2005/2993    Encoder_loss: 0.6165827512741089\n",
            "  epoch: 19/20,    batch: 2006/2993    Encoder_loss: 0.6862504482269287\n",
            "  epoch: 19/20,    batch: 2007/2993    Encoder_loss: 0.6491015553474426\n",
            "  epoch: 19/20,    batch: 2008/2993    Encoder_loss: 0.6235126256942749\n",
            "  epoch: 19/20,    batch: 2009/2993    Encoder_loss: 0.6926742196083069\n",
            "  epoch: 19/20,    batch: 2010/2993    Encoder_loss: 0.6637315154075623\n",
            "  epoch: 19/20,    batch: 2011/2993    Encoder_loss: 0.589011549949646\n",
            "  epoch: 19/20,    batch: 2012/2993    Encoder_loss: 0.6540467739105225\n",
            "  epoch: 19/20,    batch: 2013/2993    Encoder_loss: 0.7194198369979858\n",
            "  epoch: 19/20,    batch: 2014/2993    Encoder_loss: 0.6540107727050781\n",
            "  epoch: 19/20,    batch: 2015/2993    Encoder_loss: 0.6470595002174377\n",
            "  epoch: 19/20,    batch: 2016/2993    Encoder_loss: 0.7219355702400208\n",
            "  epoch: 19/20,    batch: 2017/2993    Encoder_loss: 0.6705343723297119\n",
            "  epoch: 19/20,    batch: 2018/2993    Encoder_loss: 0.5710390210151672\n",
            "  epoch: 19/20,    batch: 2019/2993    Encoder_loss: 0.6473004817962646\n",
            "  epoch: 19/20,    batch: 2020/2993    Encoder_loss: 0.6826199889183044\n",
            "  epoch: 19/20,    batch: 2021/2993    Encoder_loss: 0.5919078588485718\n",
            "  epoch: 19/20,    batch: 2022/2993    Encoder_loss: 0.6065635085105896\n",
            "  epoch: 19/20,    batch: 2023/2993    Encoder_loss: 0.6920191645622253\n",
            "  epoch: 19/20,    batch: 2024/2993    Encoder_loss: 0.6187622547149658\n",
            "  epoch: 19/20,    batch: 2025/2993    Encoder_loss: 0.6728671193122864\n",
            "  epoch: 19/20,    batch: 2026/2993    Encoder_loss: 0.7122365832328796\n",
            "  epoch: 19/20,    batch: 2027/2993    Encoder_loss: 0.6217157244682312\n",
            "  epoch: 19/20,    batch: 2028/2993    Encoder_loss: 0.6930623650550842\n",
            "  epoch: 19/20,    batch: 2029/2993    Encoder_loss: 0.6944464445114136\n",
            "  epoch: 19/20,    batch: 2030/2993    Encoder_loss: 0.6138750314712524\n",
            "  epoch: 19/20,    batch: 2031/2993    Encoder_loss: 0.6719531416893005\n",
            "  epoch: 19/20,    batch: 2032/2993    Encoder_loss: 0.6611128449440002\n",
            "  epoch: 19/20,    batch: 2033/2993    Encoder_loss: 0.6338451504707336\n",
            "  epoch: 19/20,    batch: 2034/2993    Encoder_loss: 0.7023342847824097\n",
            "  epoch: 19/20,    batch: 2035/2993    Encoder_loss: 0.6590850353240967\n",
            "  epoch: 19/20,    batch: 2036/2993    Encoder_loss: 0.6308501958847046\n",
            "  epoch: 19/20,    batch: 2037/2993    Encoder_loss: 0.6646966934204102\n",
            "  epoch: 19/20,    batch: 2038/2993    Encoder_loss: 0.6201903223991394\n",
            "  epoch: 19/20,    batch: 2039/2993    Encoder_loss: 0.584995448589325\n",
            "  epoch: 19/20,    batch: 2040/2993    Encoder_loss: 0.6644580364227295\n",
            "  epoch: 19/20,    batch: 2041/2993    Encoder_loss: 0.6730381846427917\n",
            "  epoch: 19/20,    batch: 2042/2993    Encoder_loss: 0.6142753958702087\n",
            "  epoch: 19/20,    batch: 2043/2993    Encoder_loss: 0.6351194977760315\n",
            "  epoch: 19/20,    batch: 2044/2993    Encoder_loss: 0.6849806308746338\n",
            "  epoch: 19/20,    batch: 2045/2993    Encoder_loss: 0.6275666356086731\n",
            "  epoch: 19/20,    batch: 2046/2993    Encoder_loss: 0.6023609042167664\n",
            "  epoch: 19/20,    batch: 2047/2993    Encoder_loss: 0.6871984004974365\n",
            "  epoch: 19/20,    batch: 2048/2993    Encoder_loss: 0.7203242778778076\n",
            "  epoch: 19/20,    batch: 2049/2993    Encoder_loss: 0.6382837295532227\n",
            "  epoch: 19/20,    batch: 2050/2993    Encoder_loss: 0.6678937077522278\n",
            "  epoch: 19/20,    batch: 2051/2993    Encoder_loss: 0.7007181644439697\n",
            "  epoch: 19/20,    batch: 2052/2993    Encoder_loss: 0.6221744418144226\n",
            "  epoch: 19/20,    batch: 2053/2993    Encoder_loss: 0.6129416823387146\n",
            "  epoch: 19/20,    batch: 2054/2993    Encoder_loss: 0.6960715055465698\n",
            "  epoch: 19/20,    batch: 2055/2993    Encoder_loss: 0.7151044011116028\n",
            "  epoch: 19/20,    batch: 2056/2993    Encoder_loss: 0.6042949557304382\n",
            "  epoch: 19/20,    batch: 2057/2993    Encoder_loss: 0.6731285452842712\n",
            "  epoch: 19/20,    batch: 2058/2993    Encoder_loss: 0.689709484577179\n",
            "  epoch: 19/20,    batch: 2059/2993    Encoder_loss: 0.614564061164856\n",
            "  epoch: 19/20,    batch: 2060/2993    Encoder_loss: 0.7126871943473816\n",
            "  epoch: 19/20,    batch: 2061/2993    Encoder_loss: 0.6817629337310791\n",
            "  epoch: 19/20,    batch: 2062/2993    Encoder_loss: 0.639456570148468\n",
            "  epoch: 19/20,    batch: 2063/2993    Encoder_loss: 0.7229165434837341\n",
            "  epoch: 19/20,    batch: 2064/2993    Encoder_loss: 0.6662008166313171\n",
            "  epoch: 19/20,    batch: 2065/2993    Encoder_loss: 0.6464470028877258\n",
            "  epoch: 19/20,    batch: 2066/2993    Encoder_loss: 0.7267739772796631\n",
            "  epoch: 19/20,    batch: 2067/2993    Encoder_loss: 0.6447157263755798\n",
            "  epoch: 19/20,    batch: 2068/2993    Encoder_loss: 0.6662867665290833\n",
            "  epoch: 19/20,    batch: 2069/2993    Encoder_loss: 0.734075129032135\n",
            "  epoch: 19/20,    batch: 2070/2993    Encoder_loss: 0.6168747544288635\n",
            "  epoch: 19/20,    batch: 2071/2993    Encoder_loss: 0.692412793636322\n",
            "  epoch: 19/20,    batch: 2072/2993    Encoder_loss: 0.7366225123405457\n",
            "  epoch: 19/20,    batch: 2073/2993    Encoder_loss: 0.6274705529212952\n",
            "  epoch: 19/20,    batch: 2074/2993    Encoder_loss: 0.6139742136001587\n",
            "  epoch: 19/20,    batch: 2075/2993    Encoder_loss: 0.7227555513381958\n",
            "  epoch: 19/20,    batch: 2076/2993    Encoder_loss: 0.7056163549423218\n",
            "  epoch: 19/20,    batch: 2077/2993    Encoder_loss: 0.637173056602478\n",
            "  epoch: 19/20,    batch: 2078/2993    Encoder_loss: 0.6842190623283386\n",
            "  epoch: 19/20,    batch: 2079/2993    Encoder_loss: 0.6577360033988953\n",
            "  epoch: 19/20,    batch: 2080/2993    Encoder_loss: 0.6253491044044495\n",
            "  epoch: 19/20,    batch: 2081/2993    Encoder_loss: 0.6951815485954285\n",
            "  epoch: 19/20,    batch: 2082/2993    Encoder_loss: 0.728756844997406\n",
            "  epoch: 19/20,    batch: 2083/2993    Encoder_loss: 0.679955244064331\n",
            "  epoch: 19/20,    batch: 2084/2993    Encoder_loss: 0.7253387570381165\n",
            "  epoch: 19/20,    batch: 2085/2993    Encoder_loss: 0.7134203314781189\n",
            "  epoch: 19/20,    batch: 2086/2993    Encoder_loss: 0.6208241581916809\n",
            "  epoch: 19/20,    batch: 2087/2993    Encoder_loss: 0.6586277484893799\n",
            "  epoch: 19/20,    batch: 2088/2993    Encoder_loss: 0.7035067081451416\n",
            "  epoch: 19/20,    batch: 2089/2993    Encoder_loss: 0.6442110538482666\n",
            "  epoch: 19/20,    batch: 2090/2993    Encoder_loss: 0.6806095838546753\n",
            "  epoch: 19/20,    batch: 2091/2993    Encoder_loss: 0.7273873090744019\n",
            "  epoch: 19/20,    batch: 2092/2993    Encoder_loss: 0.6134050488471985\n",
            "  epoch: 19/20,    batch: 2093/2993    Encoder_loss: 0.7096692323684692\n",
            "  epoch: 19/20,    batch: 2094/2993    Encoder_loss: 0.722686231136322\n",
            "  epoch: 19/20,    batch: 2095/2993    Encoder_loss: 0.6281232237815857\n",
            "  epoch: 19/20,    batch: 2096/2993    Encoder_loss: 0.7111822366714478\n",
            "  epoch: 19/20,    batch: 2097/2993    Encoder_loss: 0.6879090666770935\n",
            "  epoch: 19/20,    batch: 2098/2993    Encoder_loss: 0.6478273272514343\n",
            "  epoch: 19/20,    batch: 2099/2993    Encoder_loss: 0.7408291697502136\n",
            "  epoch: 19/20,    batch: 2100/2993    Encoder_loss: 0.6615668535232544\n",
            "  epoch: 19/20,    batch: 2101/2993    Encoder_loss: 0.6460850238800049\n",
            "  epoch: 19/20,    batch: 2102/2993    Encoder_loss: 0.7327634692192078\n",
            "  epoch: 19/20,    batch: 2103/2993    Encoder_loss: 0.6441413760185242\n",
            "  epoch: 19/20,    batch: 2104/2993    Encoder_loss: 0.6590907573699951\n",
            "  epoch: 19/20,    batch: 2105/2993    Encoder_loss: 0.7531103491783142\n",
            "  epoch: 19/20,    batch: 2106/2993    Encoder_loss: 0.6336393356323242\n",
            "  epoch: 19/20,    batch: 2107/2993    Encoder_loss: 0.5683516263961792\n",
            "  epoch: 19/20,    batch: 2108/2993    Encoder_loss: 0.6869304180145264\n",
            "  epoch: 19/20,    batch: 2109/2993    Encoder_loss: 0.7035190463066101\n",
            "  epoch: 19/20,    batch: 2110/2993    Encoder_loss: 0.5677751302719116\n",
            "  epoch: 19/20,    batch: 2111/2993    Encoder_loss: 0.640809178352356\n",
            "  epoch: 19/20,    batch: 2112/2993    Encoder_loss: 0.747607409954071\n",
            "  epoch: 19/20,    batch: 2113/2993    Encoder_loss: 0.7048346400260925\n",
            "  epoch: 19/20,    batch: 2114/2993    Encoder_loss: 0.7280900478363037\n",
            "  epoch: 19/20,    batch: 2115/2993    Encoder_loss: 0.7768875956535339\n",
            "  epoch: 19/20,    batch: 2116/2993    Encoder_loss: 0.7514985799789429\n",
            "  epoch: 19/20,    batch: 2117/2993    Encoder_loss: 0.665701150894165\n",
            "  epoch: 19/20,    batch: 2118/2993    Encoder_loss: 0.6986634731292725\n",
            "  epoch: 19/20,    batch: 2119/2993    Encoder_loss: 0.686478316783905\n",
            "  epoch: 19/20,    batch: 2120/2993    Encoder_loss: 0.5933248996734619\n",
            "  epoch: 19/20,    batch: 2121/2993    Encoder_loss: 0.6081330180168152\n",
            "  epoch: 19/20,    batch: 2122/2993    Encoder_loss: 0.6900635361671448\n",
            "  epoch: 19/20,    batch: 2123/2993    Encoder_loss: 0.6704088449478149\n",
            "  epoch: 19/20,    batch: 2124/2993    Encoder_loss: 0.5995105504989624\n",
            "  epoch: 19/20,    batch: 2125/2993    Encoder_loss: 0.7019930481910706\n",
            "  epoch: 19/20,    batch: 2126/2993    Encoder_loss: 0.6803397536277771\n",
            "  epoch: 19/20,    batch: 2127/2993    Encoder_loss: 0.5988753437995911\n",
            "  epoch: 19/20,    batch: 2128/2993    Encoder_loss: 0.7035372853279114\n",
            "  epoch: 19/20,    batch: 2129/2993    Encoder_loss: 0.6605228185653687\n",
            "  epoch: 19/20,    batch: 2130/2993    Encoder_loss: 0.5967347025871277\n",
            "  epoch: 19/20,    batch: 2131/2993    Encoder_loss: 0.6892893314361572\n",
            "  epoch: 19/20,    batch: 2132/2993    Encoder_loss: 0.6078126430511475\n",
            "  epoch: 19/20,    batch: 2133/2993    Encoder_loss: 0.6046396493911743\n",
            "  epoch: 19/20,    batch: 2134/2993    Encoder_loss: 0.6996847987174988\n",
            "  epoch: 19/20,    batch: 2135/2993    Encoder_loss: 0.5825591683387756\n",
            "  epoch: 19/20,    batch: 2136/2993    Encoder_loss: 0.6556495428085327\n",
            "  epoch: 19/20,    batch: 2137/2993    Encoder_loss: 0.7202938199043274\n",
            "  epoch: 19/20,    batch: 2138/2993    Encoder_loss: 0.583246111869812\n",
            "  epoch: 19/20,    batch: 2139/2993    Encoder_loss: 0.665418803691864\n",
            "  epoch: 19/20,    batch: 2140/2993    Encoder_loss: 0.6859833598136902\n",
            "  epoch: 19/20,    batch: 2141/2993    Encoder_loss: 0.6016618013381958\n",
            "  epoch: 19/20,    batch: 2142/2993    Encoder_loss: 0.6485275030136108\n",
            "  epoch: 19/20,    batch: 2143/2993    Encoder_loss: 0.7244618535041809\n",
            "  epoch: 19/20,    batch: 2144/2993    Encoder_loss: 0.6478990912437439\n",
            "  epoch: 19/20,    batch: 2145/2993    Encoder_loss: 0.6453624963760376\n",
            "  epoch: 19/20,    batch: 2146/2993    Encoder_loss: 0.6842600107192993\n",
            "  epoch: 19/20,    batch: 2147/2993    Encoder_loss: 0.6351912021636963\n",
            "  epoch: 19/20,    batch: 2148/2993    Encoder_loss: 0.6490079760551453\n",
            "  epoch: 19/20,    batch: 2149/2993    Encoder_loss: 0.7027585506439209\n",
            "  epoch: 19/20,    batch: 2150/2993    Encoder_loss: 0.6534151434898376\n",
            "  epoch: 19/20,    batch: 2151/2993    Encoder_loss: 0.6442543864250183\n",
            "  epoch: 19/20,    batch: 2152/2993    Encoder_loss: 0.7149742841720581\n",
            "  epoch: 19/20,    batch: 2153/2993    Encoder_loss: 0.6487682461738586\n",
            "  epoch: 19/20,    batch: 2154/2993    Encoder_loss: 0.6184898614883423\n",
            "  epoch: 19/20,    batch: 2155/2993    Encoder_loss: 0.7062996029853821\n",
            "  epoch: 19/20,    batch: 2156/2993    Encoder_loss: 0.6802934408187866\n",
            "  epoch: 19/20,    batch: 2157/2993    Encoder_loss: 0.6072094440460205\n",
            "  epoch: 19/20,    batch: 2158/2993    Encoder_loss: 0.700861394405365\n",
            "  epoch: 19/20,    batch: 2159/2993    Encoder_loss: 0.6510992646217346\n",
            "  epoch: 19/20,    batch: 2160/2993    Encoder_loss: 0.6084544658660889\n",
            "  epoch: 19/20,    batch: 2161/2993    Encoder_loss: 0.6934738159179688\n",
            "  epoch: 19/20,    batch: 2162/2993    Encoder_loss: 0.6208360195159912\n",
            "  epoch: 19/20,    batch: 2163/2993    Encoder_loss: 0.6141232252120972\n",
            "  epoch: 19/20,    batch: 2164/2993    Encoder_loss: 0.700851559638977\n",
            "  epoch: 19/20,    batch: 2165/2993    Encoder_loss: 0.5946764349937439\n",
            "  epoch: 19/20,    batch: 2166/2993    Encoder_loss: 0.6485092043876648\n",
            "  epoch: 19/20,    batch: 2167/2993    Encoder_loss: 0.7012971043586731\n",
            "  epoch: 19/20,    batch: 2168/2993    Encoder_loss: 0.5830386877059937\n",
            "  epoch: 19/20,    batch: 2169/2993    Encoder_loss: 0.6654528379440308\n",
            "  epoch: 19/20,    batch: 2170/2993    Encoder_loss: 0.6815696954727173\n",
            "  epoch: 19/20,    batch: 2171/2993    Encoder_loss: 0.6033563613891602\n",
            "  epoch: 19/20,    batch: 2172/2993    Encoder_loss: 0.6916831135749817\n",
            "  epoch: 19/20,    batch: 2173/2993    Encoder_loss: 0.6766437292098999\n",
            "  epoch: 19/20,    batch: 2174/2993    Encoder_loss: 0.5988895297050476\n",
            "  epoch: 19/20,    batch: 2175/2993    Encoder_loss: 0.6852931380271912\n",
            "  epoch: 19/20,    batch: 2176/2993    Encoder_loss: 0.7536783814430237\n",
            "  epoch: 19/20,    batch: 2177/2993    Encoder_loss: 0.6579417586326599\n",
            "  epoch: 19/20,    batch: 2178/2993    Encoder_loss: 0.6825708746910095\n",
            "  epoch: 19/20,    batch: 2179/2993    Encoder_loss: 0.6954232454299927\n",
            "  epoch: 19/20,    batch: 2180/2993    Encoder_loss: 0.6516640782356262\n",
            "  epoch: 19/20,    batch: 2181/2993    Encoder_loss: 0.6936651468276978\n",
            "  epoch: 19/20,    batch: 2182/2993    Encoder_loss: 0.730731189250946\n",
            "  epoch: 19/20,    batch: 2183/2993    Encoder_loss: 0.6688176393508911\n",
            "  epoch: 19/20,    batch: 2184/2993    Encoder_loss: 0.6841251254081726\n",
            "  epoch: 19/20,    batch: 2185/2993    Encoder_loss: 0.7271310687065125\n",
            "  epoch: 19/20,    batch: 2186/2993    Encoder_loss: 0.6572521924972534\n",
            "  epoch: 19/20,    batch: 2187/2993    Encoder_loss: 0.6717594265937805\n",
            "  epoch: 19/20,    batch: 2188/2993    Encoder_loss: 0.7442962527275085\n",
            "  epoch: 19/20,    batch: 2189/2993    Encoder_loss: 0.676784098148346\n",
            "  epoch: 19/20,    batch: 2190/2993    Encoder_loss: 0.6545934677124023\n",
            "  epoch: 19/20,    batch: 2191/2993    Encoder_loss: 0.7431144118309021\n",
            "  epoch: 19/20,    batch: 2192/2993    Encoder_loss: 0.695095956325531\n",
            "  epoch: 19/20,    batch: 2193/2993    Encoder_loss: 0.6839547753334045\n",
            "  epoch: 19/20,    batch: 2194/2993    Encoder_loss: 0.7316396236419678\n",
            "  epoch: 19/20,    batch: 2195/2993    Encoder_loss: 0.6325914263725281\n",
            "  epoch: 19/20,    batch: 2196/2993    Encoder_loss: 0.6639242172241211\n",
            "  epoch: 19/20,    batch: 2197/2993    Encoder_loss: 0.7277249693870544\n",
            "  epoch: 19/20,    batch: 2198/2993    Encoder_loss: 0.6294752359390259\n",
            "  epoch: 19/20,    batch: 2199/2993    Encoder_loss: 0.6812952756881714\n",
            "  epoch: 19/20,    batch: 2200/2993    Encoder_loss: 0.6983262300491333\n",
            "  epoch: 19/20,    batch: 2201/2993    Encoder_loss: 0.622519314289093\n",
            "  epoch: 19/20,    batch: 2202/2993    Encoder_loss: 0.7195711731910706\n",
            "  epoch: 19/20,    batch: 2203/2993    Encoder_loss: 0.7049685716629028\n",
            "  epoch: 19/20,    batch: 2204/2993    Encoder_loss: 0.660073459148407\n",
            "  epoch: 19/20,    batch: 2205/2993    Encoder_loss: 0.7331904768943787\n",
            "  epoch: 19/20,    batch: 2206/2993    Encoder_loss: 0.6781278252601624\n",
            "  epoch: 19/20,    batch: 2207/2993    Encoder_loss: 0.5893307328224182\n",
            "  epoch: 19/20,    batch: 2208/2993    Encoder_loss: 0.6685183644294739\n",
            "  epoch: 19/20,    batch: 2209/2993    Encoder_loss: 0.7391894459724426\n",
            "  epoch: 19/20,    batch: 2210/2993    Encoder_loss: 0.6527650356292725\n",
            "  epoch: 19/20,    batch: 2211/2993    Encoder_loss: 0.6482004523277283\n",
            "  epoch: 19/20,    batch: 2212/2993    Encoder_loss: 0.7175031900405884\n",
            "  epoch: 19/20,    batch: 2213/2993    Encoder_loss: 0.6457833051681519\n",
            "  epoch: 19/20,    batch: 2214/2993    Encoder_loss: 0.6297142505645752\n",
            "  epoch: 19/20,    batch: 2215/2993    Encoder_loss: 0.7326414585113525\n",
            "  epoch: 19/20,    batch: 2216/2993    Encoder_loss: 0.7281763553619385\n",
            "  epoch: 19/20,    batch: 2217/2993    Encoder_loss: 0.6544031500816345\n",
            "  epoch: 19/20,    batch: 2218/2993    Encoder_loss: 0.7197725772857666\n",
            "  epoch: 19/20,    batch: 2219/2993    Encoder_loss: 0.6859911680221558\n",
            "  epoch: 19/20,    batch: 2220/2993    Encoder_loss: 0.596566379070282\n",
            "  epoch: 19/20,    batch: 2221/2993    Encoder_loss: 0.6453912258148193\n",
            "  epoch: 19/20,    batch: 2222/2993    Encoder_loss: 0.7231806516647339\n",
            "  epoch: 19/20,    batch: 2223/2993    Encoder_loss: 0.7017691731452942\n",
            "  epoch: 19/20,    batch: 2224/2993    Encoder_loss: 0.6969513297080994\n",
            "  epoch: 19/20,    batch: 2225/2993    Encoder_loss: 0.7368599772453308\n",
            "  epoch: 19/20,    batch: 2226/2993    Encoder_loss: 0.644036591053009\n",
            "  epoch: 19/20,    batch: 2227/2993    Encoder_loss: 0.6636725664138794\n",
            "  epoch: 19/20,    batch: 2228/2993    Encoder_loss: 0.7218679785728455\n",
            "  epoch: 19/20,    batch: 2229/2993    Encoder_loss: 0.6455416083335876\n",
            "  epoch: 19/20,    batch: 2230/2993    Encoder_loss: 0.6971806883811951\n",
            "  epoch: 19/20,    batch: 2231/2993    Encoder_loss: 0.7300741076469421\n",
            "  epoch: 19/20,    batch: 2232/2993    Encoder_loss: 0.6626158356666565\n",
            "  epoch: 19/20,    batch: 2233/2993    Encoder_loss: 0.7045946717262268\n",
            "  epoch: 19/20,    batch: 2234/2993    Encoder_loss: 0.7035427093505859\n",
            "  epoch: 19/20,    batch: 2235/2993    Encoder_loss: 0.6044185757637024\n",
            "  epoch: 19/20,    batch: 2236/2993    Encoder_loss: 0.5799082517623901\n",
            "  epoch: 19/20,    batch: 2237/2993    Encoder_loss: 0.5712469816207886\n",
            "  epoch: 19/20,    batch: 2238/2993    Encoder_loss: 0.577195405960083\n",
            "  epoch: 19/20,    batch: 2239/2993    Encoder_loss: 0.584702730178833\n",
            "  epoch: 19/20,    batch: 2240/2993    Encoder_loss: 0.5824962854385376\n",
            "  epoch: 19/20,    batch: 2241/2993    Encoder_loss: 0.5811207294464111\n",
            "  epoch: 19/20,    batch: 2242/2993    Encoder_loss: 0.5773089528083801\n",
            "  epoch: 19/20,    batch: 2243/2993    Encoder_loss: 0.5698801875114441\n",
            "  epoch: 19/20,    batch: 2244/2993    Encoder_loss: 0.577383816242218\n",
            "  epoch: 19/20,    batch: 2245/2993    Encoder_loss: 0.5832701921463013\n",
            "  epoch: 19/20,    batch: 2246/2993    Encoder_loss: 0.5786616206169128\n",
            "  epoch: 19/20,    batch: 2247/2993    Encoder_loss: 0.5703150033950806\n",
            "  epoch: 19/20,    batch: 2248/2993    Encoder_loss: 0.5747389197349548\n",
            "  epoch: 19/20,    batch: 2249/2993    Encoder_loss: 0.5756980776786804\n",
            "  epoch: 19/20,    batch: 2250/2993    Encoder_loss: 0.5773670673370361\n",
            "  epoch: 19/20,    batch: 2251/2993    Encoder_loss: 0.6374318599700928\n",
            "  epoch: 19/20,    batch: 2252/2993    Encoder_loss: 0.7219609618186951\n",
            "  epoch: 19/20,    batch: 2253/2993    Encoder_loss: 0.6999823451042175\n",
            "  epoch: 19/20,    batch: 2254/2993    Encoder_loss: 0.6539696455001831\n",
            "  epoch: 19/20,    batch: 2255/2993    Encoder_loss: 0.640761137008667\n",
            "  epoch: 19/20,    batch: 2256/2993    Encoder_loss: 0.6886683702468872\n",
            "  epoch: 19/20,    batch: 2257/2993    Encoder_loss: 0.6889658570289612\n",
            "  epoch: 19/20,    batch: 2258/2993    Encoder_loss: 0.6462490558624268\n",
            "  epoch: 19/20,    batch: 2259/2993    Encoder_loss: 0.690655529499054\n",
            "  epoch: 19/20,    batch: 2260/2993    Encoder_loss: 0.6851794719696045\n",
            "  epoch: 19/20,    batch: 2261/2993    Encoder_loss: 0.6036606431007385\n",
            "  epoch: 19/20,    batch: 2262/2993    Encoder_loss: 0.6106165647506714\n",
            "  epoch: 19/20,    batch: 2263/2993    Encoder_loss: 0.7029575109481812\n",
            "  epoch: 19/20,    batch: 2264/2993    Encoder_loss: 0.6592032313346863\n",
            "  epoch: 19/20,    batch: 2265/2993    Encoder_loss: 0.597072184085846\n",
            "  epoch: 19/20,    batch: 2266/2993    Encoder_loss: 0.6851392984390259\n",
            "  epoch: 19/20,    batch: 2267/2993    Encoder_loss: 0.6699081659317017\n",
            "  epoch: 19/20,    batch: 2268/2993    Encoder_loss: 0.5831199884414673\n",
            "  epoch: 19/20,    batch: 2269/2993    Encoder_loss: 0.633672833442688\n",
            "  epoch: 19/20,    batch: 2270/2993    Encoder_loss: 0.7123380303382874\n",
            "  epoch: 19/20,    batch: 2271/2993    Encoder_loss: 0.6459690928459167\n",
            "  epoch: 19/20,    batch: 2272/2993    Encoder_loss: 0.6073932647705078\n",
            "  epoch: 19/20,    batch: 2273/2993    Encoder_loss: 0.6727913022041321\n",
            "  epoch: 19/20,    batch: 2274/2993    Encoder_loss: 0.6437791585922241\n",
            "  epoch: 19/20,    batch: 2275/2993    Encoder_loss: 0.634104311466217\n",
            "  epoch: 19/20,    batch: 2276/2993    Encoder_loss: 0.6887661814689636\n",
            "  epoch: 19/20,    batch: 2277/2993    Encoder_loss: 0.6047447919845581\n",
            "  epoch: 19/20,    batch: 2278/2993    Encoder_loss: 0.6130720973014832\n",
            "  epoch: 19/20,    batch: 2279/2993    Encoder_loss: 0.6827102303504944\n",
            "  epoch: 19/20,    batch: 2280/2993    Encoder_loss: 0.6046193242073059\n",
            "  epoch: 19/20,    batch: 2281/2993    Encoder_loss: 0.6376317143440247\n",
            "  epoch: 19/20,    batch: 2282/2993    Encoder_loss: 0.6822825074195862\n",
            "  epoch: 19/20,    batch: 2283/2993    Encoder_loss: 0.6264463067054749\n",
            "  epoch: 19/20,    batch: 2284/2993    Encoder_loss: 0.6554918885231018\n",
            "  epoch: 19/20,    batch: 2285/2993    Encoder_loss: 0.6627600789070129\n",
            "  epoch: 19/20,    batch: 2286/2993    Encoder_loss: 0.6373435258865356\n",
            "  epoch: 19/20,    batch: 2287/2993    Encoder_loss: 0.675971269607544\n",
            "  epoch: 19/20,    batch: 2288/2993    Encoder_loss: 0.6467438340187073\n",
            "  epoch: 19/20,    batch: 2289/2993    Encoder_loss: 0.5813712477684021\n",
            "  epoch: 19/20,    batch: 2290/2993    Encoder_loss: 0.6386216878890991\n",
            "  epoch: 19/20,    batch: 2291/2993    Encoder_loss: 0.6641865372657776\n",
            "  epoch: 19/20,    batch: 2292/2993    Encoder_loss: 0.6079860329627991\n",
            "  epoch: 19/20,    batch: 2293/2993    Encoder_loss: 0.6151136159896851\n",
            "  epoch: 19/20,    batch: 2294/2993    Encoder_loss: 0.7114113569259644\n",
            "  epoch: 19/20,    batch: 2295/2993    Encoder_loss: 0.6564322710037231\n",
            "  epoch: 19/20,    batch: 2296/2993    Encoder_loss: 0.5727999806404114\n",
            "  epoch: 19/20,    batch: 2297/2993    Encoder_loss: 0.6487290859222412\n",
            "  epoch: 19/20,    batch: 2298/2993    Encoder_loss: 0.6935080289840698\n",
            "  epoch: 19/20,    batch: 2299/2993    Encoder_loss: 0.6264466047286987\n",
            "  epoch: 19/20,    batch: 2300/2993    Encoder_loss: 0.6231284737586975\n",
            "  epoch: 19/20,    batch: 2301/2993    Encoder_loss: 0.6978665590286255\n",
            "  epoch: 19/20,    batch: 2302/2993    Encoder_loss: 0.6412257552146912\n",
            "  epoch: 19/20,    batch: 2303/2993    Encoder_loss: 0.5590670108795166\n",
            "  epoch: 19/20,    batch: 2304/2993    Encoder_loss: 0.6540119051933289\n",
            "  epoch: 19/20,    batch: 2305/2993    Encoder_loss: 0.7148392796516418\n",
            "  epoch: 19/20,    batch: 2306/2993    Encoder_loss: 0.6022179126739502\n",
            "  epoch: 19/20,    batch: 2307/2993    Encoder_loss: 0.6296808123588562\n",
            "  epoch: 19/20,    batch: 2308/2993    Encoder_loss: 0.7269266843795776\n",
            "  epoch: 19/20,    batch: 2309/2993    Encoder_loss: 0.6237702965736389\n",
            "  epoch: 19/20,    batch: 2310/2993    Encoder_loss: 0.6760632991790771\n",
            "  epoch: 19/20,    batch: 2311/2993    Encoder_loss: 0.7148200273513794\n",
            "  epoch: 19/20,    batch: 2312/2993    Encoder_loss: 0.5783621668815613\n",
            "  epoch: 19/20,    batch: 2313/2993    Encoder_loss: 0.6431286334991455\n",
            "  epoch: 19/20,    batch: 2314/2993    Encoder_loss: 0.7177436947822571\n",
            "  epoch: 19/20,    batch: 2315/2993    Encoder_loss: 0.5981870889663696\n",
            "  epoch: 19/20,    batch: 2316/2993    Encoder_loss: 0.67473304271698\n",
            "  epoch: 19/20,    batch: 2317/2993    Encoder_loss: 0.725265622138977\n",
            "  epoch: 19/20,    batch: 2318/2993    Encoder_loss: 0.627429723739624\n",
            "  epoch: 19/20,    batch: 2319/2993    Encoder_loss: 0.7095544338226318\n",
            "  epoch: 19/20,    batch: 2320/2993    Encoder_loss: 0.6769611835479736\n",
            "  epoch: 19/20,    batch: 2321/2993    Encoder_loss: 0.604373037815094\n",
            "  epoch: 19/20,    batch: 2322/2993    Encoder_loss: 0.71726393699646\n",
            "  epoch: 19/20,    batch: 2323/2993    Encoder_loss: 0.6953617334365845\n",
            "  epoch: 19/20,    batch: 2324/2993    Encoder_loss: 0.5857497453689575\n",
            "  epoch: 19/20,    batch: 2325/2993    Encoder_loss: 0.6645320057868958\n",
            "  epoch: 19/20,    batch: 2326/2993    Encoder_loss: 0.756563127040863\n",
            "  epoch: 19/20,    batch: 2327/2993    Encoder_loss: 0.675126850605011\n",
            "  epoch: 19/20,    batch: 2328/2993    Encoder_loss: 0.6445138454437256\n",
            "  epoch: 19/20,    batch: 2329/2993    Encoder_loss: 0.7143923044204712\n",
            "  epoch: 19/20,    batch: 2330/2993    Encoder_loss: 0.6790806651115417\n",
            "  epoch: 19/20,    batch: 2331/2993    Encoder_loss: 0.6086248755455017\n",
            "  epoch: 19/20,    batch: 2332/2993    Encoder_loss: 0.684372067451477\n",
            "  epoch: 19/20,    batch: 2333/2993    Encoder_loss: 0.72894287109375\n",
            "  epoch: 19/20,    batch: 2334/2993    Encoder_loss: 0.6748325824737549\n",
            "  epoch: 19/20,    batch: 2335/2993    Encoder_loss: 0.6566707491874695\n",
            "  epoch: 19/20,    batch: 2336/2993    Encoder_loss: 0.7106524705886841\n",
            "  epoch: 19/20,    batch: 2337/2993    Encoder_loss: 0.6685367822647095\n",
            "  epoch: 19/20,    batch: 2338/2993    Encoder_loss: 0.5946741700172424\n",
            "  epoch: 19/20,    batch: 2339/2993    Encoder_loss: 0.6714286208152771\n",
            "  epoch: 19/20,    batch: 2340/2993    Encoder_loss: 0.7097745537757874\n",
            "  epoch: 19/20,    batch: 2341/2993    Encoder_loss: 0.6578225493431091\n",
            "  epoch: 19/20,    batch: 2342/2993    Encoder_loss: 0.6699056625366211\n",
            "  epoch: 19/20,    batch: 2343/2993    Encoder_loss: 0.7296998500823975\n",
            "  epoch: 19/20,    batch: 2344/2993    Encoder_loss: 0.6027004718780518\n",
            "  epoch: 19/20,    batch: 2345/2993    Encoder_loss: 0.643213152885437\n",
            "  epoch: 19/20,    batch: 2346/2993    Encoder_loss: 0.7094109654426575\n",
            "  epoch: 19/20,    batch: 2347/2993    Encoder_loss: 0.6133490800857544\n",
            "  epoch: 19/20,    batch: 2348/2993    Encoder_loss: 0.694874107837677\n",
            "  epoch: 19/20,    batch: 2349/2993    Encoder_loss: 0.7004188299179077\n",
            "  epoch: 19/20,    batch: 2350/2993    Encoder_loss: 0.5992202162742615\n",
            "  epoch: 19/20,    batch: 2351/2993    Encoder_loss: 0.6957449316978455\n",
            "  epoch: 19/20,    batch: 2352/2993    Encoder_loss: 0.6650322675704956\n",
            "  epoch: 19/20,    batch: 2353/2993    Encoder_loss: 0.627629816532135\n",
            "  epoch: 19/20,    batch: 2354/2993    Encoder_loss: 0.7273114919662476\n",
            "  epoch: 19/20,    batch: 2355/2993    Encoder_loss: 0.6331979036331177\n",
            "  epoch: 19/20,    batch: 2356/2993    Encoder_loss: 0.611181914806366\n",
            "  epoch: 19/20,    batch: 2357/2993    Encoder_loss: 0.7147459387779236\n",
            "  epoch: 19/20,    batch: 2358/2993    Encoder_loss: 0.634835958480835\n",
            "  epoch: 19/20,    batch: 2359/2993    Encoder_loss: 0.5728601217269897\n",
            "  epoch: 19/20,    batch: 2360/2993    Encoder_loss: 0.6693156361579895\n",
            "  epoch: 19/20,    batch: 2361/2993    Encoder_loss: 0.705420196056366\n",
            "  epoch: 19/20,    batch: 2362/2993    Encoder_loss: 0.6060954332351685\n",
            "  epoch: 19/20,    batch: 2363/2993    Encoder_loss: 0.6462751030921936\n",
            "  epoch: 19/20,    batch: 2364/2993    Encoder_loss: 0.7195970416069031\n",
            "  epoch: 19/20,    batch: 2365/2993    Encoder_loss: 0.6189247369766235\n",
            "  epoch: 19/20,    batch: 2366/2993    Encoder_loss: 0.5830686092376709\n",
            "  epoch: 19/20,    batch: 2367/2993    Encoder_loss: 0.6997358798980713\n",
            "  epoch: 19/20,    batch: 2368/2993    Encoder_loss: 0.7078843712806702\n",
            "  epoch: 19/20,    batch: 2369/2993    Encoder_loss: 0.5629119873046875\n",
            "  epoch: 19/20,    batch: 2370/2993    Encoder_loss: 0.6351389288902283\n",
            "  epoch: 19/20,    batch: 2371/2993    Encoder_loss: 0.7034167647361755\n",
            "  epoch: 19/20,    batch: 2372/2993    Encoder_loss: 0.5990645885467529\n",
            "  epoch: 19/20,    batch: 2373/2993    Encoder_loss: 0.5978042483329773\n",
            "  epoch: 19/20,    batch: 2374/2993    Encoder_loss: 0.6914387941360474\n",
            "  epoch: 19/20,    batch: 2375/2993    Encoder_loss: 0.6719005703926086\n",
            "  epoch: 19/20,    batch: 2376/2993    Encoder_loss: 0.5651642084121704\n",
            "  epoch: 19/20,    batch: 2377/2993    Encoder_loss: 0.6437031626701355\n",
            "  epoch: 19/20,    batch: 2378/2993    Encoder_loss: 0.6621844172477722\n",
            "  epoch: 19/20,    batch: 2379/2993    Encoder_loss: 0.5804646015167236\n",
            "  epoch: 19/20,    batch: 2380/2993    Encoder_loss: 0.6572434902191162\n",
            "  epoch: 19/20,    batch: 2381/2993    Encoder_loss: 0.6519193053245544\n",
            "  epoch: 19/20,    batch: 2382/2993    Encoder_loss: 0.6026527285575867\n",
            "  epoch: 19/20,    batch: 2383/2993    Encoder_loss: 0.6695727109909058\n",
            "  epoch: 19/20,    batch: 2384/2993    Encoder_loss: 0.6295631527900696\n",
            "  epoch: 19/20,    batch: 2385/2993    Encoder_loss: 0.6054723262786865\n",
            "  epoch: 19/20,    batch: 2386/2993    Encoder_loss: 0.6919936537742615\n",
            "  epoch: 19/20,    batch: 2387/2993    Encoder_loss: 0.6403316259384155\n",
            "  epoch: 19/20,    batch: 2388/2993    Encoder_loss: 0.6326303482055664\n",
            "  epoch: 19/20,    batch: 2389/2993    Encoder_loss: 0.7094143033027649\n",
            "  epoch: 19/20,    batch: 2390/2993    Encoder_loss: 0.6226847171783447\n",
            "  epoch: 19/20,    batch: 2391/2993    Encoder_loss: 0.6463721394538879\n",
            "  epoch: 19/20,    batch: 2392/2993    Encoder_loss: 0.6625481843948364\n",
            "  epoch: 19/20,    batch: 2393/2993    Encoder_loss: 0.5681596994400024\n",
            "  epoch: 19/20,    batch: 2394/2993    Encoder_loss: 0.5842064619064331\n",
            "  epoch: 19/20,    batch: 2395/2993    Encoder_loss: 0.6632604002952576\n",
            "  epoch: 19/20,    batch: 2396/2993    Encoder_loss: 0.645429253578186\n",
            "  epoch: 19/20,    batch: 2397/2993    Encoder_loss: 0.6136826276779175\n",
            "  epoch: 19/20,    batch: 2398/2993    Encoder_loss: 0.6843026876449585\n",
            "  epoch: 19/20,    batch: 2399/2993    Encoder_loss: 0.659214198589325\n",
            "  epoch: 19/20,    batch: 2400/2993    Encoder_loss: 0.5925830006599426\n",
            "  epoch: 19/20,    batch: 2401/2993    Encoder_loss: 0.6767213344573975\n",
            "  epoch: 19/20,    batch: 2402/2993    Encoder_loss: 0.6932322978973389\n",
            "  epoch: 19/20,    batch: 2403/2993    Encoder_loss: 0.6111488938331604\n",
            "  epoch: 19/20,    batch: 2404/2993    Encoder_loss: 0.6591331362724304\n",
            "  epoch: 19/20,    batch: 2405/2993    Encoder_loss: 0.6545498371124268\n",
            "  epoch: 19/20,    batch: 2406/2993    Encoder_loss: 0.5804191827774048\n",
            "  epoch: 19/20,    batch: 2407/2993    Encoder_loss: 0.6288631558418274\n",
            "  epoch: 19/20,    batch: 2408/2993    Encoder_loss: 0.7022733092308044\n",
            "  epoch: 19/20,    batch: 2409/2993    Encoder_loss: 0.652851402759552\n",
            "  epoch: 19/20,    batch: 2410/2993    Encoder_loss: 0.6784554719924927\n",
            "  epoch: 19/20,    batch: 2411/2993    Encoder_loss: 0.7389094233512878\n",
            "  epoch: 19/20,    batch: 2412/2993    Encoder_loss: 0.6479828357696533\n",
            "  epoch: 19/20,    batch: 2413/2993    Encoder_loss: 0.7076634168624878\n",
            "  epoch: 19/20,    batch: 2414/2993    Encoder_loss: 0.7348757386207581\n",
            "  epoch: 19/20,    batch: 2415/2993    Encoder_loss: 0.6512755751609802\n",
            "  epoch: 19/20,    batch: 2416/2993    Encoder_loss: 0.7152517437934875\n",
            "  epoch: 19/20,    batch: 2417/2993    Encoder_loss: 0.7098948359489441\n",
            "  epoch: 19/20,    batch: 2418/2993    Encoder_loss: 0.6414312720298767\n",
            "  epoch: 19/20,    batch: 2419/2993    Encoder_loss: 0.7202082276344299\n",
            "  epoch: 19/20,    batch: 2420/2993    Encoder_loss: 0.6948330998420715\n",
            "  epoch: 19/20,    batch: 2421/2993    Encoder_loss: 0.671221911907196\n",
            "  epoch: 19/20,    batch: 2422/2993    Encoder_loss: 0.742163896560669\n",
            "  epoch: 19/20,    batch: 2423/2993    Encoder_loss: 0.6749657988548279\n",
            "  epoch: 19/20,    batch: 2424/2993    Encoder_loss: 0.6734559535980225\n",
            "  epoch: 19/20,    batch: 2425/2993    Encoder_loss: 0.7420217394828796\n",
            "  epoch: 19/20,    batch: 2426/2993    Encoder_loss: 0.6670127511024475\n",
            "  epoch: 19/20,    batch: 2427/2993    Encoder_loss: 0.6150473356246948\n",
            "  epoch: 19/20,    batch: 2428/2993    Encoder_loss: 0.7056559920310974\n",
            "  epoch: 19/20,    batch: 2429/2993    Encoder_loss: 0.7360760569572449\n",
            "  epoch: 19/20,    batch: 2430/2993    Encoder_loss: 0.6191310882568359\n",
            "  epoch: 19/20,    batch: 2431/2993    Encoder_loss: 0.6729964017868042\n",
            "  epoch: 19/20,    batch: 2432/2993    Encoder_loss: 0.7445362210273743\n",
            "  epoch: 19/20,    batch: 2433/2993    Encoder_loss: 0.6453441381454468\n",
            "  epoch: 19/20,    batch: 2434/2993    Encoder_loss: 0.5922644734382629\n",
            "  epoch: 19/20,    batch: 2435/2993    Encoder_loss: 0.6929282546043396\n",
            "  epoch: 19/20,    batch: 2436/2993    Encoder_loss: 0.7166091799736023\n",
            "  epoch: 19/20,    batch: 2437/2993    Encoder_loss: 0.5978937149047852\n",
            "  epoch: 19/20,    batch: 2438/2993    Encoder_loss: 0.6843473315238953\n",
            "  epoch: 19/20,    batch: 2439/2993    Encoder_loss: 0.7437850832939148\n",
            "  epoch: 19/20,    batch: 2440/2993    Encoder_loss: 0.6195833086967468\n",
            "  epoch: 19/20,    batch: 2441/2993    Encoder_loss: 0.6039225459098816\n",
            "  epoch: 19/20,    batch: 2442/2993    Encoder_loss: 0.6995747089385986\n",
            "  epoch: 19/20,    batch: 2443/2993    Encoder_loss: 0.6896799802780151\n",
            "  epoch: 19/20,    batch: 2444/2993    Encoder_loss: 0.61599200963974\n",
            "  epoch: 19/20,    batch: 2445/2993    Encoder_loss: 0.7172679901123047\n",
            "  epoch: 19/20,    batch: 2446/2993    Encoder_loss: 0.7083824872970581\n",
            "  epoch: 19/20,    batch: 2447/2993    Encoder_loss: 0.6433327794075012\n",
            "  epoch: 19/20,    batch: 2448/2993    Encoder_loss: 0.7193185091018677\n",
            "  epoch: 19/20,    batch: 2449/2993    Encoder_loss: 0.6638075113296509\n",
            "  epoch: 19/20,    batch: 2450/2993    Encoder_loss: 0.651641845703125\n",
            "  epoch: 19/20,    batch: 2451/2993    Encoder_loss: 0.7293870449066162\n",
            "  epoch: 19/20,    batch: 2452/2993    Encoder_loss: 0.6503287553787231\n",
            "  epoch: 19/20,    batch: 2453/2993    Encoder_loss: 0.6699643731117249\n",
            "  epoch: 19/20,    batch: 2454/2993    Encoder_loss: 0.7583698034286499\n",
            "  epoch: 19/20,    batch: 2455/2993    Encoder_loss: 0.6341536045074463\n",
            "  epoch: 19/20,    batch: 2456/2993    Encoder_loss: 0.6724507212638855\n",
            "  epoch: 19/20,    batch: 2457/2993    Encoder_loss: 0.735443651676178\n",
            "  epoch: 19/20,    batch: 2458/2993    Encoder_loss: 0.6496875286102295\n",
            "  epoch: 19/20,    batch: 2459/2993    Encoder_loss: 0.7168806791305542\n",
            "  epoch: 19/20,    batch: 2460/2993    Encoder_loss: 0.7057167291641235\n",
            "  epoch: 19/20,    batch: 2461/2993    Encoder_loss: 0.6352911591529846\n",
            "  epoch: 19/20,    batch: 2462/2993    Encoder_loss: 0.6901772618293762\n",
            "  epoch: 19/20,    batch: 2463/2993    Encoder_loss: 0.7329813838005066\n",
            "  epoch: 19/20,    batch: 2464/2993    Encoder_loss: 0.6441177129745483\n",
            "  epoch: 19/20,    batch: 2465/2993    Encoder_loss: 0.6733500957489014\n",
            "  epoch: 19/20,    batch: 2466/2993    Encoder_loss: 0.7441593408584595\n",
            "  epoch: 19/20,    batch: 2467/2993    Encoder_loss: 0.6467404961585999\n",
            "  epoch: 19/20,    batch: 2468/2993    Encoder_loss: 0.636528730392456\n",
            "  epoch: 19/20,    batch: 2469/2993    Encoder_loss: 0.7484779953956604\n",
            "  epoch: 19/20,    batch: 2470/2993    Encoder_loss: 0.7066368460655212\n",
            "  epoch: 19/20,    batch: 2471/2993    Encoder_loss: 0.6721172332763672\n",
            "  epoch: 19/20,    batch: 2472/2993    Encoder_loss: 0.7157738208770752\n",
            "  epoch: 19/20,    batch: 2473/2993    Encoder_loss: 0.6722970604896545\n",
            "  epoch: 19/20,    batch: 2474/2993    Encoder_loss: 0.628994345664978\n",
            "  epoch: 19/20,    batch: 2475/2993    Encoder_loss: 0.6996949911117554\n",
            "  epoch: 19/20,    batch: 2476/2993    Encoder_loss: 0.7342647910118103\n",
            "  epoch: 19/20,    batch: 2477/2993    Encoder_loss: 0.6484987735748291\n",
            "  epoch: 19/20,    batch: 2478/2993    Encoder_loss: 0.7062106728553772\n",
            "  epoch: 19/20,    batch: 2479/2993    Encoder_loss: 0.7228943109512329\n",
            "  epoch: 19/20,    batch: 2480/2993    Encoder_loss: 0.6514151096343994\n",
            "  epoch: 19/20,    batch: 2481/2993    Encoder_loss: 0.7397764921188354\n",
            "  epoch: 19/20,    batch: 2482/2993    Encoder_loss: 0.7243301868438721\n",
            "  epoch: 19/20,    batch: 2483/2993    Encoder_loss: 0.6808004975318909\n",
            "  epoch: 19/20,    batch: 2484/2993    Encoder_loss: 0.7441604733467102\n",
            "  epoch: 19/20,    batch: 2485/2993    Encoder_loss: 0.7125186920166016\n",
            "  epoch: 19/20,    batch: 2486/2993    Encoder_loss: 0.7170025110244751\n",
            "  epoch: 19/20,    batch: 2487/2993    Encoder_loss: 0.7825273275375366\n",
            "  epoch: 19/20,    batch: 2488/2993    Encoder_loss: 0.6946491003036499\n",
            "  epoch: 19/20,    batch: 2489/2993    Encoder_loss: 0.6997630000114441\n",
            "  epoch: 19/20,    batch: 2490/2993    Encoder_loss: 0.7707132697105408\n",
            "  epoch: 19/20,    batch: 2491/2993    Encoder_loss: 0.6734002828598022\n",
            "  epoch: 19/20,    batch: 2492/2993    Encoder_loss: 0.7232415676116943\n",
            "  epoch: 19/20,    batch: 2493/2993    Encoder_loss: 0.759782075881958\n",
            "  epoch: 19/20,    batch: 2494/2993    Encoder_loss: 0.6652787923812866\n",
            "  epoch: 19/20,    batch: 2495/2993    Encoder_loss: 0.6867073178291321\n",
            "  epoch: 19/20,    batch: 2496/2993    Encoder_loss: 0.782850980758667\n",
            "  epoch: 19/20,    batch: 2497/2993    Encoder_loss: 0.7036651372909546\n",
            "  epoch: 19/20,    batch: 2498/2993    Encoder_loss: 0.6796005368232727\n",
            "  epoch: 19/20,    batch: 2499/2993    Encoder_loss: 0.7571753263473511\n",
            "  epoch: 19/20,    batch: 2500/2993    Encoder_loss: 0.6970880627632141\n",
            "  epoch: 19/20,    batch: 2501/2993    Encoder_loss: 0.6882901787757874\n",
            "  epoch: 19/20,    batch: 2502/2993    Encoder_loss: 0.7518428564071655\n",
            "  epoch: 19/20,    batch: 2503/2993    Encoder_loss: 0.7270413637161255\n",
            "  epoch: 19/20,    batch: 2504/2993    Encoder_loss: 0.7083685994148254\n",
            "  epoch: 19/20,    batch: 2505/2993    Encoder_loss: 0.7499150633811951\n",
            "  epoch: 19/20,    batch: 2506/2993    Encoder_loss: 0.6973772644996643\n",
            "  epoch: 19/20,    batch: 2507/2993    Encoder_loss: 0.642404317855835\n",
            "  epoch: 19/20,    batch: 2508/2993    Encoder_loss: 0.7310288548469543\n",
            "  epoch: 19/20,    batch: 2509/2993    Encoder_loss: 0.7288349866867065\n",
            "  epoch: 19/20,    batch: 2510/2993    Encoder_loss: 0.6687599420547485\n",
            "  epoch: 19/20,    batch: 2511/2993    Encoder_loss: 0.7726178765296936\n",
            "  epoch: 19/20,    batch: 2512/2993    Encoder_loss: 0.7572259902954102\n",
            "  epoch: 19/20,    batch: 2513/2993    Encoder_loss: 0.6900404095649719\n",
            "  epoch: 19/20,    batch: 2514/2993    Encoder_loss: 0.7846390604972839\n",
            "  epoch: 19/20,    batch: 2515/2993    Encoder_loss: 0.7377899885177612\n",
            "  epoch: 19/20,    batch: 2516/2993    Encoder_loss: 0.7003301978111267\n",
            "  epoch: 19/20,    batch: 2517/2993    Encoder_loss: 0.7869731783866882\n",
            "  epoch: 19/20,    batch: 2518/2993    Encoder_loss: 0.6868094205856323\n",
            "  epoch: 19/20,    batch: 2519/2993    Encoder_loss: 0.6943352222442627\n",
            "  epoch: 19/20,    batch: 2520/2993    Encoder_loss: 0.8055627346038818\n",
            "  epoch: 19/20,    batch: 2521/2993    Encoder_loss: 0.6870505213737488\n",
            "  epoch: 19/20,    batch: 2522/2993    Encoder_loss: 0.7131271362304688\n",
            "  epoch: 19/20,    batch: 2523/2993    Encoder_loss: 0.7532421946525574\n",
            "  epoch: 19/20,    batch: 2524/2993    Encoder_loss: 0.6910548806190491\n",
            "  epoch: 19/20,    batch: 2525/2993    Encoder_loss: 0.7886577844619751\n",
            "  epoch: 19/20,    batch: 2526/2993    Encoder_loss: 0.7431580424308777\n",
            "  epoch: 19/20,    batch: 2527/2993    Encoder_loss: 0.6395577788352966\n",
            "  epoch: 19/20,    batch: 2528/2993    Encoder_loss: 0.6938663721084595\n",
            "  epoch: 19/20,    batch: 2529/2993    Encoder_loss: 0.7677726745605469\n",
            "  epoch: 19/20,    batch: 2530/2993    Encoder_loss: 0.6832467913627625\n",
            "  epoch: 19/20,    batch: 2531/2993    Encoder_loss: 0.7135096788406372\n",
            "  epoch: 19/20,    batch: 2532/2993    Encoder_loss: 0.7581518292427063\n",
            "  epoch: 19/20,    batch: 2533/2993    Encoder_loss: 0.6604618430137634\n",
            "  epoch: 19/20,    batch: 2534/2993    Encoder_loss: 0.6349130272865295\n",
            "  epoch: 19/20,    batch: 2535/2993    Encoder_loss: 0.7384744882583618\n",
            "  epoch: 19/20,    batch: 2536/2993    Encoder_loss: 0.6972323656082153\n",
            "  epoch: 19/20,    batch: 2537/2993    Encoder_loss: 0.6657410860061646\n",
            "  epoch: 19/20,    batch: 2538/2993    Encoder_loss: 0.7297857403755188\n",
            "  epoch: 19/20,    batch: 2539/2993    Encoder_loss: 0.6729530096054077\n",
            "  epoch: 19/20,    batch: 2540/2993    Encoder_loss: 0.6662713885307312\n",
            "  epoch: 19/20,    batch: 2541/2993    Encoder_loss: 0.7411210536956787\n",
            "  epoch: 19/20,    batch: 2542/2993    Encoder_loss: 0.6963430047035217\n",
            "  epoch: 19/20,    batch: 2543/2993    Encoder_loss: 0.6613972783088684\n",
            "  epoch: 19/20,    batch: 2544/2993    Encoder_loss: 0.7584229707717896\n",
            "  epoch: 19/20,    batch: 2545/2993    Encoder_loss: 0.699562132358551\n",
            "  epoch: 19/20,    batch: 2546/2993    Encoder_loss: 0.6639406681060791\n",
            "  epoch: 19/20,    batch: 2547/2993    Encoder_loss: 0.7637122869491577\n",
            "  epoch: 19/20,    batch: 2548/2993    Encoder_loss: 0.6734059453010559\n",
            "  epoch: 19/20,    batch: 2549/2993    Encoder_loss: 0.6799317598342896\n",
            "  epoch: 19/20,    batch: 2550/2993    Encoder_loss: 0.7645076513290405\n",
            "  epoch: 19/20,    batch: 2551/2993    Encoder_loss: 0.644942045211792\n",
            "  epoch: 19/20,    batch: 2552/2993    Encoder_loss: 0.68305504322052\n",
            "  epoch: 19/20,    batch: 2553/2993    Encoder_loss: 0.7262933850288391\n",
            "  epoch: 19/20,    batch: 2554/2993    Encoder_loss: 0.6402513384819031\n",
            "  epoch: 19/20,    batch: 2555/2993    Encoder_loss: 0.7319595217704773\n",
            "  epoch: 19/20,    batch: 2556/2993    Encoder_loss: 0.7161617279052734\n",
            "  epoch: 19/20,    batch: 2557/2993    Encoder_loss: 0.6285681128501892\n",
            "  epoch: 19/20,    batch: 2558/2993    Encoder_loss: 0.6875616312026978\n",
            "  epoch: 19/20,    batch: 2559/2993    Encoder_loss: 0.6516938805580139\n",
            "  epoch: 19/20,    batch: 2560/2993    Encoder_loss: 0.564225435256958\n",
            "  epoch: 19/20,    batch: 2561/2993    Encoder_loss: 0.6574358344078064\n",
            "  epoch: 19/20,    batch: 2562/2993    Encoder_loss: 0.7115883231163025\n",
            "  epoch: 19/20,    batch: 2563/2993    Encoder_loss: 0.6111425757408142\n",
            "  epoch: 19/20,    batch: 2564/2993    Encoder_loss: 0.6486552953720093\n",
            "  epoch: 19/20,    batch: 2565/2993    Encoder_loss: 0.6647914052009583\n",
            "  epoch: 19/20,    batch: 2566/2993    Encoder_loss: 0.5856002569198608\n",
            "  epoch: 19/20,    batch: 2567/2993    Encoder_loss: 0.6163864135742188\n",
            "  epoch: 19/20,    batch: 2568/2993    Encoder_loss: 0.6658521294593811\n",
            "  epoch: 19/20,    batch: 2569/2993    Encoder_loss: 0.605914294719696\n",
            "  epoch: 19/20,    batch: 2570/2993    Encoder_loss: 0.629211962223053\n",
            "  epoch: 19/20,    batch: 2571/2993    Encoder_loss: 0.661636471748352\n",
            "  epoch: 19/20,    batch: 2572/2993    Encoder_loss: 0.5827955007553101\n",
            "  epoch: 19/20,    batch: 2573/2993    Encoder_loss: 0.6216051578521729\n",
            "  epoch: 19/20,    batch: 2574/2993    Encoder_loss: 0.7110093235969543\n",
            "  epoch: 19/20,    batch: 2575/2993    Encoder_loss: 0.6383695006370544\n",
            "  epoch: 19/20,    batch: 2576/2993    Encoder_loss: 0.6195391416549683\n",
            "  epoch: 19/20,    batch: 2577/2993    Encoder_loss: 0.7009076476097107\n",
            "  epoch: 19/20,    batch: 2578/2993    Encoder_loss: 0.6122079491615295\n",
            "  epoch: 19/20,    batch: 2579/2993    Encoder_loss: 0.6205979585647583\n",
            "  epoch: 19/20,    batch: 2580/2993    Encoder_loss: 0.7030967473983765\n",
            "  epoch: 19/20,    batch: 2581/2993    Encoder_loss: 0.6055932641029358\n",
            "  epoch: 19/20,    batch: 2582/2993    Encoder_loss: 0.6714397072792053\n",
            "  epoch: 19/20,    batch: 2583/2993    Encoder_loss: 0.6990826725959778\n",
            "  epoch: 19/20,    batch: 2584/2993    Encoder_loss: 0.5842646360397339\n",
            "  epoch: 19/20,    batch: 2585/2993    Encoder_loss: 0.6714014410972595\n",
            "  epoch: 19/20,    batch: 2586/2993    Encoder_loss: 0.6707388758659363\n",
            "  epoch: 19/20,    batch: 2587/2993    Encoder_loss: 0.6109951138496399\n",
            "  epoch: 19/20,    batch: 2588/2993    Encoder_loss: 0.6994588971138\n",
            "  epoch: 19/20,    batch: 2589/2993    Encoder_loss: 0.6524341702461243\n",
            "  epoch: 19/20,    batch: 2590/2993    Encoder_loss: 0.6275057196617126\n",
            "  epoch: 19/20,    batch: 2591/2993    Encoder_loss: 0.6881428956985474\n",
            "  epoch: 19/20,    batch: 2592/2993    Encoder_loss: 0.6168696284294128\n",
            "  epoch: 19/20,    batch: 2593/2993    Encoder_loss: 0.5797789692878723\n",
            "  epoch: 19/20,    batch: 2594/2993    Encoder_loss: 0.6634867191314697\n",
            "  epoch: 19/20,    batch: 2595/2993    Encoder_loss: 0.6653920412063599\n",
            "  epoch: 19/20,    batch: 2596/2993    Encoder_loss: 0.5953972935676575\n",
            "  epoch: 19/20,    batch: 2597/2993    Encoder_loss: 0.647022545337677\n",
            "  epoch: 19/20,    batch: 2598/2993    Encoder_loss: 0.6422348618507385\n",
            "  epoch: 19/20,    batch: 2599/2993    Encoder_loss: 0.5741046667098999\n",
            "  epoch: 19/20,    batch: 2600/2993    Encoder_loss: 0.6282070279121399\n",
            "  epoch: 19/20,    batch: 2601/2993    Encoder_loss: 0.6668973565101624\n",
            "  epoch: 19/20,    batch: 2602/2993    Encoder_loss: 0.6073598265647888\n",
            "  epoch: 19/20,    batch: 2603/2993    Encoder_loss: 0.6569138169288635\n",
            "  epoch: 19/20,    batch: 2604/2993    Encoder_loss: 0.6459681391716003\n",
            "  epoch: 19/20,    batch: 2605/2993    Encoder_loss: 0.5652223825454712\n",
            "  epoch: 19/20,    batch: 2606/2993    Encoder_loss: 0.6152579188346863\n",
            "  epoch: 19/20,    batch: 2607/2993    Encoder_loss: 0.6629404425621033\n",
            "  epoch: 19/20,    batch: 2608/2993    Encoder_loss: 0.593219518661499\n",
            "  epoch: 19/20,    batch: 2609/2993    Encoder_loss: 0.6312066912651062\n",
            "  epoch: 19/20,    batch: 2610/2993    Encoder_loss: 0.7222607731819153\n",
            "  epoch: 19/20,    batch: 2611/2993    Encoder_loss: 0.6247814297676086\n",
            "  epoch: 19/20,    batch: 2612/2993    Encoder_loss: 0.6724836826324463\n",
            "  epoch: 19/20,    batch: 2613/2993    Encoder_loss: 0.708574116230011\n",
            "  epoch: 19/20,    batch: 2614/2993    Encoder_loss: 0.5954734086990356\n",
            "  epoch: 19/20,    batch: 2615/2993    Encoder_loss: 0.6912527680397034\n",
            "  epoch: 19/20,    batch: 2616/2993    Encoder_loss: 0.6919183731079102\n",
            "  epoch: 19/20,    batch: 2617/2993    Encoder_loss: 0.6266396641731262\n",
            "  epoch: 19/20,    batch: 2618/2993    Encoder_loss: 0.7094153165817261\n",
            "  epoch: 19/20,    batch: 2619/2993    Encoder_loss: 0.6679162979125977\n",
            "  epoch: 19/20,    batch: 2620/2993    Encoder_loss: 0.6415932178497314\n",
            "  epoch: 19/20,    batch: 2621/2993    Encoder_loss: 0.7216243743896484\n",
            "  epoch: 19/20,    batch: 2622/2993    Encoder_loss: 0.6608985662460327\n",
            "  epoch: 19/20,    batch: 2623/2993    Encoder_loss: 0.6538922786712646\n",
            "  epoch: 19/20,    batch: 2624/2993    Encoder_loss: 0.6920607686042786\n",
            "  epoch: 19/20,    batch: 2625/2993    Encoder_loss: 0.5951979160308838\n",
            "  epoch: 19/20,    batch: 2626/2993    Encoder_loss: 0.5854001641273499\n",
            "  epoch: 19/20,    batch: 2627/2993    Encoder_loss: 0.6917620897293091\n",
            "  epoch: 19/20,    batch: 2628/2993    Encoder_loss: 0.6583757996559143\n",
            "  epoch: 19/20,    batch: 2629/2993    Encoder_loss: 0.6077945232391357\n",
            "  epoch: 19/20,    batch: 2630/2993    Encoder_loss: 0.6910982728004456\n",
            "  epoch: 19/20,    batch: 2631/2993    Encoder_loss: 0.6536940336227417\n",
            "  epoch: 19/20,    batch: 2632/2993    Encoder_loss: 0.569058358669281\n",
            "  epoch: 19/20,    batch: 2633/2993    Encoder_loss: 0.6585968136787415\n",
            "  epoch: 19/20,    batch: 2634/2993    Encoder_loss: 0.707473874092102\n",
            "  epoch: 19/20,    batch: 2635/2993    Encoder_loss: 0.6427074670791626\n",
            "  epoch: 19/20,    batch: 2636/2993    Encoder_loss: 0.688597559928894\n",
            "  epoch: 19/20,    batch: 2637/2993    Encoder_loss: 0.6645622849464417\n",
            "  epoch: 19/20,    batch: 2638/2993    Encoder_loss: 0.5860214829444885\n",
            "  epoch: 19/20,    batch: 2639/2993    Encoder_loss: 0.6491137146949768\n",
            "  epoch: 19/20,    batch: 2640/2993    Encoder_loss: 0.7058599591255188\n",
            "  epoch: 19/20,    batch: 2641/2993    Encoder_loss: 0.6365988850593567\n",
            "  epoch: 19/20,    batch: 2642/2993    Encoder_loss: 0.6973293423652649\n",
            "  epoch: 19/20,    batch: 2643/2993    Encoder_loss: 0.7304584980010986\n",
            "  epoch: 19/20,    batch: 2644/2993    Encoder_loss: 0.6306901574134827\n",
            "  epoch: 19/20,    batch: 2645/2993    Encoder_loss: 0.7335869073867798\n",
            "  epoch: 19/20,    batch: 2646/2993    Encoder_loss: 0.7163373231887817\n",
            "  epoch: 19/20,    batch: 2647/2993    Encoder_loss: 0.6475337743759155\n",
            "  epoch: 19/20,    batch: 2648/2993    Encoder_loss: 0.7306966185569763\n",
            "  epoch: 19/20,    batch: 2649/2993    Encoder_loss: 0.668043315410614\n",
            "  epoch: 19/20,    batch: 2650/2993    Encoder_loss: 0.6342160701751709\n",
            "  epoch: 19/20,    batch: 2651/2993    Encoder_loss: 0.7226251363754272\n",
            "  epoch: 19/20,    batch: 2652/2993    Encoder_loss: 0.656260073184967\n",
            "  epoch: 19/20,    batch: 2653/2993    Encoder_loss: 0.6609643697738647\n",
            "  epoch: 19/20,    batch: 2654/2993    Encoder_loss: 0.7441608905792236\n",
            "  epoch: 19/20,    batch: 2655/2993    Encoder_loss: 0.6380094289779663\n",
            "  epoch: 19/20,    batch: 2656/2993    Encoder_loss: 0.6617401242256165\n",
            "  epoch: 19/20,    batch: 2657/2993    Encoder_loss: 0.6938889026641846\n",
            "  epoch: 19/20,    batch: 2658/2993    Encoder_loss: 0.6233119964599609\n",
            "  epoch: 19/20,    batch: 2659/2993    Encoder_loss: 0.6294037699699402\n",
            "  epoch: 19/20,    batch: 2660/2993    Encoder_loss: 0.6998785138130188\n",
            "  epoch: 19/20,    batch: 2661/2993    Encoder_loss: 0.6884210109710693\n",
            "  epoch: 19/20,    batch: 2662/2993    Encoder_loss: 0.6202924251556396\n",
            "  epoch: 19/20,    batch: 2663/2993    Encoder_loss: 0.6883065104484558\n",
            "  epoch: 19/20,    batch: 2664/2993    Encoder_loss: 0.6961292028427124\n",
            "  epoch: 19/20,    batch: 2665/2993    Encoder_loss: 0.6406097412109375\n",
            "  epoch: 19/20,    batch: 2666/2993    Encoder_loss: 0.6797305345535278\n",
            "  epoch: 19/20,    batch: 2667/2993    Encoder_loss: 0.7366278767585754\n",
            "  epoch: 19/20,    batch: 2668/2993    Encoder_loss: 0.6360164880752563\n",
            "  epoch: 19/20,    batch: 2669/2993    Encoder_loss: 0.644162118434906\n",
            "  epoch: 19/20,    batch: 2670/2993    Encoder_loss: 0.7163642048835754\n",
            "  epoch: 19/20,    batch: 2671/2993    Encoder_loss: 0.6423898935317993\n",
            "  epoch: 19/20,    batch: 2672/2993    Encoder_loss: 0.6252676248550415\n",
            "  epoch: 19/20,    batch: 2673/2993    Encoder_loss: 0.6955167055130005\n",
            "  epoch: 19/20,    batch: 2674/2993    Encoder_loss: 0.6773080825805664\n",
            "  epoch: 19/20,    batch: 2675/2993    Encoder_loss: 0.5840636491775513\n",
            "  epoch: 19/20,    batch: 2676/2993    Encoder_loss: 0.6606751680374146\n",
            "  epoch: 19/20,    batch: 2677/2993    Encoder_loss: 0.6835342645645142\n",
            "  epoch: 19/20,    batch: 2678/2993    Encoder_loss: 0.6206539869308472\n",
            "  epoch: 19/20,    batch: 2679/2993    Encoder_loss: 0.6868489384651184\n",
            "  epoch: 19/20,    batch: 2680/2993    Encoder_loss: 0.6676495671272278\n",
            "  epoch: 19/20,    batch: 2681/2993    Encoder_loss: 0.6213779449462891\n",
            "  epoch: 19/20,    batch: 2682/2993    Encoder_loss: 0.702151358127594\n",
            "  epoch: 19/20,    batch: 2683/2993    Encoder_loss: 0.6372013092041016\n",
            "  epoch: 19/20,    batch: 2684/2993    Encoder_loss: 0.629444420337677\n",
            "  epoch: 19/20,    batch: 2685/2993    Encoder_loss: 0.7245385050773621\n",
            "  epoch: 19/20,    batch: 2686/2993    Encoder_loss: 0.6125229001045227\n",
            "  epoch: 19/20,    batch: 2687/2993    Encoder_loss: 0.6429228186607361\n",
            "  epoch: 19/20,    batch: 2688/2993    Encoder_loss: 0.7208585143089294\n",
            "  epoch: 19/20,    batch: 2689/2993    Encoder_loss: 0.6039592623710632\n",
            "  epoch: 19/20,    batch: 2690/2993    Encoder_loss: 0.6596422791481018\n",
            "  epoch: 19/20,    batch: 2691/2993    Encoder_loss: 0.6980211138725281\n",
            "  epoch: 19/20,    batch: 2692/2993    Encoder_loss: 0.6383944749832153\n",
            "  epoch: 19/20,    batch: 2693/2993    Encoder_loss: 0.6709514856338501\n",
            "  epoch: 19/20,    batch: 2694/2993    Encoder_loss: 0.7321510314941406\n",
            "  epoch: 19/20,    batch: 2695/2993    Encoder_loss: 0.6184511780738831\n",
            "  epoch: 19/20,    batch: 2696/2993    Encoder_loss: 0.5930492877960205\n",
            "  epoch: 19/20,    batch: 2697/2993    Encoder_loss: 0.7139638066291809\n",
            "  epoch: 19/20,    batch: 2698/2993    Encoder_loss: 0.6779787540435791\n",
            "  epoch: 19/20,    batch: 2699/2993    Encoder_loss: 0.5661875009536743\n",
            "  epoch: 19/20,    batch: 2700/2993    Encoder_loss: 0.6568087935447693\n",
            "  epoch: 19/20,    batch: 2701/2993    Encoder_loss: 0.7140637636184692\n",
            "  epoch: 19/20,    batch: 2702/2993    Encoder_loss: 0.6011013388633728\n",
            "  epoch: 19/20,    batch: 2703/2993    Encoder_loss: 0.6084834933280945\n",
            "  epoch: 19/20,    batch: 2704/2993    Encoder_loss: 0.697012186050415\n",
            "  epoch: 19/20,    batch: 2705/2993    Encoder_loss: 0.6360169649124146\n",
            "  epoch: 19/20,    batch: 2706/2993    Encoder_loss: 0.5785728096961975\n",
            "  epoch: 19/20,    batch: 2707/2993    Encoder_loss: 0.6688271760940552\n",
            "  epoch: 19/20,    batch: 2708/2993    Encoder_loss: 0.6856327652931213\n",
            "  epoch: 19/20,    batch: 2709/2993    Encoder_loss: 0.5900222063064575\n",
            "  epoch: 19/20,    batch: 2710/2993    Encoder_loss: 0.6603837609291077\n",
            "  epoch: 19/20,    batch: 2711/2993    Encoder_loss: 0.7480332851409912\n",
            "  epoch: 19/20,    batch: 2712/2993    Encoder_loss: 0.6320573091506958\n",
            "  epoch: 19/20,    batch: 2713/2993    Encoder_loss: 0.6641258597373962\n",
            "  epoch: 19/20,    batch: 2714/2993    Encoder_loss: 0.6840874552726746\n",
            "  epoch: 19/20,    batch: 2715/2993    Encoder_loss: 0.5692816972732544\n",
            "  epoch: 19/20,    batch: 2716/2993    Encoder_loss: 0.6531782150268555\n",
            "  epoch: 19/20,    batch: 2717/2993    Encoder_loss: 0.6776796579360962\n",
            "  epoch: 19/20,    batch: 2718/2993    Encoder_loss: 0.6282761693000793\n",
            "  epoch: 19/20,    batch: 2719/2993    Encoder_loss: 0.710759162902832\n",
            "  epoch: 19/20,    batch: 2720/2993    Encoder_loss: 0.6607221961021423\n",
            "  epoch: 19/20,    batch: 2721/2993    Encoder_loss: 0.6135314106941223\n",
            "  epoch: 19/20,    batch: 2722/2993    Encoder_loss: 0.6985504031181335\n",
            "  epoch: 19/20,    batch: 2723/2993    Encoder_loss: 0.6270892024040222\n",
            "  epoch: 19/20,    batch: 2724/2993    Encoder_loss: 0.6337729096412659\n",
            "  epoch: 19/20,    batch: 2725/2993    Encoder_loss: 0.7343358397483826\n",
            "  epoch: 19/20,    batch: 2726/2993    Encoder_loss: 0.6718245148658752\n",
            "  epoch: 19/20,    batch: 2727/2993    Encoder_loss: 0.5894730091094971\n",
            "  epoch: 19/20,    batch: 2728/2993    Encoder_loss: 0.6578867435455322\n",
            "  epoch: 19/20,    batch: 2729/2993    Encoder_loss: 0.7075886130332947\n",
            "  epoch: 19/20,    batch: 2730/2993    Encoder_loss: 0.6287944912910461\n",
            "  epoch: 19/20,    batch: 2731/2993    Encoder_loss: 0.6843799948692322\n",
            "  epoch: 19/20,    batch: 2732/2993    Encoder_loss: 0.7580878734588623\n",
            "  epoch: 19/20,    batch: 2733/2993    Encoder_loss: 0.6549718976020813\n",
            "  epoch: 19/20,    batch: 2734/2993    Encoder_loss: 0.6087998151779175\n",
            "  epoch: 19/20,    batch: 2735/2993    Encoder_loss: 0.7051328420639038\n",
            "  epoch: 19/20,    batch: 2736/2993    Encoder_loss: 0.7220834493637085\n",
            "  epoch: 19/20,    batch: 2737/2993    Encoder_loss: 0.6048877835273743\n",
            "  epoch: 19/20,    batch: 2738/2993    Encoder_loss: 0.6712636947631836\n",
            "  epoch: 19/20,    batch: 2739/2993    Encoder_loss: 0.7225794196128845\n",
            "  epoch: 19/20,    batch: 2740/2993    Encoder_loss: 0.6360492706298828\n",
            "  epoch: 19/20,    batch: 2741/2993    Encoder_loss: 0.6251766681671143\n",
            "  epoch: 19/20,    batch: 2742/2993    Encoder_loss: 0.7148334383964539\n",
            "  epoch: 19/20,    batch: 2743/2993    Encoder_loss: 0.7094554305076599\n",
            "  epoch: 19/20,    batch: 2744/2993    Encoder_loss: 0.6064210534095764\n",
            "  epoch: 19/20,    batch: 2745/2993    Encoder_loss: 0.6711954474449158\n",
            "  epoch: 19/20,    batch: 2746/2993    Encoder_loss: 0.7018632888793945\n",
            "  epoch: 19/20,    batch: 2747/2993    Encoder_loss: 0.6338630318641663\n",
            "  epoch: 19/20,    batch: 2748/2993    Encoder_loss: 0.6786706447601318\n",
            "  epoch: 19/20,    batch: 2749/2993    Encoder_loss: 0.6744120121002197\n",
            "  epoch: 19/20,    batch: 2750/2993    Encoder_loss: 0.6438438892364502\n",
            "  epoch: 19/20,    batch: 2751/2993    Encoder_loss: 0.692135214805603\n",
            "  epoch: 19/20,    batch: 2752/2993    Encoder_loss: 0.6433572769165039\n",
            "  epoch: 19/20,    batch: 2753/2993    Encoder_loss: 0.6155241131782532\n",
            "  epoch: 19/20,    batch: 2754/2993    Encoder_loss: 0.6960344910621643\n",
            "  epoch: 19/20,    batch: 2755/2993    Encoder_loss: 0.6597386002540588\n",
            "  epoch: 19/20,    batch: 2756/2993    Encoder_loss: 0.6608363389968872\n",
            "  epoch: 19/20,    batch: 2757/2993    Encoder_loss: 0.7056297063827515\n",
            "  epoch: 19/20,    batch: 2758/2993    Encoder_loss: 0.6121494174003601\n",
            "  epoch: 19/20,    batch: 2759/2993    Encoder_loss: 0.6335341334342957\n",
            "  epoch: 19/20,    batch: 2760/2993    Encoder_loss: 0.6544443964958191\n",
            "  epoch: 19/20,    batch: 2761/2993    Encoder_loss: 0.5989402532577515\n",
            "  epoch: 19/20,    batch: 2762/2993    Encoder_loss: 0.629607081413269\n",
            "  epoch: 19/20,    batch: 2763/2993    Encoder_loss: 0.714669942855835\n",
            "  epoch: 19/20,    batch: 2764/2993    Encoder_loss: 0.6695931553840637\n",
            "  epoch: 19/20,    batch: 2765/2993    Encoder_loss: 0.6724173426628113\n",
            "  epoch: 19/20,    batch: 2766/2993    Encoder_loss: 0.7215157151222229\n",
            "  epoch: 19/20,    batch: 2767/2993    Encoder_loss: 0.6442156434059143\n",
            "  epoch: 19/20,    batch: 2768/2993    Encoder_loss: 0.6332216262817383\n",
            "  epoch: 19/20,    batch: 2769/2993    Encoder_loss: 0.6985375881195068\n",
            "  epoch: 19/20,    batch: 2770/2993    Encoder_loss: 0.6701018214225769\n",
            "  epoch: 19/20,    batch: 2771/2993    Encoder_loss: 0.6641245484352112\n",
            "  epoch: 19/20,    batch: 2772/2993    Encoder_loss: 0.7240023016929626\n",
            "  epoch: 19/20,    batch: 2773/2993    Encoder_loss: 0.6955875754356384\n",
            "  epoch: 19/20,    batch: 2774/2993    Encoder_loss: 0.6776636242866516\n",
            "  epoch: 19/20,    batch: 2775/2993    Encoder_loss: 0.7142658829689026\n",
            "  epoch: 19/20,    batch: 2776/2993    Encoder_loss: 0.7047146558761597\n",
            "  epoch: 19/20,    batch: 2777/2993    Encoder_loss: 0.619314432144165\n",
            "  epoch: 19/20,    batch: 2778/2993    Encoder_loss: 0.6663837432861328\n",
            "  epoch: 19/20,    batch: 2779/2993    Encoder_loss: 0.6571822762489319\n",
            "  epoch: 19/20,    batch: 2780/2993    Encoder_loss: 0.5964099764823914\n",
            "  epoch: 19/20,    batch: 2781/2993    Encoder_loss: 0.663709282875061\n",
            "  epoch: 19/20,    batch: 2782/2993    Encoder_loss: 0.6647484302520752\n",
            "  epoch: 19/20,    batch: 2783/2993    Encoder_loss: 0.6533982157707214\n",
            "  epoch: 19/20,    batch: 2784/2993    Encoder_loss: 0.7163472771644592\n",
            "  epoch: 19/20,    batch: 2785/2993    Encoder_loss: 0.6450566649436951\n",
            "  epoch: 19/20,    batch: 2786/2993    Encoder_loss: 0.6448891758918762\n",
            "  epoch: 19/20,    batch: 2787/2993    Encoder_loss: 0.7213147282600403\n",
            "  epoch: 19/20,    batch: 2788/2993    Encoder_loss: 0.6234635710716248\n",
            "  epoch: 19/20,    batch: 2789/2993    Encoder_loss: 0.6570739150047302\n",
            "  epoch: 19/20,    batch: 2790/2993    Encoder_loss: 0.7247216701507568\n",
            "  epoch: 19/20,    batch: 2791/2993    Encoder_loss: 0.639636754989624\n",
            "  epoch: 19/20,    batch: 2792/2993    Encoder_loss: 0.6886021494865417\n",
            "  epoch: 19/20,    batch: 2793/2993    Encoder_loss: 0.7001856565475464\n",
            "  epoch: 19/20,    batch: 2794/2993    Encoder_loss: 0.637729287147522\n",
            "  epoch: 19/20,    batch: 2795/2993    Encoder_loss: 0.6521152257919312\n",
            "  epoch: 19/20,    batch: 2796/2993    Encoder_loss: 0.6959831714630127\n",
            "  epoch: 19/20,    batch: 2797/2993    Encoder_loss: 0.6670762896537781\n",
            "  epoch: 19/20,    batch: 2798/2993    Encoder_loss: 0.6215450763702393\n",
            "  epoch: 19/20,    batch: 2799/2993    Encoder_loss: 0.6847434639930725\n",
            "  epoch: 19/20,    batch: 2800/2993    Encoder_loss: 0.6943838000297546\n",
            "  epoch: 19/20,    batch: 2801/2993    Encoder_loss: 0.602483332157135\n",
            "  epoch: 19/20,    batch: 2802/2993    Encoder_loss: 0.6319515109062195\n",
            "  epoch: 19/20,    batch: 2803/2993    Encoder_loss: 0.733425498008728\n",
            "  epoch: 19/20,    batch: 2804/2993    Encoder_loss: 0.6943882703781128\n",
            "  epoch: 19/20,    batch: 2805/2993    Encoder_loss: 0.6495857238769531\n",
            "  epoch: 19/20,    batch: 2806/2993    Encoder_loss: 0.7199533581733704\n",
            "  epoch: 19/20,    batch: 2807/2993    Encoder_loss: 0.7018772959709167\n",
            "  epoch: 19/20,    batch: 2808/2993    Encoder_loss: 0.6214901208877563\n",
            "  epoch: 19/20,    batch: 2809/2993    Encoder_loss: 0.68797367811203\n",
            "  epoch: 19/20,    batch: 2810/2993    Encoder_loss: 0.743450939655304\n",
            "  epoch: 19/20,    batch: 2811/2993    Encoder_loss: 0.6385573148727417\n",
            "  epoch: 19/20,    batch: 2812/2993    Encoder_loss: 0.6297889947891235\n",
            "  epoch: 19/20,    batch: 2813/2993    Encoder_loss: 0.7454046010971069\n",
            "  epoch: 19/20,    batch: 2814/2993    Encoder_loss: 0.7005457282066345\n",
            "  epoch: 19/20,    batch: 2815/2993    Encoder_loss: 0.7133347392082214\n",
            "  epoch: 19/20,    batch: 2816/2993    Encoder_loss: 0.7734563946723938\n",
            "  epoch: 19/20,    batch: 2817/2993    Encoder_loss: 0.6849735379219055\n",
            "  epoch: 19/20,    batch: 2818/2993    Encoder_loss: 0.7013463377952576\n",
            "  epoch: 19/20,    batch: 2819/2993    Encoder_loss: 0.7459917068481445\n",
            "  epoch: 19/20,    batch: 2820/2993    Encoder_loss: 0.6664782762527466\n",
            "  epoch: 19/20,    batch: 2821/2993    Encoder_loss: 0.7053568363189697\n",
            "  epoch: 19/20,    batch: 2822/2993    Encoder_loss: 0.741153359413147\n",
            "  epoch: 19/20,    batch: 2823/2993    Encoder_loss: 0.6669345498085022\n",
            "  epoch: 19/20,    batch: 2824/2993    Encoder_loss: 0.7215480208396912\n",
            "  epoch: 19/20,    batch: 2825/2993    Encoder_loss: 0.7321069836616516\n",
            "  epoch: 19/20,    batch: 2826/2993    Encoder_loss: 0.6943172216415405\n",
            "  epoch: 19/20,    batch: 2827/2993    Encoder_loss: 0.7351095676422119\n",
            "  epoch: 19/20,    batch: 2828/2993    Encoder_loss: 0.6995986700057983\n",
            "  epoch: 19/20,    batch: 2829/2993    Encoder_loss: 0.6033735871315002\n",
            "  epoch: 19/20,    batch: 2830/2993    Encoder_loss: 0.6678129434585571\n",
            "  epoch: 19/20,    batch: 2831/2993    Encoder_loss: 0.7537661194801331\n",
            "  epoch: 19/20,    batch: 2832/2993    Encoder_loss: 0.6783249974250793\n",
            "  epoch: 19/20,    batch: 2833/2993    Encoder_loss: 0.6683942675590515\n",
            "  epoch: 19/20,    batch: 2834/2993    Encoder_loss: 0.7304267883300781\n",
            "  epoch: 19/20,    batch: 2835/2993    Encoder_loss: 0.7028675079345703\n",
            "  epoch: 19/20,    batch: 2836/2993    Encoder_loss: 0.6315326690673828\n",
            "  epoch: 19/20,    batch: 2837/2993    Encoder_loss: 0.7034037113189697\n",
            "  epoch: 19/20,    batch: 2838/2993    Encoder_loss: 0.7605432868003845\n",
            "  epoch: 19/20,    batch: 2839/2993    Encoder_loss: 0.6764724254608154\n",
            "  epoch: 19/20,    batch: 2840/2993    Encoder_loss: 0.6667961478233337\n",
            "  epoch: 19/20,    batch: 2841/2993    Encoder_loss: 0.7503166198730469\n",
            "  epoch: 19/20,    batch: 2842/2993    Encoder_loss: 0.6892907023429871\n",
            "  epoch: 19/20,    batch: 2843/2993    Encoder_loss: 0.5942508578300476\n",
            "  epoch: 19/20,    batch: 2844/2993    Encoder_loss: 0.7064279913902283\n",
            "  epoch: 19/20,    batch: 2845/2993    Encoder_loss: 0.7655983567237854\n",
            "  epoch: 19/20,    batch: 2846/2993    Encoder_loss: 0.6670478582382202\n",
            "  epoch: 19/20,    batch: 2847/2993    Encoder_loss: 0.7061838507652283\n",
            "  epoch: 19/20,    batch: 2848/2993    Encoder_loss: 0.7635563611984253\n",
            "  epoch: 19/20,    batch: 2849/2993    Encoder_loss: 0.6663126349449158\n",
            "  epoch: 19/20,    batch: 2850/2993    Encoder_loss: 0.7413886785507202\n",
            "  epoch: 19/20,    batch: 2851/2993    Encoder_loss: 0.7569140791893005\n",
            "  epoch: 19/20,    batch: 2852/2993    Encoder_loss: 0.6711893677711487\n",
            "  epoch: 19/20,    batch: 2853/2993    Encoder_loss: 0.7695465087890625\n",
            "  epoch: 19/20,    batch: 2854/2993    Encoder_loss: 0.7317482829093933\n",
            "  epoch: 19/20,    batch: 2855/2993    Encoder_loss: 0.6715539693832397\n",
            "  epoch: 19/20,    batch: 2856/2993    Encoder_loss: 0.7620344161987305\n",
            "  epoch: 19/20,    batch: 2857/2993    Encoder_loss: 0.7080503702163696\n",
            "  epoch: 19/20,    batch: 2858/2993    Encoder_loss: 0.6898899674415588\n",
            "  epoch: 19/20,    batch: 2859/2993    Encoder_loss: 0.7567861080169678\n",
            "  epoch: 19/20,    batch: 2860/2993    Encoder_loss: 0.680810809135437\n",
            "  epoch: 19/20,    batch: 2861/2993    Encoder_loss: 0.7105034589767456\n",
            "  epoch: 19/20,    batch: 2862/2993    Encoder_loss: 0.7558374404907227\n",
            "  epoch: 19/20,    batch: 2863/2993    Encoder_loss: 0.6716982126235962\n",
            "  epoch: 19/20,    batch: 2864/2993    Encoder_loss: 0.6684613823890686\n",
            "  epoch: 19/20,    batch: 2865/2993    Encoder_loss: 0.7518277764320374\n",
            "  epoch: 19/20,    batch: 2866/2993    Encoder_loss: 0.6995277404785156\n",
            "  epoch: 19/20,    batch: 2867/2993    Encoder_loss: 0.6775456070899963\n",
            "  epoch: 19/20,    batch: 2868/2993    Encoder_loss: 0.744209885597229\n",
            "  epoch: 19/20,    batch: 2869/2993    Encoder_loss: 0.7082384824752808\n",
            "  epoch: 19/20,    batch: 2870/2993    Encoder_loss: 0.679387629032135\n",
            "  epoch: 19/20,    batch: 2871/2993    Encoder_loss: 0.7515497803688049\n",
            "  epoch: 19/20,    batch: 2872/2993    Encoder_loss: 0.7486721277236938\n",
            "  epoch: 19/20,    batch: 2873/2993    Encoder_loss: 0.6892200708389282\n",
            "  epoch: 19/20,    batch: 2874/2993    Encoder_loss: 0.7274054288864136\n",
            "  epoch: 19/20,    batch: 2875/2993    Encoder_loss: 0.6992925405502319\n",
            "  epoch: 19/20,    batch: 2876/2993    Encoder_loss: 0.6388415098190308\n",
            "  epoch: 19/20,    batch: 2877/2993    Encoder_loss: 0.7052486538887024\n",
            "  epoch: 19/20,    batch: 2878/2993    Encoder_loss: 0.7508643865585327\n",
            "  epoch: 19/20,    batch: 2879/2993    Encoder_loss: 0.6736226677894592\n",
            "  epoch: 19/20,    batch: 2880/2993    Encoder_loss: 0.7432023286819458\n",
            "  epoch: 19/20,    batch: 2881/2993    Encoder_loss: 0.7591081261634827\n",
            "  epoch: 19/20,    batch: 2882/2993    Encoder_loss: 0.6585754156112671\n",
            "  epoch: 19/20,    batch: 2883/2993    Encoder_loss: 0.7508359551429749\n",
            "  epoch: 19/20,    batch: 2884/2993    Encoder_loss: 0.728561520576477\n",
            "  epoch: 19/20,    batch: 2885/2993    Encoder_loss: 0.6801638007164001\n",
            "  epoch: 19/20,    batch: 2886/2993    Encoder_loss: 0.7712106108665466\n",
            "  epoch: 19/20,    batch: 2887/2993    Encoder_loss: 0.7099837064743042\n",
            "  epoch: 19/20,    batch: 2888/2993    Encoder_loss: 0.7001579403877258\n",
            "  epoch: 19/20,    batch: 2889/2993    Encoder_loss: 0.7702569365501404\n",
            "  epoch: 19/20,    batch: 2890/2993    Encoder_loss: 0.6989966630935669\n",
            "  epoch: 19/20,    batch: 2891/2993    Encoder_loss: 0.7312777042388916\n",
            "  epoch: 19/20,    batch: 2892/2993    Encoder_loss: 0.7878515720367432\n",
            "  epoch: 19/20,    batch: 2893/2993    Encoder_loss: 0.6859725713729858\n",
            "  epoch: 19/20,    batch: 2894/2993    Encoder_loss: 0.7376521825790405\n",
            "  epoch: 19/20,    batch: 2895/2993    Encoder_loss: 0.7539164423942566\n",
            "  epoch: 19/20,    batch: 2896/2993    Encoder_loss: 0.6770484447479248\n",
            "  epoch: 19/20,    batch: 2897/2993    Encoder_loss: 0.706699013710022\n",
            "  epoch: 19/20,    batch: 2898/2993    Encoder_loss: 0.7727142572402954\n",
            "  epoch: 19/20,    batch: 2899/2993    Encoder_loss: 0.6953772306442261\n",
            "  epoch: 19/20,    batch: 2900/2993    Encoder_loss: 0.715592086315155\n",
            "  epoch: 19/20,    batch: 2901/2993    Encoder_loss: 0.7670382261276245\n",
            "  epoch: 19/20,    batch: 2902/2993    Encoder_loss: 0.706195592880249\n",
            "  epoch: 19/20,    batch: 2903/2993    Encoder_loss: 0.6838712096214294\n",
            "  epoch: 19/20,    batch: 2904/2993    Encoder_loss: 0.7672277688980103\n",
            "  epoch: 19/20,    batch: 2905/2993    Encoder_loss: 0.7613174319267273\n",
            "  epoch: 19/20,    batch: 2906/2993    Encoder_loss: 0.7201399207115173\n",
            "  epoch: 19/20,    batch: 2907/2993    Encoder_loss: 0.741990327835083\n",
            "  epoch: 19/20,    batch: 2908/2993    Encoder_loss: 0.7264388799667358\n",
            "  epoch: 19/20,    batch: 2909/2993    Encoder_loss: 0.7187473773956299\n",
            "  epoch: 19/20,    batch: 2910/2993    Encoder_loss: 0.7695158123970032\n",
            "  epoch: 19/20,    batch: 2911/2993    Encoder_loss: 0.7526076436042786\n",
            "  epoch: 19/20,    batch: 2912/2993    Encoder_loss: 0.6828455328941345\n",
            "  epoch: 19/20,    batch: 2913/2993    Encoder_loss: 0.7501463294029236\n",
            "  epoch: 19/20,    batch: 2914/2993    Encoder_loss: 0.7515885829925537\n",
            "  epoch: 19/20,    batch: 2915/2993    Encoder_loss: 0.711201012134552\n",
            "  epoch: 19/20,    batch: 2916/2993    Encoder_loss: 0.7770434021949768\n",
            "  epoch: 19/20,    batch: 2917/2993    Encoder_loss: 0.742324709892273\n",
            "  epoch: 19/20,    batch: 2918/2993    Encoder_loss: 0.7102945446968079\n",
            "  epoch: 19/20,    batch: 2919/2993    Encoder_loss: 0.7662791609764099\n",
            "  epoch: 19/20,    batch: 2920/2993    Encoder_loss: 0.7135632038116455\n",
            "  epoch: 19/20,    batch: 2921/2993    Encoder_loss: 0.726901650428772\n",
            "  epoch: 19/20,    batch: 2922/2993    Encoder_loss: 0.7825047373771667\n",
            "  epoch: 19/20,    batch: 2923/2993    Encoder_loss: 0.6998206377029419\n",
            "  epoch: 19/20,    batch: 2924/2993    Encoder_loss: 0.7232828736305237\n",
            "  epoch: 19/20,    batch: 2925/2993    Encoder_loss: 0.7817321419715881\n",
            "  epoch: 19/20,    batch: 2926/2993    Encoder_loss: 0.7032796144485474\n",
            "  epoch: 19/20,    batch: 2927/2993    Encoder_loss: 0.7554408311843872\n",
            "  epoch: 19/20,    batch: 2928/2993    Encoder_loss: 0.7442758679389954\n",
            "  epoch: 19/20,    batch: 2929/2993    Encoder_loss: 0.6342884302139282\n",
            "  epoch: 19/20,    batch: 2930/2993    Encoder_loss: 0.6531359553337097\n",
            "  epoch: 19/20,    batch: 2931/2993    Encoder_loss: 0.7513805627822876\n",
            "  epoch: 19/20,    batch: 2932/2993    Encoder_loss: 0.7231793999671936\n",
            "  epoch: 19/20,    batch: 2933/2993    Encoder_loss: 0.6591827273368835\n",
            "  epoch: 19/20,    batch: 2934/2993    Encoder_loss: 0.7569518685340881\n",
            "  epoch: 19/20,    batch: 2935/2993    Encoder_loss: 0.7306650280952454\n",
            "  epoch: 19/20,    batch: 2936/2993    Encoder_loss: 0.6625575423240662\n",
            "  epoch: 19/20,    batch: 2937/2993    Encoder_loss: 0.6950103640556335\n",
            "  epoch: 19/20,    batch: 2938/2993    Encoder_loss: 0.7456595301628113\n",
            "  epoch: 19/20,    batch: 2939/2993    Encoder_loss: 0.6773757338523865\n",
            "  epoch: 19/20,    batch: 2940/2993    Encoder_loss: 0.6746022701263428\n",
            "  epoch: 19/20,    batch: 2941/2993    Encoder_loss: 0.7600366473197937\n",
            "  epoch: 19/20,    batch: 2942/2993    Encoder_loss: 0.7211179137229919\n",
            "  epoch: 19/20,    batch: 2943/2993    Encoder_loss: 0.6052087545394897\n",
            "  epoch: 19/20,    batch: 2944/2993    Encoder_loss: 0.6418322324752808\n",
            "  epoch: 19/20,    batch: 2945/2993    Encoder_loss: 0.7330039739608765\n",
            "  epoch: 19/20,    batch: 2946/2993    Encoder_loss: 0.6895143985748291\n",
            "  epoch: 19/20,    batch: 2947/2993    Encoder_loss: 0.6996003985404968\n",
            "  epoch: 19/20,    batch: 2948/2993    Encoder_loss: 0.753913938999176\n",
            "  epoch: 19/20,    batch: 2949/2993    Encoder_loss: 0.6679933071136475\n",
            "  epoch: 19/20,    batch: 2950/2993    Encoder_loss: 0.688969075679779\n",
            "  epoch: 19/20,    batch: 2951/2993    Encoder_loss: 0.7626469135284424\n",
            "  epoch: 19/20,    batch: 2952/2993    Encoder_loss: 0.6506132483482361\n",
            "  epoch: 19/20,    batch: 2953/2993    Encoder_loss: 0.6985974907875061\n",
            "  epoch: 19/20,    batch: 2954/2993    Encoder_loss: 0.7472636103630066\n",
            "  epoch: 19/20,    batch: 2955/2993    Encoder_loss: 0.6217743754386902\n",
            "  epoch: 19/20,    batch: 2956/2993    Encoder_loss: 0.7071730494499207\n",
            "  epoch: 19/20,    batch: 2957/2993    Encoder_loss: 0.7403315901756287\n",
            "  epoch: 19/20,    batch: 2958/2993    Encoder_loss: 0.6456202268600464\n",
            "  epoch: 19/20,    batch: 2959/2993    Encoder_loss: 0.7466208338737488\n",
            "  epoch: 19/20,    batch: 2960/2993    Encoder_loss: 0.7208673357963562\n",
            "  epoch: 19/20,    batch: 2961/2993    Encoder_loss: 0.6411209106445312\n",
            "  epoch: 19/20,    batch: 2962/2993    Encoder_loss: 0.7182601094245911\n",
            "  epoch: 19/20,    batch: 2963/2993    Encoder_loss: 0.6815733313560486\n",
            "  epoch: 19/20,    batch: 2964/2993    Encoder_loss: 0.5926312804222107\n",
            "  epoch: 19/20,    batch: 2965/2993    Encoder_loss: 0.6720724701881409\n",
            "  epoch: 19/20,    batch: 2966/2993    Encoder_loss: 0.7091094851493835\n",
            "  epoch: 19/20,    batch: 2967/2993    Encoder_loss: 0.6169235110282898\n",
            "  epoch: 19/20,    batch: 2968/2993    Encoder_loss: 0.6731892228126526\n",
            "  epoch: 19/20,    batch: 2969/2993    Encoder_loss: 0.6880902647972107\n",
            "  epoch: 19/20,    batch: 2970/2993    Encoder_loss: 0.607499361038208\n",
            "  epoch: 19/20,    batch: 2971/2993    Encoder_loss: 0.655504047870636\n",
            "  epoch: 19/20,    batch: 2972/2993    Encoder_loss: 0.7156953811645508\n",
            "  epoch: 19/20,    batch: 2973/2993    Encoder_loss: 0.6418465971946716\n",
            "  epoch: 19/20,    batch: 2974/2993    Encoder_loss: 0.661268949508667\n",
            "  epoch: 19/20,    batch: 2975/2993    Encoder_loss: 0.693577229976654\n",
            "  epoch: 19/20,    batch: 2976/2993    Encoder_loss: 0.6134141087532043\n",
            "  epoch: 19/20,    batch: 2977/2993    Encoder_loss: 0.6226449608802795\n",
            "  epoch: 19/20,    batch: 2978/2993    Encoder_loss: 0.6948804259300232\n",
            "  epoch: 19/20,    batch: 2979/2993    Encoder_loss: 0.6389246582984924\n",
            "  epoch: 19/20,    batch: 2980/2993    Encoder_loss: 0.6529279351234436\n",
            "  epoch: 19/20,    batch: 2981/2993    Encoder_loss: 0.7267926931381226\n",
            "  epoch: 19/20,    batch: 2982/2993    Encoder_loss: 0.6256422400474548\n",
            "  epoch: 19/20,    batch: 2983/2993    Encoder_loss: 0.667963981628418\n",
            "  epoch: 19/20,    batch: 2984/2993    Encoder_loss: 0.741271436214447\n",
            "  epoch: 19/20,    batch: 2985/2993    Encoder_loss: 0.6385389566421509\n",
            "  epoch: 19/20,    batch: 2986/2993    Encoder_loss: 0.6996412873268127\n",
            "  epoch: 19/20,    batch: 2987/2993    Encoder_loss: 0.7231884002685547\n",
            "  epoch: 19/20,    batch: 2988/2993    Encoder_loss: 0.6419637799263\n",
            "  epoch: 19/20,    batch: 2989/2993    Encoder_loss: 0.7334038019180298\n",
            "  epoch: 19/20,    batch: 2990/2993    Encoder_loss: 0.7115647196769714\n",
            "  epoch: 19/20,    batch: 2991/2993    Encoder_loss: 0.6612471342086792\n",
            "  epoch: 19/20,    batch: 2992/2993    Encoder_loss: 0.7064908146858215\n",
            "epoch: 19/20,  Tot_epoch_loss: 1999.6781005859375\n",
            "  adding: encoder_checkpoints/ (stored 0%)\n",
            "  adding: encoder_checkpoints/encoder_epoch10.h5 (deflated 9%)\n",
            "  adding: encoder_checkpoints/encoder_epoch4.h5 (deflated 9%)\n",
            "  adding: encoder_checkpoints/encoder_epoch16.h5 (deflated 9%)\n",
            "  adding: encoder_checkpoints/encoder_epoch3.h5 (deflated 9%)\n",
            "  adding: encoder_checkpoints/encoder_epoch8.h5 (deflated 9%)\n",
            "  adding: encoder_checkpoints/encoder_epoch15.h5 (deflated 9%)\n",
            "  adding: encoder_checkpoints/encoder_epoch17.h5 (deflated 9%)\n",
            "  adding: encoder_checkpoints/encoder_epoch13.h5 (deflated 9%)\n",
            "  adding: encoder_checkpoints/encoder_epoch18.h5 (deflated 9%)\n",
            "  adding: encoder_checkpoints/encoder_epoch9.h5 (deflated 9%)\n",
            "  adding: encoder_checkpoints/encoder_epoch0.h5 (deflated 10%)\n",
            "  adding: encoder_checkpoints/encoder_epoch1.h5 (deflated 10%)\n",
            "  adding: encoder_checkpoints/encoder_epoch2.h5 (deflated 10%)\n",
            "  adding: encoder_checkpoints/encoder_epoch12.h5 (deflated 9%)\n",
            "  adding: encoder_checkpoints/encoder_epoch6.h5 (deflated 9%)\n",
            "  adding: encoder_checkpoints/encoder_epoch7.h5 (deflated 9%)\n",
            "  adding: encoder_checkpoints/.ipynb_checkpoints/ (stored 0%)\n",
            "  adding: encoder_checkpoints/encoder_epoch5.h5 (deflated 9%)\n",
            "  adding: encoder_checkpoints/encoder_epoch11.h5 (deflated 9%)\n",
            "  adding: encoder_checkpoints/encoder_epoch14.h5 (deflated 9%)\n",
            "  adding: encoder_checkpoints/encoder_epoch19.h5 (deflated 9%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Anomaly Detection"
      ],
      "metadata": {
        "id": "Xndp1iQ-17uK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def reconstruction_loss(time_sequences, fake_sequences, discriminator, _lambda):\n",
        "  '''\n",
        "  This function acts as both recontruction loss function when mapping a time sequence to\n",
        "  a latent variable 'z' and as anomaly score.\n",
        "\n",
        "  This loss is the sum of 2 losses:\n",
        "      - residual loss: the sum of the absolute value of the components of the difference\n",
        "          between a real time sequence and a generated one by the generator\n",
        "\n",
        "      - discrimination loss: the sum of the absolute value of the components of the difference\n",
        "          between the outputs of the LSTM layer of the discriminator when the inputs\n",
        "          are a real time sequence and a generated one\n",
        "  '''\n",
        "  residual_loss = tf.reduce_sum(abs(time_sequences - fake_sequences))\n",
        "\n",
        "  interm_layer = discriminator.layers[0]  # LSTM layer\n",
        "\n",
        "  features_real = interm_layer(time_sequences)\n",
        "  features_fake = interm_layer(fake_sequences)\n",
        "\n",
        "  discrimination_loss = tf.reduce_sum(abs(features_real-features_fake))\n",
        "\n",
        "  total_loss = (1-_lambda)*residual_loss + _lambda*discrimination_loss\n",
        "\n",
        "  return total_loss\n",
        "\n",
        "def anomaly_score(test_data, generator, discriminator, encoder, _lambda):\n",
        "  '''\n",
        "  Outputs a list of losses, each loss corresponding to a time window\n",
        "  '''\n",
        "\n",
        "  # IMPORTANT: DURING ANOMALY DETECTION, SET BATCH_SIZE=1!!!!!!!!!!!!!!!!!!\n",
        "  # i.e., a batch contains a single window of timesteps\n",
        "\n",
        "  i = 0\n",
        "  loss_list = []\n",
        "  for _, batch in enumerate(test_data):\n",
        "    print(f\"batch: {i} out of {len(test_data)}\")\n",
        "    i+=1\n",
        "\n",
        "    # map time sequences to latent space\n",
        "    latent_var = encoder(batch[0]) # batch size is 1, so batch[0] points to the window\n",
        "\n",
        "    # reconstruct time sequences from latent space\n",
        "    reconstr_sequences = generator(latent_var)\n",
        "\n",
        "    # compute reconstruction loss\n",
        "    loss = reconstruction_loss(batch[0], reconstr_sequences, discriminator, _lambda)\n",
        "\n",
        "    loss_list.append(loss)\n",
        "  return loss_list\n"
      ],
      "metadata": {
        "id": "qLKMChTJAINk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Perform inference\n",
        "Either use the generator and discriminator at the state you have them now (if you just trained them), or load a previously saved checkpoint"
      ],
      "metadata": {
        "id": "_fp-XAX5fdXZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generator = init_generator(in_dim=(WINDOW_SIZE, LATENT_VAR_SIZE), out_dim=(WINDOW_SIZE, SAMPLE_SIZE))\n",
        "discriminator = init_discriminator(in_dim=(WINDOW_SIZE, SAMPLE_SIZE), out_dim=1)\n",
        "encoder = init_encoder(in_dim=(WINDOW_SIZE, SAMPLE_SIZE), out_dim=(WINDOW_SIZE, LATENT_VAR_SIZE))\n",
        "\n",
        "# download and uzip latest generator and discriminator checkpoints\n",
        "!cp ./drive/MyDrive/ml-applications/TimeSeriesAnomalyDetection_project/saved_checkpoints/checkpoints_2023-07-26_17:42:21.134678.zip .\n",
        "!unzip ./checkpoints_2023-07-26_17:42:21.134678.zip -d .\n",
        "\n",
        "# download and unzip latest encoder checkpoint\n",
        "!cp ./drive/MyDrive/ml-applications/TimeSeriesAnomalyDetection_project/saved_encoder_checkpoints/encoder_checkpoints_2023-08-10_22:37:38.628102.zip .\n",
        "!unzip ./encoder_checkpoints_2023-08-10_22:37:38.628102.zip -d .\n",
        "\n",
        "epoch = 19\n",
        "generator.load_weights(f\"./checkpoints/generator/gen_epoch{epoch}.h5\")\n",
        "discriminator.load_weights(f\"./checkpoints/discriminator/discr_epoch{epoch}.h5\")\n",
        "\n",
        "epoch_enc = 19 # SET THIS TO 19 AFTER FULLY TRAINING THE ENCODER!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
        "encoder.load_weights(f\"./encoder_checkpoints/encoder_epoch{epoch_enc}.h5\")"
      ],
      "metadata": {
        "id": "FPrZlASiPSLu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a795144-8d89-428d-8ed8-3014a2b10d11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  ./checkpoints_2023-07-26_17:42:21.134678.zip\n",
            "   creating: ./checkpoints/\n",
            "   creating: ./checkpoints/generator/\n",
            "  inflating: ./checkpoints/generator/gen_epoch0.h5  \n",
            "  inflating: ./checkpoints/generator/gen_epoch7.h5  \n",
            "  inflating: ./checkpoints/generator/gen_epoch4.h5  \n",
            "  inflating: ./checkpoints/generator/gen_epoch2.h5  \n",
            "  inflating: ./checkpoints/generator/gen_epoch12.h5  \n",
            "  inflating: ./checkpoints/generator/gen_epoch16.h5  \n",
            "  inflating: ./checkpoints/generator/gen_epoch13.h5  \n",
            "  inflating: ./checkpoints/generator/gen_epoch10.h5  \n",
            "  inflating: ./checkpoints/generator/gen_epoch15.h5  \n",
            "  inflating: ./checkpoints/generator/gen_epoch19.h5  \n",
            "  inflating: ./checkpoints/generator/gen_epoch8.h5  \n",
            "  inflating: ./checkpoints/generator/gen_epoch11.h5  \n",
            "  inflating: ./checkpoints/generator/gen_epoch18.h5  \n",
            "  inflating: ./checkpoints/generator/gen_epoch14.h5  \n",
            "  inflating: ./checkpoints/generator/gen_epoch1.h5  \n",
            "  inflating: ./checkpoints/generator/gen_epoch6.h5  \n",
            "  inflating: ./checkpoints/generator/gen_epoch9.h5  \n",
            "  inflating: ./checkpoints/generator/gen_epoch3.h5  \n",
            "  inflating: ./checkpoints/generator/gen_epoch5.h5  \n",
            "  inflating: ./checkpoints/generator/gen_epoch17.h5  \n",
            "   creating: ./checkpoints/discriminator/\n",
            "  inflating: ./checkpoints/discriminator/discr_epoch16.h5  \n",
            "  inflating: ./checkpoints/discriminator/discr_epoch9.h5  \n",
            "  inflating: ./checkpoints/discriminator/discr_epoch6.h5  \n",
            "  inflating: ./checkpoints/discriminator/discr_epoch18.h5  \n",
            "  inflating: ./checkpoints/discriminator/discr_epoch12.h5  \n",
            "  inflating: ./checkpoints/discriminator/discr_epoch5.h5  \n",
            "  inflating: ./checkpoints/discriminator/discr_epoch17.h5  \n",
            "  inflating: ./checkpoints/discriminator/discr_epoch11.h5  \n",
            "  inflating: ./checkpoints/discriminator/discr_epoch15.h5  \n",
            "  inflating: ./checkpoints/discriminator/discr_epoch3.h5  \n",
            "  inflating: ./checkpoints/discriminator/discr_epoch8.h5  \n",
            "  inflating: ./checkpoints/discriminator/discr_epoch1.h5  \n",
            "  inflating: ./checkpoints/discriminator/discr_epoch4.h5  \n",
            "  inflating: ./checkpoints/discriminator/discr_epoch2.h5  \n",
            "  inflating: ./checkpoints/discriminator/discr_epoch10.h5  \n",
            "  inflating: ./checkpoints/discriminator/discr_epoch19.h5  \n",
            "  inflating: ./checkpoints/discriminator/discr_epoch0.h5  \n",
            "  inflating: ./checkpoints/discriminator/discr_epoch13.h5  \n",
            "  inflating: ./checkpoints/discriminator/discr_epoch7.h5  \n",
            "  inflating: ./checkpoints/discriminator/discr_epoch14.h5  \n",
            "Archive:  ./encoder_checkpoints_2023-08-10_22:37:38.628102.zip\n",
            "   creating: ./encoder_checkpoints/\n",
            "  inflating: ./encoder_checkpoints/encoder_epoch10.h5  \n",
            "  inflating: ./encoder_checkpoints/encoder_epoch4.h5  \n",
            "  inflating: ./encoder_checkpoints/encoder_epoch16.h5  \n",
            "  inflating: ./encoder_checkpoints/encoder_epoch3.h5  \n",
            "  inflating: ./encoder_checkpoints/encoder_epoch8.h5  \n",
            "  inflating: ./encoder_checkpoints/encoder_epoch15.h5  \n",
            "  inflating: ./encoder_checkpoints/encoder_epoch17.h5  \n",
            "  inflating: ./encoder_checkpoints/encoder_epoch13.h5  \n",
            "  inflating: ./encoder_checkpoints/encoder_epoch18.h5  \n",
            "  inflating: ./encoder_checkpoints/encoder_epoch9.h5  \n",
            "  inflating: ./encoder_checkpoints/encoder_epoch0.h5  \n",
            "  inflating: ./encoder_checkpoints/encoder_epoch1.h5  \n",
            "  inflating: ./encoder_checkpoints/encoder_epoch2.h5  \n",
            "  inflating: ./encoder_checkpoints/encoder_epoch12.h5  \n",
            "  inflating: ./encoder_checkpoints/encoder_epoch6.h5  \n",
            "  inflating: ./encoder_checkpoints/encoder_epoch7.h5  \n",
            "   creating: ./encoder_checkpoints/.ipynb_checkpoints/\n",
            "  inflating: ./encoder_checkpoints/encoder_epoch5.h5  \n",
            "  inflating: ./encoder_checkpoints/encoder_epoch11.h5  \n",
            "  inflating: ./encoder_checkpoints/encoder_epoch14.h5  \n",
            "  inflating: ./encoder_checkpoints/encoder_epoch19.h5  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss_list = anomaly_score(test_dataset, generator, discriminator, encoder, LAMBDA)"
      ],
      "metadata": {
        "id": "ZK7kf_ErATDk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0488d1d6-896f-4375-8595-06c61bf165c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch: 0 out of 289\n",
            "batch: 1 out of 289\n",
            "batch: 2 out of 289\n",
            "batch: 3 out of 289\n",
            "batch: 4 out of 289\n",
            "batch: 5 out of 289\n",
            "batch: 6 out of 289\n",
            "batch: 7 out of 289\n",
            "batch: 8 out of 289\n",
            "batch: 9 out of 289\n",
            "batch: 10 out of 289\n",
            "batch: 11 out of 289\n",
            "batch: 12 out of 289\n",
            "batch: 13 out of 289\n",
            "batch: 14 out of 289\n",
            "batch: 15 out of 289\n",
            "batch: 16 out of 289\n",
            "batch: 17 out of 289\n",
            "batch: 18 out of 289\n",
            "batch: 19 out of 289\n",
            "batch: 20 out of 289\n",
            "batch: 21 out of 289\n",
            "batch: 22 out of 289\n",
            "batch: 23 out of 289\n",
            "batch: 24 out of 289\n",
            "batch: 25 out of 289\n",
            "batch: 26 out of 289\n",
            "batch: 27 out of 289\n",
            "batch: 28 out of 289\n",
            "batch: 29 out of 289\n",
            "batch: 30 out of 289\n",
            "batch: 31 out of 289\n",
            "batch: 32 out of 289\n",
            "batch: 33 out of 289\n",
            "batch: 34 out of 289\n",
            "batch: 35 out of 289\n",
            "batch: 36 out of 289\n",
            "batch: 37 out of 289\n",
            "batch: 38 out of 289\n",
            "batch: 39 out of 289\n",
            "batch: 40 out of 289\n",
            "batch: 41 out of 289\n",
            "batch: 42 out of 289\n",
            "batch: 43 out of 289\n",
            "batch: 44 out of 289\n",
            "batch: 45 out of 289\n",
            "batch: 46 out of 289\n",
            "batch: 47 out of 289\n",
            "batch: 48 out of 289\n",
            "batch: 49 out of 289\n",
            "batch: 50 out of 289\n",
            "batch: 51 out of 289\n",
            "batch: 52 out of 289\n",
            "batch: 53 out of 289\n",
            "batch: 54 out of 289\n",
            "batch: 55 out of 289\n",
            "batch: 56 out of 289\n",
            "batch: 57 out of 289\n",
            "batch: 58 out of 289\n",
            "batch: 59 out of 289\n",
            "batch: 60 out of 289\n",
            "batch: 61 out of 289\n",
            "batch: 62 out of 289\n",
            "batch: 63 out of 289\n",
            "batch: 64 out of 289\n",
            "batch: 65 out of 289\n",
            "batch: 66 out of 289\n",
            "batch: 67 out of 289\n",
            "batch: 68 out of 289\n",
            "batch: 69 out of 289\n",
            "batch: 70 out of 289\n",
            "batch: 71 out of 289\n",
            "batch: 72 out of 289\n",
            "batch: 73 out of 289\n",
            "batch: 74 out of 289\n",
            "batch: 75 out of 289\n",
            "batch: 76 out of 289\n",
            "batch: 77 out of 289\n",
            "batch: 78 out of 289\n",
            "batch: 79 out of 289\n",
            "batch: 80 out of 289\n",
            "batch: 81 out of 289\n",
            "batch: 82 out of 289\n",
            "batch: 83 out of 289\n",
            "batch: 84 out of 289\n",
            "batch: 85 out of 289\n",
            "batch: 86 out of 289\n",
            "batch: 87 out of 289\n",
            "batch: 88 out of 289\n",
            "batch: 89 out of 289\n",
            "batch: 90 out of 289\n",
            "batch: 91 out of 289\n",
            "batch: 92 out of 289\n",
            "batch: 93 out of 289\n",
            "batch: 94 out of 289\n",
            "batch: 95 out of 289\n",
            "batch: 96 out of 289\n",
            "batch: 97 out of 289\n",
            "batch: 98 out of 289\n",
            "batch: 99 out of 289\n",
            "batch: 100 out of 289\n",
            "batch: 101 out of 289\n",
            "batch: 102 out of 289\n",
            "batch: 103 out of 289\n",
            "batch: 104 out of 289\n",
            "batch: 105 out of 289\n",
            "batch: 106 out of 289\n",
            "batch: 107 out of 289\n",
            "batch: 108 out of 289\n",
            "batch: 109 out of 289\n",
            "batch: 110 out of 289\n",
            "batch: 111 out of 289\n",
            "batch: 112 out of 289\n",
            "batch: 113 out of 289\n",
            "batch: 114 out of 289\n",
            "batch: 115 out of 289\n",
            "batch: 116 out of 289\n",
            "batch: 117 out of 289\n",
            "batch: 118 out of 289\n",
            "batch: 119 out of 289\n",
            "batch: 120 out of 289\n",
            "batch: 121 out of 289\n",
            "batch: 122 out of 289\n",
            "batch: 123 out of 289\n",
            "batch: 124 out of 289\n",
            "batch: 125 out of 289\n",
            "batch: 126 out of 289\n",
            "batch: 127 out of 289\n",
            "batch: 128 out of 289\n",
            "batch: 129 out of 289\n",
            "batch: 130 out of 289\n",
            "batch: 131 out of 289\n",
            "batch: 132 out of 289\n",
            "batch: 133 out of 289\n",
            "batch: 134 out of 289\n",
            "batch: 135 out of 289\n",
            "batch: 136 out of 289\n",
            "batch: 137 out of 289\n",
            "batch: 138 out of 289\n",
            "batch: 139 out of 289\n",
            "batch: 140 out of 289\n",
            "batch: 141 out of 289\n",
            "batch: 142 out of 289\n",
            "batch: 143 out of 289\n",
            "batch: 144 out of 289\n",
            "batch: 145 out of 289\n",
            "batch: 146 out of 289\n",
            "batch: 147 out of 289\n",
            "batch: 148 out of 289\n",
            "batch: 149 out of 289\n",
            "batch: 150 out of 289\n",
            "batch: 151 out of 289\n",
            "batch: 152 out of 289\n",
            "batch: 153 out of 289\n",
            "batch: 154 out of 289\n",
            "batch: 155 out of 289\n",
            "batch: 156 out of 289\n",
            "batch: 157 out of 289\n",
            "batch: 158 out of 289\n",
            "batch: 159 out of 289\n",
            "batch: 160 out of 289\n",
            "batch: 161 out of 289\n",
            "batch: 162 out of 289\n",
            "batch: 163 out of 289\n",
            "batch: 164 out of 289\n",
            "batch: 165 out of 289\n",
            "batch: 166 out of 289\n",
            "batch: 167 out of 289\n",
            "batch: 168 out of 289\n",
            "batch: 169 out of 289\n",
            "batch: 170 out of 289\n",
            "batch: 171 out of 289\n",
            "batch: 172 out of 289\n",
            "batch: 173 out of 289\n",
            "batch: 174 out of 289\n",
            "batch: 175 out of 289\n",
            "batch: 176 out of 289\n",
            "batch: 177 out of 289\n",
            "batch: 178 out of 289\n",
            "batch: 179 out of 289\n",
            "batch: 180 out of 289\n",
            "batch: 181 out of 289\n",
            "batch: 182 out of 289\n",
            "batch: 183 out of 289\n",
            "batch: 184 out of 289\n",
            "batch: 185 out of 289\n",
            "batch: 186 out of 289\n",
            "batch: 187 out of 289\n",
            "batch: 188 out of 289\n",
            "batch: 189 out of 289\n",
            "batch: 190 out of 289\n",
            "batch: 191 out of 289\n",
            "batch: 192 out of 289\n",
            "batch: 193 out of 289\n",
            "batch: 194 out of 289\n",
            "batch: 195 out of 289\n",
            "batch: 196 out of 289\n",
            "batch: 197 out of 289\n",
            "batch: 198 out of 289\n",
            "batch: 199 out of 289\n",
            "batch: 200 out of 289\n",
            "batch: 201 out of 289\n",
            "batch: 202 out of 289\n",
            "batch: 203 out of 289\n",
            "batch: 204 out of 289\n",
            "batch: 205 out of 289\n",
            "batch: 206 out of 289\n",
            "batch: 207 out of 289\n",
            "batch: 208 out of 289\n",
            "batch: 209 out of 289\n",
            "batch: 210 out of 289\n",
            "batch: 211 out of 289\n",
            "batch: 212 out of 289\n",
            "batch: 213 out of 289\n",
            "batch: 214 out of 289\n",
            "batch: 215 out of 289\n",
            "batch: 216 out of 289\n",
            "batch: 217 out of 289\n",
            "batch: 218 out of 289\n",
            "batch: 219 out of 289\n",
            "batch: 220 out of 289\n",
            "batch: 221 out of 289\n",
            "batch: 222 out of 289\n",
            "batch: 223 out of 289\n",
            "batch: 224 out of 289\n",
            "batch: 225 out of 289\n",
            "batch: 226 out of 289\n",
            "batch: 227 out of 289\n",
            "batch: 228 out of 289\n",
            "batch: 229 out of 289\n",
            "batch: 230 out of 289\n",
            "batch: 231 out of 289\n",
            "batch: 232 out of 289\n",
            "batch: 233 out of 289\n",
            "batch: 234 out of 289\n",
            "batch: 235 out of 289\n",
            "batch: 236 out of 289\n",
            "batch: 237 out of 289\n",
            "batch: 238 out of 289\n",
            "batch: 239 out of 289\n",
            "batch: 240 out of 289\n",
            "batch: 241 out of 289\n",
            "batch: 242 out of 289\n",
            "batch: 243 out of 289\n",
            "batch: 244 out of 289\n",
            "batch: 245 out of 289\n",
            "batch: 246 out of 289\n",
            "batch: 247 out of 289\n",
            "batch: 248 out of 289\n",
            "batch: 249 out of 289\n",
            "batch: 250 out of 289\n",
            "batch: 251 out of 289\n",
            "batch: 252 out of 289\n",
            "batch: 253 out of 289\n",
            "batch: 254 out of 289\n",
            "batch: 255 out of 289\n",
            "batch: 256 out of 289\n",
            "batch: 257 out of 289\n",
            "batch: 258 out of 289\n",
            "batch: 259 out of 289\n",
            "batch: 260 out of 289\n",
            "batch: 261 out of 289\n",
            "batch: 262 out of 289\n",
            "batch: 263 out of 289\n",
            "batch: 264 out of 289\n",
            "batch: 265 out of 289\n",
            "batch: 266 out of 289\n",
            "batch: 267 out of 289\n",
            "batch: 268 out of 289\n",
            "batch: 269 out of 289\n",
            "batch: 270 out of 289\n",
            "batch: 271 out of 289\n",
            "batch: 272 out of 289\n",
            "batch: 273 out of 289\n",
            "batch: 274 out of 289\n",
            "batch: 275 out of 289\n",
            "batch: 276 out of 289\n",
            "batch: 277 out of 289\n",
            "batch: 278 out of 289\n",
            "batch: 279 out of 289\n",
            "batch: 280 out of 289\n",
            "batch: 281 out of 289\n",
            "batch: 282 out of 289\n",
            "batch: 283 out of 289\n",
            "batch: 284 out of 289\n",
            "batch: 285 out of 289\n",
            "batch: 286 out of 289\n",
            "batch: 287 out of 289\n",
            "batch: 288 out of 289\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validation_loss_list = anomaly_score(validation_dataset, generator, discriminator, encoder, LAMBDA)"
      ],
      "metadata": {
        "id": "n5Ja_buX8rCU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "850de339-d2e1-49e7-876e-6c430f4254d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch: 0 out of 281\n",
            "batch: 1 out of 281\n",
            "batch: 2 out of 281\n",
            "batch: 3 out of 281\n",
            "batch: 4 out of 281\n",
            "batch: 5 out of 281\n",
            "batch: 6 out of 281\n",
            "batch: 7 out of 281\n",
            "batch: 8 out of 281\n",
            "batch: 9 out of 281\n",
            "batch: 10 out of 281\n",
            "batch: 11 out of 281\n",
            "batch: 12 out of 281\n",
            "batch: 13 out of 281\n",
            "batch: 14 out of 281\n",
            "batch: 15 out of 281\n",
            "batch: 16 out of 281\n",
            "batch: 17 out of 281\n",
            "batch: 18 out of 281\n",
            "batch: 19 out of 281\n",
            "batch: 20 out of 281\n",
            "batch: 21 out of 281\n",
            "batch: 22 out of 281\n",
            "batch: 23 out of 281\n",
            "batch: 24 out of 281\n",
            "batch: 25 out of 281\n",
            "batch: 26 out of 281\n",
            "batch: 27 out of 281\n",
            "batch: 28 out of 281\n",
            "batch: 29 out of 281\n",
            "batch: 30 out of 281\n",
            "batch: 31 out of 281\n",
            "batch: 32 out of 281\n",
            "batch: 33 out of 281\n",
            "batch: 34 out of 281\n",
            "batch: 35 out of 281\n",
            "batch: 36 out of 281\n",
            "batch: 37 out of 281\n",
            "batch: 38 out of 281\n",
            "batch: 39 out of 281\n",
            "batch: 40 out of 281\n",
            "batch: 41 out of 281\n",
            "batch: 42 out of 281\n",
            "batch: 43 out of 281\n",
            "batch: 44 out of 281\n",
            "batch: 45 out of 281\n",
            "batch: 46 out of 281\n",
            "batch: 47 out of 281\n",
            "batch: 48 out of 281\n",
            "batch: 49 out of 281\n",
            "batch: 50 out of 281\n",
            "batch: 51 out of 281\n",
            "batch: 52 out of 281\n",
            "batch: 53 out of 281\n",
            "batch: 54 out of 281\n",
            "batch: 55 out of 281\n",
            "batch: 56 out of 281\n",
            "batch: 57 out of 281\n",
            "batch: 58 out of 281\n",
            "batch: 59 out of 281\n",
            "batch: 60 out of 281\n",
            "batch: 61 out of 281\n",
            "batch: 62 out of 281\n",
            "batch: 63 out of 281\n",
            "batch: 64 out of 281\n",
            "batch: 65 out of 281\n",
            "batch: 66 out of 281\n",
            "batch: 67 out of 281\n",
            "batch: 68 out of 281\n",
            "batch: 69 out of 281\n",
            "batch: 70 out of 281\n",
            "batch: 71 out of 281\n",
            "batch: 72 out of 281\n",
            "batch: 73 out of 281\n",
            "batch: 74 out of 281\n",
            "batch: 75 out of 281\n",
            "batch: 76 out of 281\n",
            "batch: 77 out of 281\n",
            "batch: 78 out of 281\n",
            "batch: 79 out of 281\n",
            "batch: 80 out of 281\n",
            "batch: 81 out of 281\n",
            "batch: 82 out of 281\n",
            "batch: 83 out of 281\n",
            "batch: 84 out of 281\n",
            "batch: 85 out of 281\n",
            "batch: 86 out of 281\n",
            "batch: 87 out of 281\n",
            "batch: 88 out of 281\n",
            "batch: 89 out of 281\n",
            "batch: 90 out of 281\n",
            "batch: 91 out of 281\n",
            "batch: 92 out of 281\n",
            "batch: 93 out of 281\n",
            "batch: 94 out of 281\n",
            "batch: 95 out of 281\n",
            "batch: 96 out of 281\n",
            "batch: 97 out of 281\n",
            "batch: 98 out of 281\n",
            "batch: 99 out of 281\n",
            "batch: 100 out of 281\n",
            "batch: 101 out of 281\n",
            "batch: 102 out of 281\n",
            "batch: 103 out of 281\n",
            "batch: 104 out of 281\n",
            "batch: 105 out of 281\n",
            "batch: 106 out of 281\n",
            "batch: 107 out of 281\n",
            "batch: 108 out of 281\n",
            "batch: 109 out of 281\n",
            "batch: 110 out of 281\n",
            "batch: 111 out of 281\n",
            "batch: 112 out of 281\n",
            "batch: 113 out of 281\n",
            "batch: 114 out of 281\n",
            "batch: 115 out of 281\n",
            "batch: 116 out of 281\n",
            "batch: 117 out of 281\n",
            "batch: 118 out of 281\n",
            "batch: 119 out of 281\n",
            "batch: 120 out of 281\n",
            "batch: 121 out of 281\n",
            "batch: 122 out of 281\n",
            "batch: 123 out of 281\n",
            "batch: 124 out of 281\n",
            "batch: 125 out of 281\n",
            "batch: 126 out of 281\n",
            "batch: 127 out of 281\n",
            "batch: 128 out of 281\n",
            "batch: 129 out of 281\n",
            "batch: 130 out of 281\n",
            "batch: 131 out of 281\n",
            "batch: 132 out of 281\n",
            "batch: 133 out of 281\n",
            "batch: 134 out of 281\n",
            "batch: 135 out of 281\n",
            "batch: 136 out of 281\n",
            "batch: 137 out of 281\n",
            "batch: 138 out of 281\n",
            "batch: 139 out of 281\n",
            "batch: 140 out of 281\n",
            "batch: 141 out of 281\n",
            "batch: 142 out of 281\n",
            "batch: 143 out of 281\n",
            "batch: 144 out of 281\n",
            "batch: 145 out of 281\n",
            "batch: 146 out of 281\n",
            "batch: 147 out of 281\n",
            "batch: 148 out of 281\n",
            "batch: 149 out of 281\n",
            "batch: 150 out of 281\n",
            "batch: 151 out of 281\n",
            "batch: 152 out of 281\n",
            "batch: 153 out of 281\n",
            "batch: 154 out of 281\n",
            "batch: 155 out of 281\n",
            "batch: 156 out of 281\n",
            "batch: 157 out of 281\n",
            "batch: 158 out of 281\n",
            "batch: 159 out of 281\n",
            "batch: 160 out of 281\n",
            "batch: 161 out of 281\n",
            "batch: 162 out of 281\n",
            "batch: 163 out of 281\n",
            "batch: 164 out of 281\n",
            "batch: 165 out of 281\n",
            "batch: 166 out of 281\n",
            "batch: 167 out of 281\n",
            "batch: 168 out of 281\n",
            "batch: 169 out of 281\n",
            "batch: 170 out of 281\n",
            "batch: 171 out of 281\n",
            "batch: 172 out of 281\n",
            "batch: 173 out of 281\n",
            "batch: 174 out of 281\n",
            "batch: 175 out of 281\n",
            "batch: 176 out of 281\n",
            "batch: 177 out of 281\n",
            "batch: 178 out of 281\n",
            "batch: 179 out of 281\n",
            "batch: 180 out of 281\n",
            "batch: 181 out of 281\n",
            "batch: 182 out of 281\n",
            "batch: 183 out of 281\n",
            "batch: 184 out of 281\n",
            "batch: 185 out of 281\n",
            "batch: 186 out of 281\n",
            "batch: 187 out of 281\n",
            "batch: 188 out of 281\n",
            "batch: 189 out of 281\n",
            "batch: 190 out of 281\n",
            "batch: 191 out of 281\n",
            "batch: 192 out of 281\n",
            "batch: 193 out of 281\n",
            "batch: 194 out of 281\n",
            "batch: 195 out of 281\n",
            "batch: 196 out of 281\n",
            "batch: 197 out of 281\n",
            "batch: 198 out of 281\n",
            "batch: 199 out of 281\n",
            "batch: 200 out of 281\n",
            "batch: 201 out of 281\n",
            "batch: 202 out of 281\n",
            "batch: 203 out of 281\n",
            "batch: 204 out of 281\n",
            "batch: 205 out of 281\n",
            "batch: 206 out of 281\n",
            "batch: 207 out of 281\n",
            "batch: 208 out of 281\n",
            "batch: 209 out of 281\n",
            "batch: 210 out of 281\n",
            "batch: 211 out of 281\n",
            "batch: 212 out of 281\n",
            "batch: 213 out of 281\n",
            "batch: 214 out of 281\n",
            "batch: 215 out of 281\n",
            "batch: 216 out of 281\n",
            "batch: 217 out of 281\n",
            "batch: 218 out of 281\n",
            "batch: 219 out of 281\n",
            "batch: 220 out of 281\n",
            "batch: 221 out of 281\n",
            "batch: 222 out of 281\n",
            "batch: 223 out of 281\n",
            "batch: 224 out of 281\n",
            "batch: 225 out of 281\n",
            "batch: 226 out of 281\n",
            "batch: 227 out of 281\n",
            "batch: 228 out of 281\n",
            "batch: 229 out of 281\n",
            "batch: 230 out of 281\n",
            "batch: 231 out of 281\n",
            "batch: 232 out of 281\n",
            "batch: 233 out of 281\n",
            "batch: 234 out of 281\n",
            "batch: 235 out of 281\n",
            "batch: 236 out of 281\n",
            "batch: 237 out of 281\n",
            "batch: 238 out of 281\n",
            "batch: 239 out of 281\n",
            "batch: 240 out of 281\n",
            "batch: 241 out of 281\n",
            "batch: 242 out of 281\n",
            "batch: 243 out of 281\n",
            "batch: 244 out of 281\n",
            "batch: 245 out of 281\n",
            "batch: 246 out of 281\n",
            "batch: 247 out of 281\n",
            "batch: 248 out of 281\n",
            "batch: 249 out of 281\n",
            "batch: 250 out of 281\n",
            "batch: 251 out of 281\n",
            "batch: 252 out of 281\n",
            "batch: 253 out of 281\n",
            "batch: 254 out of 281\n",
            "batch: 255 out of 281\n",
            "batch: 256 out of 281\n",
            "batch: 257 out of 281\n",
            "batch: 258 out of 281\n",
            "batch: 259 out of 281\n",
            "batch: 260 out of 281\n",
            "batch: 261 out of 281\n",
            "batch: 262 out of 281\n",
            "batch: 263 out of 281\n",
            "batch: 264 out of 281\n",
            "batch: 265 out of 281\n",
            "batch: 266 out of 281\n",
            "batch: 267 out of 281\n",
            "batch: 268 out of 281\n",
            "batch: 269 out of 281\n",
            "batch: 270 out of 281\n",
            "batch: 271 out of 281\n",
            "batch: 272 out of 281\n",
            "batch: 273 out of 281\n",
            "batch: 274 out of 281\n",
            "batch: 275 out of 281\n",
            "batch: 276 out of 281\n",
            "batch: 277 out of 281\n",
            "batch: 278 out of 281\n",
            "batch: 279 out of 281\n",
            "batch: 280 out of 281\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save in Drive the losses obtained on test or validation datasets"
      ],
      "metadata": {
        "id": "5PUSxrU_zR8N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss_array = np.array([i.numpy().item() for i in test_loss_list])\n",
        "\n",
        "with open('test_loss.npy', 'wb') as f:\n",
        "  np.save(f, test_loss_array)\n",
        "\n",
        "!cp ./test_loss.npy ./drive/MyDrive/ml-applications/TimeSeriesAnomalyDetection_project/saved_losses_modifiedModel/"
      ],
      "metadata": {
        "id": "Y15kwIVpl6Yp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af1d0406-9905-418f-d4dc-64cdd75ac377"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1936.99621582, 1955.69384766, 1930.90209961, 1932.89746094,\n",
              "       2296.17285156, 2185.13256836, 2015.30444336, 2509.19726562,\n",
              "       1978.28271484, 2326.88330078, 1857.4654541 , 2274.29516602,\n",
              "       2446.6262207 , 2046.8236084 , 2132.75341797, 1965.10693359,\n",
              "       2196.20654297, 2118.03320312, 1943.59301758, 2256.95166016,\n",
              "       2134.10327148, 2197.70336914, 2117.75610352, 1880.02807617,\n",
              "       2241.06958008, 1955.47265625, 2163.00756836, 1902.93859863,\n",
              "       2163.12402344, 1838.88867188, 2328.37084961, 1868.06726074,\n",
              "       2106.55541992, 1815.25842285, 2188.58081055, 1785.99438477,\n",
              "       2010.22766113, 1597.91601562, 2492.53393555, 1980.27990723,\n",
              "       2186.93261719, 1895.11279297, 1958.0546875 , 2146.29541016,\n",
              "       1854.12890625, 1971.07763672, 2212.76977539, 1705.37072754,\n",
              "       2163.99145508, 1704.4519043 , 2175.80688477, 1890.5020752 ,\n",
              "       2206.47094727, 2054.70410156, 2017.85913086, 1992.05419922,\n",
              "       1995.0847168 , 2144.78369141, 1990.26269531, 2092.07421875,\n",
              "       2232.01123047, 1941.51049805, 2057.59204102, 2233.20849609,\n",
              "       1825.28991699, 2111.50415039, 1851.00549316, 2152.48657227,\n",
              "       1978.61352539, 1977.97619629, 2112.90478516, 1793.80957031,\n",
              "       2290.13256836, 1820.70153809, 2359.04467773, 1846.94714355,\n",
              "       2076.48583984, 2271.16821289, 1908.08410645, 2036.71923828,\n",
              "       2220.90405273, 1900.99499512, 2072.11206055, 2095.04638672,\n",
              "       1914.96606445, 2213.03100586, 2146.30102539, 2063.96557617,\n",
              "       2136.40258789, 1816.51062012, 2212.24267578, 2019.09643555,\n",
              "       2092.43725586, 2118.33959961, 2003.88806152, 2095.88427734,\n",
              "       2148.88134766, 1953.12768555, 2052.67700195, 2149.42871094,\n",
              "       1911.71411133, 2183.69140625, 1959.25646973, 2079.83178711,\n",
              "       2075.51391602, 1971.37841797, 2053.41967773, 1803.52270508,\n",
              "       2283.09472656, 1747.61352539, 2322.13525391, 1726.7064209 ,\n",
              "       2428.24414062, 1867.42285156, 2442.85595703, 1872.7989502 ,\n",
              "       2240.67700195, 2001.37475586, 2371.23046875, 1676.33886719,\n",
              "       2165.98974609, 2028.85266113, 1876.40246582, 1919.39648438,\n",
              "       1741.46191406, 2103.09008789, 1880.45080566, 1975.87805176,\n",
              "       2008.83605957, 1668.84082031, 1996.22619629, 1989.78308105,\n",
              "       1989.07080078, 1825.28234863, 2086.55859375, 2057.16235352,\n",
              "       1828.54187012, 2063.22998047, 1976.40869141, 1857.35021973,\n",
              "       2083.89111328, 1907.44970703, 2139.20019531, 2048.40771484,\n",
              "       1922.82531738, 1933.73486328, 1837.50195312, 2153.50878906,\n",
              "       1925.15698242, 1994.56298828, 2101.53222656, 1854.63061523,\n",
              "       2033.75561523, 2164.64941406, 1719.83190918, 2180.92016602,\n",
              "       2006.98486328, 1915.76538086, 2118.13867188, 1742.33325195,\n",
              "       2201.39086914, 2193.91943359, 2110.64013672, 1826.62866211,\n",
              "       2008.3807373 , 2018.5682373 , 1839.61218262, 2064.73461914,\n",
              "       2069.15405273, 2037.69763184, 1774.86022949, 2062.36352539,\n",
              "       2158.18530273, 1738.99487305, 2076.94702148, 2156.70361328,\n",
              "       1803.85095215, 1990.55895996, 2001.30273438, 1856.41821289,\n",
              "       2376.97143555, 1992.3704834 , 1998.97631836, 1822.53930664,\n",
              "       1992.46777344, 1701.57434082, 1968.34594727, 2065.08374023,\n",
              "       1765.11340332, 2084.88647461, 2078.80639648, 2055.20068359,\n",
              "       2043.2902832 , 1644.61474609, 2127.14306641, 2196.64233398,\n",
              "       1944.06665039, 1607.28564453, 2050.56225586, 1997.95703125,\n",
              "       1944.61291504, 2092.62255859, 1772.42077637, 2098.25292969,\n",
              "       1974.55822754, 2020.3416748 , 2080.28369141, 1861.68212891,\n",
              "       2080.38500977, 2154.59692383, 1901.73706055, 2103.19482422,\n",
              "       2085.68066406, 1895.41577148, 2096.36987305, 2108.93261719,\n",
              "       1945.86108398, 2219.57177734, 1801.05895996, 2031.75976562,\n",
              "       1895.90063477, 2053.74609375, 2102.41845703, 2164.94995117,\n",
              "       1903.3145752 , 2121.70263672, 2177.36450195, 1853.41015625,\n",
              "       2270.44702148, 1987.75793457, 1952.9173584 , 2225.49072266,\n",
              "       1911.08544922, 2050.1159668 , 1958.90100098, 2519.72363281,\n",
              "       1712.09069824, 2109.57885742, 1848.41601562, 1944.26550293,\n",
              "       2023.34851074, 1955.34667969, 1801.01940918, 1977.51123047,\n",
              "       1991.84448242, 1808.57495117, 1914.84912109, 2077.21948242,\n",
              "       1810.46154785, 1890.62353516, 2073.00634766, 1837.93249512,\n",
              "       1813.25646973, 2037.34216309, 1760.62927246, 2007.70263672,\n",
              "       2111.68481445, 1807.81298828, 1938.4666748 , 2030.84912109,\n",
              "       1999.56359863, 2000.6048584 , 1806.92102051, 2252.69091797,\n",
              "       1963.57958984, 2249.57470703, 2427.46264648, 1883.15576172,\n",
              "       2180.39355469, 1917.19458008, 2695.32714844, 1638.77233887,\n",
              "       2194.87109375, 2035.63049316, 1778.54187012, 2080.17871094,\n",
              "       1778.80053711, 1976.71252441, 1766.05505371, 2108.78100586,\n",
              "       1666.96569824, 2246.98510742, 2061.27783203, 1973.68212891,\n",
              "       1886.05224609, 2039.90625   , 1879.40844727, 2262.87670898,\n",
              "       2028.23815918])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compute and plot performance measures"
      ],
      "metadata": {
        "id": "uppC0m13Ko5L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "\n",
        "#!cp ./drive/MyDrive/ml-applications/TimeSeriesAnomalyDetection_project/saved_losses/test_loss.npy .\n",
        "\n",
        "def compute_f1_score(anomaly_scores, ground_truth, thresholds):\n",
        "    f1_dict = {}\n",
        "\n",
        "    for t in thresholds:\n",
        "        assigned_labels = [0 if i < t else 1 for i in anomaly_scores]\n",
        "        f1_dict[t] = f1_score(ground_truth, assigned_labels)\n",
        "\n",
        "    return f1_dict\n",
        "\n",
        "def compute_precision_score(anomaly_scores, ground_truth, thresholds):\n",
        "    precision_dict = {}\n",
        "\n",
        "    for t in thresholds:\n",
        "        assigned_labels = [0 if i < t else 1 for i in anomaly_scores]\n",
        "        precision_dict[t] = precision_score(ground_truth, assigned_labels)\n",
        "\n",
        "    return precision_dict\n",
        "\n",
        "def compute_recall_score(anomaly_scores, ground_truth, thresholds):\n",
        "    recall_dict = {}\n",
        "\n",
        "    for t in thresholds:\n",
        "        assigned_labels = [0 if i < t else 1 for i in anomaly_scores]\n",
        "        recall_dict[t] = recall_score(ground_truth, assigned_labels)\n",
        "\n",
        "    return recall_dict"
      ],
      "metadata": {
        "id": "JaXQLD9_QDCy"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import RocCurveDisplay\n",
        "\n",
        "def plot_metric(metric_results_dict, chosen_th, model_name, x_axis_descr, y_axis_descr):\n",
        "\n",
        "  plt.figure().set_facecolor(\"w\")\n",
        "  plt.style.use('default')\n",
        "\n",
        "  plt.title(model_name)\n",
        "  plt.xlabel(x_axis_descr)\n",
        "  plt.ylabel(y_axis_descr)\n",
        "\n",
        "  plt.plot(metric_results_dict.keys(), metric_results_dict.values(), '-s', linewidth=1, markersize=2)\n",
        "\n",
        "  plt.plot(chosen_th, metric_results_dict[chosen_th], '-o', markersize=6, color='orange',\n",
        "           label='Score: {:.2f} @ chosen threshold={:.2f}'.format(metric_results_dict[chosen_th], chosen_th))\n",
        "\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "def compute_metrics(anomaly_scores, ground_truth, model_name, num_thresholds=10):\n",
        "\n",
        "  min_threshold = anomaly_scores.min()\n",
        "  max_threshold = anomaly_scores.max()\n",
        "\n",
        "  thresholds = np.linspace(start=min_threshold, stop=max_threshold, num=num_thresholds)\n",
        "\n",
        "  print(\"\\nF1 score\")\n",
        "  f1_res = compute_f1_score(anomaly_scores, ground_truth, thresholds)\n",
        "  for i in f1_res.keys():\n",
        "      print(f\"{i}: {f1_res[i]}\")\n",
        "\n",
        "  maxval = 0\n",
        "  chosen_th = 0\n",
        "  for k in f1_res.keys():\n",
        "    if f1_res[k] > maxval:\n",
        "      maxval = f1_res[k]\n",
        "      chosen_th = k\n",
        "\n",
        "  plot_metric(f1_res, chosen_th, model_name, \"threshold\", \"F1 score\")\n",
        "\n",
        "  print(\"\\nPrecision score:\")\n",
        "  precision_res = compute_precision_score(anomaly_scores, ground_truth, thresholds)\n",
        "  for i in precision_res.keys():\n",
        "      print(f\"{i}: {precision_res[i]}\")\n",
        "\n",
        "  plot_metric(precision_res, chosen_th, model_name, \"threshold\", \"Precision score\")\n",
        "\n",
        "  print(\"\\nRecall score:\")\n",
        "  recall_res = compute_recall_score(anomaly_scores, ground_truth, thresholds)\n",
        "  for i in recall_res.keys():\n",
        "    print(f\"{i}: {recall_res[i]}\")\n",
        "\n",
        "  plot_metric(recall_res, chosen_th, model_name, \"threshold\", \"Recall score\")"
      ],
      "metadata": {
        "id": "QhbLUX287KEA"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load previously computed losses"
      ],
      "metadata": {
        "id": "91Y3aGUYK1ZN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp ./drive/MyDrive/ml-applications/TimeSeriesAnomalyDetection_project/saved_losses_modifiedModel/test_loss.npy .\n",
        "!cp ./drive/MyDrive/ml-applications/TimeSeriesAnomalyDetection_project/saved_losses_modifiedModel/validation_loss.npy .\n",
        "\n",
        "with open('test_loss.npy', 'rb') as f:\n",
        "  test_loss = np.load(f)\n",
        "\n",
        "with open('validation_loss.npy', 'rb') as g:\n",
        "  validation_loss = np.load(g)"
      ],
      "metadata": {
        "id": "iRjHNHMLSTnq"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#overlapped_windows_rec1, overlapped_labels_rec1 = window_data(df_rec1_labelled, WINDOW_SIZE, 1)\n",
        "#overlapped_windows_rec5, overlapped_labels_rec5 = window_data(df_rec5_labelled, WINDOW_SIZE, 1)"
      ],
      "metadata": {
        "id": "eKyUhgtVY1iS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losses = np.concatenate((test_loss, validation_loss))\n",
        "labels = np.concatenate((overlapped_labels_rec1, overlapped_labels_rec5))\n",
        "\n",
        "compute_metrics(losses, labels, \"ModifiedTAnoGAN\", num_thresholds=15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iO2tAmc_Tsde",
        "outputId": "0885d8fe-b4f8-4274-906e-63baebbfa189"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "F1 score\n",
            "1549.2977294921875: 0.4667145486376083\n",
            "1652.223920549665: 0.46835528842894913\n",
            "1755.150111607143: 0.47881672265770814\n",
            "1858.0763026646205: 0.5030278764826586\n",
            "1961.0024937220983: 0.5367074210975263\n",
            "2063.9286847795756: 0.5878741366078281\n",
            "2166.8548758370534: 0.6222260673962884\n",
            "2269.7810668945312: 0.624668219489735\n",
            "2372.707257952009: 0.5286839145106862\n",
            "2475.633449009487: 0.34148658275943955\n",
            "2578.559640066964: 0.135067264573991\n",
            "2681.485831124442: 0.03626404759656247\n",
            "2784.4120221819194: 0.00422305403589596\n",
            "2887.338213239397: 0.002305696992986838\n",
            "2990.264404296875: 0.00019234468166955183\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Precision score:\n",
            "1549.2977294921875: 0.3043885587141728\n",
            "1652.223920549665: 0.3060838747784997\n",
            "1755.150111607143: 0.31607478362645147\n",
            "1858.0763026646205: 0.3399627938440724\n",
            "1961.0024937220983: 0.3809792919710976\n",
            "2063.9286847795756: 0.4612184574963052\n",
            "2166.8548758370534: 0.5654088050314465\n",
            "2269.7810668945312: 0.7150297619047619\n",
            "2372.707257952009: 0.8471162001696353\n",
            "2475.633449009487: 0.9646690518783542\n",
            "2578.559640066964: 1.0\n",
            "2681.485831124442: 1.0\n",
            "2784.4120221819194: 1.0\n",
            "2887.338213239397: 1.0\n",
            "2990.264404296875: 1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Recall score:\n",
            "1549.2977294921875: 1.0\n",
            "1652.223920549665: 0.9968260075021641\n",
            "1755.150111607143: 0.9870154852361258\n",
            "1858.0763026646205: 0.9667211695681447\n",
            "1961.0024937220983: 0.9077618543810715\n",
            "2063.9286847795756: 0.8104260844474368\n",
            "2166.8548758370534: 0.6917380013465423\n",
            "2269.7810668945312: 0.5545830528036934\n",
            "2372.707257952009: 0.3842454554198326\n",
            "2475.633449009487: 0.20746369144945656\n",
            "2578.559640066964: 0.07242473790516495\n",
            "2681.485831124442: 0.01846686544195441\n",
            "2784.4120221819194: 0.0021159949985572763\n",
            "2887.338213239397: 0.0011541790901221506\n",
            "2990.264404296875: 9.618159084351255e-05\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ROC plot"
      ],
      "metadata": {
        "id": "UCpDyPB_M4Yc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def roc_plot(losses, labels, plot_title, num_thresholds=10):\n",
        "  min_threshold = losses.min()\n",
        "  max_threshold = losses.max()\n",
        "\n",
        "  thresholds = np.linspace(start=min_threshold, stop=max_threshold, num=15)\n",
        "\n",
        "  sens = list()\n",
        "  fpr = list()\n",
        "  for threshold in thresholds:\n",
        "    predicted_labels = (losses >= threshold).astype(int)  # losses above threshold are predicted as anomaly\n",
        "\n",
        "    matching = (predicted_labels == labels).astype(int)\n",
        "    tp = matching[predicted_labels==1].astype(int).sum()\n",
        "\n",
        "    cm_anomaly = np.zeros((2, 2))\n",
        "    n_samples = len(losses)\n",
        "    n_not_collisions = n_samples - sum(labels)\n",
        "    n_detected = sum(predicted_labels)\n",
        "\n",
        "    fp = n_detected - tp\n",
        "    fn = sum(labels) - tp\n",
        "    tn = n_not_collisions - fp\n",
        "\n",
        "    sens.append(tp / (tp + fn))\n",
        "    fpr.append(1-tn /(fp + tn))\n",
        "\n",
        "  fig, ax = plt.subplots(1, 1)\n",
        "  ax.plot(fpr, sens)\n",
        "  plt.title(plot_title)"
      ],
      "metadata": {
        "id": "rO7Ijl8xM4Jj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "roc_plot(losses, labels, \"ROC curve ModifiedTAnoGAN\", 15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "1BXFf-FLpi9u",
        "outputId": "48a10db2-1153-4dea-d51d-7160553ec292"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGzCAYAAAD9pBdvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABJJUlEQVR4nO3deVxU5f4H8M/MwMyA7ALDIoqCKy64Eu4YgeW1vC2adt1umeVyK9q0RbS6YppmuWTZYguu3ezXLa8bai5p5JoriqDgwibCIDszz+8PZHQElCFmDsN83q/XvIxznjPzndPI+fg8zzxHJoQQICIiIpKIXOoCiIiIyLYxjBAREZGkGEaIiIhIUgwjREREJCmGESIiIpIUwwgRERFJimGEiIiIJMUwQkRERJJiGCEiIiJJMYwQUaMzePBgDB482PDzhQsXIJPJsGrVKqN2mzdvRmhoKNRqNWQyGfLy8jBhwgQEBgY2aD2BgYGYMGFCgz4nEd3CMEJWYdWqVZDJZIaHnZ0d/P39MWHCBFy+fLnGY4QQ+PbbbzFw4EC4ubnB0dERXbp0wTvvvIPCwsJaX2vjxo148MEH4enpCaVSCT8/P4wcORI7duww19trlKoCgEwmw3vvvVdjm6eeegoymQxOTk4Wrg64du0aRo4cCQcHByxbtgzffvstmjVrZvbXDQwMNPos1va4PTht2rQJMpkMfn5+0Ov1Zq/xdllZWZgxYwa6dOkCJycnqNVqBAcHY+LEidi7d2+txy1fvhwymQxhYWG1tql6rwsXLqy2r+rv7MGDBxvkfVDTZid1AUSmeOedd9C6dWuUlJTgwIEDWLVqFfbu3YsTJ05ArVYb2ul0OowZMwbr16/HgAEDMHv2bDg6OmLPnj2YM2cONmzYgO3bt0Oj0RiOEULgn//8J1atWoXu3bsjJiYGPj4+uHr1KjZu3Ij7778f+/btQ9++faV465JRq9VYs2YN3nrrLaPthYWF+L//+z+j824urVq1QnFxMezt7Q3b/vjjDxQUFODdd99FZGSkYfvKlSvNesFfvHgxbty4Yfh506ZNWLNmDT788EN4enoatt/+OYmPj0dgYCAuXLiAHTt2GNVrTomJiRg2bBgKCgrw5JNP4rnnnoNKpUJqaip+/PFHrFq1Cr/++isGDhxY7diqmhMTE5GcnIzg4OBaX2fBggV4/vnn4ejoaM63Q02ZILICX331lQAg/vjjD6Ptr7/+ugAg1q1bZ7R97ty5AoB45ZVXqj3XTz/9JORyuRg6dKjR9gULFggA4sUXXxR6vb7acd988434/fffG+Dd1N+NGzcs9lqpqakCgHj00UcFAHH06FGj/fHx8cLe3l4MHz5cNGvWrEFfe9CgQWLQoEF3bfP111/X+Jkwh1atWonx48fXuK/qc5Oamlrj/hs3bohmzZqJjz/+WHTv3l1MmDDBfIXeJjc3V/j6+gofHx9x+vTpavv1er1YvXq1SExMrLYvJSVFABA//PCD8PLyErNnz67xNQCI0NBQAUAsXLjQaF9tf2eJasJhGrJqAwYMAACcP3/esK24uBgLFixAu3btEBcXV+2Y4cOHY/z48di8eTMOHDhgOCYuLg4dOnTABx98AJlMVu24sWPHok+fPnetR6/X46OPPkKXLl2gVqvh5eWFoUOHGrqqa5v7AFR2ec+ePdvw8+zZsyGTyXDq1CmMGTMG7u7u6N+/v6G+ixcvVnuOmTNnQqlU4vr164Ztv//+O4YOHQpXV1c4Ojpi0KBB2Ldv313fx+3Cw8PRunVrrF692mh7fHw8hg4dCg8PjxqPW758OUJCQqBSqeDn54epU6ciLy+vWrvPPvsMQUFBcHBwQJ8+fbBnz55qbe48b4MHD8b48eMBAL1794ZMJjPM6ahpzoher8fixYsREhICtVoNjUaDyZMnG50noLJ37L333kOLFi3g6OiIiIgInDx5sg5nqXYbN25EcXExnnjiCTz55JP44YcfUFJSUq2dTCbDtGnT8OOPP6Jz585QqVQICQnB5s2bq7U9cuQIHnzwQbi4uMDJyQn333+/4bNcZcWKFbh69SoWL16MDh061Ph6o0ePRu/evavti4+Ph7u7O4YNG4bHH38c8fHxtb6/fv36YciQIZg/fz6Ki4vrckqIqmEYIat24cIFAIC7u7th2969e3H9+nWMGTMGdnY1j0SOGzcOAPDzzz8bjsnNzcWYMWOgUCjqXc/TTz+NF198EQEBAXj//fcxY8YMqNXqahcKUzzxxBMoKirC3LlzMWnSJIwcORIymQzr16+v1nb9+vWIiooynI8dO3Zg4MCB0Gq1iI2Nxdy5c5GXl4chQ4YgMTGxzjWMHj0aa9euhRACAJCTk4OtW7dizJgxNbafPXs2pk6dCj8/PyxcuBCPPfYYPv30U0RFRaG8vNzQ7osvvsDkyZPh4+OD+fPno1+/fnj44YeRnp5+13refPNNPPvsswAqh+6+/fZbTJ48udb2kydPxquvvop+/frho48+wsSJExEfH4/o6GijembNmoW3334b3bp1w4IFC9CmTRtERUXddY7RvcTHxyMiIgI+Pj548sknUVBQgP/+9781tt27dy+mTJmCJ598EvPnz0dJSQkee+wxXLt2zdDm5MmTGDBgAI4dO4bXXnsNb7/9NlJTUzF48GD8/vvvhnb//e9/4eDggEcffbReNT/66KNQKpUYPXo0zp07hz/++KPW9rNnz0ZmZiY++eQTk1+LCACHacg6VHX5bt++XWRnZ4v09HTx/fffCy8vL6FSqUR6erqh7eLFiwUAsXHjxlqfLzc31zAEIYQQH3300T2PuZcdO3YIAOJf//pXtX1Vwz5VQx9fffVVtTYARGxsrOHn2NhYAUCMHj26Wtvw8HDRs2dPo22JiYkCgPjmm28Mr9m2bVsRHR1tNOxUVFQkWrduLR544IG7vp+qWhcsWCBOnDghAIg9e/YIIYRYtmyZcHJyEoWFhWL8+PFGwzRZWVlCqVSKqKgoodPpDNuXLl0qAIgvv/xSCCFEWVmZ8Pb2FqGhoaK0tNTQ7rPPPhMAjIZpajpvtQ0DjB8/XrRq1crw8549ewQAER8fb9Ru8+bNRtur6h42bJjR+XrjjTcEgHoN02RmZgo7OzuxcuVKw7a+ffuKRx55pFpbAEKpVIrk5GTDtmPHjgkAYsmSJYZtI0aMEEqlUpw/f96w7cqVK8LZ2VkMHDjQsM3d3V2EhoZWex2tViuys7MNjzuH/g4ePCgAiG3btgkhKj9HLVq0EC+88EKNNU+dOlUIIURERITw8fERRUVFQggO05Bp2DNCViUyMhJeXl4ICAjA448/jmbNmuGnn35CixYtDG0KCgoAAM7OzrU+T9U+rVZr9OfdjrmX//znP5DJZIiNja22r6Zhn7p67rnnqm0bNWoUDh06ZDQ8tW7dOqhUKjzyyCMAgKNHj+LcuXMYM2YMrl27hpycHOTk5KCwsBD3338/du/eXeeJniEhIejatSvWrFkDAFi9ejUeeeSRGicsbt++HWVlZXjxxRchl9/6FTNp0iS4uLjgl19+AQAcPHgQWVlZeO6556BUKg3tJkyYAFdX1zrVVRcbNmyAq6srHnjgAcM5yMnJQc+ePeHk5ISdO3ca1T19+nSj/18vvvhivV977dq1kMvleOyxxwzbRo8ejf/973/VhoiAys93UFCQ4eeuXbvCxcUFKSkpAConZm/duhUjRoxAmzZtDO18fX0xZswY7N271+gzXdO3nMaOHQsvLy/D4/XXXzfaHx8fD41Gg4iICACVn91Ro0Zh7dq10Ol0tb7X2bNnIyMjAytWrKjLqSEywjBCVmXZsmXYtm0bvv/+ezz00EPIycmBSqUyalMVKKpCSU3uDCwuLi73POZezp8/Dz8/v1rnUNRX69atq2174oknIJfLsW7dOgCVcx02bNhgmEcAAOfOnQMAjB8/3uji4+Xlhc8//xylpaXIz8+vcx1jxozBhg0bkJycjN9++63WIZqquSzt27c32q5UKtGmTRvD/qo/27Zta9TO3t7e6EL7V507dw75+fnw9vaudh5u3LiBrKysu9bj5eVlNAxoiu+++w59+vTBtWvXkJycjOTkZHTv3h1lZWXYsGFDtfYtW7asts3d3d0QXLKzs1FUVFTt3AJAx44dodfrDUNczs7ORt/6qfLOO+9g27Zt2LZtW7V9Op0Oa9euRUREBFJTUw01h4WFITMzEwkJCbW+14EDByIiIoJzR6he+NVesip9+vRBr169AAAjRoxA//79MWbMGCQlJRn+FdixY0cAwJ9//okRI0bU+Dx//vknAKBTp04AYJjgd/z48VqPaQi19ZDc7V+cDg4O1bb5+flhwIABWL9+Pd544w0cOHAAaWlpeP/99w1tqno9FixYgNDQ0Bqf25T1QUaPHo2ZM2di0qRJaN68OaKioup8rJT0ej28vb1rnYTp5eVllte9fZ7FnQEHqOyBqJr3UqW2+Uri5lwdU3To0AHHjh1DeXm50Veiu3btWusxO3bswNWrV7F27VqsXbu2xprv9v89NjYWgwcPxqeffgo3NzeTaybbxTBCVkuhUCAuLg4RERFYunQpZsyYAQDo378/3NzcsHr1arz55ps1/oL/5ptvAAB/+9vfDMe4u7tjzZo1eOONN+o1iTUoKAhbtmxBbm5urb0jVf/CvvNbJTV9M+ZeRo0ahSlTpiApKQnr1q2Do6Mjhg8fblQPUNnr0xDrWrRs2RL9+vXDrl278Pzzz9c6ObhVq1YAgKSkJKMejrKyMqSmphpqqWp37tw5DBkyxNCuvLwcqamp6Nat21+uGag8D9u3b0e/fv1qDHZ31n3u3DmjurOzs2scUrmX+Ph42Nvb49tvv632edq7dy8+/vhjpKWl1dgbUhsvLy84OjoiKSmp2r4zZ85ALpcjICAAQOVn+8CBA9i4cSNGjhxZ55q9vb2xbNmyavt++OEHbNy4EStWrKj1PA4aNAiDBw/G+++/j1mzZtX5fRFxAitZhbtNhuvTp4/QaDSiuLjYsO29994TAMTrr79erf3PP/8s5HK5iI6ONto+b948AUC8/PLLNa4z8u233951nZG6TGAVQghPT0/x97//3Wj/yy+/XOsE1uzs7BpfLzMzUygUChEbGyv8/PzEyJEjjfbrdDoRFBQk2rZtKwoKCqodn5WVVet7EcJ4AmuVXbt2idjYWHHq1CnDttomsA4dOtTofS9fvrzaBFYvLy+zT2DdtWuXACBmzpxZ7T2Wl5eL69evG+q2t7dvsAmswcHBYsiQITUec+nSJSGTycS8efMM23DbZNDb3bnGyYgRI4RKpTJ6vYyMDOHi4mI0gfXatWtCo9EIPz8/kZSUVO159Xq90WsWFRUJZ2dn8c9//rPGmvft2ycAiLVr19615qrzXbX+CCewUl2wZ4Ss3quvvoonnngCq1atMkz2nDFjBo4cOYL3338f+/fvx2OPPQYHBwfs3bsX3333HTp27Iivv/662vOcPHkSCxcuxM6dO/H444/Dx8cHGRkZ+PHHH5GYmIjffvut1joiIiIwduxYfPzxxzh37hyGDh0KvV6PPXv2ICIiAtOmTQMAPPPMM5g3bx6eeeYZ9OrVC7t378bZs2dNft/e3t6IiIjAokWLUFBQgFGjRhntl8vl+Pzzz/Hggw8iJCQEEydOhL+/Py5fvoydO3fCxcWl1q+Y1mbQoEEYNGjQXdt4eXlh5syZmDNnDoYOHYqHH34YSUlJWL58OXr37o1//OMfACrnhrz33nuYPHkyhgwZglGjRiE1NRVfffVVg84ZGTRoECZPnoy4uDgcPXoUUVFRsLe3x7lz57BhwwZ89NFHePzxx+Hl5YVXXnkFcXFx+Nvf/oaHHnoIR44cwf/+9z+jlVXr4vfff0dycrLh//md/P390aNHD8THx1ebQHov7733HrZt24b+/ftjypQpsLOzw6efforS0lLMnz/f0M7DwwMbN27E8OHD0a1bNzz55JPo3bs37O3tkZ6ebpizUtUz89NPP6GgoAAPP/xwja973333wcvLC/Hx8dU+a7er+oz8+uuvJr0vsnFSpyGiurhbz0hVD0BQUJCoqKgw2v7VV1+Jfv36CRcXF6FWq0VISIiYM2fOXVcy/f7770VUVJTw8PAQdnZ2wtfXV4waNUrs2rXrnnVWVFSIBQsWiA4dOgilUim8vLzEgw8+KA4dOmRoU1RUJJ5++mnh6uoqnJ2dxciRI0VWVpbJPSNCCLFy5UoBQDg7Oxv1DN3uyJEj4tFHHxXNmzcXKpVKtGrVSowcOVIkJCTc9b3U1DNSkzt7RqosXbpUdOjQQdjb2wuNRiOef/55Qy/E7ZYvXy5at24tVCqV6NWrl9i9e3e1FVj/Ss9Ilc8++0z07NlTODg4CGdnZ9GlSxfx2muviStXrhja6HQ6MWfOHOHr6yscHBzE4MGDxYkTJ0xegXX69OkCgNHXb+80e/ZsAUAcO3ZMCFH3nhEhhDh8+LCIjo4WTk5OwtHRUURERIjffvutxte5evWqePXVV0WnTp2Eg4ODUKlUok2bNmLcuHFi9+7dhnbDhw8XarVaFBYW1lrzhAkThL29vcjJyblrzTt37hQA2DNCdSYToh4zo4iIiIgaCL/aS0RERJJiGCEiIiJJMYwQERGRpBhGiIiISFIMI0RERCQphhEiIiKSlFUseqbX63HlyhU4Ozv/pbufEhERkeUIIVBQUAA/Pz+ju3jfySrCyJUrVwz3WyAiIiLrkp6ejhYtWtS63yrCSNVt3tPT0w23RyciIqLGTavVIiAgwHAdr41VhJGqoRkXFxeGESIiIitzrykWnMBKREREkmIYISIiIkkxjBAREZGkGEaIiIhIUgwjREREJCmGESIiIpIUwwgRERFJimGEiIiIJMUwQkRERJJiGCEiIiJJmRxGdu/ejeHDh8PPzw8ymQw//vjjPY/ZtWsXevToAZVKheDgYKxataoepRIREVFTZHIYKSwsRLdu3bBs2bI6tU9NTcWwYcMQERGBo0eP4sUXX8QzzzyDLVu2mFwsERERNT0m3yjvwQcfxIMPPljn9itWrEDr1q2xcOFCAEDHjh2xd+9efPjhh4iOjq7xmNLSUpSWlhp+1mq1ppZJREREd1FcpsOJK/k4lp6Ho+l5mPdYVzippLl/rtlfdf/+/YiMjDTaFh0djRdffLHWY+Li4jBnzhwzV0ZERNT0lVbocOl6MdJyi5B2rQhnMgpwLD0PSZkF0OmFod0/7muF+9o0l6RGs4eRjIwMaDQao20ajQZarRbFxcVwcHCodszMmTMRExNj+Fmr1SIgIMDcpRIREVkdIQTyispxMbfoZuAoRFpuES5eK0J6bhGuaksgRM3HejmrEBrghtAAN/i7Vb8eW4o0/TH3oFKpoFKppC6DiIioUajQ6XElrwQXcyuDRlUvR9WfBaUVdz3eUalASw9HtPRwRGuvZght4YbQlm7wcVFDJpNZ6F3UzuxhxMfHB5mZmUbbMjMz4eLiUmOvCBERkS3SlpQj7WZvxsU7AsflvGKjIZWaaFxUNwNHM7T0cESr5o4IuPln82bKRhE6amP2MBIeHo5NmzYZbdu2bRvCw8PN/dJERESNhk4vcDW/2LhXI7cyfKTlFuF6Ufldj1fayQ29G1WPVs0r/2zh7ggHpcJC76ThmRxGbty4geTkZMPPqampOHr0KDw8PNCyZUvMnDkTly9fxjfffAMAeO6557B06VK89tpr+Oc//4kdO3Zg/fr1+OWXXxruXRARETUCBSXlRgHj9rkbl/OKUa67e++GRzOlUci4FTqawdtZBbm88fZu/BUmh5GDBw8iIiLC8HPVRNPx48dj1apVuHr1KtLS0gz7W7dujV9++QUvvfQSPvroI7Ro0QKff/55rV/rJSIiaqx0eoEMbQkuXiu8LXAUGwJIbmHZXY+3V8gQ4F45fGIIGzeDR4CHo2RfrZWaTIja5tg2HlqtFq6ursjPz4eLi4vU5RARURN2o7TCMIxSOX+jEGm5xUjPLcKl60X37N1o3kxpHDY8bs3d0LiooWiivRs1qev12zYjGBER2SydXiBTW2IYPkm741GX3o0WN3s3Wt0WNir/dICz2t5C76TpYBghIqIm50Zpxa2gccdk0UvXi1Gm09/1eA+j3g0HtPJoVvlzc0f42FjvhiUwjBARkVUSQuDCtSIcungdF+9Y6OuaCb0bLT0cbhtSacbeDQkwjBARkVWoCh8HUq4ZHpna0lrbuzvao2XzZobejduHU3xdHdi70YgwjBARUaNUl/ChVMgRGuCGdj5ORpNFAzwc4cLeDavBMEJERI1CncNHSzfc16Y57mvjgR4t3aG2t97FvqgSwwgREUmC4YOqMIwQEZFFMHxQbRhGiIjILIQQSM0pxIGUXEP4yCpg+KDqGEaIiKhB1DV8dDeEj+bo3tKN4YMYRoiIqH4YPqihMIwQEVGdMHyQuTCMEBFRjRg+yFIYRoiICEBl+EjJKbwZPCoDSDbDB1kAwwgRkY2qU/iwk6N7AMMHmRfDCBGRjWD4oMaKYYSIqImqa/jocduwS2gAwwdZHsMIEVETwfBB1ophhIjISjF8UFPBMEJEZCWEEDifXYhb93bJRc4Nhg+yfgwjRESNFMMH2QqGESKiRoLhg2wVwwgRkYRyC8uQcDoTv57NrjV89GzpbrirbTeGD2qCGEaIiCwsPbcI205lYuupDCSm5kIvbu1j+CBbxDBCRGRmQgicySjA1pOVAeTkFa3R/o6+Lnigozf6BXsyfJBNYhghIjIDnV7g0MXr2HoyA1tPZSItt8iwTy4DegV6IDrEB1GdNAjwcJSwUiLpMYwQETWQknId9iXnYOvJTGw/nYlrhWWGfUo7OQa29URUJx/c39EbzZ1UElZK1LgwjBAR/QX5xeXYeSYLW09lYFdSNorKdIZ9Lmo73N9Rg+gQDQa09UIzFX/lEtWEfzOIiEyUkV+CbaczsfVkBvafv4aK22ag+rioERWiQXSID/q09oC9Qi5hpUTWgWGEiKgOkrNuYOupDGw5mYlj6XlG+9p6OxkCSBd/V8hkMmmKJLJSDCNERDXQ6wWOXcrDlpvfgEnJLjTa36OlG6JuTkBt4+UkUZVETQPDCBHRTWUVehxIuYYtJzOw7VQmsm676Zy9Qoa+QZ6ICtHggY4aeLuoJayUqGlhGCEim3ajtAK/JmVj66kM7DiThYKSCsM+J5UdBrf3QlSIDwa394KL2l7CSomaLoYRIrI52QWlSDidia2nMrE3OQdlFXrDPk8nFR7opEFUiAZ9g5pDZccFyIjMjWGEiGzCxWuFhhVQD168DnHbEuyBzR0rFyAL0SA0wB0KOSegElkSwwgRNUlCCJy8ojWsgHomo8Bofxd/V0SHaBAV4oO23k78BgyRhBhGiKjJqNDpkXghF1tPZmLbqUxczis27FPIZQhrXbkE+wOdNPBzc5CwUiK6HcMIEVm14jIddp/LxtaTmUg4k4m8onLDPgd7BQa180JUiAZDOnjDzVEpYaVEVBuGESKyOtcLy7DjTBa2nMzA7nPZKCm/NQHV3dH+5hLsPugf7AkHJSegEjV2DCNEZBUu5xVXzv84mYnEC7nQ3bYEu7+bg2EF1F6t3GHHJdiJrArDCBE1SkIInM28gS0nM7D1VAZOXNYa7e/g44yoEB9Eh2jQydeFE1CJrBjDCBE1Gjq9wJG06zcDSCYuXisy7JPJgN6tPBAVokFUJx+0bO4oYaVE1JAYRohIUiXlOuw/fw1bT1UuwZ5zo8ywT2knx4DgyiXY7++ogaeTSsJKichcGEaIyOK0JeXYeSYLW09lYteZLBSW6Qz7nNV2uL+DN6JCfDConReaqfhriqip499yIrKITG0Jtp2qXIJ9//kclOtuTUDVuKgQ1alyBdSw1s2htOMEVCJbwjBCRGZzPvuGYQn2I2l5RvuCvZ0Q1alyBdSu/q6Qcwl2IpvFMEJEDUavF/jzcr5hCfbkrBtG+7u3dDP0gAR5OUlUJRE1NgwjRPSXlOv0OJByzbAEe4a2xLDPXiFDeJAnojpp8EAnDTQuagkrJaLGimGEiExWWFqBX89mY+vJDCScyUJBSYVhXzOlAoM7eCOqkwaD23vD1cFewkqJyBowjBBRnVy7UYrtpzOx9WQm9iTnoKzi1hLsnk5KPNCpcv2P8KDmUNtzCXYiqjuGESKqVdq1Imw9VbkE+8GLubhtBXa0au6I6BAfRHXSoHtLdyg4AZWI6olhhIgMhBA4dVWLLSczsfVkBs5kFBjt7+zvguhOPogK8UE7jROXYCeiBsEwQmTjKnR6HLx43fAV3EvXiw37FHIZ+gR6IDpEgwdCfODv5iBhpUTUVDGMENmgknId9pzLwdaTGdh+OhPXi8oN+9T2cgxs64XoEB8M6eAN92ZKCSslIlvAMEJkI/KKyrDjTBa2nMzA7rM5KC6/tQS7m6M97u+gQXSIBgPaesFByQmoRGQ5DCNETdzhtOtYvjMZO5OyobttBqq/mwMe6KRBdIgPege6w07BJdiJSBr1+u2zbNkyBAYGQq1WIywsDImJiXdtv3jxYrRv3x4ODg4ICAjASy+9hJKSkrseQ0R/ze8p1/CPz3/Ho8t/w/bTWdDpBTr4OONfQ4Lx8/T+2Pt6BGY/HILwoOYMIkQkKZN7RtatW4eYmBisWLECYWFhWLx4MaKjo5GUlARvb+9q7VevXo0ZM2bgyy+/RN++fXH27FlMmDABMpkMixYtapA3QUSVhBDYm5yDJQnJSLyQCwCwk8vwaA9/PDswCMHeXIKdiBofmRBC3LvZLWFhYejduzeWLl0KANDr9QgICMD06dMxY8aMau2nTZuG06dPIyEhwbDt5Zdfxu+//469e/fW6TW1Wi1cXV2Rn58PFxcXU8olsglCCOw4k4UlO5JxND0PAKBUyDGydwtMHhiEAA9HaQskIptU1+u3ST0jZWVlOHToEGbOnGnYJpfLERkZif3799d4TN++ffHdd98hMTERffr0QUpKCjZt2oSxY8fW+jqlpaUoLS01ejNEVJ1eL7D1VAaW7EjGySuVf09UdnKMCWuJyQOD4OPKe8EQUeNnUhjJycmBTqeDRqMx2q7RaHDmzJkajxkzZgxycnLQv39/CCFQUVGB5557Dm+88UatrxMXF4c5c+aYUhqRTdHpBX7+8wqW7UzG2czKO+M6KhUYG94Kz/RvAy9nlcQVEhHVndm/TbNr1y7MnTsXy5cvR1hYGJKTk/HCCy/g3Xffxdtvv13jMTNnzkRMTIzhZ61Wi4CAAHOXStTolev0+PHIZSzfdR6pOYUAAGe1HSb2DcTEfq25JggRWSWTwoinpycUCgUyMzONtmdmZsLHx6fGY95++22MHTsWzzzzDACgS5cuKCwsxLPPPos333wTcnn1WfwqlQoqFf9lR1SltEKH/xy6jOW7kg0rpLo52uPpfq0xrm8g74xLRFbNpDCiVCrRs2dPJCQkYMSIEQAqJ7AmJCRg2rRpNR5TVFRULXAoFJULKpk4d5bI5pSU67A2MQ2f7k7B1fzKr8N7OikxaUAb/OO+Vmim4lJBRGT9TP5NFhMTg/Hjx6NXr17o06cPFi9ejMLCQkycOBEAMG7cOPj7+yMuLg4AMHz4cCxatAjdu3c3DNO8/fbbGD58uCGUEJGxwtIKxP9+EZ/tTkXOjcrJ3BoXFSYPDMLoPi25QioRNSkmh5FRo0YhOzsbs2bNQkZGBkJDQ7F582bDpNa0tDSjnpC33noLMpkMb731Fi5fvgwvLy8MHz4c//73vxvuXRA1EdqScny7/yI+35NiuF+Mv5sDnh8chCd6tYDKjiGEiJoek9cZkQLXGaGmLq+oDF/uu4BV+1KhLakAAAQ2d8SUiGD8vbs/7LlCKhFZIbOsM0JEDSvnRim+2JuKb367gMKyyhvXBXs7YVpEMP7W1ZfLtBORTWAYIZJAlrYEn+5OQfzvF1FSrgcAdPR1wfQhwRga4gO5XCZxhURElsMwQmRBl/OKsWLXeaw7mI6yisoQ0q2FK6YPaYv7O3pDJmMIISLbwzBCZAEXrxXik13n8Z/Dl1Cuq5ym1auVO6bf3xYD23oyhBCRTWMYITKj5KwbWL4zGf937Ap0+soQ0jeoOaYPaYv72ngwhBARgWGEyCzOZGixZEcyNh2/iqrvqw1u74XpQ4LRs5WHtMURETUyDCNEDej4pXws2XEOW0/dumVCVCcNpg0JRtcWbtIVRkTUiDGMEDWAQxevY8mOc9iVlA0AkMmAh7r4YlpEMDr6cm0cIqK7YRghqichBA6k5GLJjnP47fw1AIBCLsMj3fwwJSIYwd5OEldIRGQdGEaITCSEwO5zOVi64xz+uHAdAGAnl+GxHi0wJSIIrZo3k7hCIiLrwjBCVEdCCCSczsKSnck4lp4HAFAq5BjVOwDPDQ6Cv5uDtAUSEVkphhGie9DrBTafzMCSHck4fVULAFDby/FUWCs8O7ANNC5qiSskIrJuDCNEtajQ6fHzn1exdGcykrNuAACaKRUYGx6IZwa0hqeTSuIKiYiaBoYRojuU6/TYeOQylu9MxoVrRQAAZ7UdJvZrjX/2C4Sbo1LiComImhaGEaKbSit02HDwEj7ZdR6X84oBAO6O9nhmQBuMDW8FF7W9xBUSETVNDCNk84rLdFj7Rxo+/TUFGdoSAICnkwrPDmyNp8JaoZmKf02IiMyJv2XJZhWWVuC7Axexck8Kcm6UAQB8XNR4blAbPNmnJdT2CokrJCKyDQwjZHO0JeX4et8FfLEvFXlF5QCAFu4OmDI4GI/19IfKjiGEiMiSGEbIZlwvLMNX+1Lx1W8XUFBSAQBo7dkMUwYHYUR3f9gr5BJXSERkmxhGqMnLuVGKlXtS8N3+iygs0wEA2no7YdqQYPytqx8UcpnEFRIR2TaGEWqyMvJL8Onu81iTmIaScj0AoJOvC6YPCUZ0iA/kDCFERI0Cwwg1OZeuF2HFr+ex/o9LKNNVhpBuAW7415BgDOngDZmMIYSIqDFhGKEm40JOIZbvSsYPhy+jQi8AAH0CPTD9/mD0D/ZkCCEiaqQYRsjqJWcVYOmOZPx07ApuZhD0C26O6UPa4r42zaUtjoiI7olhhKzWqStaLNuZjE0nrkLcDCER7b0wbUhb9GzlLm1xRERUZwwjZHX+vJSHjxOSsf10pmFbdIgG04e0RWd/VwkrIyKi+mAYIatx8EIuluxIxq9nswEAMhkwrIsvpg0JRgcfF4mrIyKi+mIYoUZNCIH9569hyY5k7E+5BgBQyGV4JNQPUyOCEeTlJHGFRET0VzGMUKOVc6MUL68/ZugJsVfI8HjPFnh+UDBaNneUuDoiImooDCPUKB1IuYZ/rTmCrIJSKO3keLJ3ACYPCoK/m4PUpRERUQNjGKFGRa8XWL4rGYu2nYVeVC7bvuypHmincZa6NCIiMhOGEWo0rt0oxYvrjmLPuRwAwKM9/PHeiM5wVPJjSkTUlPG3PDUKiam5mL7mMDK1pVDby/HuI53xRK8AqcsiIiILYBghSen1Ap/8eh6Ltp2FTi8Q5NUMy5/qifY+HJYhIrIVDCMkmdzCMry07qjh2zJ/7145LNNMxY8lEZEt4W99ksQfF3IxffURZGhLoLKT451HQjCyVwBvZkdEZIMYRsii9HqBT3en4IOtSdDpBdp4NcPyp3pwBVUiIhvGMEIWk1tYhpfXH8XOpMphmRGhfvj337twWIaIyMbxKkAWcfBCLqavOYKr+ZXDMnMeDsGo3hyWISIihhEyM71eYOWeFMzfcnNYxrMZlj3VAx19OSxDRESVGEbIbK4XluHlDcew40wWAODhbn6Y+2gXOHFYhoiIbsOrApnFoYvXMX31YVzJL4HSTo7Zw0Mwug+HZYiIqDqGEWpQQgh8vicV728+gwq9QGvPZlg6pjtC/FylLo2IiBophhFqMHlFZXhlwzFsP105LPO3rr6Ie7QLnNX2EldGRESNGcMINYgjadcxbfURXM4rhlIhx9vDO+EfYS05LENERPfEMEJ/iRACX+xNxbz/VQ7LtGruiGVjeqCzP4dliIiobhhGqN7yi8rxyvfHsO1UJgBgWBdfzHuMwzJERGQahhGql6PpeZgaf/jWsMzfOuIf97XisAwREZmMYYRMIoTAV/suIO5/p1GuE2jpUTks06UFh2WIiKh+GEaozvKLy/Ha98ew5WTlsMyDnX3w/uNd4cJhGSIi+gsYRqhOjqXnYdqaw0jPLYa9Qoa3hnXCuHAOyxAR0V/HMEJ3JYTA179dwL83VQ7LBHg4YNmYHujawk3q0oiIqIlgGKFaaUvK8fr3f+J/JzIAANEhGsx/vBtcHTgsQ0REDYdhhGp0/FI+pq4+jLTcItgrZHjjoY6Y0DeQwzJERNTgGEbIiBAC3x64iPd+Po0ynR4t3B2wdEwPhAa4SV0aERE1UQwjZKAtKcfM/xzHL8evAgCiOmmw4PFucHXksAwREZmPvD4HLVu2DIGBgVCr1QgLC0NiYuJd2+fl5WHq1Knw9fWFSqVCu3btsGnTpnoVTOZx4nI+hi/Zi1+OX4WdXIa3/9YJn47tySBCRERmZ3LPyLp16xATE4MVK1YgLCwMixcvRnR0NJKSkuDt7V2tfVlZGR544AF4e3vj+++/h7+/Py5evAg3N7eGqJ/+IiEEvjtwEe/eHJbxd3PA0jHd0b2lu9SlERGRjZAJIYQpB4SFhaF3795YunQpAECv1yMgIADTp0/HjBkzqrVfsWIFFixYgDNnzsDevn7/ytZqtXB1dUV+fj5cXFzq9RxUXUFJOWb+cBw//1k5LBPZUYMPnugKN0elxJUREVFTUNfrt0nDNGVlZTh06BAiIyNvPYFcjsjISOzfv7/GY3766SeEh4dj6tSp0Gg06Ny5M+bOnQudTlfr65SWlkKr1Ro9qGGdvFI5LPPzn5XDMm8N64iV43oyiBARkcWZNEyTk5MDnU4HjUZjtF2j0eDMmTM1HpOSkoIdO3bgqaeewqZNm5CcnIwpU6agvLwcsbGxNR4TFxeHOXPmmFIa1ZEQAqsT0zDnv6dQVlE5LLNkTHf04LAMERFJxOzfptHr9fD29sZnn30GhUKBnj174vLly1iwYEGtYWTmzJmIiYkx/KzVahEQEGDuUpu8G6UVeOOH4/jp2BUAwP0dvLFwZDf2hhARkaRMCiOenp5QKBTIzMw02p6ZmQkfH58aj/H19YW9vT0UCoVhW8eOHZGRkYGysjIoldUvhCqVCiqVypTS6B5OXdFi6urDSM0phEIuw+tD22PSgDZcxIyIiCRn0pwRpVKJnj17IiEhwbBNr9cjISEB4eHhNR7Tr18/JCcnQ6/XG7adPXsWvr6+NQYRalhCCKxJTMPfl+9Dak4h/FzVWD/5Pjw7MIhBhIiIGgWT1xmJiYnBypUr8fXXX+P06dN4/vnnUVhYiIkTJwIAxo0bh5kzZxraP//888jNzcULL7yAs2fP4pdffsHcuXMxderUhnsXVKPC0gq8uO4oZv5wHKUVekS098Iv/xqAnq08pC6NiIjIwOQ5I6NGjUJ2djZmzZqFjIwMhIaGYvPmzYZJrWlpaZDLb2WcgIAAbNmyBS+99BK6du0Kf39/vPDCC3j99dcb7l1QNaevVg7LpGRXDsu8Fl05LCOXszeEiIgaF5PXGZEC1xmpOyEE1v2RjtifTqK0Qg8fFzWWjumOXoHsDSEiIsuq6/Wb96ZpQgpLK/DWjyew8chlAMDg9l5YNDIUHs04N4eIiBovhpEmIimjAFPiD+H8zWGZl6Pa4bmBQRyWISKiRo9hxMoJIbDh0CXM+r8TKCmvHJb5eHR39GnNYRkiIrIODCNWrKiscljmh8OVwzID23nhw5Hd0NyJa7QQEZH1YBixUmczCzAl/jCSs25ALgNejmqP5wdxWIaIiKwPw4gV2nAwHW/fHJbxdlZhyejuCGvTXOqyiIiI6oVhxIoUl+nw9v+dwPeHLgEABrT1xIejQuHJYRkiIrJiDCNWorC0Ao998hvOZBRALgNiHmiHKYODOSxDRERWj2HESny1LxVnMgrg6aTEktE9EB7EYRkiImoaTL43DVleXlEZPt2dAgB4+2+dGESIiKhJYRixAp/uTkFBSQU6+DhjeFc/qcshIiJqUAwjjVxWQQm+2pcKAHglqj3niBARUZPDMNLILd95HiXlenRv6Yb7O3pLXQ4REVGDYxhpxC5dL0L87xcBAK9Gt4dMxl4RIiJqehhGGrGPtp9DuU6gf7An+gZ5Sl0OERGRWTCMNFLJWTfwn8OVi5u9Et1e4mqIiIjMh2Gkkfpw21noBfBAJw1CA9ykLoeIiMhsGEYaoROX8/HL8auQyYCXo9pJXQ4REZFZMYw0Qgu3JgEAHunmhw4+LhJXQ0REZF4MI43MHxdysTMpG3ZyGV6MZK8IERE1fQwjjYgQAgs2V/aKjOwdgEDPZhJXREREZH4MI43I7nM5SLyQC6WdHNOHBEtdDhERkUUwjDQSQggs2HIGADDuvlbwdXWQuCIiIiLLYBhpJDafyMCJy1o0Uyrw/OAgqcshIiKyGIaRRkCnF1i47SwA4OkBbdDcSSVxRURERJbDMNII/HjkMpKzbsDN0R7PDGgtdTlEREQWxTAisbIKPT7cXtkr8vygILio7SWuiIiIyLIYRiS27o80XLpeDG9nFcaFB0pdDhERkcUxjEiouEyHj3ckAwCmDwmGg1IhcUVERESWxzAioa/3X0B2QSlauDtgVO+WUpdDREQkCYYRiWhLyvHJrvMAgJci20Fpx/8VRERkm3gFlMjnu1OQX1yOYG8njOjuL3U5REREkmEYkcC1G6X4Ym8qAOCVqHZQyGUSV0RERCQdhhEJfLLrPArLdOji74roEB+pyyEiIpIUw4iFXc0vxjcHLgIAXo1uD5mMvSJERGTbGEYs7OOEZJRV6NGntQcGtPWUuhwiIiLJMYxY0IWcQqw/mA6AvSJERERVGEYs6MPtZ6HTC0S090LvQA+pyyEiImoUGEYs5EyGFj8duwIAeDmqvcTVEBERNR4MIxaycOtZCAEM6+qLzv6uUpdDRETUaDCMWMCRtOvYdioTchkQ80A7qcshIiJqVBhGLOCDrUkAgMd7tkCQl5PE1RARETUuDCNmti85B/uSr8FeIcO/7m8rdTlERESNDsOIGQkhsGBLZa/IU2Gt0MLdUeKKiIiIGh+GETPafjoLR9Pz4GCvwJSIIKnLISIiapQYRsxErxdYeHOuyMR+gfB2VktcERERUePEMGIm//3zCs5kFMBZbYfJA9krQkREVBuGETMo1+nx4bazAIDnBgXB1dFe4oqIiIgaL4YRM/j+0CVcuFYETyclJvQNlLocIiKiRo1hpIGVlOvw0fZzAIApg4PRTGUncUVERESNG8NIA/vuwEVkaEvg56rGmLCWUpdDRETU6DGMNKAbpRVYvus8AOCFyLZQ2yskroiIiKjxYxhpQF/tTUVuYRlaezbDYz1aSF0OERGRVWAYaSB5RWX4bHcKgMqb4dkpeGqJiIjqglfMBrLi1xQUlFago68LhnXxlbocIiIiq8Ew0gCytCVY9VsqAOCVqHaQy2USV0RERGQ96hVGli1bhsDAQKjVaoSFhSExMbFOx61duxYymQwjRoyoz8s2Wkt3JqOkXI8eLd0wpIO31OUQERFZFZPDyLp16xATE4PY2FgcPnwY3bp1Q3R0NLKysu563IULF/DKK69gwIAB9S62MUrPLcKaxDQAwKvRHSCTsVeEiIjIFCaHkUWLFmHSpEmYOHEiOnXqhBUrVsDR0RFffvllrcfodDo89dRTmDNnDtq0afOXCm5sFm8/h3KdwIC2nggPai51OURERFbHpDBSVlaGQ4cOITIy8tYTyOWIjIzE/v37az3unXfegbe3N55++uk6vU5paSm0Wq3RozFKzirAxiOXAACvRLWXuBoiIiLrZFIYycnJgU6ng0ajMdqu0WiQkZFR4zF79+7FF198gZUrV9b5deLi4uDq6mp4BAQEmFKmxSzadhZ6AUSHaNAtwE3qcoiIiKySWb9NU1BQgLFjx2LlypXw9PSs83EzZ85Efn6+4ZGenm7GKuvn+KV8bDqeAZkMeJm9IkRERPVm0l3cPD09oVAokJmZabQ9MzMTPj4+1dqfP38eFy5cwPDhww3b9Hp95Qvb2SEpKQlBQUHVjlOpVFCpVKaUZnEfbE0CAIwI9Uc7jbPE1RAREVkvk3pGlEolevbsiYSEBMM2vV6PhIQEhIeHV2vfoUMHHD9+HEePHjU8Hn74YURERODo0aONdvjlXn5PuYZfz2bDTi7Di5FtpS6HiIjIqpl8f/uYmBiMHz8evXr1Qp8+fbB48WIUFhZi4sSJAIBx48bB398fcXFxUKvV6Ny5s9Hxbm5uAFBtu7UQQhh6RUb1DkCr5s0kroiIiMi6mRxGRo0ahezsbMyaNQsZGRkIDQ3F5s2bDZNa09LSIJc33YVd03KL8MeF67BXyDB9CHtFiIiI/iqZEEJIXcS9aLVauLq6Ij8/Hy4uLpLW8tOxK/jXmiPoFuCG/5vaT9JaiIiIGrO6Xr+bbheGmRy/lAcA6NbCVdpCiIiImgiGERMdu5QPAOjizzBCRETUEBhGTKDTC5y8XBlGuMgZERFRw2AYMUFK9g0UlungqFQgyMtJ6nKIiIiaBIYRE/x5c4ims58rFHLenZeIiKghMIyY4M+bk1e7cPIqERFRg2EYMcGfN+eLdGUYISIiajAMI3VUrtPj1BUtAKBrCzdpiyEiImpCGEbq6GxmAUor9HBW2yGwuaPU5RARETUZDCN1VDV5tWsLV8hknLxKRETUUBhG6uhWGHGTthAiIqImhmGkjqq+SdOVK68SERE1KIaROigp1yEpowAA0JUrrxIRETUohpE6OH1Viwq9QPNmSvi5qqUuh4iIqElhGKmD45c5eZWIiMhcGEbq4Fj6zTv1cvIqERFRg2MYqYPjl/MAAN248ioREVGDYxi5h8LSCiRn3QDAe9IQERGZA8PIPZy8ooVeAL6uang7c/IqERFRQ2MYuQfDnXq5vggREZFZMIzcw7GbK6924/oiREREZsEwcg/H2TNCRERkVgwjd5FfVI4L14oAVK4xQkRERA2PYeQuqhY7a+nhCDdHpcTVEBERNU0MI3dxrOrmeOwVISIiMhuGkbs4funWMvBERERkHgwjd/GnoWfETdI6iIiImjKGkVpkF5TiSn4JZDKgM79JQ0REZDYMI7Wouh9NkJcTnFR20hZDRETUhDGM1OLPqvki7BUhIiIyK4aRWvzJyatEREQWwTBSAyGEIYx04eRVIiIis2IYqcHV/BLk3CiFQi5DiJ+L1OUQERE1aQwjNajqFWmncYbaXiFxNURERE0bw0gNqtYX6cb5IkRERGbHMFKDqnvSdGEYISIiMjuGkTvcPnm1GyevEhERmR3DyB3ScouQX1wOpUKOdhpnqcshIiJq8hhG7nDsZq9IRz8XKO14eoiIiMyNV9s7HK+6OR5XXiUiIrIIhpE7HOPKq0RERBbFMHIbnV7g5OWqMOImbTFEREQ2gmHkNinZN1BYpoODvQLB3k5Sl0NERGQTGEZuU/WV3s7+LlDIZRJXQ0REZBsYRm5TtfIqh2iIiIgsh2HkNn9e5uRVIiIiS2MYualcp8epK1oA7BkhIiKyJIaRm85mFqC0Qg9ntR1aeThKXQ4REZHNYBi56c/b1heRc/IqERGRxTCM3FQVRrr4u0lbCBERkY1hGLmp6ps03Th5lYiIyKIYRgCUlOuQlFEAAOjCMEJERGRRDCMATl/VokIv0LyZEv5uDlKXQ0REZFMYRgAcv7m+SJcWrpDJOHmViIjIkhhGABxL583xiIiIpMIwAuD45TwAQFd/zhchIiKytHqFkWXLliEwMBBqtRphYWFITEyste3KlSsxYMAAuLu7w93dHZGRkXdtb2mFpRVIzroBgMvAExERScHkMLJu3TrExMQgNjYWhw8fRrdu3RAdHY2srKwa2+/atQujR4/Gzp07sX//fgQEBCAqKgqXL1/+y8U3hNNXtdALwMdFDW8XtdTlEBER2RyTw8iiRYswadIkTJw4EZ06dcKKFSvg6OiIL7/8ssb28fHxmDJlCkJDQ9GhQwd8/vnn0Ov1SEhI+MvFN4S8onIAgMaVQYSIiEgKJoWRsrIyHDp0CJGRkbeeQC5HZGQk9u/fX6fnKCoqQnl5OTw8PGptU1paCq1Wa/Qwl9IKPQBAbcfpM0RERFIw6Qqck5MDnU4HjUZjtF2j0SAjI6NOz/H666/Dz8/PKNDcKS4uDq6uroZHQECAKWWapKRcBwBQ2SvM9hpERERUO4t2B8ybNw9r167Fxo0boVbXPiwyc+ZM5OfnGx7p6elmq4k9I0RERNKyM6Wxp6cnFAoFMjMzjbZnZmbCx8fnrsd+8MEHmDdvHrZv346uXbveta1KpYJKpTKltHpjzwgREZG0TOoOUCqV6Nmzp9Hk06rJqOHh4bUeN3/+fLz77rvYvHkzevXqVf9qzaCqZ0TFnhEiIiJJmNQzAgAxMTEYP348evXqhT59+mDx4sUoLCzExIkTAQDjxo2Dv78/4uLiAADvv/8+Zs2ahdWrVyMwMNAwt8TJyQlOTk4N+Fbqp6pnRG3PMEJERCQFk8PIqFGjkJ2djVmzZiEjIwOhoaHYvHmzYVJrWloa5PJbF/ZPPvkEZWVlePzxx42eJzY2FrNnz/5r1TeAWz0jHKYhIiKSgslhBACmTZuGadOm1bhv165dRj9fuHChPi9hMewZISIikpbNX4HZM0JERCQthhH2jBAREUnK5q/A7BkhIiKSFsNIBXtGiIiIpGTzV+CScvaMEBERScnmwwh7RoiIiKRl81dg9owQERFJy+bDSFXPiIo9I0RERJKw+Sswe0aIiIikZfNhxNAzwhvlERERScLmr8BVPSNqe/aMEBERScHmwwh7RoiIiKRl01dgIQR7RoiIiCRm02GkTKc3/De/TUNERCQNm74CV/WKAICa36YhIiKShE2Hkar5IjIZYK+QSVwNERGRbbLtMFI1X8ROAZmMYYSIiEgKth1GuPoqERGR5Gz6KlxyW88IERERScOmwwh7RoiIiKRn01fhUvaMEBERSc6mw0gJe0aIiIgkZ9NX4VLDHXtt+jQQERFJyqavwlU9I1wKnoiISDo2HUbYM0JERCQ9m74Kl5RXzRlhzwgREZFUbDqMlFawZ4SIiEhqNn0VNix6xp4RIiIiydh0GDEsesaeESIiIsnY9FW4apiGPSNERETSsekwYpjAyp4RIiIiydj0VZg9I0RERNKz6TDCnhEiIiLp2fRVmD0jRERE0rPpMMKeESIiIunZ9FX41qJn7BkhIiKSik2HkQpdZRixU8gkroSIiMh22XQYqcIoQkREJB2GESIiIpIUwwgRERFJimGEiIiIJMUwQkRERJJiGCEiIiJJMYwQERGRpBhGiIiISFIMI0RERCQphhEiIiKSFMMIERERSYphhIiIiCTFMEJERESSYhghIiIiSTGMEBERkaQYRoiIiEhSDCNEREQkKYYRIiIikhTDCBEREUmKYYSIiIgkVa8wsmzZMgQGBkKtViMsLAyJiYl3bb9hwwZ06NABarUaXbp0waZNm+pVLBERETU9JoeRdevWISYmBrGxsTh8+DC6deuG6OhoZGVl1dj+t99+w+jRo/H000/jyJEjGDFiBEaMGIETJ0785eKJiIjI+pkcRhYtWoRJkyZh4sSJ6NSpE1asWAFHR0d8+eWXNbb/6KOPMHToULz66qvo2LEj3n33XfTo0QNLly79y8UTERGR9TMpjJSVleHQoUOIjIy89QRyOSIjI7F///4aj9m/f79RewCIjo6utT0AlJaWQqvVGj2IiIioaTIpjOTk5ECn00Gj0Rht12g0yMjIqPGYjIwMk9oDQFxcHFxdXQ2PgIAAU8qss8d6tsDUiCC09mxmlucnIiKie7OTuoCazJw5EzExMYaftVqtWQLJU2GtGvw5iYiIyDQmhRFPT08oFApkZmYabc/MzISPj0+Nx/j4+JjUHgBUKhVUKpUppREREZGVMmmYRqlUomfPnkhISDBs0+v1SEhIQHh4eI3HhIeHG7UHgG3bttXanoiIiGyLycM0MTExGD9+PHr16oU+ffpg8eLFKCwsxMSJEwEA48aNg7+/P+Li4gAAL7zwAgYNGoSFCxdi2LBhWLt2LQ4ePIjPPvusYd8JERERWSWTw8ioUaOQnZ2NWbNmISMjA6Ghodi8ebNhkmpaWhrk8lsdLn379sXq1avx1ltv4Y033kDbtm3x448/onPnzg33LoiIiMhqyYQQQuoi7kWr1cLV1RX5+flwcXGRuhwiIiKqg7pev3lvGiIiIpIUwwgRERFJimGEiIiIJMUwQkRERJJiGCEiIiJJMYwQERGRpBhGiIiISFIMI0RERCSpRnnX3jtVrcum1WolroSIiIjqquq6fa/1Va0ijBQUFAAAAgICJK6EiIiITFVQUABXV9da91vFcvB6vR5XrlyBs7MzZDJZgz2vVqtFQEAA0tPTucy8GfE8Ww7PtWXwPFsGz7NlmPM8CyFQUFAAPz8/o/vW3ckqekbkcjlatGhhtud3cXHhB90CeJ4th+faMnieLYPn2TLMdZ7v1iNShRNYiYiISFIMI0RERCQpmw4jKpUKsbGxUKlUUpfSpPE8Ww7PtWXwPFsGz7NlNIbzbBUTWImIiKjpsumeESIiIpIewwgRERFJimGEiIiIJMUwQkRERJJiGCEiIiJJNfkwsmzZMgQGBkKtViMsLAyJiYl3bb9hwwZ06NABarUaXbp0waZNmyxUqXUz5TyvXLkSAwYMgLu7O9zd3REZGXnP/y90i6mf6Spr166FTCbDiBEjzFtgE2Hqec7Ly8PUqVPh6+sLlUqFdu3a8fdHHZh6nhcvXoz27dvDwcEBAQEBeOmll1BSUmKhaq3T7t27MXz4cPj5+UEmk+HHH3+85zG7du1Cjx49oFKpEBwcjFWrVpm3SNGErV27ViiVSvHll1+KkydPikmTJgk3NzeRmZlZY/t9+/YJhUIh5s+fL06dOiXeeustYW9vL44fP27hyq2Lqed5zJgxYtmyZeLIkSPi9OnTYsKECcLV1VVcunTJwpVbH1PPdZXU1FTh7+8vBgwYIB555BHLFGvFTD3PpaWlolevXuKhhx4Se/fuFampqWLXrl3i6NGjFq7cuph6nuPj44VKpRLx8fEiNTVVbNmyRfj6+oqXXnrJwpVbl02bNok333xT/PDDDwKA2Lhx413bp6SkCEdHRxETEyNOnTollixZIhQKhdi8ebPZamzSYaRPnz5i6tSphp91Op3w8/MTcXFxNbYfOXKkGDZsmNG2sLAwMXnyZLPWae1MPc93qqioEM7OzuLrr782V4lNRn3OdUVFhejbt6/4/PPPxfjx4xlG6sDU8/zJJ5+INm3aiLKyMkuV2CSYep6nTp0qhgwZYrQtJiZG9OvXz6x1NiV1CSOvvfaaCAkJMdo2atQoER0dbba6muwwTVlZGQ4dOoTIyEjDNrlcjsjISOzfv7/GY/bv32/UHgCio6NrbU/1O893KioqQnl5OTw8PMxVZpNQ33P9zjvvwNvbG08//bQlyrR69TnPP/30E8LDwzF16lRoNBp07twZc+fOhU6ns1TZVqc+57lv3744dOiQYSgnJSUFmzZtwkMPPWSRmm2FFNdCq7hrb33k5ORAp9NBo9EYbddoNDhz5kyNx2RkZNTYPiMjw2x1Wrv6nOc7vf766/Dz86v24Sdj9TnXe/fuxRdffIGjR49aoMKmoT7nOSUlBTt27MBTTz2FTZs2ITk5GVOmTEF5eTliY2MtUbbVqc95HjNmDHJyctC/f38IIVBRUYHnnnsOb7zxhiVKthm1XQu1Wi2Ki4vh4ODQ4K/ZZHtGyDrMmzcPa9euxcaNG6FWq6Uup0kpKCjA2LFjsXLlSnh6ekpdTpOm1+vh7e2Nzz77DD179sSoUaPw5ptvYsWKFVKX1qTs2rULc+fOxfLly3H48GH88MMP+OWXX/Duu+9KXRr9RU22Z8TT0xMKhQKZmZlG2zMzM+Hj41PjMT4+Pia1p/qd5yoffPAB5s2bh+3bt6Nr167mLLNJMPVcnz9/HhcuXMDw4cMN2/R6PQDAzs4OSUlJCAoKMm/RVqg+n2lfX1/Y29tDoVAYtnXs2BEZGRkoKyuDUqk0a83WqD7n+e2338bYsWPxzDPPAAC6dOmCwsJCPPvss3jzzTchl/Pf1w2htmuhi4uLWXpFgCbcM6JUKtGzZ08kJCQYtun1eiQkJCA8PLzGY8LDw43aA8C2bdtqbU/1O88AMH/+fLz77rvYvHkzevXqZYlSrZ6p57pDhw44fvw4jh49ang8/PDDiIiIwNGjRxEQEGDJ8q1GfT7T/fr1Q3JysiHsAcDZs2fh6+vLIFKL+pznoqKiaoGjKgAK3vO1wUhyLTTb1NhGYO3atUKlUolVq1aJU6dOiWeffVa4ubmJjIwMIYQQY8eOFTNmzDC037dvn7CzsxMffPCBOH36tIiNjeVXe+vA1PM8b948oVQqxffffy+uXr1qeBQUFEj1FqyGqef6Tvw2Td2Yep7T0tKEs7OzmDZtmkhKShI///yz8Pb2Fu+9955Ub8EqmHqeY2NjhbOzs1izZo1ISUkRW7duFUFBQWLkyJFSvQWrUFBQII4cOSKOHDkiAIhFixaJI0eOiIsXLwohhJgxY4YYO3asoX3VV3tfffVVcfr0abFs2TJ+tfevWrJkiWjZsqVQKpWiT58+4sCBA4Z9gwYNEuPHjzdqv379etGuXTuhVCpFSEiI+OWXXyxcsXUy5Ty3atVKAKj2iI2NtXzhVsjUz/TtGEbqztTz/Ntvv4mwsDChUqlEmzZtxL///W9RUVFh4aqtjynnuby8XMyePVsEBQUJtVotAgICxJQpU8T169ctX7gV2blzZ42/c6vO7fjx48WgQYOqHRMaGiqUSqVo06aN+Oqrr8xao0wI9m0RERGRdJrsnBEiIiKyDgwjREREJCmGESIiIpIUwwgRERFJimGEiIiIJMUwQkRERJJiGCEiIiJJMYwQERGRpBhGiIiISFIMI0RERCQphhEiIiKS1P8DwCewhwbVXtQAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss_array = np.array([i.numpy().item() for i in test_loss_list])\n",
        "test_ground_truth = labels_rec1\n",
        "\n",
        "validation_loss_array = np.array([i.numpy().item() for i in validation_loss_list])\n",
        "validation_ground_truth = labels_rec5\n",
        "\n",
        "print(\"Test set metrics:\")\n",
        "compute_metrics(test_loss_array, test_ground_truth, num_thresholds=15)\n",
        "print(\"\\nValidation set metrics:\")\n",
        "compute_metrics(validation_loss_array, validation_ground_truth, num_thresholds=15)"
      ],
      "metadata": {
        "id": "3XBIdzzN8ewr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67685de2-3a3d-4ab5-e780-763de4a918b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set metrics:\n",
            "\n",
            "F1 score\n",
            "1577.239990234375: 0.3099415204678363\n",
            "1653.994838169643: 0.3035714285714286\n",
            "1730.7496861049108: 0.30434782608695654\n",
            "1807.5045340401787: 0.33108108108108103\n",
            "1884.2593819754466: 0.3671875\n",
            "1961.0142299107142: 0.39622641509433965\n",
            "2037.769077845982: 0.3902439024390244\n",
            "2114.52392578125: 0.45871559633027525\n",
            "2191.278773716518: 0.3846153846153846\n",
            "2268.033621651786: 0.34285714285714286\n",
            "2344.7884695870534: 0.2033898305084746\n",
            "2421.5433175223216: 0.1724137931034483\n",
            "2498.298165457589: 0.037037037037037035\n",
            "2575.0530133928573: 0.037037037037037035\n",
            "2651.807861328125: 0.037037037037037035\n",
            "\n",
            "Precision score:\n",
            "1577.239990234375: 0.18339100346020762\n",
            "1653.994838169643: 0.18021201413427562\n",
            "1730.7496861049108: 0.1821561338289963\n",
            "1807.5045340401787: 0.20164609053497942\n",
            "1884.2593819754466: 0.2315270935960591\n",
            "1961.0142299107142: 0.2641509433962264\n",
            "2037.769077845982: 0.2882882882882883\n",
            "2114.52392578125: 0.44642857142857145\n",
            "2191.278773716518: 0.6\n",
            "2268.033621651786: 0.7058823529411765\n",
            "2344.7884695870534: 1.0\n",
            "2421.5433175223216: 1.0\n",
            "2498.298165457589: 1.0\n",
            "2575.0530133928573: 1.0\n",
            "2651.807861328125: 1.0\n",
            "\n",
            "Recall score:\n",
            "1577.239990234375: 1.0\n",
            "1653.994838169643: 0.9622641509433962\n",
            "1730.7496861049108: 0.9245283018867925\n",
            "1807.5045340401787: 0.9245283018867925\n",
            "1884.2593819754466: 0.8867924528301887\n",
            "1961.0142299107142: 0.7924528301886793\n",
            "2037.769077845982: 0.6037735849056604\n",
            "2114.52392578125: 0.4716981132075472\n",
            "2191.278773716518: 0.2830188679245283\n",
            "2268.033621651786: 0.22641509433962265\n",
            "2344.7884695870534: 0.11320754716981132\n",
            "2421.5433175223216: 0.09433962264150944\n",
            "2498.298165457589: 0.018867924528301886\n",
            "2575.0530133928573: 0.018867924528301886\n",
            "2651.807861328125: 0.018867924528301886\n",
            "\n",
            "Validation set metrics:\n",
            "\n",
            "F1 score\n",
            "1779.5916748046875: 0.6019900497512437\n",
            "1845.283403669085: 0.6065162907268171\n",
            "1910.975132533482: 0.6173469387755103\n",
            "1976.6668613978795: 0.6273458445040214\n",
            "2042.3585902622767: 0.6824925816023739\n",
            "2108.050319126674: 0.7028753993610223\n",
            "2173.7420479910716: 0.7132867132867132\n",
            "2239.4337768554688: 0.7372549019607844\n",
            "2305.125505719866: 0.7181818181818181\n",
            "2370.817234584263: 0.6666666666666666\n",
            "2436.508963448661: 0.5988700564971752\n",
            "2502.200692313058: 0.3841059602649007\n",
            "2567.8924211774556: 0.2074074074074074\n",
            "2633.584150041853: 0.09448818897637795\n",
            "2699.27587890625: 0.01639344262295082\n",
            "\n",
            "Precision score:\n",
            "1779.5916748046875: 0.4306049822064057\n",
            "1845.283403669085: 0.4352517985611511\n",
            "1910.975132533482: 0.44649446494464945\n",
            "1976.6668613978795: 0.4642857142857143\n",
            "2042.3585902622767: 0.5324074074074074\n",
            "2108.050319126674: 0.5729166666666666\n",
            "2173.7420479910716: 0.6181818181818182\n",
            "2239.4337768554688: 0.7014925373134329\n",
            "2305.125505719866: 0.797979797979798\n",
            "2370.817234584263: 0.9014084507042254\n",
            "2436.508963448661: 0.9464285714285714\n",
            "2502.200692313058: 0.9666666666666667\n",
            "2567.8924211774556: 1.0\n",
            "2633.584150041853: 1.0\n",
            "2699.27587890625: 1.0\n",
            "\n",
            "Recall score:\n",
            "1779.5916748046875: 1.0\n",
            "1845.283403669085: 1.0\n",
            "1910.975132533482: 1.0\n",
            "1976.6668613978795: 0.9669421487603306\n",
            "2042.3585902622767: 0.9504132231404959\n",
            "2108.050319126674: 0.9090909090909091\n",
            "2173.7420479910716: 0.8429752066115702\n",
            "2239.4337768554688: 0.7768595041322314\n",
            "2305.125505719866: 0.6528925619834711\n",
            "2370.817234584263: 0.5289256198347108\n",
            "2436.508963448661: 0.4380165289256198\n",
            "2502.200692313058: 0.2396694214876033\n",
            "2567.8924211774556: 0.11570247933884298\n",
            "2633.584150041853: 0.049586776859504134\n",
            "2699.27587890625: 0.008264462809917356\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we tested the performance of the model on overlapping windows. We did not notice any difference in performance results between a test dataset consisting of overlapping windows and one of non-overlapping windows."
      ],
      "metadata": {
        "id": "TIQuqe4O2FYA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##overlapped_windows_rec1, overlapped_labels_rec1 = window_data(df_rec1_labelled, WINDOW_SIZE, 1)\n",
        "##overlapped_windows_rec5, overlapped_labels_rec5 = window_data(df_rec5_labelled, WINDOW_SIZE, 1)\n",
        "#\n",
        "#overlapped_validation_dataset = tf.data.Dataset.from_tensor_slices((overlapped_windows_rec5, overlapped_labels_rec5)).map(lambda x, y: (tf.cast(x, tf.float32), y)).batch(TEST_BATCH_SIZE)\n",
        "#overlapped_test_dataset = tf.data.Dataset.from_tensor_slices((overlapped_windows_rec1, overlapped_labels_rec1)).map(lambda x, y: (tf.cast(x, tf.float32), y)).batch(TEST_BATCH_SIZE)\n",
        "#\n",
        "#test_loss_list = anomaly_score(overlapped_test_dataset, generator, discriminator, encoder, LAMBDA)\n",
        "#print()\n",
        "#validation_loss_list = anomaly_score(overlapped_validation_dataset, generator, discriminator, encoder, LAMBDA)\n",
        "#\n",
        "test_loss_array = np.array([i.numpy().item() for i in test_loss_list])\n",
        "test_ground_truth = overlapped_labels_rec1\n",
        "\n",
        "validation_loss_array = np.array([i.numpy().item() for i in validation_loss_list])\n",
        "validation_ground_truth = overlapped_labels_rec5\n",
        "\n",
        "print(\"Test set metrics:\")\n",
        "compute_metrics(test_loss_array, test_ground_truth, num_thresholds=15)\n",
        "print(\"\\nValidation set metrics:\")\n",
        "compute_metrics(validation_loss_array, validation_ground_truth, num_thresholds=15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "daP2b_LkKCTw",
        "outputId": "0d8012c8-83fa-4b64-ce06-d868a8a05678"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set metrics:\n",
            "\n",
            "F1 score\n",
            "1549.2977294921875: 0.31733994458217873\n",
            "1628.6830444335938: 0.3178723612675711\n",
            "1708.068359375: 0.3237717424473604\n",
            "1787.4536743164062: 0.33979675913210655\n",
            "1866.8389892578125: 0.36508927456611306\n",
            "1946.2243041992188: 0.39020346646571213\n",
            "2025.609619140625: 0.40089043747580333\n",
            "2104.9949340820312: 0.4010064892067276\n",
            "2184.3802490234375: 0.366304347826087\n",
            "2263.7655639648438: 0.2956186807896004\n",
            "2343.15087890625: 0.17206085753803596\n",
            "2422.5361938476562: 0.09106728538283064\n",
            "2501.9215087890625: 0.04304932735426009\n",
            "2581.3068237304688: 0.012180267965895249\n",
            "2660.692138671875: 0.0006125574272588055\n",
            "\n",
            "Precision score:\n",
            "1549.2977294921875: 0.18859421043508406\n",
            "1628.6830444335938: 0.18917973532326707\n",
            "1708.068359375: 0.19410903768752286\n",
            "1787.4536743164062: 0.20701425607389062\n",
            "1866.8389892578125: 0.22926140818566723\n",
            "1946.2243041992188: 0.25874475314811113\n",
            "2025.609619140625: 0.29301075268817206\n",
            "2104.9949340820312: 0.35316071845113134\n",
            "2184.3802490234375: 0.44813829787234044\n",
            "2263.7655639648438: 0.6898876404494382\n",
            "2343.15087890625: 0.886039886039886\n",
            "2422.5361938476562: 0.8532608695652174\n",
            "2501.9215087890625: 0.8888888888888888\n",
            "2581.3068237304688: 1.0\n",
            "2660.692138671875: 1.0\n",
            "\n",
            "Recall score:\n",
            "1549.2977294921875: 1.0\n",
            "1628.6830444335938: 0.9941789215686274\n",
            "1708.068359375: 0.9751838235294118\n",
            "1787.4536743164062: 0.9476102941176471\n",
            "1866.8389892578125: 0.8958333333333334\n",
            "1946.2243041992188: 0.7931985294117647\n",
            "2025.609619140625: 0.6344975490196079\n",
            "2104.9949340820312: 0.4638480392156863\n",
            "2184.3802490234375: 0.30974264705882354\n",
            "2263.7655639648438: 0.1881127450980392\n",
            "2343.15087890625: 0.09528186274509803\n",
            "2422.5361938476562: 0.048100490196078434\n",
            "2501.9215087890625: 0.022058823529411766\n",
            "2581.3068237304688: 0.006127450980392157\n",
            "2660.692138671875: 0.00030637254901960784\n",
            "\n",
            "Validation set metrics:\n",
            "\n",
            "F1 score\n",
            "1692.982421875: 0.5948380102572656\n",
            "1785.6454206194196: 0.5960558201721401\n",
            "1878.3084193638392: 0.6019532908704883\n",
            "1970.971418108259: 0.6186186186186187\n",
            "2063.6344168526784: 0.6711314053779807\n",
            "2156.2974155970983: 0.7045155382590282\n",
            "2248.960414341518: 0.7240459033893782\n",
            "2341.6234130859375: 0.6855060728744939\n",
            "2434.286411830357: 0.5437066402378592\n",
            "2526.9494105747767: 0.323746918652424\n",
            "2619.6124093191966: 0.11096398305084747\n",
            "2712.275408063616: 0.03146129432868773\n",
            "2804.938406808036: 0.005034260942525521\n",
            "2897.6014055524556: 0.003358992302309307\n",
            "2990.264404296875: 0.0002803476310625175\n",
            "\n",
            "Precision score:\n",
            "1692.982421875: 0.42332344213649853\n",
            "1785.6454206194196: 0.42455806202011787\n",
            "1878.3084193638392: 0.4317475787293659\n",
            "1970.971418108259: 0.4546712346817763\n",
            "2063.6344168526784: 0.5258805756539715\n",
            "2156.2974155970983: 0.5952611218568665\n",
            "2248.960414341518: 0.6907702100572883\n",
            "2341.6234130859375: 0.8113858539390454\n",
            "2434.286411830357: 0.9276293540750761\n",
            "2526.9494105747767: 0.9949494949494949\n",
            "2619.6124093191966: 1.0\n",
            "2712.275408063616: 1.0\n",
            "2804.938406808036: 1.0\n",
            "2897.6014055524556: 1.0\n",
            "2990.264404296875: 1.0\n",
            "\n",
            "Recall score:\n",
            "1692.982421875: 1.0\n",
            "1785.6454206194196: 1.0\n",
            "1878.3084193638392: 0.9936912939857002\n",
            "1970.971418108259: 0.9674751156596103\n",
            "2063.6344168526784: 0.9272395906350764\n",
            "2156.2974155970983: 0.8628907892892191\n",
            "2248.960414341518: 0.7606897518575635\n",
            "2341.6234130859375: 0.5934389457451282\n",
            "2434.286411830357: 0.3845506799383149\n",
            "2526.9494105747767: 0.19332679097154074\n",
            "2619.6124093191966: 0.05874106266647974\n",
            "2712.275408063616: 0.015982055236225992\n",
            "2804.938406808036: 0.0025234824057198935\n",
            "2897.6014055524556: 0.0016823216038132623\n",
            "2990.264404296875: 0.00014019346698443852\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('test_loss.npy', 'wb') as f:\n",
        "  np.save(f, test_loss_array)\n",
        "\n",
        "!cp ./test_loss.npy ./drive/MyDrive/ml-applications/TimeSeriesAnomalyDetection_project/saved_losses_modifiedModel/\n",
        "\n",
        "with open('validation_loss.npy', 'wb') as f:\n",
        "  np.save(f, validation_loss_array)\n",
        "\n",
        "!cp ./validation_loss.npy ./drive/MyDrive/ml-applications/TimeSeriesAnomalyDetection_project/saved_losses_modifiedModel/"
      ],
      "metadata": {
        "id": "eHQSWvZaw7k8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}